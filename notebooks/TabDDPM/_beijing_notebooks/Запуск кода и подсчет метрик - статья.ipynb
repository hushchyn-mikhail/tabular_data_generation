{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом ноутбуке берется переписанный код статьи и проверяется корректность его запуска, а именно, что итоговые метрики будут похожи на предоставленные в статье."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/TabDDPM_copy/TabDDPM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/main/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 11435,
     "status": "ok",
     "timestamp": 1742850942286,
     "user": {
      "displayName": "Elina Telesheva",
      "userId": "03968090829384653347"
     },
     "user_tz": -180
    },
    "id": "o77KHt0w3DWc"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *\n",
    "from models.tabddpm.tabddpm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O1OrGo4GoOJ1"
   },
   "source": [
    "### Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1742849874687,
     "user": {
      "displayName": "Elina Telesheva",
      "userId": "03968090829384653347"
     },
     "user_tz": -180
    },
    "id": "VTQyrTBDqohs"
   },
   "outputs": [],
   "source": [
    "model_name = 'tabddpm'\n",
    "dataname = 'beijing'\n",
    "model_short = 'TabDDPM'\n",
    "save_cat = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1742849874691,
     "user": {
      "displayName": "Elina Telesheva",
      "userId": "03968090829384653347"
     },
     "user_tz": -180
    },
    "id": "HDL4dxAaubQa"
   },
   "outputs": [],
   "source": [
    "CONFIG.add_arg('dataname', dataname)\n",
    "CONFIG.add_arg('method', model_name)\n",
    "CONFIG.add_arg('save_cat', save_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1742849874685,
     "user": {
      "displayName": "Elina Telesheva",
      "userId": "03968090829384653347"
     },
     "user_tz": -180
    },
    "id": "mDTuHIDqlu0n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing dataset beijing from UCI.\n",
      "Aready downloaded.\n",
      "{'cat_col_idx': [0, 1, 2, 3, 8],\n",
      " 'column_names': None,\n",
      " 'data_path': 'data/beijing/beijing.csv',\n",
      " 'file_type': 'csv',\n",
      " 'header': 'infer',\n",
      " 'name': 'beijing',\n",
      " 'num_col_idx': [5, 6, 7, 9, 10, 11],\n",
      " 'raw_data_path': 'data/beijing/PRSA_data_2010.1.1-2014.12.31.csv',\n",
      " 'target_col_idx': [4],\n",
      " 'task_type': 'regression',\n",
      " 'test_path': None}\n",
      "n_clusters: 25\n",
      "beijing (37581, 12) (4176, 12) (41757, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/TabDDPM_copy/TabDDPM/utils.py:373: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.rename(columns = idx_name_mapping, inplace=True)\n",
      "/workspace/TabDDPM_copy/TabDDPM/utils.py:374: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.rename(columns = idx_name_mapping, inplace=True)\n",
      "/workspace/TabDDPM_copy/TabDDPM/utils.py:379: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
      "/workspace/TabDDPM_copy/TabDDPM/utils.py:379: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
      "/workspace/TabDDPM_copy/TabDDPM/utils.py:379: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
      "/workspace/TabDDPM_copy/TabDDPM/utils.py:379: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
      "/workspace/TabDDPM_copy/TabDDPM/utils.py:383: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
      "/workspace/TabDDPM_copy/TabDDPM/utils.py:383: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
      "/workspace/TabDDPM_copy/TabDDPM/utils.py:383: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
      "/workspace/TabDDPM_copy/TabDDPM/utils.py:383: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
      "/workspace/TabDDPM_copy/TabDDPM/utils.py:412: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[num_columns] = train_df[num_columns].astype(np.float32)\n",
      "/workspace/TabDDPM_copy/TabDDPM/utils.py:413: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[num_columns] = test_df[num_columns].astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical (37581, 6)\n",
      "Categorical (37581, 5)\n",
      "Processing and Saving beijing Successfully!\n",
      "beijing\n",
      "Total 41757\n",
      "Train 37581\n",
      "Test 4176\n",
      "Num 7\n",
      "Cat 5\n"
     ]
    }
   ],
   "source": [
    "download_dataset(dataname)\n",
    "process_data(dataname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 163,
     "status": "ok",
     "timestamp": 1742849874855,
     "user": {
      "displayName": "Elina Telesheva",
      "userId": "03968090829384653347"
     },
     "user_tz": -180
    },
    "id": "VsKZydqtt3mn",
    "outputId": "6c5765d8-cd82-4629-d27b-51ed0d5dd820"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = f'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "CONFIG.add_arg('device', device)\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "\n",
    "CONFIG.add_arg('sample_save_path',\n",
    "               f\"synthetic/{CONFIG.get_arg('dataname')}/{CONFIG.get_arg('method')}.csv\")\n",
    "CONFIG.add_arg('real_path',\n",
    "               f\"synthetic/{CONFIG.get_arg('dataname')}/real.csv\")\n",
    "CONFIG.add_arg('test_path',\n",
    "               f\"synthetic/{CONFIG.get_arg('dataname')}/test.csv\")\n",
    "CONFIG.add_arg('info_path',\n",
    "               f\"data/{CONFIG.get_arg('dataname')}/info.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1742849874933,
     "user": {
      "displayName": "Elina Telesheva",
      "userId": "03968090829384653347"
     },
     "user_tz": -180
    },
    "id": "gFtvnuj1tjB7",
    "outputId": "c2b24970-cea9-4ae2-feff-45c29f92788a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataname': 'beijing',\n",
       " 'method': 'tabddpm',\n",
       " 'device': 'cuda',\n",
       " 'mode': 'train',\n",
       " 'train': 1,\n",
       " 'sample_save_path': 'synthetic/beijing/tabddpm.csv',\n",
       " 'sigma_scheduller_name': 'constant',\n",
       " 'sigma_value': 0.001,\n",
       " 'num_noise': 66,\n",
       " 'real_path': 'synthetic/beijing/real.csv',\n",
       " 'test_path': 'synthetic/beijing/test.csv',\n",
       " 'info_path': 'data/beijing/info.json',\n",
       " 'save_path': './synthetic/shoppers_ON_QnSC_200k/initial_tabddpm_ON_QnSC_200k_mult_9.csv',\n",
       " 'num_clusters': 25,\n",
       " 'save_cat': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG.get_all_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uL818VPDwpaW"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1742849874982,
     "user": {
      "displayName": "Elina Telesheva",
      "userId": "03968090829384653347"
     },
     "user_tz": -180
    },
    "id": "fBJBP6k5woSK"
   },
   "outputs": [],
   "source": [
    "CONFIG.add_arg('mode', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 70,
     "status": "ok",
     "timestamp": 1742849875060,
     "user": {
      "displayName": "Elina Telesheva",
      "userId": "03968090829384653347"
     },
     "user_tz": -180
    },
    "id": "1mULrEuFluee"
   },
   "outputs": [],
   "source": [
    "tabddpm = TabDDPM(CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1742849875101,
     "user": {
      "displayName": "Elina Telesheva",
      "userId": "03968090829384653347"
     },
     "user_tz": -180
    },
    "id": "4Urv02tmnbqa",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START TRAINING\n",
      "No NaNs in numerical features, skipping\n",
      "83\n",
      "{'num_classes': 2, 'is_y_cond': False, 'rtdl_params': {'d_layers': [1024, 2048, 2048, 1024], 'dropout': 0.0}, 'd_in': 83}\n",
      "mlp\n",
      "MLPDiffusion(\n",
      "  (mlp): MLP(\n",
      "    (blocks): ModuleList(\n",
      "      (0): Block(\n",
      "        (linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (activation): ReLU()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (1): Block(\n",
      "        (linear): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "        (activation): ReLU()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (2): Block(\n",
      "        (linear): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "        (activation): ReLU()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (3): Block(\n",
      "        (linear): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "        (activation): ReLU()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (head): Linear(in_features=1024, out_features=83, bias=True)\n",
      "  )\n",
      "  (proj): Linear(in_features=83, out_features=1024, bias=True)\n",
      "  (time_embed): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (1): SiLU()\n",
      "    (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  )\n",
      ")\n",
      "the number of parameters 11713619\n",
      "Steps:  100000\n",
      "Step 1/100000 MLoss: 2.5009 GLoss: 1.3029 Sum: 3.8038\n",
      "Step 2/100000 MLoss: 32.5383 GLoss: 60155.3828 Sum: 60187.9211\n",
      "Step 3/100000 MLoss: 9.2391 GLoss: 339.4251 Sum: 348.6642\n",
      "Step 4/100000 MLoss: 2.4772 GLoss: 2.9401 Sum: 5.4173\n",
      "Step 5/100000 MLoss: 2.4685 GLoss: 1.107 Sum: 3.5755\n",
      "Step 6/100000 MLoss: 2.6442 GLoss: 2.617 Sum: 5.2612000000000005\n",
      "Step 7/100000 MLoss: 2.7415 GLoss: 1.7171 Sum: 4.4586\n",
      "Step 8/100000 MLoss: 2.4188 GLoss: 1.0286 Sum: 3.4474\n",
      "Step 9/100000 MLoss: 2.4716 GLoss: 1.0607 Sum: 3.5323\n",
      "Step 10/100000 MLoss: 2.3505 GLoss: 1.04 Sum: 3.3905\n",
      "Step 11/100000 MLoss: 2.3648 GLoss: 0.9864 Sum: 3.3512\n",
      "Step 12/100000 MLoss: 2.372 GLoss: 0.99 Sum: 3.362\n",
      "Step 13/100000 MLoss: 2.377 GLoss: 1.0168 Sum: 3.3937999999999997\n",
      "Step 14/100000 MLoss: 2.4226 GLoss: 1.0123 Sum: 3.4349\n",
      "Step 15/100000 MLoss: 2.4451 GLoss: 1.0156 Sum: 3.4607\n",
      "Step 16/100000 MLoss: 2.4074 GLoss: 1.0212 Sum: 3.4286000000000003\n",
      "Step 17/100000 MLoss: 2.3087 GLoss: 0.9959 Sum: 3.3045999999999998\n",
      "Step 18/100000 MLoss: 2.3571 GLoss: 0.9983 Sum: 3.3554\n",
      "Step 19/100000 MLoss: 2.431 GLoss: 0.9921 Sum: 3.4231\n",
      "Step 20/100000 MLoss: 2.4462 GLoss: 1.0022 Sum: 3.4484000000000004\n",
      "Step 21/100000 MLoss: 2.4957 GLoss: 0.9958 Sum: 3.4915\n",
      "Step 22/100000 MLoss: 2.3701 GLoss: 0.998 Sum: 3.3681\n",
      "Step 23/100000 MLoss: 2.4084 GLoss: 0.9993 Sum: 3.4076999999999997\n",
      "Step 24/100000 MLoss: 2.3906 GLoss: 1.0055 Sum: 3.3961\n",
      "Step 25/100000 MLoss: 2.3979 GLoss: 1.0052 Sum: 3.4031000000000002\n",
      "Step 26/100000 MLoss: 2.5686 GLoss: 0.9952 Sum: 3.5638\n",
      "Step 27/100000 MLoss: 2.4297 GLoss: 1.0001 Sum: 3.4298\n",
      "Step 28/100000 MLoss: 2.422 GLoss: 0.9881 Sum: 3.4101\n",
      "Step 29/100000 MLoss: 2.4532 GLoss: 1.0066 Sum: 3.4597999999999995\n",
      "Step 30/100000 MLoss: 2.6352 GLoss: 0.9997 Sum: 3.6349\n",
      "Step 31/100000 MLoss: 2.4129 GLoss: 1.0002 Sum: 3.4131\n",
      "Step 32/100000 MLoss: 2.5195 GLoss: 1.0033 Sum: 3.5228\n",
      "Step 33/100000 MLoss: 2.4948 GLoss: 1.0043 Sum: 3.4991000000000003\n",
      "Step 34/100000 MLoss: 2.3565 GLoss: 1.0021 Sum: 3.3586\n",
      "Step 35/100000 MLoss: 2.398 GLoss: 0.9935 Sum: 3.3915\n",
      "Step 36/100000 MLoss: 2.3844 GLoss: 1.0096 Sum: 3.394\n",
      "Step 37/100000 MLoss: 2.3874 GLoss: 1.0038 Sum: 3.3912\n",
      "Step 38/100000 MLoss: 2.3766 GLoss: 1.0055 Sum: 3.3821\n",
      "Step 39/100000 MLoss: 2.3566 GLoss: 1.0027 Sum: 3.3592999999999997\n",
      "Step 40/100000 MLoss: 2.3697 GLoss: 0.9736 Sum: 3.3433\n",
      "Step 41/100000 MLoss: 2.2912 GLoss: 0.9985 Sum: 3.2897\n",
      "Step 42/100000 MLoss: 2.4326 GLoss: 1.0031 Sum: 3.4356999999999998\n",
      "Step 43/100000 MLoss: 2.326 GLoss: 1.0079 Sum: 3.3339\n",
      "Step 44/100000 MLoss: 2.357 GLoss: 1.0175 Sum: 3.3745000000000003\n",
      "Step 45/100000 MLoss: 2.477 GLoss: 1.0048 Sum: 3.4818\n",
      "Step 46/100000 MLoss: 2.3729 GLoss: 0.9971 Sum: 3.37\n",
      "Step 47/100000 MLoss: 2.2704 GLoss: 1.0112 Sum: 3.2816\n",
      "Step 48/100000 MLoss: 2.4756 GLoss: 0.9991 Sum: 3.4747\n",
      "Step 49/100000 MLoss: 2.4747 GLoss: 0.9918 Sum: 3.4665\n",
      "Step 50/100000 MLoss: 2.5862 GLoss: 1.0019 Sum: 3.5881\n",
      "Step 51/100000 MLoss: 2.4078 GLoss: 1.0093 Sum: 3.4171\n",
      "Step 52/100000 MLoss: 2.4518 GLoss: 1.0102 Sum: 3.4619999999999997\n",
      "Step 53/100000 MLoss: 2.3596 GLoss: 0.9855 Sum: 3.3451\n",
      "Step 54/100000 MLoss: 2.3863 GLoss: 0.9983 Sum: 3.3846\n",
      "Step 55/100000 MLoss: 2.4864 GLoss: 1.0015 Sum: 3.4879000000000002\n",
      "Step 56/100000 MLoss: 2.3204 GLoss: 1.0083 Sum: 3.3286999999999995\n",
      "Step 57/100000 MLoss: 2.4262 GLoss: 1.0027 Sum: 3.4289\n",
      "Step 58/100000 MLoss: 2.3503 GLoss: 1.0112 Sum: 3.3615\n",
      "Step 59/100000 MLoss: 2.3678 GLoss: 1.0025 Sum: 3.3703\n",
      "Step 60/100000 MLoss: 2.4652 GLoss: 1.0108 Sum: 3.476\n",
      "Step 61/100000 MLoss: 2.3019 GLoss: 0.9876 Sum: 3.2895\n",
      "Step 62/100000 MLoss: 2.4066 GLoss: 0.9966 Sum: 3.4032\n",
      "Step 63/100000 MLoss: 2.4627 GLoss: 0.9924 Sum: 3.4551\n",
      "Step 64/100000 MLoss: 2.3995 GLoss: 0.9935 Sum: 3.3930000000000002\n",
      "Step 65/100000 MLoss: 2.4145 GLoss: 1.0023 Sum: 3.4168\n",
      "Step 66/100000 MLoss: 2.5769 GLoss: 1.0014 Sum: 3.5783000000000005\n",
      "Step 67/100000 MLoss: 2.4212 GLoss: 0.9945 Sum: 3.4156999999999997\n",
      "Step 68/100000 MLoss: 2.3494 GLoss: 1.0018 Sum: 3.3512000000000004\n",
      "Step 69/100000 MLoss: 2.4553 GLoss: 0.9956 Sum: 3.4509\n",
      "Step 70/100000 MLoss: 2.5407 GLoss: 1.0 Sum: 3.5407\n",
      "Step 71/100000 MLoss: 2.4015 GLoss: 0.9934 Sum: 3.3949\n",
      "Step 72/100000 MLoss: 2.4681 GLoss: 1.0181 Sum: 3.4862\n",
      "Step 73/100000 MLoss: 2.4137 GLoss: 1.003 Sum: 3.4166999999999996\n",
      "Step 74/100000 MLoss: 2.3923 GLoss: 0.9877 Sum: 3.38\n",
      "Step 75/100000 MLoss: 2.3516 GLoss: 1.0016 Sum: 3.3532\n",
      "Step 76/100000 MLoss: 2.4983 GLoss: 1.0018 Sum: 3.5000999999999998\n",
      "Step 77/100000 MLoss: 2.4408 GLoss: 1.004 Sum: 3.4448\n",
      "Step 78/100000 MLoss: 2.4094 GLoss: 0.997 Sum: 3.4064\n",
      "Step 79/100000 MLoss: 2.441 GLoss: 0.989 Sum: 3.4299999999999997\n",
      "Step 80/100000 MLoss: 2.2877 GLoss: 0.9632 Sum: 3.2509\n",
      "Step 81/100000 MLoss: 2.3475 GLoss: 0.9886 Sum: 3.3361\n",
      "Step 82/100000 MLoss: 2.5496 GLoss: 0.9942 Sum: 3.5438\n",
      "Step 83/100000 MLoss: 2.4239 GLoss: 1.005 Sum: 3.4289\n",
      "Step 84/100000 MLoss: 2.4692 GLoss: 1.0077 Sum: 3.4768999999999997\n",
      "Step 85/100000 MLoss: 2.3955 GLoss: 0.9875 Sum: 3.383\n",
      "Step 86/100000 MLoss: 2.3747 GLoss: 1.0127 Sum: 3.3873999999999995\n",
      "Step 87/100000 MLoss: 2.4379 GLoss: 1.0121 Sum: 3.45\n",
      "Step 88/100000 MLoss: 2.3325 GLoss: 1.0115 Sum: 3.3440000000000003\n",
      "Step 89/100000 MLoss: 2.3815 GLoss: 1.0103 Sum: 3.3918\n",
      "Step 90/100000 MLoss: 2.3606 GLoss: 1.0164 Sum: 3.377\n",
      "Step 91/100000 MLoss: 2.3651 GLoss: 1.0045 Sum: 3.3696\n",
      "Step 92/100000 MLoss: 2.4077 GLoss: 1.008 Sum: 3.4157\n",
      "Step 93/100000 MLoss: 2.2962 GLoss: 1.004 Sum: 3.3002\n",
      "Step 94/100000 MLoss: 2.3368 GLoss: 1.0005 Sum: 3.3373\n",
      "Step 95/100000 MLoss: 2.3986 GLoss: 1.0064 Sum: 3.4050000000000002\n",
      "Step 96/100000 MLoss: 2.4226 GLoss: 1.023 Sum: 3.4455999999999998\n",
      "Step 97/100000 MLoss: 2.3545 GLoss: 1.0162 Sum: 3.3707\n",
      "Step 98/100000 MLoss: 2.4248 GLoss: 0.9982 Sum: 3.423\n",
      "Step 99/100000 MLoss: 2.4732 GLoss: 1.0015 Sum: 3.4747\n",
      "Step 100/100000 MLoss: 2.4164 GLoss: 0.9985 Sum: 3.4149\n",
      "Step 101/100000 MLoss: 2.4007 GLoss: 1.0109 Sum: 3.4116\n",
      "Step 102/100000 MLoss: 2.3863 GLoss: 0.9991 Sum: 3.3853999999999997\n",
      "Step 103/100000 MLoss: 2.3115 GLoss: 1.0102 Sum: 3.3217\n",
      "Step 104/100000 MLoss: 2.3553 GLoss: 1.0076 Sum: 3.3629000000000002\n",
      "Step 105/100000 MLoss: 2.3959 GLoss: 0.9952 Sum: 3.3911000000000002\n",
      "Step 106/100000 MLoss: 2.3401 GLoss: 0.9938 Sum: 3.3339\n",
      "Step 107/100000 MLoss: 2.3651 GLoss: 0.9934 Sum: 3.3585\n",
      "Step 108/100000 MLoss: 2.436 GLoss: 0.9952 Sum: 3.4312\n",
      "Step 109/100000 MLoss: 2.3294 GLoss: 1.0115 Sum: 3.3409000000000004\n",
      "Step 110/100000 MLoss: 3.0251 GLoss: 1.0025 Sum: 4.0276\n",
      "Step 111/100000 MLoss: 2.3566 GLoss: 1.0072 Sum: 3.3638\n",
      "Step 112/100000 MLoss: 2.4019 GLoss: 1.0156 Sum: 3.4175\n",
      "Step 113/100000 MLoss: 2.437 GLoss: 1.0004 Sum: 3.4374\n",
      "Step 114/100000 MLoss: 2.3817 GLoss: 0.9937 Sum: 3.3754\n",
      "Step 115/100000 MLoss: 2.4574 GLoss: 1.0107 Sum: 3.4680999999999997\n",
      "Step 116/100000 MLoss: 2.4569 GLoss: 0.9921 Sum: 3.449\n",
      "Step 117/100000 MLoss: 2.399 GLoss: 0.9877 Sum: 3.3867000000000003\n",
      "Step 118/100000 MLoss: 2.4119 GLoss: 1.0011 Sum: 3.4130000000000003\n",
      "Step 119/100000 MLoss: 2.3936 GLoss: 1.0132 Sum: 3.4068000000000005\n",
      "Step 120/100000 MLoss: 2.103 GLoss: 0.9974 Sum: 3.1004\n",
      "Step 121/100000 MLoss: 2.3728 GLoss: 0.9949 Sum: 3.3676999999999997\n",
      "Step 122/100000 MLoss: 2.4765 GLoss: 0.9958 Sum: 3.4723\n",
      "Step 123/100000 MLoss: 2.3544 GLoss: 1.0003 Sum: 3.3547000000000002\n",
      "Step 124/100000 MLoss: 2.4584 GLoss: 0.9993 Sum: 3.4577\n",
      "Step 125/100000 MLoss: 2.4394 GLoss: 0.9911 Sum: 3.4305\n",
      "Step 126/100000 MLoss: 3.0038 GLoss: 0.9842 Sum: 3.988\n",
      "Step 127/100000 MLoss: 2.315 GLoss: 1.0199 Sum: 3.3349\n",
      "Step 128/100000 MLoss: 2.4389 GLoss: 1.0085 Sum: 3.4474\n",
      "Step 129/100000 MLoss: 2.4201 GLoss: 1.0003 Sum: 3.4204\n",
      "Step 130/100000 MLoss: 2.3748 GLoss: 0.9963 Sum: 3.3711\n",
      "Step 131/100000 MLoss: 2.3277 GLoss: 1.0006 Sum: 3.3283\n",
      "Step 132/100000 MLoss: 2.3351 GLoss: 0.9988 Sum: 3.3339000000000003\n",
      "Step 133/100000 MLoss: 2.3696 GLoss: 1.007 Sum: 3.3766\n",
      "Step 134/100000 MLoss: 2.3614 GLoss: 0.9878 Sum: 3.3492\n",
      "Step 135/100000 MLoss: 2.3364 GLoss: 0.9859 Sum: 3.3223\n",
      "Step 136/100000 MLoss: 2.3497 GLoss: 1.0042 Sum: 3.3539\n",
      "Step 137/100000 MLoss: 2.3674 GLoss: 0.9901 Sum: 3.3575\n",
      "Step 138/100000 MLoss: 2.4363 GLoss: 0.9995 Sum: 3.4358000000000004\n",
      "Step 139/100000 MLoss: 2.4035 GLoss: 1.014 Sum: 3.4175000000000004\n",
      "Step 140/100000 MLoss: 2.4133 GLoss: 1.0019 Sum: 3.4152\n",
      "Step 141/100000 MLoss: 2.4563 GLoss: 0.9818 Sum: 3.4381000000000004\n",
      "Step 142/100000 MLoss: 2.4069 GLoss: 0.9943 Sum: 3.4012\n",
      "Step 143/100000 MLoss: 2.4565 GLoss: 1.0062 Sum: 3.4627\n",
      "Step 144/100000 MLoss: 2.5681 GLoss: 1.0073 Sum: 3.5754\n",
      "Step 145/100000 MLoss: 2.3659 GLoss: 1.0045 Sum: 3.3704\n",
      "Step 146/100000 MLoss: 2.4011 GLoss: 0.9933 Sum: 3.3944\n",
      "Step 147/100000 MLoss: 2.3507 GLoss: 0.9927 Sum: 3.3434\n",
      "Step 148/100000 MLoss: 2.7103 GLoss: 0.9921 Sum: 3.7024\n",
      "Step 149/100000 MLoss: 2.3359 GLoss: 0.9919 Sum: 3.3278\n",
      "Step 150/100000 MLoss: 2.5057 GLoss: 1.0272 Sum: 3.5328999999999997\n",
      "Step 151/100000 MLoss: 2.3754 GLoss: 0.991 Sum: 3.3664\n",
      "Step 152/100000 MLoss: 2.5836 GLoss: 0.9954 Sum: 3.579\n",
      "Step 153/100000 MLoss: 2.3464 GLoss: 0.9955 Sum: 3.3419\n",
      "Step 154/100000 MLoss: 2.442 GLoss: 0.9977 Sum: 3.4397\n",
      "Step 155/100000 MLoss: 2.3348 GLoss: 1.0017 Sum: 3.3365\n",
      "Step 156/100000 MLoss: 2.3978 GLoss: 0.9836 Sum: 3.3814\n",
      "Step 157/100000 MLoss: 2.2994 GLoss: 0.9968 Sum: 3.2962\n",
      "Step 158/100000 MLoss: 2.3437 GLoss: 0.9892 Sum: 3.3329\n",
      "Step 159/100000 MLoss: 2.4049 GLoss: 0.9938 Sum: 3.3987\n",
      "Step 160/100000 MLoss: 2.5483 GLoss: 0.9919 Sum: 3.5401999999999996\n",
      "Step 161/100000 MLoss: 2.4215 GLoss: 1.0311 Sum: 3.4526\n",
      "Step 162/100000 MLoss: 2.5164 GLoss: 0.9931 Sum: 3.5095\n",
      "Step 163/100000 MLoss: 2.4107 GLoss: 0.9815 Sum: 3.3922\n",
      "Step 164/100000 MLoss: 2.3328 GLoss: 1.0178 Sum: 3.3506\n",
      "Step 165/100000 MLoss: 2.3865 GLoss: 0.987 Sum: 3.3735\n",
      "Step 166/100000 MLoss: 2.3165 GLoss: 0.9936 Sum: 3.3101000000000003\n",
      "Step 167/100000 MLoss: 2.3783 GLoss: 0.9923 Sum: 3.3705999999999996\n",
      "Step 168/100000 MLoss: 2.4086 GLoss: 0.9906 Sum: 3.3992\n",
      "Step 169/100000 MLoss: 2.4522 GLoss: 0.9929 Sum: 3.4451\n",
      "Step 170/100000 MLoss: 2.5361 GLoss: 0.987 Sum: 3.5231\n",
      "Step 171/100000 MLoss: 2.3534 GLoss: 1.0076 Sum: 3.361\n",
      "Step 172/100000 MLoss: 2.2764 GLoss: 0.985 Sum: 3.2614\n",
      "Step 173/100000 MLoss: 2.395 GLoss: 1.0116 Sum: 3.4066\n",
      "Step 174/100000 MLoss: 2.5299 GLoss: 0.9979 Sum: 3.5278\n",
      "Step 175/100000 MLoss: 2.5479 GLoss: 1.0142 Sum: 3.5621\n",
      "Step 176/100000 MLoss: 2.4446 GLoss: 0.9919 Sum: 3.4364999999999997\n",
      "Step 177/100000 MLoss: 2.2995 GLoss: 0.9824 Sum: 3.2819000000000003\n",
      "Step 178/100000 MLoss: 2.3788 GLoss: 0.9903 Sum: 3.3691\n",
      "Step 179/100000 MLoss: 2.4623 GLoss: 1.0223 Sum: 3.4846\n",
      "Step 180/100000 MLoss: 2.1521 GLoss: 0.99 Sum: 3.1421\n",
      "Step 181/100000 MLoss: 2.4458 GLoss: 1.0193 Sum: 3.4651000000000005\n",
      "Step 182/100000 MLoss: 2.3713 GLoss: 0.9979 Sum: 3.3692\n",
      "Step 183/100000 MLoss: 2.3435 GLoss: 0.9999 Sum: 3.3434\n",
      "Step 184/100000 MLoss: 2.3743 GLoss: 1.0031 Sum: 3.3773999999999997\n",
      "Step 185/100000 MLoss: 2.2897 GLoss: 0.9929 Sum: 3.2826\n",
      "Step 186/100000 MLoss: 2.2705 GLoss: 1.0056 Sum: 3.2761000000000005\n",
      "Step 187/100000 MLoss: 2.4435 GLoss: 1.0347 Sum: 3.4781999999999997\n",
      "Step 188/100000 MLoss: 2.3513 GLoss: 0.9996 Sum: 3.3509\n",
      "Step 189/100000 MLoss: 2.4737 GLoss: 0.9906 Sum: 3.4643\n",
      "Step 190/100000 MLoss: 2.6079 GLoss: 1.0184 Sum: 3.6262999999999996\n",
      "Step 191/100000 MLoss: 2.4615 GLoss: 1.0067 Sum: 3.4682\n",
      "Step 192/100000 MLoss: 2.4464 GLoss: 0.9923 Sum: 3.4387\n",
      "Step 193/100000 MLoss: 2.2949 GLoss: 0.9951 Sum: 3.29\n",
      "Step 194/100000 MLoss: 2.4587 GLoss: 1.0131 Sum: 3.4718\n",
      "Step 195/100000 MLoss: 2.3048 GLoss: 0.9972 Sum: 3.302\n",
      "Step 196/100000 MLoss: 2.3448 GLoss: 1.0146 Sum: 3.3594\n",
      "Step 197/100000 MLoss: 2.4383 GLoss: 0.9916 Sum: 3.4299\n",
      "Step 198/100000 MLoss: 2.3997 GLoss: 0.9865 Sum: 3.3862\n",
      "Step 199/100000 MLoss: 2.4259 GLoss: 0.9933 Sum: 3.4192\n",
      "Step 200/100000 MLoss: 2.2158 GLoss: 0.971 Sum: 3.1868000000000003\n",
      "Step 201/100000 MLoss: 2.4542 GLoss: 0.989 Sum: 3.4432\n",
      "Step 202/100000 MLoss: 2.3976 GLoss: 0.9979 Sum: 3.3955\n",
      "Step 203/100000 MLoss: 2.2721 GLoss: 0.9903 Sum: 3.2624\n",
      "Step 204/100000 MLoss: 2.3915 GLoss: 0.9902 Sum: 3.3817000000000004\n",
      "Step 205/100000 MLoss: 2.4473 GLoss: 1.0066 Sum: 3.4539\n",
      "Step 206/100000 MLoss: 2.6119 GLoss: 1.0818 Sum: 3.6936999999999998\n",
      "Step 207/100000 MLoss: 2.6163 GLoss: 1.0627 Sum: 3.679\n",
      "Step 208/100000 MLoss: 2.4015 GLoss: 1.019 Sum: 3.4204999999999997\n",
      "Step 209/100000 MLoss: 2.37 GLoss: 1.0034 Sum: 3.3734\n",
      "Step 210/100000 MLoss: 2.5953 GLoss: 1.0028 Sum: 3.5980999999999996\n",
      "Step 211/100000 MLoss: 2.4482 GLoss: 1.0101 Sum: 3.4583\n",
      "Step 212/100000 MLoss: 2.3395 GLoss: 0.9867 Sum: 3.3262\n",
      "Step 213/100000 MLoss: 2.356 GLoss: 1.0042 Sum: 3.3602\n",
      "Step 214/100000 MLoss: 2.8026 GLoss: 1.1702 Sum: 3.9728\n",
      "Step 215/100000 MLoss: 2.4063 GLoss: 0.9915 Sum: 3.3978\n",
      "Step 216/100000 MLoss: 2.3458 GLoss: 0.9842 Sum: 3.33\n",
      "Step 217/100000 MLoss: 2.411 GLoss: 0.9819 Sum: 3.3929\n",
      "Step 218/100000 MLoss: 2.3897 GLoss: 0.9882 Sum: 3.3779\n",
      "Step 219/100000 MLoss: 2.4786 GLoss: 1.0005 Sum: 3.4791\n",
      "Step 220/100000 MLoss: 2.337 GLoss: 0.9985 Sum: 3.3355\n",
      "Step 221/100000 MLoss: 2.414 GLoss: 0.9896 Sum: 3.4036\n",
      "Step 222/100000 MLoss: 2.4606 GLoss: 1.0031 Sum: 3.4637000000000002\n",
      "Step 223/100000 MLoss: 2.2931 GLoss: 0.9929 Sum: 3.286\n",
      "Step 224/100000 MLoss: 2.3487 GLoss: 0.9999 Sum: 3.3486000000000002\n",
      "Step 225/100000 MLoss: 2.382 GLoss: 1.0056 Sum: 3.3876\n",
      "Step 226/100000 MLoss: 2.4213 GLoss: 0.9998 Sum: 3.4211\n",
      "Step 227/100000 MLoss: 2.441 GLoss: 1.001 Sum: 3.4419999999999997\n",
      "Step 228/100000 MLoss: 2.4218 GLoss: 0.9844 Sum: 3.4062\n",
      "Step 229/100000 MLoss: 2.5407 GLoss: 0.9999 Sum: 3.5406000000000004\n",
      "Step 230/100000 MLoss: 2.6609 GLoss: 1.0068 Sum: 3.6677\n",
      "Step 231/100000 MLoss: 2.3689 GLoss: 0.9946 Sum: 3.3635\n",
      "Step 232/100000 MLoss: 2.405 GLoss: 1.0004 Sum: 3.4053999999999998\n",
      "Step 233/100000 MLoss: 2.3297 GLoss: 0.9919 Sum: 3.3216\n",
      "Step 234/100000 MLoss: 2.3976 GLoss: 0.9869 Sum: 3.3845\n",
      "Step 235/100000 MLoss: 2.3356 GLoss: 1.0168 Sum: 3.3524\n",
      "Step 236/100000 MLoss: 2.2678 GLoss: 0.9909 Sum: 3.2586999999999997\n",
      "Step 237/100000 MLoss: 2.4341 GLoss: 0.9915 Sum: 3.4256\n",
      "Step 238/100000 MLoss: 2.3958 GLoss: 1.0109 Sum: 3.4067\n",
      "Step 239/100000 MLoss: 2.5684 GLoss: 1.0033 Sum: 3.5717\n",
      "Step 240/100000 MLoss: 2.3607 GLoss: 0.9683 Sum: 3.329\n",
      "Step 241/100000 MLoss: 2.4243 GLoss: 1.0126 Sum: 3.4369\n",
      "Step 242/100000 MLoss: 2.4335 GLoss: 0.994 Sum: 3.4275\n",
      "Step 243/100000 MLoss: 2.3021 GLoss: 0.9974 Sum: 3.2994999999999997\n",
      "Step 244/100000 MLoss: 2.3075 GLoss: 1.0033 Sum: 3.3108000000000004\n",
      "Step 245/100000 MLoss: 2.387 GLoss: 0.9966 Sum: 3.3836\n",
      "Step 246/100000 MLoss: 2.3864 GLoss: 0.9919 Sum: 3.3783000000000003\n",
      "Step 247/100000 MLoss: 2.3231 GLoss: 0.9955 Sum: 3.3186\n",
      "Step 248/100000 MLoss: 2.2641 GLoss: 0.9901 Sum: 3.2542\n",
      "Step 249/100000 MLoss: 2.3565 GLoss: 0.9925 Sum: 3.349\n",
      "Step 250/100000 MLoss: 2.3411 GLoss: 1.0189 Sum: 3.36\n",
      "Step 251/100000 MLoss: 2.7209 GLoss: 1.091 Sum: 3.8118999999999996\n",
      "Step 252/100000 MLoss: 2.5256 GLoss: 1.0372 Sum: 3.5627999999999997\n",
      "Step 253/100000 MLoss: 2.3527 GLoss: 0.992 Sum: 3.3447\n",
      "Step 254/100000 MLoss: 2.2377 GLoss: 0.9824 Sum: 3.2201\n",
      "Step 255/100000 MLoss: 2.3381 GLoss: 0.9886 Sum: 3.3266999999999998\n",
      "Step 256/100000 MLoss: 2.4161 GLoss: 0.9878 Sum: 3.4039\n",
      "Step 257/100000 MLoss: 2.4131 GLoss: 0.971 Sum: 3.3841\n",
      "Step 258/100000 MLoss: 2.3248 GLoss: 1.0053 Sum: 3.3301000000000003\n",
      "Step 259/100000 MLoss: 2.2567 GLoss: 0.988 Sum: 3.2447\n",
      "Step 260/100000 MLoss: 2.946 GLoss: 1.151 Sum: 4.097\n",
      "Step 261/100000 MLoss: 2.8223 GLoss: 1.1659 Sum: 3.9882\n",
      "Step 262/100000 MLoss: 2.4806 GLoss: 1.0128 Sum: 3.4934\n",
      "Step 263/100000 MLoss: 2.4737 GLoss: 0.9879 Sum: 3.4616\n",
      "Step 264/100000 MLoss: 2.4585 GLoss: 1.0244 Sum: 3.4829\n",
      "Step 265/100000 MLoss: 2.3802 GLoss: 0.983 Sum: 3.3632\n",
      "Step 266/100000 MLoss: 2.3877 GLoss: 1.0051 Sum: 3.3928000000000003\n",
      "Step 267/100000 MLoss: 2.2035 GLoss: 1.0101 Sum: 3.2136\n",
      "Step 268/100000 MLoss: 2.2996 GLoss: 0.9987 Sum: 3.2983\n",
      "Step 269/100000 MLoss: 2.3404 GLoss: 0.9983 Sum: 3.3387\n",
      "Step 270/100000 MLoss: 2.301 GLoss: 1.0104 Sum: 3.3114\n",
      "Step 271/100000 MLoss: 2.3671 GLoss: 0.9748 Sum: 3.3419000000000003\n",
      "Step 272/100000 MLoss: 2.3733 GLoss: 0.9954 Sum: 3.3687\n",
      "Step 273/100000 MLoss: 2.3076 GLoss: 0.9996 Sum: 3.3072\n",
      "Step 274/100000 MLoss: 2.3424 GLoss: 1.0005 Sum: 3.3429\n",
      "Step 275/100000 MLoss: 2.3485 GLoss: 0.9801 Sum: 3.3286\n",
      "Step 276/100000 MLoss: 2.4307 GLoss: 0.9773 Sum: 3.408\n",
      "Step 277/100000 MLoss: 2.3605 GLoss: 0.9827 Sum: 3.3432\n",
      "Step 278/100000 MLoss: 2.4496 GLoss: 1.0104 Sum: 3.46\n",
      "Step 279/100000 MLoss: 2.4071 GLoss: 0.984 Sum: 3.3911\n",
      "Step 280/100000 MLoss: 2.4395 GLoss: 1.0468 Sum: 3.4863\n",
      "Step 281/100000 MLoss: 2.4543 GLoss: 1.0089 Sum: 3.4631999999999996\n",
      "Step 282/100000 MLoss: 2.3783 GLoss: 0.9918 Sum: 3.3701\n",
      "Step 283/100000 MLoss: 2.4181 GLoss: 0.9921 Sum: 3.4101999999999997\n",
      "Step 284/100000 MLoss: 2.3567 GLoss: 0.9927 Sum: 3.3494\n",
      "Step 285/100000 MLoss: 2.4022 GLoss: 1.0621 Sum: 3.4643\n",
      "Step 286/100000 MLoss: 2.4829 GLoss: 1.0044 Sum: 3.4873\n",
      "Step 287/100000 MLoss: 2.5372 GLoss: 1.1742 Sum: 3.7114\n",
      "Step 288/100000 MLoss: 2.3855 GLoss: 0.9828 Sum: 3.3683\n",
      "Step 289/100000 MLoss: 2.4068 GLoss: 1.0158 Sum: 3.4226\n",
      "Step 290/100000 MLoss: 2.3491 GLoss: 1.0038 Sum: 3.3529\n",
      "Step 291/100000 MLoss: 2.3415 GLoss: 0.9922 Sum: 3.3337\n",
      "Step 292/100000 MLoss: 2.3289 GLoss: 1.0003 Sum: 3.3292\n",
      "Step 293/100000 MLoss: 2.3672 GLoss: 0.987 Sum: 3.3542\n",
      "Step 294/100000 MLoss: 2.4031 GLoss: 0.9847 Sum: 3.3878\n",
      "Step 295/100000 MLoss: 2.3828 GLoss: 0.982 Sum: 3.3648\n",
      "Step 296/100000 MLoss: 2.4036 GLoss: 0.9995 Sum: 3.4031000000000002\n",
      "Step 297/100000 MLoss: 2.3318 GLoss: 1.0295 Sum: 3.3613\n",
      "Step 298/100000 MLoss: 2.3923 GLoss: 0.9665 Sum: 3.3588\n",
      "Step 299/100000 MLoss: 2.2507 GLoss: 0.9815 Sum: 3.2322\n",
      "Step 300/100000 MLoss: 2.4984 GLoss: 0.9555 Sum: 3.4539\n",
      "Step 301/100000 MLoss: 2.4435 GLoss: 0.9854 Sum: 3.4288999999999996\n",
      "Step 302/100000 MLoss: 2.4111 GLoss: 0.9754 Sum: 3.3865\n",
      "Step 303/100000 MLoss: 2.3755 GLoss: 0.9966 Sum: 3.3721\n",
      "Step 304/100000 MLoss: 2.3747 GLoss: 0.9644 Sum: 3.3390999999999997\n",
      "Step 305/100000 MLoss: 2.633 GLoss: 1.1332 Sum: 3.7662\n",
      "Step 306/100000 MLoss: 2.8355 GLoss: 1.1 Sum: 3.9355\n",
      "Step 307/100000 MLoss: 2.5458 GLoss: 0.9919 Sum: 3.5377\n",
      "Step 308/100000 MLoss: 2.2824 GLoss: 0.9979 Sum: 3.2803\n",
      "Step 309/100000 MLoss: 2.4093 GLoss: 1.0245 Sum: 3.4337999999999997\n",
      "Step 310/100000 MLoss: 2.2386 GLoss: 0.9766 Sum: 3.2152\n",
      "Step 311/100000 MLoss: 2.3605 GLoss: 0.9906 Sum: 3.3511\n",
      "Step 312/100000 MLoss: 2.36 GLoss: 1.0041 Sum: 3.3640999999999996\n",
      "Step 313/100000 MLoss: 2.3171 GLoss: 1.001 Sum: 3.3181\n",
      "Step 314/100000 MLoss: 2.376 GLoss: 0.9985 Sum: 3.3745\n",
      "Step 315/100000 MLoss: 2.3419 GLoss: 0.9878 Sum: 3.3297\n",
      "Step 316/100000 MLoss: 2.3802 GLoss: 1.0052 Sum: 3.3853999999999997\n",
      "Step 317/100000 MLoss: 2.3843 GLoss: 0.9883 Sum: 3.3726000000000003\n",
      "Step 318/100000 MLoss: 2.4297 GLoss: 0.9992 Sum: 3.4289\n",
      "Step 319/100000 MLoss: 2.3758 GLoss: 0.9912 Sum: 3.367\n",
      "Step 320/100000 MLoss: 2.6344 GLoss: 1.0787 Sum: 3.7131\n",
      "Step 321/100000 MLoss: 2.4857 GLoss: 1.0143 Sum: 3.5\n",
      "Step 322/100000 MLoss: 2.3235 GLoss: 0.9825 Sum: 3.306\n",
      "Step 323/100000 MLoss: 2.3843 GLoss: 0.9819 Sum: 3.3662\n",
      "Step 324/100000 MLoss: 2.2965 GLoss: 0.9739 Sum: 3.2704\n",
      "Step 325/100000 MLoss: 2.4489 GLoss: 1.0098 Sum: 3.4587000000000003\n",
      "Step 326/100000 MLoss: 2.3443 GLoss: 0.9777 Sum: 3.322\n",
      "Step 327/100000 MLoss: 2.379 GLoss: 0.9766 Sum: 3.3556\n",
      "Step 328/100000 MLoss: 2.4163 GLoss: 0.9693 Sum: 3.3856\n",
      "Step 329/100000 MLoss: 2.2995 GLoss: 0.9807 Sum: 3.2802000000000002\n",
      "Step 330/100000 MLoss: 2.3092 GLoss: 0.9921 Sum: 3.3013000000000003\n",
      "Step 331/100000 MLoss: 2.3573 GLoss: 0.975 Sum: 3.3323\n",
      "Step 332/100000 MLoss: 2.3306 GLoss: 0.9656 Sum: 3.2962\n",
      "Step 333/100000 MLoss: 2.3126 GLoss: 0.9677 Sum: 3.2803000000000004\n",
      "Step 334/100000 MLoss: 2.344 GLoss: 0.9766 Sum: 3.3205999999999998\n",
      "Step 335/100000 MLoss: 2.3113 GLoss: 0.9845 Sum: 3.2958000000000003\n",
      "Step 336/100000 MLoss: 2.2942 GLoss: 0.9627 Sum: 3.2569\n",
      "Step 337/100000 MLoss: 2.2892 GLoss: 0.9734 Sum: 3.2626\n",
      "Step 338/100000 MLoss: 2.1891 GLoss: 0.9681 Sum: 3.1571999999999996\n",
      "Step 339/100000 MLoss: 2.385 GLoss: 0.9967 Sum: 3.3817\n",
      "Step 340/100000 MLoss: 2.2979 GLoss: 0.9511 Sum: 3.2489999999999997\n",
      "Step 341/100000 MLoss: 2.6689 GLoss: 1.1129 Sum: 3.7817999999999996\n",
      "Step 342/100000 MLoss: 2.9049 GLoss: 1.1322 Sum: 4.037100000000001\n",
      "Step 343/100000 MLoss: 2.4624 GLoss: 1.009 Sum: 3.4714\n",
      "Step 344/100000 MLoss: 2.3769 GLoss: 0.9704 Sum: 3.3473\n",
      "Step 345/100000 MLoss: 2.3901 GLoss: 1.0018 Sum: 3.3918999999999997\n",
      "Step 346/100000 MLoss: 2.3708 GLoss: 0.976 Sum: 3.3468\n",
      "Step 347/100000 MLoss: 2.3417 GLoss: 1.0073 Sum: 3.349\n",
      "Step 348/100000 MLoss: 2.4061 GLoss: 1.0006 Sum: 3.4067\n",
      "Step 349/100000 MLoss: 2.4683 GLoss: 1.0064 Sum: 3.4747000000000003\n",
      "Step 350/100000 MLoss: 2.577 GLoss: 1.0056 Sum: 3.5826000000000002\n",
      "Step 351/100000 MLoss: 2.4036 GLoss: 0.9939 Sum: 3.3975\n",
      "Step 352/100000 MLoss: 2.3824 GLoss: 0.978 Sum: 3.3604000000000003\n",
      "Step 353/100000 MLoss: 2.3799 GLoss: 0.9927 Sum: 3.3726000000000003\n",
      "Step 354/100000 MLoss: 2.2689 GLoss: 0.974 Sum: 3.2428999999999997\n",
      "Step 355/100000 MLoss: 2.5056 GLoss: 0.9639 Sum: 3.4695\n",
      "Step 356/100000 MLoss: 2.4142 GLoss: 1.0299 Sum: 3.4441\n",
      "Step 357/100000 MLoss: 2.2531 GLoss: 0.9782 Sum: 3.2313\n",
      "Step 358/100000 MLoss: 2.2868 GLoss: 0.9643 Sum: 3.2511\n",
      "Step 359/100000 MLoss: 2.3944 GLoss: 0.9812 Sum: 3.3756\n",
      "Step 360/100000 MLoss: 2.3157 GLoss: 0.9697 Sum: 3.2854\n",
      "Step 361/100000 MLoss: 2.3867 GLoss: 0.9622 Sum: 3.3489\n",
      "Step 362/100000 MLoss: 2.3119 GLoss: 0.9862 Sum: 3.2981\n",
      "Step 363/100000 MLoss: 2.3636 GLoss: 0.9802 Sum: 3.3438\n",
      "Step 364/100000 MLoss: 2.3179 GLoss: 0.9733 Sum: 3.2912\n",
      "Step 365/100000 MLoss: 2.2898 GLoss: 0.9601 Sum: 3.2499000000000002\n",
      "Step 366/100000 MLoss: 2.3508 GLoss: 0.9609 Sum: 3.3117\n",
      "Step 367/100000 MLoss: 2.2767 GLoss: 0.9516 Sum: 3.2283\n",
      "Step 368/100000 MLoss: 2.3325 GLoss: 0.9649 Sum: 3.2974\n",
      "Step 369/100000 MLoss: 2.3708 GLoss: 0.9655 Sum: 3.3363\n",
      "Step 370/100000 MLoss: 2.2041 GLoss: 0.9769 Sum: 3.181\n",
      "Step 371/100000 MLoss: 2.3346 GLoss: 0.967 Sum: 3.3016\n",
      "Step 372/100000 MLoss: 2.3155 GLoss: 0.9702 Sum: 3.2857000000000003\n",
      "Step 373/100000 MLoss: 2.231 GLoss: 0.9706 Sum: 3.2016\n",
      "Step 374/100000 MLoss: 2.3435 GLoss: 0.954 Sum: 3.2975000000000003\n",
      "Step 375/100000 MLoss: 2.3362 GLoss: 0.9826 Sum: 3.3188\n",
      "Step 376/100000 MLoss: 2.4197 GLoss: 0.952 Sum: 3.3717\n",
      "Step 377/100000 MLoss: 2.5877 GLoss: 1.0431 Sum: 3.6308\n",
      "Step 378/100000 MLoss: 2.5366 GLoss: 1.0453 Sum: 3.5819\n",
      "Step 379/100000 MLoss: 2.3001 GLoss: 0.9854 Sum: 3.2855\n",
      "Step 380/100000 MLoss: 2.6334 GLoss: 0.9503 Sum: 3.5837\n",
      "Step 381/100000 MLoss: 2.4466 GLoss: 0.9962 Sum: 3.4428\n",
      "Step 382/100000 MLoss: 2.2519 GLoss: 0.9858 Sum: 3.2377000000000002\n",
      "Step 383/100000 MLoss: 2.3252 GLoss: 0.9948 Sum: 3.3200000000000003\n",
      "Step 384/100000 MLoss: 2.3195 GLoss: 0.9777 Sum: 3.2972\n",
      "Step 385/100000 MLoss: 2.2845 GLoss: 0.9564 Sum: 3.2409\n",
      "Step 386/100000 MLoss: 2.372 GLoss: 0.975 Sum: 3.347\n",
      "Step 387/100000 MLoss: 2.5448 GLoss: 1.1731 Sum: 3.7179\n",
      "Step 388/100000 MLoss: 2.4172 GLoss: 1.057 Sum: 3.4741999999999997\n",
      "Step 389/100000 MLoss: 2.3328 GLoss: 0.9817 Sum: 3.3145000000000002\n",
      "Step 390/100000 MLoss: 2.3031 GLoss: 0.9711 Sum: 3.2742\n",
      "Step 391/100000 MLoss: 2.3239 GLoss: 0.9865 Sum: 3.3104\n",
      "Step 392/100000 MLoss: 2.3362 GLoss: 0.9775 Sum: 3.3137\n",
      "Step 393/100000 MLoss: 2.3154 GLoss: 0.9848 Sum: 3.3002\n",
      "Step 394/100000 MLoss: 2.4816 GLoss: 0.9865 Sum: 3.4680999999999997\n",
      "Step 395/100000 MLoss: 2.3979 GLoss: 0.9638 Sum: 3.3617\n",
      "Step 396/100000 MLoss: 2.302 GLoss: 0.974 Sum: 3.276\n",
      "Step 397/100000 MLoss: 2.3587 GLoss: 0.9628 Sum: 3.3215\n",
      "Step 398/100000 MLoss: 2.4546 GLoss: 0.9898 Sum: 3.4444\n",
      "Step 399/100000 MLoss: 2.2786 GLoss: 0.9904 Sum: 3.269\n",
      "Step 400/100000 MLoss: 2.4356 GLoss: 0.9799 Sum: 3.4154999999999998\n",
      "Step 401/100000 MLoss: 2.3878 GLoss: 0.9699 Sum: 3.3577\n",
      "Step 402/100000 MLoss: 2.3398 GLoss: 0.9571 Sum: 3.2969\n",
      "Step 403/100000 MLoss: 2.4182 GLoss: 0.9788 Sum: 3.3970000000000002\n",
      "Step 404/100000 MLoss: 2.2966 GLoss: 0.9697 Sum: 3.2663\n",
      "Step 405/100000 MLoss: 2.4072 GLoss: 0.9699 Sum: 3.3771\n",
      "Step 406/100000 MLoss: 2.3187 GLoss: 0.9512 Sum: 3.2699000000000003\n",
      "Step 407/100000 MLoss: 2.334 GLoss: 0.9787 Sum: 3.3127\n",
      "Step 408/100000 MLoss: 2.3261 GLoss: 0.9653 Sum: 3.2914\n",
      "Step 409/100000 MLoss: 2.3389 GLoss: 0.9663 Sum: 3.3052\n",
      "Step 410/100000 MLoss: 2.3588 GLoss: 0.9538 Sum: 3.3125999999999998\n",
      "Step 411/100000 MLoss: 2.425 GLoss: 0.9906 Sum: 3.4156\n",
      "Step 412/100000 MLoss: 2.2897 GLoss: 0.9692 Sum: 3.2588999999999997\n",
      "Step 413/100000 MLoss: 2.2089 GLoss: 0.9796 Sum: 3.1885\n",
      "Step 414/100000 MLoss: 2.346 GLoss: 0.9801 Sum: 3.3261000000000003\n",
      "Step 415/100000 MLoss: 2.3192 GLoss: 0.9728 Sum: 3.292\n",
      "Step 416/100000 MLoss: 2.3252 GLoss: 0.9612 Sum: 3.2864000000000004\n",
      "Step 417/100000 MLoss: 2.2239 GLoss: 0.9671 Sum: 3.191\n",
      "Step 418/100000 MLoss: 2.3585 GLoss: 0.9716 Sum: 3.3301\n",
      "Step 419/100000 MLoss: 2.3234 GLoss: 0.9709 Sum: 3.2943\n",
      "Step 420/100000 MLoss: 2.2807 GLoss: 0.9844 Sum: 3.2651\n",
      "Step 421/100000 MLoss: 2.2877 GLoss: 0.9776 Sum: 3.2653\n",
      "Step 422/100000 MLoss: 2.3507 GLoss: 0.971 Sum: 3.3217\n",
      "Step 423/100000 MLoss: 2.2026 GLoss: 0.9555 Sum: 3.1581\n",
      "Step 424/100000 MLoss: 2.3427 GLoss: 0.966 Sum: 3.3087\n",
      "Step 425/100000 MLoss: 2.4787 GLoss: 0.9635 Sum: 3.4421999999999997\n",
      "Step 426/100000 MLoss: 2.4846 GLoss: 0.9542 Sum: 3.4388\n",
      "Step 427/100000 MLoss: 2.3942 GLoss: 1.0122 Sum: 3.4064\n",
      "Step 428/100000 MLoss: 2.4169 GLoss: 0.9856 Sum: 3.4025\n",
      "Step 429/100000 MLoss: 2.3199 GLoss: 0.9516 Sum: 3.2715\n",
      "Step 430/100000 MLoss: 2.3271 GLoss: 0.9771 Sum: 3.3042000000000002\n",
      "Step 431/100000 MLoss: 2.2565 GLoss: 0.9735 Sum: 3.23\n",
      "Step 432/100000 MLoss: 2.3558 GLoss: 0.9628 Sum: 3.3186\n",
      "Step 433/100000 MLoss: 2.3014 GLoss: 0.9869 Sum: 3.2883\n",
      "Step 434/100000 MLoss: 2.3441 GLoss: 0.9562 Sum: 3.3003\n",
      "Step 435/100000 MLoss: 2.3317 GLoss: 1.0037 Sum: 3.3354\n",
      "Step 436/100000 MLoss: 2.4462 GLoss: 1.018 Sum: 3.4642\n",
      "Step 437/100000 MLoss: 2.3548 GLoss: 0.9792 Sum: 3.334\n",
      "Step 438/100000 MLoss: 2.1972 GLoss: 0.9696 Sum: 3.1668000000000003\n",
      "Step 439/100000 MLoss: 2.4011 GLoss: 0.9714 Sum: 3.3725\n",
      "Step 440/100000 MLoss: 2.4185 GLoss: 0.9758 Sum: 3.3943\n",
      "Step 441/100000 MLoss: 2.1507 GLoss: 0.9604 Sum: 3.1111\n",
      "Step 442/100000 MLoss: 2.3416 GLoss: 0.9693 Sum: 3.3109\n",
      "Step 443/100000 MLoss: 2.3516 GLoss: 0.9607 Sum: 3.3123\n",
      "Step 444/100000 MLoss: 2.3253 GLoss: 0.9635 Sum: 3.2888\n",
      "Step 445/100000 MLoss: 2.3592 GLoss: 0.9719 Sum: 3.3311\n",
      "Step 446/100000 MLoss: 2.3722 GLoss: 0.9527 Sum: 3.3249\n",
      "Step 447/100000 MLoss: 2.3078 GLoss: 0.9802 Sum: 3.288\n",
      "Step 448/100000 MLoss: 2.24 GLoss: 0.9373 Sum: 3.1773000000000002\n",
      "Step 449/100000 MLoss: 2.6434 GLoss: 0.9449 Sum: 3.5883000000000003\n",
      "Step 450/100000 MLoss: 2.1619 GLoss: 0.969 Sum: 3.1309\n",
      "Step 451/100000 MLoss: 2.3031 GLoss: 0.9452 Sum: 3.2483000000000004\n",
      "Step 452/100000 MLoss: 2.2505 GLoss: 0.9448 Sum: 3.1953\n",
      "Step 453/100000 MLoss: 2.3511 GLoss: 0.9493 Sum: 3.3004000000000002\n",
      "Step 454/100000 MLoss: 2.2043 GLoss: 0.9636 Sum: 3.1679\n",
      "Step 455/100000 MLoss: 2.2235 GLoss: 0.9425 Sum: 3.166\n",
      "Step 456/100000 MLoss: 2.3269 GLoss: 0.9381 Sum: 3.265\n",
      "Step 457/100000 MLoss: 2.2532 GLoss: 0.9586 Sum: 3.2118\n",
      "Step 458/100000 MLoss: 2.2396 GLoss: 0.9677 Sum: 3.2073\n",
      "Step 459/100000 MLoss: 2.2488 GLoss: 0.9512 Sum: 3.2\n",
      "Step 460/100000 MLoss: 2.3724 GLoss: 0.948 Sum: 3.3204\n",
      "Step 461/100000 MLoss: 2.3101 GLoss: 0.9668 Sum: 3.2769\n",
      "Step 462/100000 MLoss: 2.2392 GLoss: 0.9597 Sum: 3.1989\n",
      "Step 463/100000 MLoss: 2.3426 GLoss: 1.0134 Sum: 3.356\n",
      "Step 464/100000 MLoss: 2.3834 GLoss: 1.0003 Sum: 3.3837\n",
      "Step 465/100000 MLoss: 2.3988 GLoss: 0.9652 Sum: 3.364\n",
      "Step 466/100000 MLoss: 2.389 GLoss: 0.9706 Sum: 3.3596\n",
      "Step 467/100000 MLoss: 2.3166 GLoss: 0.9541 Sum: 3.2707\n",
      "Step 468/100000 MLoss: 2.3352 GLoss: 0.9662 Sum: 3.3014\n",
      "Step 469/100000 MLoss: 2.4424 GLoss: 0.9744 Sum: 3.4168000000000003\n",
      "Step 470/100000 MLoss: 2.108 GLoss: 0.9623 Sum: 3.0703\n",
      "Step 471/100000 MLoss: 2.4067 GLoss: 0.964 Sum: 3.3707\n",
      "Step 472/100000 MLoss: 2.2788 GLoss: 0.9613 Sum: 3.2401\n",
      "Step 473/100000 MLoss: 2.3405 GLoss: 0.966 Sum: 3.3064999999999998\n",
      "Step 474/100000 MLoss: 2.3077 GLoss: 0.9423 Sum: 3.25\n",
      "Step 475/100000 MLoss: 2.3461 GLoss: 0.9793 Sum: 3.3253999999999997\n",
      "Step 476/100000 MLoss: 2.4373 GLoss: 0.969 Sum: 3.4063\n",
      "Step 477/100000 MLoss: 2.2713 GLoss: 0.9586 Sum: 3.2299\n",
      "Step 478/100000 MLoss: 2.2888 GLoss: 0.9529 Sum: 3.2417000000000002\n",
      "Step 479/100000 MLoss: 2.3445 GLoss: 0.9472 Sum: 3.2917\n",
      "Step 480/100000 MLoss: 2.391 GLoss: 0.9305 Sum: 3.3215\n",
      "Step 481/100000 MLoss: 2.3093 GLoss: 0.962 Sum: 3.2713\n",
      "Step 482/100000 MLoss: 2.4261 GLoss: 0.9451 Sum: 3.3712\n",
      "Step 483/100000 MLoss: 2.2422 GLoss: 0.9794 Sum: 3.2216\n",
      "Step 484/100000 MLoss: 2.3463 GLoss: 0.9749 Sum: 3.3211999999999997\n",
      "Step 485/100000 MLoss: 2.2815 GLoss: 0.9558 Sum: 3.2373\n",
      "Step 486/100000 MLoss: 2.3101 GLoss: 0.9788 Sum: 3.2889\n",
      "Step 487/100000 MLoss: 2.333 GLoss: 0.9803 Sum: 3.3133\n",
      "Step 488/100000 MLoss: 2.3382 GLoss: 0.9679 Sum: 3.3061\n",
      "Step 489/100000 MLoss: 2.3683 GLoss: 0.9474 Sum: 3.3157\n",
      "Step 490/100000 MLoss: 2.2375 GLoss: 0.9301 Sum: 3.1675999999999997\n",
      "Step 491/100000 MLoss: 2.2478 GLoss: 0.9519 Sum: 3.1997\n",
      "Step 492/100000 MLoss: 2.3563 GLoss: 0.9627 Sum: 3.319\n",
      "Step 493/100000 MLoss: 2.251 GLoss: 0.9563 Sum: 3.2073\n",
      "Step 494/100000 MLoss: 2.2264 GLoss: 0.961 Sum: 3.1874\n",
      "Step 495/100000 MLoss: 2.268 GLoss: 0.9615 Sum: 3.2295\n",
      "Step 496/100000 MLoss: 2.3505 GLoss: 0.9483 Sum: 3.2988\n",
      "Step 497/100000 MLoss: 2.3183 GLoss: 0.9451 Sum: 3.2634\n",
      "Step 498/100000 MLoss: 2.3058 GLoss: 0.9454 Sum: 3.2512\n",
      "Step 499/100000 MLoss: 2.2772 GLoss: 0.9383 Sum: 3.2155\n",
      "Step 500/100000 MLoss: 2.3389 GLoss: 0.9516 Sum: 3.2905\n",
      "Step 501/100000 MLoss: 2.2421 GLoss: 0.9822 Sum: 3.2243000000000004\n",
      "Step 502/100000 MLoss: 2.2448 GLoss: 0.9395 Sum: 3.1843000000000004\n",
      "Step 503/100000 MLoss: 2.2398 GLoss: 0.951 Sum: 3.1908\n",
      "Step 504/100000 MLoss: 2.2642 GLoss: 0.9572 Sum: 3.2214\n",
      "Step 505/100000 MLoss: 2.3232 GLoss: 0.9292 Sum: 3.2523999999999997\n",
      "Step 506/100000 MLoss: 2.2911 GLoss: 0.9791 Sum: 3.2702\n",
      "Step 507/100000 MLoss: 2.3208 GLoss: 0.9487 Sum: 3.2695000000000003\n",
      "Step 508/100000 MLoss: 2.273 GLoss: 0.9719 Sum: 3.2449000000000003\n",
      "Step 509/100000 MLoss: 2.3666 GLoss: 0.9531 Sum: 3.3197\n",
      "Step 510/100000 MLoss: 2.3924 GLoss: 0.9242 Sum: 3.3165999999999998\n",
      "Step 511/100000 MLoss: 2.2974 GLoss: 0.9506 Sum: 3.248\n",
      "Step 512/100000 MLoss: 2.2105 GLoss: 0.9443 Sum: 3.1548000000000003\n",
      "Step 513/100000 MLoss: 2.3269 GLoss: 0.9399 Sum: 3.2668\n",
      "Step 514/100000 MLoss: 2.2716 GLoss: 0.9579 Sum: 3.2295\n",
      "Step 515/100000 MLoss: 2.3071 GLoss: 0.927 Sum: 3.2341\n",
      "Step 516/100000 MLoss: 2.2475 GLoss: 0.9649 Sum: 3.2124\n",
      "Step 517/100000 MLoss: 2.2649 GLoss: 0.9566 Sum: 3.2215\n",
      "Step 518/100000 MLoss: 2.2879 GLoss: 0.9447 Sum: 3.2326\n",
      "Step 519/100000 MLoss: 2.2111 GLoss: 0.9461 Sum: 3.1572\n",
      "Step 520/100000 MLoss: 2.2297 GLoss: 0.9443 Sum: 3.174\n",
      "Step 521/100000 MLoss: 2.1527 GLoss: 0.9498 Sum: 3.1025\n",
      "Step 522/100000 MLoss: 2.3304 GLoss: 0.9566 Sum: 3.287\n",
      "Step 523/100000 MLoss: 2.251 GLoss: 0.9548 Sum: 3.2058\n",
      "Step 524/100000 MLoss: 2.3185 GLoss: 0.9336 Sum: 3.2520999999999995\n",
      "Step 525/100000 MLoss: 2.3721 GLoss: 0.9579 Sum: 3.33\n",
      "Step 526/100000 MLoss: 2.1802 GLoss: 0.9211 Sum: 3.1013\n",
      "Step 527/100000 MLoss: 2.3361 GLoss: 0.9651 Sum: 3.3012\n",
      "Step 528/100000 MLoss: 2.319 GLoss: 0.9243 Sum: 3.2433\n",
      "Step 529/100000 MLoss: 2.2815 GLoss: 0.9972 Sum: 3.2786999999999997\n",
      "Step 530/100000 MLoss: 2.1477 GLoss: 0.9478 Sum: 3.0955\n",
      "Step 531/100000 MLoss: 2.3078 GLoss: 0.9203 Sum: 3.2281\n",
      "Step 532/100000 MLoss: 2.3366 GLoss: 0.9518 Sum: 3.2883999999999998\n",
      "Step 533/100000 MLoss: 2.2571 GLoss: 0.9364 Sum: 3.1935\n",
      "Step 534/100000 MLoss: 2.2942 GLoss: 0.9571 Sum: 3.2513\n",
      "Step 535/100000 MLoss: 2.3375 GLoss: 0.9483 Sum: 3.2858\n",
      "Step 536/100000 MLoss: 2.2781 GLoss: 0.9524 Sum: 3.2304999999999997\n",
      "Step 537/100000 MLoss: 2.2635 GLoss: 0.9558 Sum: 3.2193\n",
      "Step 538/100000 MLoss: 2.2804 GLoss: 0.9309 Sum: 3.2113\n",
      "Step 539/100000 MLoss: 2.3307 GLoss: 0.9529 Sum: 3.2836000000000003\n",
      "Step 540/100000 MLoss: 2.1505 GLoss: 1.0056 Sum: 3.1561000000000003\n",
      "Step 541/100000 MLoss: 2.325 GLoss: 0.9659 Sum: 3.2909\n",
      "Step 542/100000 MLoss: 2.3112 GLoss: 0.9391 Sum: 3.2503\n",
      "Step 543/100000 MLoss: 2.3123 GLoss: 0.9461 Sum: 3.2584\n",
      "Step 544/100000 MLoss: 2.2611 GLoss: 0.9603 Sum: 3.2214\n",
      "Step 545/100000 MLoss: 2.2497 GLoss: 0.9574 Sum: 3.2070999999999996\n",
      "Step 546/100000 MLoss: 2.3962 GLoss: 0.9443 Sum: 3.3405\n",
      "Step 547/100000 MLoss: 2.3238 GLoss: 0.9496 Sum: 3.2733999999999996\n",
      "Step 548/100000 MLoss: 2.3704 GLoss: 0.9588 Sum: 3.3292\n",
      "Step 549/100000 MLoss: 2.3069 GLoss: 0.9415 Sum: 3.2484\n",
      "Step 550/100000 MLoss: 2.2689 GLoss: 0.9343 Sum: 3.2032\n",
      "Step 551/100000 MLoss: 2.3047 GLoss: 0.9292 Sum: 3.2339\n",
      "Step 552/100000 MLoss: 2.2431 GLoss: 0.9534 Sum: 3.1965000000000003\n",
      "Step 553/100000 MLoss: 2.2777 GLoss: 0.9355 Sum: 3.2131999999999996\n",
      "Step 554/100000 MLoss: 2.365 GLoss: 0.962 Sum: 3.327\n",
      "Step 555/100000 MLoss: 2.3025 GLoss: 0.9328 Sum: 3.2353\n",
      "Step 556/100000 MLoss: 2.2336 GLoss: 0.9401 Sum: 3.1737\n",
      "Step 557/100000 MLoss: 2.1859 GLoss: 0.9473 Sum: 3.1332000000000004\n",
      "Step 558/100000 MLoss: 2.1914 GLoss: 0.9601 Sum: 3.1514999999999995\n",
      "Step 559/100000 MLoss: 2.3295 GLoss: 0.9415 Sum: 3.271\n",
      "Step 560/100000 MLoss: 2.4733 GLoss: 0.9505 Sum: 3.4238\n",
      "Step 561/100000 MLoss: 2.1728 GLoss: 0.9278 Sum: 3.1006\n",
      "Step 562/100000 MLoss: 2.355 GLoss: 0.9478 Sum: 3.3028\n",
      "Step 563/100000 MLoss: 2.2228 GLoss: 0.9358 Sum: 3.1586\n",
      "Step 564/100000 MLoss: 2.3334 GLoss: 0.9395 Sum: 3.2729\n",
      "Step 565/100000 MLoss: 2.2483 GLoss: 0.946 Sum: 3.1943\n",
      "Step 566/100000 MLoss: 2.2133 GLoss: 0.9416 Sum: 3.1548999999999996\n",
      "Step 567/100000 MLoss: 2.2869 GLoss: 0.9225 Sum: 3.2094\n",
      "Step 568/100000 MLoss: 2.2359 GLoss: 0.9312 Sum: 3.1671\n",
      "Step 569/100000 MLoss: 2.3609 GLoss: 0.9227 Sum: 3.2836\n",
      "Step 570/100000 MLoss: 2.224 GLoss: 0.945 Sum: 3.169\n",
      "Step 571/100000 MLoss: 2.2424 GLoss: 0.9311 Sum: 3.1734999999999998\n",
      "Step 572/100000 MLoss: 2.2713 GLoss: 1.0218 Sum: 3.2931\n",
      "Step 573/100000 MLoss: 2.2412 GLoss: 0.9388 Sum: 3.18\n",
      "Step 574/100000 MLoss: 2.3349 GLoss: 0.9452 Sum: 3.2801\n",
      "Step 575/100000 MLoss: 2.171 GLoss: 0.9576 Sum: 3.1285999999999996\n",
      "Step 576/100000 MLoss: 2.1585 GLoss: 0.9323 Sum: 3.0908\n",
      "Step 577/100000 MLoss: 2.2604 GLoss: 0.9235 Sum: 3.1839000000000004\n",
      "Step 578/100000 MLoss: 2.253 GLoss: 0.9369 Sum: 3.1899\n",
      "Step 579/100000 MLoss: 2.2327 GLoss: 0.9214 Sum: 3.1540999999999997\n",
      "Step 580/100000 MLoss: 2.3097 GLoss: 0.9251 Sum: 3.2348\n",
      "Step 581/100000 MLoss: 2.2343 GLoss: 0.9377 Sum: 3.172\n",
      "Step 582/100000 MLoss: 2.2098 GLoss: 0.9184 Sum: 3.1282\n",
      "Step 583/100000 MLoss: 2.2754 GLoss: 0.9239 Sum: 3.1993\n",
      "Step 584/100000 MLoss: 2.3526 GLoss: 0.914 Sum: 3.2666\n",
      "Step 585/100000 MLoss: 2.262 GLoss: 0.9304 Sum: 3.1924\n",
      "Step 586/100000 MLoss: 2.2241 GLoss: 0.9134 Sum: 3.1375\n",
      "Step 587/100000 MLoss: 2.3067 GLoss: 0.9042 Sum: 3.2109\n",
      "Step 588/100000 MLoss: 2.2812 GLoss: 0.9071 Sum: 3.1883\n",
      "Step 589/100000 MLoss: 2.3327 GLoss: 1.004 Sum: 3.3367\n",
      "Step 590/100000 MLoss: 2.197 GLoss: 0.909 Sum: 3.106\n",
      "Step 591/100000 MLoss: 2.3732 GLoss: 1.2678 Sum: 3.641\n",
      "Step 592/100000 MLoss: 2.29 GLoss: 1.0093 Sum: 3.2993\n",
      "Step 593/100000 MLoss: 2.2905 GLoss: 0.9468 Sum: 3.2373000000000003\n",
      "Step 594/100000 MLoss: 2.3037 GLoss: 0.9536 Sum: 3.2573\n",
      "Step 595/100000 MLoss: 2.32 GLoss: 0.9527 Sum: 3.2727\n",
      "Step 596/100000 MLoss: 2.2775 GLoss: 0.9358 Sum: 3.2133\n",
      "Step 597/100000 MLoss: 2.389 GLoss: 0.9524 Sum: 3.3413999999999997\n",
      "Step 598/100000 MLoss: 2.4261 GLoss: 0.9375 Sum: 3.3636\n",
      "Step 599/100000 MLoss: 2.3358 GLoss: 0.9916 Sum: 3.3274\n",
      "Step 600/100000 MLoss: 2.2641 GLoss: 0.9595 Sum: 3.2236000000000002\n",
      "Step 601/100000 MLoss: 2.3588 GLoss: 0.9464 Sum: 3.3052\n",
      "Step 602/100000 MLoss: 2.2936 GLoss: 0.9438 Sum: 3.2374\n",
      "Step 603/100000 MLoss: 2.2562 GLoss: 0.9471 Sum: 3.2033000000000005\n",
      "Step 604/100000 MLoss: 2.295 GLoss: 0.9449 Sum: 3.2399\n",
      "Step 605/100000 MLoss: 2.3452 GLoss: 0.9656 Sum: 3.3108000000000004\n",
      "Step 606/100000 MLoss: 2.3077 GLoss: 0.9452 Sum: 3.2529000000000003\n",
      "Step 607/100000 MLoss: 2.245 GLoss: 0.9508 Sum: 3.1958\n",
      "Step 608/100000 MLoss: 2.2292 GLoss: 0.928 Sum: 3.1572\n",
      "Step 609/100000 MLoss: 2.2939 GLoss: 0.9341 Sum: 3.2279999999999998\n",
      "Step 610/100000 MLoss: 2.1117 GLoss: 0.9126 Sum: 3.0242999999999998\n",
      "Step 611/100000 MLoss: 2.2836 GLoss: 0.9569 Sum: 3.2405\n",
      "Step 612/100000 MLoss: 2.3137 GLoss: 0.9394 Sum: 3.2531\n",
      "Step 613/100000 MLoss: 2.3122 GLoss: 0.9279 Sum: 3.2401\n",
      "Step 614/100000 MLoss: 2.3409 GLoss: 0.9438 Sum: 3.2847\n",
      "Step 615/100000 MLoss: 2.2545 GLoss: 0.9273 Sum: 3.1818\n",
      "Step 616/100000 MLoss: 2.2421 GLoss: 0.9281 Sum: 3.1702000000000004\n",
      "Step 617/100000 MLoss: 2.257 GLoss: 0.9106 Sum: 3.1676\n",
      "Step 618/100000 MLoss: 2.2862 GLoss: 0.9227 Sum: 3.2089\n",
      "Step 619/100000 MLoss: 2.1059 GLoss: 0.921 Sum: 3.0269000000000004\n",
      "Step 620/100000 MLoss: 2.1108 GLoss: 0.9197 Sum: 3.0305\n",
      "Step 621/100000 MLoss: 2.3019 GLoss: 0.9078 Sum: 3.2096999999999998\n",
      "Step 622/100000 MLoss: 2.2951 GLoss: 0.9677 Sum: 3.2628000000000004\n",
      "Step 623/100000 MLoss: 2.2765 GLoss: 0.9075 Sum: 3.184\n",
      "Step 624/100000 MLoss: 2.2221 GLoss: 0.9746 Sum: 3.1967000000000003\n",
      "Step 625/100000 MLoss: 2.4206 GLoss: 0.9746 Sum: 3.3952\n",
      "Step 626/100000 MLoss: 2.2491 GLoss: 0.9464 Sum: 3.1955\n",
      "Step 627/100000 MLoss: 2.2722 GLoss: 0.9545 Sum: 3.2267\n",
      "Step 628/100000 MLoss: 2.3378 GLoss: 0.9355 Sum: 3.2733\n",
      "Step 629/100000 MLoss: 2.3172 GLoss: 0.9369 Sum: 3.2541\n",
      "Step 630/100000 MLoss: 2.0968 GLoss: 0.9533 Sum: 3.0501\n",
      "Step 631/100000 MLoss: 2.3142 GLoss: 0.9445 Sum: 3.2587\n",
      "Step 632/100000 MLoss: 2.2407 GLoss: 0.944 Sum: 3.1847\n",
      "Step 633/100000 MLoss: 2.4614 GLoss: 0.9268 Sum: 3.3882\n",
      "Step 634/100000 MLoss: 2.2439 GLoss: 0.9607 Sum: 3.2046\n",
      "Step 635/100000 MLoss: 2.307 GLoss: 0.9661 Sum: 3.2731\n",
      "Step 636/100000 MLoss: 2.4438 GLoss: 0.9985 Sum: 3.4423\n",
      "Step 637/100000 MLoss: 2.2418 GLoss: 0.9673 Sum: 3.2091000000000003\n",
      "Step 638/100000 MLoss: 2.3041 GLoss: 0.9381 Sum: 3.2422\n",
      "Step 639/100000 MLoss: 2.3081 GLoss: 0.9412 Sum: 3.2493\n",
      "Step 640/100000 MLoss: 2.1921 GLoss: 0.9614 Sum: 3.1535\n",
      "Step 641/100000 MLoss: 2.2818 GLoss: 0.949 Sum: 3.2308\n",
      "Step 642/100000 MLoss: 2.209 GLoss: 0.9379 Sum: 3.1469\n",
      "Step 643/100000 MLoss: 2.39 GLoss: 0.9315 Sum: 3.3215000000000003\n",
      "Step 644/100000 MLoss: 2.3647 GLoss: 0.9278 Sum: 3.2925\n",
      "Step 645/100000 MLoss: 2.3459 GLoss: 0.9183 Sum: 3.2641999999999998\n",
      "Step 646/100000 MLoss: 2.2685 GLoss: 1.0731 Sum: 3.3415999999999997\n",
      "Step 647/100000 MLoss: 2.3786 GLoss: 1.031 Sum: 3.4096\n",
      "Step 648/100000 MLoss: 2.2618 GLoss: 0.9545 Sum: 3.2163\n",
      "Step 649/100000 MLoss: 2.3884 GLoss: 0.9248 Sum: 3.3131999999999997\n",
      "Step 650/100000 MLoss: 2.0877 GLoss: 0.9123 Sum: 3.0\n",
      "Step 651/100000 MLoss: 2.2273 GLoss: 0.916 Sum: 3.1433\n",
      "Step 652/100000 MLoss: 2.2016 GLoss: 0.9142 Sum: 3.1158\n",
      "Step 653/100000 MLoss: 2.1863 GLoss: 0.9147 Sum: 3.101\n",
      "Step 654/100000 MLoss: 2.197 GLoss: 0.9244 Sum: 3.1214\n",
      "Step 655/100000 MLoss: 2.306 GLoss: 0.8963 Sum: 3.2023\n",
      "Step 656/100000 MLoss: 2.2713 GLoss: 1.0285 Sum: 3.2998000000000003\n",
      "Step 657/100000 MLoss: 2.3411 GLoss: 0.9309 Sum: 3.272\n",
      "Step 658/100000 MLoss: 2.2879 GLoss: 1.0143 Sum: 3.3022\n",
      "Step 659/100000 MLoss: 2.2441 GLoss: 1.0148 Sum: 3.2588999999999997\n",
      "Step 660/100000 MLoss: 2.3774 GLoss: 0.9142 Sum: 3.2916000000000003\n",
      "Step 661/100000 MLoss: 2.269 GLoss: 0.9288 Sum: 3.1978\n",
      "Step 662/100000 MLoss: 2.2783 GLoss: 0.9234 Sum: 3.2017\n",
      "Step 663/100000 MLoss: 2.241 GLoss: 0.9411 Sum: 3.1821\n",
      "Step 664/100000 MLoss: 2.3588 GLoss: 0.9467 Sum: 3.3055\n",
      "Step 665/100000 MLoss: 2.149 GLoss: 0.9198 Sum: 3.0688\n",
      "Step 666/100000 MLoss: 2.2725 GLoss: 0.936 Sum: 3.2085\n",
      "Step 667/100000 MLoss: 2.2498 GLoss: 0.9213 Sum: 3.1711\n",
      "Step 668/100000 MLoss: 2.3537 GLoss: 0.9561 Sum: 3.3098\n",
      "Step 669/100000 MLoss: 2.2639 GLoss: 0.9269 Sum: 3.1908\n",
      "Step 670/100000 MLoss: 2.0521 GLoss: 0.921 Sum: 2.9730999999999996\n",
      "Step 671/100000 MLoss: 2.3093 GLoss: 0.916 Sum: 3.2253\n",
      "Step 672/100000 MLoss: 2.3999 GLoss: 0.941 Sum: 3.3409\n",
      "Step 673/100000 MLoss: 2.242 GLoss: 0.9302 Sum: 3.1722\n",
      "Step 674/100000 MLoss: 2.2276 GLoss: 0.9105 Sum: 3.1380999999999997\n",
      "Step 675/100000 MLoss: 2.342 GLoss: 0.9235 Sum: 3.2655000000000003\n",
      "Step 676/100000 MLoss: 2.2145 GLoss: 0.9167 Sum: 3.1312\n",
      "Step 677/100000 MLoss: 2.2304 GLoss: 0.9235 Sum: 3.1539\n",
      "Step 678/100000 MLoss: 2.1622 GLoss: 0.9013 Sum: 3.0635\n",
      "Step 679/100000 MLoss: 2.2066 GLoss: 0.9204 Sum: 3.127\n",
      "Step 680/100000 MLoss: 2.5442 GLoss: 0.9897 Sum: 3.5339\n",
      "Step 681/100000 MLoss: 2.3435 GLoss: 0.9034 Sum: 3.2469\n",
      "Step 682/100000 MLoss: 2.3191 GLoss: 0.9458 Sum: 3.2649\n",
      "Step 683/100000 MLoss: 2.3323 GLoss: 0.9763 Sum: 3.3086\n",
      "Step 684/100000 MLoss: 2.2398 GLoss: 0.8927 Sum: 3.1325\n",
      "Step 685/100000 MLoss: 2.3206 GLoss: 0.9219 Sum: 3.2425\n",
      "Step 686/100000 MLoss: 2.3268 GLoss: 0.9311 Sum: 3.2579000000000002\n",
      "Step 687/100000 MLoss: 2.3387 GLoss: 0.9092 Sum: 3.2478999999999996\n",
      "Step 688/100000 MLoss: 2.2736 GLoss: 0.905 Sum: 3.1786000000000003\n",
      "Step 689/100000 MLoss: 2.336 GLoss: 0.9082 Sum: 3.2441999999999998\n",
      "Step 690/100000 MLoss: 2.0921 GLoss: 0.8837 Sum: 2.9758\n",
      "Step 691/100000 MLoss: 2.2608 GLoss: 0.8898 Sum: 3.1506000000000003\n",
      "Step 692/100000 MLoss: 2.3044 GLoss: 0.8852 Sum: 3.1895999999999995\n",
      "Step 693/100000 MLoss: 2.253 GLoss: 0.8842 Sum: 3.1372\n",
      "Step 694/100000 MLoss: 2.2486 GLoss: 0.9029 Sum: 3.1515000000000004\n",
      "Step 695/100000 MLoss: 2.2999 GLoss: 0.8886 Sum: 3.1885\n",
      "Step 696/100000 MLoss: 2.2313 GLoss: 0.8881 Sum: 3.1194\n",
      "Step 697/100000 MLoss: 2.2205 GLoss: 0.8847 Sum: 3.1052\n",
      "Step 698/100000 MLoss: 2.3053 GLoss: 0.8926 Sum: 3.1978999999999997\n",
      "Step 699/100000 MLoss: 2.3216 GLoss: 0.8788 Sum: 3.2004\n",
      "Step 700/100000 MLoss: 2.2001 GLoss: 0.8746 Sum: 3.0747\n",
      "Step 701/100000 MLoss: 2.3612 GLoss: 0.8756 Sum: 3.2368\n",
      "Step 702/100000 MLoss: 2.2681 GLoss: 0.8827 Sum: 3.1508000000000003\n",
      "Step 703/100000 MLoss: 2.2024 GLoss: 0.9165 Sum: 3.1189\n",
      "Step 704/100000 MLoss: 2.1958 GLoss: 0.8579 Sum: 3.0537\n",
      "Step 705/100000 MLoss: 2.3776 GLoss: 1.0121 Sum: 3.3897000000000004\n",
      "Step 706/100000 MLoss: 2.4179 GLoss: 0.9345 Sum: 3.3524\n",
      "Step 707/100000 MLoss: 2.3632 GLoss: 0.9221 Sum: 3.2853\n",
      "Step 708/100000 MLoss: 2.3494 GLoss: 0.9186 Sum: 3.2680000000000002\n",
      "Step 709/100000 MLoss: 2.2955 GLoss: 0.9309 Sum: 3.2264\n",
      "Step 710/100000 MLoss: 2.3328 GLoss: 0.9036 Sum: 3.2364\n",
      "Step 711/100000 MLoss: 2.2844 GLoss: 0.9085 Sum: 3.1929000000000003\n",
      "Step 712/100000 MLoss: 2.3374 GLoss: 0.9443 Sum: 3.2817000000000003\n",
      "Step 713/100000 MLoss: 2.3002 GLoss: 0.9401 Sum: 3.2403\n",
      "Step 714/100000 MLoss: 2.3056 GLoss: 0.9498 Sum: 3.2554\n",
      "Step 715/100000 MLoss: 2.3232 GLoss: 0.9443 Sum: 3.2675\n",
      "Step 716/100000 MLoss: 2.3147 GLoss: 0.9192 Sum: 3.2339\n",
      "Step 717/100000 MLoss: 2.2869 GLoss: 0.9186 Sum: 3.2055000000000002\n",
      "Step 718/100000 MLoss: 2.1436 GLoss: 0.9229 Sum: 3.0665000000000004\n",
      "Step 719/100000 MLoss: 2.2839 GLoss: 0.9064 Sum: 3.1903\n",
      "Step 720/100000 MLoss: 2.4743 GLoss: 0.927 Sum: 3.4013\n",
      "Step 721/100000 MLoss: 2.2934 GLoss: 0.9068 Sum: 3.2002\n",
      "Step 722/100000 MLoss: 2.3223 GLoss: 0.905 Sum: 3.2272999999999996\n",
      "Step 723/100000 MLoss: 2.3328 GLoss: 0.9067 Sum: 3.2395\n",
      "Step 724/100000 MLoss: 2.2401 GLoss: 0.9018 Sum: 3.1419\n",
      "Step 725/100000 MLoss: 2.4095 GLoss: 0.8919 Sum: 3.3014\n",
      "Step 726/100000 MLoss: 2.2601 GLoss: 0.8955 Sum: 3.1555999999999997\n",
      "Step 727/100000 MLoss: 2.1711 GLoss: 0.8953 Sum: 3.0664\n",
      "Step 728/100000 MLoss: 2.2881 GLoss: 0.9175 Sum: 3.2056\n",
      "Step 729/100000 MLoss: 2.1438 GLoss: 0.8698 Sum: 3.0136000000000003\n",
      "Step 730/100000 MLoss: 2.2516 GLoss: 0.9188 Sum: 3.1704\n",
      "Step 731/100000 MLoss: 2.1597 GLoss: 0.8821 Sum: 3.0418\n",
      "Step 732/100000 MLoss: 2.2907 GLoss: 0.8647 Sum: 3.1554\n",
      "Step 733/100000 MLoss: 2.2637 GLoss: 0.8873 Sum: 3.151\n",
      "Step 734/100000 MLoss: 2.199 GLoss: 0.8703 Sum: 3.0692999999999997\n",
      "Step 735/100000 MLoss: 2.2474 GLoss: 0.8752 Sum: 3.1226\n",
      "Step 736/100000 MLoss: 2.2114 GLoss: 0.9298 Sum: 3.1411999999999995\n",
      "Step 737/100000 MLoss: 2.189 GLoss: 0.8774 Sum: 3.0664\n",
      "Step 738/100000 MLoss: 2.2094 GLoss: 0.9952 Sum: 3.2046\n",
      "Step 739/100000 MLoss: 2.3612 GLoss: 0.9927 Sum: 3.3539000000000003\n",
      "Step 740/100000 MLoss: 2.3403 GLoss: 0.8892 Sum: 3.2295\n",
      "Step 741/100000 MLoss: 2.3331 GLoss: 0.9226 Sum: 3.2557\n",
      "Step 742/100000 MLoss: 2.2968 GLoss: 0.933 Sum: 3.2298\n",
      "Step 743/100000 MLoss: 2.3021 GLoss: 0.9068 Sum: 3.2089\n",
      "Step 744/100000 MLoss: 2.184 GLoss: 0.9411 Sum: 3.1251\n",
      "Step 745/100000 MLoss: 2.3336 GLoss: 0.9865 Sum: 3.3201\n",
      "Step 746/100000 MLoss: 2.3559 GLoss: 0.9159 Sum: 3.2718000000000003\n",
      "Step 747/100000 MLoss: 2.3647 GLoss: 0.9026 Sum: 3.2673\n",
      "Step 748/100000 MLoss: 2.1355 GLoss: 0.9313 Sum: 3.0667999999999997\n",
      "Step 749/100000 MLoss: 2.2454 GLoss: 0.9205 Sum: 3.1659\n",
      "Step 750/100000 MLoss: 2.0742 GLoss: 0.9054 Sum: 2.9795999999999996\n",
      "Step 751/100000 MLoss: 2.1712 GLoss: 0.9057 Sum: 3.0768999999999997\n",
      "Step 752/100000 MLoss: 2.3639 GLoss: 0.9139 Sum: 3.2778\n",
      "Step 753/100000 MLoss: 2.238 GLoss: 0.9151 Sum: 3.1531000000000002\n",
      "Step 754/100000 MLoss: 2.2141 GLoss: 0.8929 Sum: 3.107\n",
      "Step 755/100000 MLoss: 2.2114 GLoss: 1.0318 Sum: 3.2432\n",
      "Step 756/100000 MLoss: 2.2874 GLoss: 0.9214 Sum: 3.2088\n",
      "Step 757/100000 MLoss: 2.2775 GLoss: 0.8769 Sum: 3.1544\n",
      "Step 758/100000 MLoss: 2.3861 GLoss: 0.9185 Sum: 3.3045999999999998\n",
      "Step 759/100000 MLoss: 2.2166 GLoss: 0.8859 Sum: 3.1025\n",
      "Step 760/100000 MLoss: 2.2298 GLoss: 0.9054 Sum: 3.1352\n",
      "Step 761/100000 MLoss: 2.2454 GLoss: 0.8996 Sum: 3.145\n",
      "Step 762/100000 MLoss: 2.2787 GLoss: 0.9018 Sum: 3.1805000000000003\n",
      "Step 763/100000 MLoss: 2.3699 GLoss: 0.8887 Sum: 3.2586\n",
      "Step 764/100000 MLoss: 2.29 GLoss: 0.8867 Sum: 3.1767000000000003\n",
      "Step 765/100000 MLoss: 2.2065 GLoss: 0.8906 Sum: 3.0971\n",
      "Step 766/100000 MLoss: 2.1806 GLoss: 0.9028 Sum: 3.0834\n",
      "Step 767/100000 MLoss: 2.1991 GLoss: 0.8911 Sum: 3.0902000000000003\n",
      "Step 768/100000 MLoss: 2.2112 GLoss: 0.8863 Sum: 3.0974999999999997\n",
      "Step 769/100000 MLoss: 2.1397 GLoss: 0.8737 Sum: 3.0134\n",
      "Step 770/100000 MLoss: 2.1127 GLoss: 0.8557 Sum: 2.9684\n",
      "Step 771/100000 MLoss: 2.1839 GLoss: 0.8749 Sum: 3.0587999999999997\n",
      "Step 772/100000 MLoss: 2.3303 GLoss: 0.8927 Sum: 3.223\n",
      "Step 773/100000 MLoss: 2.2794 GLoss: 0.866 Sum: 3.1454\n",
      "Step 774/100000 MLoss: 2.2112 GLoss: 0.8859 Sum: 3.0970999999999997\n",
      "Step 775/100000 MLoss: 2.2379 GLoss: 0.8794 Sum: 3.1172999999999997\n",
      "Step 776/100000 MLoss: 2.3787 GLoss: 0.8795 Sum: 3.2581999999999995\n",
      "Step 777/100000 MLoss: 2.2599 GLoss: 0.8755 Sum: 3.1353999999999997\n",
      "Step 778/100000 MLoss: 2.2312 GLoss: 0.8684 Sum: 3.0995999999999997\n",
      "Step 779/100000 MLoss: 2.279 GLoss: 0.8842 Sum: 3.1632\n",
      "Step 780/100000 MLoss: 2.1626 GLoss: 0.8805 Sum: 3.0431\n",
      "Step 781/100000 MLoss: 2.2703 GLoss: 0.8799 Sum: 3.1502000000000003\n",
      "Step 782/100000 MLoss: 2.1261 GLoss: 0.8702 Sum: 2.9963\n",
      "Step 783/100000 MLoss: 2.2291 GLoss: 0.9096 Sum: 3.1387\n",
      "Step 784/100000 MLoss: 2.2229 GLoss: 0.8684 Sum: 3.0913\n",
      "Step 785/100000 MLoss: 2.3523 GLoss: 0.859 Sum: 3.2113\n",
      "Step 786/100000 MLoss: 2.2887 GLoss: 0.875 Sum: 3.1637\n",
      "Step 787/100000 MLoss: 2.1906 GLoss: 0.8573 Sum: 3.0479\n",
      "Step 788/100000 MLoss: 2.2259 GLoss: 0.873 Sum: 3.0989000000000004\n",
      "Step 789/100000 MLoss: 2.2407 GLoss: 0.8788 Sum: 3.1195\n",
      "Step 790/100000 MLoss: 2.2898 GLoss: 0.8893 Sum: 3.1791\n",
      "Step 791/100000 MLoss: 2.2591 GLoss: 0.8763 Sum: 3.1354\n",
      "Step 792/100000 MLoss: 2.3225 GLoss: 0.8796 Sum: 3.2020999999999997\n",
      "Step 793/100000 MLoss: 2.2291 GLoss: 0.8532 Sum: 3.0823\n",
      "Step 794/100000 MLoss: 2.1967 GLoss: 0.87 Sum: 3.0667\n",
      "Step 795/100000 MLoss: 2.2612 GLoss: 0.8765 Sum: 3.1377\n",
      "Step 796/100000 MLoss: 2.3845 GLoss: 0.8662 Sum: 3.2507\n",
      "Step 797/100000 MLoss: 2.3051 GLoss: 0.874 Sum: 3.1791\n",
      "Step 798/100000 MLoss: 2.2197 GLoss: 0.8718 Sum: 3.0915\n",
      "Step 799/100000 MLoss: 2.3405 GLoss: 0.9152 Sum: 3.2557\n",
      "Step 800/100000 MLoss: 2.143 GLoss: 0.8833 Sum: 3.0263\n",
      "Step 801/100000 MLoss: 2.3255 GLoss: 0.8776 Sum: 3.2031\n",
      "Step 802/100000 MLoss: 2.2073 GLoss: 0.8736 Sum: 3.0809\n",
      "Step 803/100000 MLoss: 2.2672 GLoss: 0.8764 Sum: 3.1435999999999997\n",
      "Step 804/100000 MLoss: 2.2784 GLoss: 0.8844 Sum: 3.1628\n",
      "Step 805/100000 MLoss: 2.3211 GLoss: 0.8913 Sum: 3.2123999999999997\n",
      "Step 806/100000 MLoss: 2.2078 GLoss: 0.8727 Sum: 3.0805000000000002\n",
      "Step 807/100000 MLoss: 2.2064 GLoss: 0.9156 Sum: 3.122\n",
      "Step 808/100000 MLoss: 2.3322 GLoss: 0.8757 Sum: 3.2079\n",
      "Step 809/100000 MLoss: 2.3603 GLoss: 0.8887 Sum: 3.249\n",
      "Step 810/100000 MLoss: 2.1723 GLoss: 0.8719 Sum: 3.0442\n",
      "Step 811/100000 MLoss: 2.2038 GLoss: 0.9353 Sum: 3.1391\n",
      "Step 812/100000 MLoss: 2.3059 GLoss: 0.9245 Sum: 3.2304\n",
      "Step 813/100000 MLoss: 2.1445 GLoss: 0.8761 Sum: 3.0206\n",
      "Step 814/100000 MLoss: 2.3284 GLoss: 0.9194 Sum: 3.2478\n",
      "Step 815/100000 MLoss: 2.1492 GLoss: 0.8867 Sum: 3.0359\n",
      "Step 816/100000 MLoss: 2.2373 GLoss: 0.8853 Sum: 3.1226\n",
      "Step 817/100000 MLoss: 2.2243 GLoss: 0.9035 Sum: 3.1277999999999997\n",
      "Step 818/100000 MLoss: 2.3257 GLoss: 0.887 Sum: 3.2127\n",
      "Step 819/100000 MLoss: 2.2977 GLoss: 0.8859 Sum: 3.1835999999999998\n",
      "Step 820/100000 MLoss: 2.0209 GLoss: 0.8696 Sum: 2.8905000000000003\n",
      "Step 821/100000 MLoss: 2.2482 GLoss: 0.9055 Sum: 3.1537\n",
      "Step 822/100000 MLoss: 2.187 GLoss: 0.8807 Sum: 3.0677\n",
      "Step 823/100000 MLoss: 2.2036 GLoss: 0.916 Sum: 3.1195999999999997\n",
      "Step 824/100000 MLoss: 2.2517 GLoss: 0.9199 Sum: 3.1716\n",
      "Step 825/100000 MLoss: 2.1968 GLoss: 0.8775 Sum: 3.0743\n",
      "Step 826/100000 MLoss: 2.3061 GLoss: 0.9347 Sum: 3.2407999999999997\n",
      "Step 827/100000 MLoss: 2.2843 GLoss: 0.9286 Sum: 3.2129\n",
      "Step 828/100000 MLoss: 2.2882 GLoss: 0.8747 Sum: 3.1628999999999996\n",
      "Step 829/100000 MLoss: 2.3343 GLoss: 0.9138 Sum: 3.2481\n",
      "Step 830/100000 MLoss: 2.3786 GLoss: 0.9441 Sum: 3.3227\n",
      "Step 831/100000 MLoss: 2.2355 GLoss: 0.9044 Sum: 3.1399\n",
      "Step 832/100000 MLoss: 2.233 GLoss: 0.8902 Sum: 3.1232\n",
      "Step 833/100000 MLoss: 2.2184 GLoss: 0.9127 Sum: 3.1311\n",
      "Step 834/100000 MLoss: 2.1504 GLoss: 0.9017 Sum: 3.0521\n",
      "Step 835/100000 MLoss: 2.3461 GLoss: 0.8917 Sum: 3.2378\n",
      "Step 836/100000 MLoss: 2.1993 GLoss: 0.8947 Sum: 3.0940000000000003\n",
      "Step 837/100000 MLoss: 2.2601 GLoss: 0.8853 Sum: 3.1454\n",
      "Step 838/100000 MLoss: 2.318 GLoss: 0.8848 Sum: 3.2028\n",
      "Step 839/100000 MLoss: 2.2921 GLoss: 0.8931 Sum: 3.1852\n",
      "Step 840/100000 MLoss: 2.404 GLoss: 0.8911 Sum: 3.2950999999999997\n",
      "Step 841/100000 MLoss: 2.2029 GLoss: 0.8736 Sum: 3.0765000000000002\n",
      "Step 842/100000 MLoss: 2.2618 GLoss: 0.8691 Sum: 3.1309\n",
      "Step 843/100000 MLoss: 2.2709 GLoss: 0.8645 Sum: 3.1354\n",
      "Step 844/100000 MLoss: 2.2596 GLoss: 0.8712 Sum: 3.1308\n",
      "Step 845/100000 MLoss: 2.1804 GLoss: 0.9101 Sum: 3.0905\n",
      "Step 846/100000 MLoss: 2.1846 GLoss: 0.8591 Sum: 3.0437000000000003\n",
      "Step 847/100000 MLoss: 2.4666 GLoss: 0.9989 Sum: 3.4655\n",
      "Step 848/100000 MLoss: 2.3498 GLoss: 1.0145 Sum: 3.3643\n",
      "Step 849/100000 MLoss: 2.2459 GLoss: 0.8834 Sum: 3.1292999999999997\n",
      "Step 850/100000 MLoss: 2.2359 GLoss: 0.9221 Sum: 3.158\n",
      "Step 851/100000 MLoss: 2.3229 GLoss: 0.9638 Sum: 3.2867\n",
      "Step 852/100000 MLoss: 2.2952 GLoss: 0.9436 Sum: 3.2388\n",
      "Step 853/100000 MLoss: 2.2177 GLoss: 0.8926 Sum: 3.1102999999999996\n",
      "Step 854/100000 MLoss: 2.1878 GLoss: 0.9492 Sum: 3.1370000000000005\n",
      "Step 855/100000 MLoss: 2.2335 GLoss: 0.9924 Sum: 3.2258999999999998\n",
      "Step 856/100000 MLoss: 2.4384 GLoss: 0.927 Sum: 3.3654\n",
      "Step 857/100000 MLoss: 2.2558 GLoss: 0.9019 Sum: 3.1576999999999997\n",
      "Step 858/100000 MLoss: 2.2632 GLoss: 0.9228 Sum: 3.186\n",
      "Step 859/100000 MLoss: 2.3919 GLoss: 0.934 Sum: 3.3259000000000003\n",
      "Step 860/100000 MLoss: 2.1301 GLoss: 0.9207 Sum: 3.0508\n",
      "Step 861/100000 MLoss: 2.1325 GLoss: 0.8987 Sum: 3.0312\n",
      "Step 862/100000 MLoss: 2.2618 GLoss: 0.8971 Sum: 3.1589\n",
      "Step 863/100000 MLoss: 2.2032 GLoss: 0.9065 Sum: 3.1096999999999997\n",
      "Step 864/100000 MLoss: 2.2543 GLoss: 0.8849 Sum: 3.1392\n",
      "Step 865/100000 MLoss: 2.2038 GLoss: 0.9021 Sum: 3.1059\n",
      "Step 866/100000 MLoss: 2.2442 GLoss: 0.8967 Sum: 3.1409000000000002\n",
      "Step 867/100000 MLoss: 2.2232 GLoss: 0.8852 Sum: 3.1083999999999996\n",
      "Step 868/100000 MLoss: 2.2104 GLoss: 0.8883 Sum: 3.0987\n",
      "Step 869/100000 MLoss: 2.1957 GLoss: 0.886 Sum: 3.0817\n",
      "Step 870/100000 MLoss: 2.2352 GLoss: 0.8868 Sum: 3.122\n",
      "Step 871/100000 MLoss: 2.3772 GLoss: 0.9377 Sum: 3.3149\n",
      "Step 872/100000 MLoss: 2.2932 GLoss: 0.9121 Sum: 3.2053000000000003\n",
      "Step 873/100000 MLoss: 2.414 GLoss: 0.874 Sum: 3.2880000000000003\n",
      "Step 874/100000 MLoss: 2.1828 GLoss: 0.8899 Sum: 3.0726999999999998\n",
      "Step 875/100000 MLoss: 2.3127 GLoss: 0.8829 Sum: 3.1955999999999998\n",
      "Step 876/100000 MLoss: 2.2426 GLoss: 0.8921 Sum: 3.1347\n",
      "Step 877/100000 MLoss: 2.2143 GLoss: 0.8655 Sum: 3.0798\n",
      "Step 878/100000 MLoss: 2.1938 GLoss: 0.8618 Sum: 3.0556\n",
      "Step 879/100000 MLoss: 2.2035 GLoss: 0.872 Sum: 3.0755\n",
      "Step 880/100000 MLoss: 2.3616 GLoss: 0.8867 Sum: 3.2483000000000004\n",
      "Step 881/100000 MLoss: 2.4053 GLoss: 0.8824 Sum: 3.2877\n",
      "Step 882/100000 MLoss: 2.3196 GLoss: 0.8733 Sum: 3.1929\n",
      "Step 883/100000 MLoss: 2.2629 GLoss: 0.8718 Sum: 3.1347\n",
      "Step 884/100000 MLoss: 2.3002 GLoss: 0.8638 Sum: 3.1639999999999997\n",
      "Step 885/100000 MLoss: 2.2109 GLoss: 0.8713 Sum: 3.0822000000000003\n",
      "Step 886/100000 MLoss: 2.4268 GLoss: 0.8579 Sum: 3.2847\n",
      "Step 887/100000 MLoss: 2.293 GLoss: 0.8894 Sum: 3.1824000000000003\n",
      "Step 888/100000 MLoss: 2.204 GLoss: 0.8575 Sum: 3.0615\n",
      "Step 889/100000 MLoss: 2.2683 GLoss: 0.8755 Sum: 3.1437999999999997\n",
      "Step 890/100000 MLoss: 2.336 GLoss: 0.8751 Sum: 3.2111\n",
      "Step 891/100000 MLoss: 2.1472 GLoss: 0.871 Sum: 3.0182\n",
      "Step 892/100000 MLoss: 2.2115 GLoss: 0.8681 Sum: 3.0796\n",
      "Step 893/100000 MLoss: 2.1802 GLoss: 0.8635 Sum: 3.0437000000000003\n",
      "Step 894/100000 MLoss: 2.1429 GLoss: 0.8632 Sum: 3.0061\n",
      "Step 895/100000 MLoss: 2.2686 GLoss: 0.8818 Sum: 3.1504000000000003\n",
      "Step 896/100000 MLoss: 2.262 GLoss: 0.8761 Sum: 3.1381\n",
      "Step 897/100000 MLoss: 2.2388 GLoss: 0.8725 Sum: 3.1113\n",
      "Step 898/100000 MLoss: 2.1869 GLoss: 0.8463 Sum: 3.0332\n",
      "Step 899/100000 MLoss: 2.2786 GLoss: 0.8773 Sum: 3.1559\n",
      "Step 900/100000 MLoss: 2.3637 GLoss: 0.8766 Sum: 3.2403000000000004\n",
      "Step 901/100000 MLoss: 2.231 GLoss: 0.8984 Sum: 3.1294\n",
      "Step 902/100000 MLoss: 2.1979 GLoss: 0.8843 Sum: 3.0822000000000003\n",
      "Step 903/100000 MLoss: 2.3276 GLoss: 0.8614 Sum: 3.189\n",
      "Step 904/100000 MLoss: 2.2854 GLoss: 0.8603 Sum: 3.1457\n",
      "Step 905/100000 MLoss: 2.2559 GLoss: 0.8752 Sum: 3.1311\n",
      "Step 906/100000 MLoss: 2.1591 GLoss: 0.8702 Sum: 3.0293\n",
      "Step 907/100000 MLoss: 2.2677 GLoss: 0.8555 Sum: 3.1232\n",
      "Step 908/100000 MLoss: 2.1849 GLoss: 0.8631 Sum: 3.048\n",
      "Step 909/100000 MLoss: 2.4486 GLoss: 0.8497 Sum: 3.2983\n",
      "Step 910/100000 MLoss: 2.6589 GLoss: 0.8695 Sum: 3.5284\n",
      "Step 911/100000 MLoss: 2.236 GLoss: 0.8685 Sum: 3.1045000000000003\n",
      "Step 912/100000 MLoss: 2.239 GLoss: 0.8728 Sum: 3.1117999999999997\n",
      "Step 913/100000 MLoss: 2.2696 GLoss: 0.8439 Sum: 3.1135\n",
      "Step 914/100000 MLoss: 2.2529 GLoss: 0.8545 Sum: 3.1074\n",
      "Step 915/100000 MLoss: 2.1875 GLoss: 0.8482 Sum: 3.0357\n",
      "Step 916/100000 MLoss: 2.191 GLoss: 0.8818 Sum: 3.0728\n",
      "Step 917/100000 MLoss: 2.2523 GLoss: 0.8784 Sum: 3.1307\n",
      "Step 918/100000 MLoss: 2.2585 GLoss: 0.8456 Sum: 3.1041000000000003\n",
      "Step 919/100000 MLoss: 2.2788 GLoss: 0.8572 Sum: 3.136\n",
      "Step 920/100000 MLoss: 1.9815 GLoss: 0.8376 Sum: 2.8191\n",
      "Step 921/100000 MLoss: 2.2621 GLoss: 0.8526 Sum: 3.1147\n",
      "Step 922/100000 MLoss: 2.2686 GLoss: 0.8729 Sum: 3.1415\n",
      "Step 923/100000 MLoss: 2.1314 GLoss: 0.8389 Sum: 2.9703\n",
      "Step 924/100000 MLoss: 2.2632 GLoss: 0.9096 Sum: 3.1727999999999996\n",
      "Step 925/100000 MLoss: 2.287 GLoss: 0.8731 Sum: 3.1601\n",
      "Step 926/100000 MLoss: 2.2456 GLoss: 0.8541 Sum: 3.0997\n",
      "Step 927/100000 MLoss: 2.2081 GLoss: 0.8732 Sum: 3.0812999999999997\n",
      "Step 928/100000 MLoss: 2.2668 GLoss: 0.8563 Sum: 3.1231\n",
      "Step 929/100000 MLoss: 2.2122 GLoss: 0.866 Sum: 3.0782000000000003\n",
      "Step 930/100000 MLoss: 2.3061 GLoss: 0.869 Sum: 3.1750999999999996\n",
      "Step 931/100000 MLoss: 2.2708 GLoss: 0.9364 Sum: 3.2072\n",
      "Step 932/100000 MLoss: 2.2574 GLoss: 0.9277 Sum: 3.1851000000000003\n",
      "Step 933/100000 MLoss: 2.2097 GLoss: 0.8535 Sum: 3.0632\n",
      "Step 934/100000 MLoss: 2.2361 GLoss: 0.8836 Sum: 3.1197\n",
      "Step 935/100000 MLoss: 2.2822 GLoss: 0.8779 Sum: 3.1601\n",
      "Step 936/100000 MLoss: 2.2599 GLoss: 0.8595 Sum: 3.1194\n",
      "Step 937/100000 MLoss: 2.2784 GLoss: 0.8701 Sum: 3.1485\n",
      "Step 938/100000 MLoss: 2.2905 GLoss: 0.8853 Sum: 3.1758\n",
      "Step 939/100000 MLoss: 2.1607 GLoss: 0.8815 Sum: 3.0422\n",
      "Step 940/100000 MLoss: 2.2532 GLoss: 0.8486 Sum: 3.1018\n",
      "Step 941/100000 MLoss: 2.3306 GLoss: 0.87 Sum: 3.2006\n",
      "Step 942/100000 MLoss: 2.2108 GLoss: 0.8918 Sum: 3.1026\n",
      "Step 943/100000 MLoss: 2.4576 GLoss: 0.8705 Sum: 3.3281\n",
      "Step 944/100000 MLoss: 2.3218 GLoss: 0.8662 Sum: 3.188\n",
      "Step 945/100000 MLoss: 2.2376 GLoss: 0.8586 Sum: 3.0962\n",
      "Step 946/100000 MLoss: 2.2944 GLoss: 0.8579 Sum: 3.1523\n",
      "Step 947/100000 MLoss: 2.2281 GLoss: 0.8709 Sum: 3.099\n",
      "Step 948/100000 MLoss: 2.2243 GLoss: 0.8605 Sum: 3.0848\n",
      "Step 949/100000 MLoss: 2.2779 GLoss: 0.8614 Sum: 3.1393\n",
      "Step 950/100000 MLoss: 2.2411 GLoss: 0.8286 Sum: 3.0697\n",
      "Step 951/100000 MLoss: 2.1702 GLoss: 0.8462 Sum: 3.0164\n",
      "Step 952/100000 MLoss: 2.2394 GLoss: 0.8603 Sum: 3.0997\n",
      "Step 953/100000 MLoss: 2.1401 GLoss: 0.8453 Sum: 2.9854\n",
      "Step 954/100000 MLoss: 2.1764 GLoss: 0.8262 Sum: 3.0026\n",
      "Step 955/100000 MLoss: 2.1748 GLoss: 0.873 Sum: 3.0477999999999996\n",
      "Step 956/100000 MLoss: 2.2025 GLoss: 0.8242 Sum: 3.0267\n",
      "Step 957/100000 MLoss: 2.5778 GLoss: 0.8595 Sum: 3.4373\n",
      "Step 958/100000 MLoss: 2.1908 GLoss: 0.8202 Sum: 3.011\n",
      "Step 959/100000 MLoss: 2.1456 GLoss: 0.8919 Sum: 3.0375\n",
      "Step 960/100000 MLoss: 2.1278 GLoss: 0.8832 Sum: 3.011\n",
      "Step 961/100000 MLoss: 2.2177 GLoss: 0.8295 Sum: 3.0471999999999997\n",
      "Step 962/100000 MLoss: 2.2581 GLoss: 0.9492 Sum: 3.2073\n",
      "Step 963/100000 MLoss: 2.2217 GLoss: 0.9659 Sum: 3.1875999999999998\n",
      "Step 964/100000 MLoss: 2.2018 GLoss: 0.8494 Sum: 3.0512\n",
      "Step 965/100000 MLoss: 2.1953 GLoss: 0.8608 Sum: 3.0561\n",
      "Step 966/100000 MLoss: 2.2418 GLoss: 0.9094 Sum: 3.1512000000000002\n",
      "Step 967/100000 MLoss: 2.2707 GLoss: 0.8833 Sum: 3.154\n",
      "Step 968/100000 MLoss: 2.2377 GLoss: 0.999 Sum: 3.2367\n",
      "Step 969/100000 MLoss: 2.2212 GLoss: 0.8759 Sum: 3.0971\n",
      "Step 970/100000 MLoss: 2.1657 GLoss: 0.8795 Sum: 3.0452000000000004\n",
      "Step 971/100000 MLoss: 2.3241 GLoss: 0.9081 Sum: 3.2322\n",
      "Step 972/100000 MLoss: 2.1737 GLoss: 0.8875 Sum: 3.0612000000000004\n",
      "Step 973/100000 MLoss: 2.3241 GLoss: 0.8893 Sum: 3.2134\n",
      "Step 974/100000 MLoss: 2.1875 GLoss: 0.8799 Sum: 3.0674\n",
      "Step 975/100000 MLoss: 2.1544 GLoss: 0.862 Sum: 3.0164\n",
      "Step 976/100000 MLoss: 2.2036 GLoss: 0.8616 Sum: 3.0652\n",
      "Step 977/100000 MLoss: 2.2539 GLoss: 0.8444 Sum: 3.0983\n",
      "Step 978/100000 MLoss: 2.2385 GLoss: 0.8572 Sum: 3.0957\n",
      "Step 979/100000 MLoss: 2.2338 GLoss: 0.8595 Sum: 3.0933\n",
      "Step 980/100000 MLoss: 2.2254 GLoss: 0.8691 Sum: 3.0945\n",
      "Step 981/100000 MLoss: 2.1863 GLoss: 0.8936 Sum: 3.0799000000000003\n",
      "Step 982/100000 MLoss: 2.2095 GLoss: 0.8371 Sum: 3.0465999999999998\n",
      "Step 983/100000 MLoss: 2.2555 GLoss: 0.8561 Sum: 3.1116\n",
      "Step 984/100000 MLoss: 2.2085 GLoss: 0.8361 Sum: 3.0446\n",
      "Step 985/100000 MLoss: 2.2081 GLoss: 0.8544 Sum: 3.0625\n",
      "Step 986/100000 MLoss: 2.195 GLoss: 0.8536 Sum: 3.0486\n",
      "Step 987/100000 MLoss: 2.2243 GLoss: 0.82 Sum: 3.0443\n",
      "Step 988/100000 MLoss: 2.1717 GLoss: 0.8455 Sum: 3.0172\n",
      "Step 989/100000 MLoss: 2.2096 GLoss: 0.8293 Sum: 3.0389\n",
      "Step 990/100000 MLoss: 2.151 GLoss: 0.8673 Sum: 3.0183\n",
      "Step 991/100000 MLoss: 2.2017 GLoss: 0.8569 Sum: 3.0586\n",
      "Step 992/100000 MLoss: 2.236 GLoss: 0.9 Sum: 3.136\n",
      "Step 993/100000 MLoss: 2.3286 GLoss: 0.8445 Sum: 3.1731\n",
      "Step 994/100000 MLoss: 2.2662 GLoss: 0.8616 Sum: 3.1278\n",
      "Step 995/100000 MLoss: 2.2311 GLoss: 0.8566 Sum: 3.0877\n",
      "Step 996/100000 MLoss: 2.2885 GLoss: 0.8455 Sum: 3.134\n",
      "Step 997/100000 MLoss: 2.2122 GLoss: 0.8399 Sum: 3.0521000000000003\n",
      "Step 998/100000 MLoss: 2.2371 GLoss: 0.8529 Sum: 3.09\n",
      "Step 999/100000 MLoss: 2.1688 GLoss: 0.8407 Sum: 3.0095\n",
      "Step 1000/100000 MLoss: 2.1547 GLoss: 0.8679 Sum: 3.0226\n",
      "Step 1001/100000 MLoss: 2.2197 GLoss: 0.8399 Sum: 3.0596\n",
      "Step 1002/100000 MLoss: 2.2202 GLoss: 0.8717 Sum: 3.0919000000000003\n",
      "Step 1003/100000 MLoss: 2.2414 GLoss: 0.8248 Sum: 3.0662000000000003\n",
      "Step 1004/100000 MLoss: 2.2291 GLoss: 0.9237 Sum: 3.1528\n",
      "Step 1005/100000 MLoss: 2.2302 GLoss: 0.9267 Sum: 3.1569\n",
      "Step 1006/100000 MLoss: 2.1596 GLoss: 0.8486 Sum: 3.0082000000000004\n",
      "Step 1007/100000 MLoss: 2.2931 GLoss: 0.8611 Sum: 3.1542\n",
      "Step 1008/100000 MLoss: 2.2722 GLoss: 0.8713 Sum: 3.1435000000000004\n",
      "Step 1009/100000 MLoss: 2.2949 GLoss: 0.8251 Sum: 3.12\n",
      "Step 1010/100000 MLoss: 2.1051 GLoss: 0.868 Sum: 2.9731\n",
      "Step 1011/100000 MLoss: 2.1529 GLoss: 0.8614 Sum: 3.0143\n",
      "Step 1012/100000 MLoss: 2.1333 GLoss: 0.8955 Sum: 3.0288000000000004\n",
      "Step 1013/100000 MLoss: 2.2808 GLoss: 0.8599 Sum: 3.1407000000000003\n",
      "Step 1014/100000 MLoss: 2.2114 GLoss: 0.8481 Sum: 3.0595\n",
      "Step 1015/100000 MLoss: 2.1878 GLoss: 0.8566 Sum: 3.0444000000000004\n",
      "Step 1016/100000 MLoss: 2.2102 GLoss: 0.8484 Sum: 3.0586\n",
      "Step 1017/100000 MLoss: 2.2022 GLoss: 0.8665 Sum: 3.0686999999999998\n",
      "Step 1018/100000 MLoss: 2.3389 GLoss: 0.8691 Sum: 3.208\n",
      "Step 1019/100000 MLoss: 2.2882 GLoss: 0.8568 Sum: 3.1449999999999996\n",
      "Step 1020/100000 MLoss: 2.2463 GLoss: 0.831 Sum: 3.0773\n",
      "Step 1021/100000 MLoss: 2.2163 GLoss: 0.9019 Sum: 3.1182\n",
      "Step 1022/100000 MLoss: 2.324 GLoss: 0.8799 Sum: 3.2039\n",
      "Step 1023/100000 MLoss: 2.2355 GLoss: 0.8447 Sum: 3.0802\n",
      "Step 1024/100000 MLoss: 2.1733 GLoss: 0.8834 Sum: 3.0566999999999998\n",
      "Step 1025/100000 MLoss: 2.2451 GLoss: 0.8942 Sum: 3.1393\n",
      "Step 1026/100000 MLoss: 2.2001 GLoss: 0.8338 Sum: 3.0339\n",
      "Step 1027/100000 MLoss: 2.2442 GLoss: 0.8812 Sum: 3.1254\n",
      "Step 1028/100000 MLoss: 2.2401 GLoss: 0.9098 Sum: 3.1499\n",
      "Step 1029/100000 MLoss: 2.1992 GLoss: 0.9012 Sum: 3.1003999999999996\n",
      "Step 1030/100000 MLoss: 2.2843 GLoss: 0.8802 Sum: 3.1645\n",
      "Step 1031/100000 MLoss: 2.2027 GLoss: 0.8292 Sum: 3.0319000000000003\n",
      "Step 1032/100000 MLoss: 2.2785 GLoss: 0.8865 Sum: 3.165\n",
      "Step 1033/100000 MLoss: 2.2364 GLoss: 0.8323 Sum: 3.0687\n",
      "Step 1034/100000 MLoss: 2.2877 GLoss: 0.8644 Sum: 3.1521\n",
      "Step 1035/100000 MLoss: 2.2967 GLoss: 0.8635 Sum: 3.1602\n",
      "Step 1036/100000 MLoss: 2.1817 GLoss: 0.8543 Sum: 3.036\n",
      "Step 1037/100000 MLoss: 2.2651 GLoss: 0.8358 Sum: 3.1008999999999998\n",
      "Step 1038/100000 MLoss: 2.2236 GLoss: 0.8421 Sum: 3.0656999999999996\n",
      "Step 1039/100000 MLoss: 2.2644 GLoss: 0.8312 Sum: 3.0956\n",
      "Step 1040/100000 MLoss: 2.3451 GLoss: 0.8333 Sum: 3.1784\n",
      "Step 1041/100000 MLoss: 2.404 GLoss: 0.8134 Sum: 3.2174\n",
      "Step 1042/100000 MLoss: 2.2948 GLoss: 0.8294 Sum: 3.1242\n",
      "Step 1043/100000 MLoss: 2.2069 GLoss: 0.815 Sum: 3.0219\n",
      "Step 1044/100000 MLoss: 2.2894 GLoss: 0.8728 Sum: 3.1622000000000003\n",
      "Step 1045/100000 MLoss: 2.2087 GLoss: 0.845 Sum: 3.0537\n",
      "Step 1046/100000 MLoss: 2.2394 GLoss: 0.8308 Sum: 3.0702\n",
      "Step 1047/100000 MLoss: 2.1636 GLoss: 0.8523 Sum: 3.0159000000000002\n",
      "Step 1048/100000 MLoss: 2.1912 GLoss: 0.8587 Sum: 3.0499\n",
      "Step 1049/100000 MLoss: 2.3155 GLoss: 0.8475 Sum: 3.1630000000000003\n",
      "Step 1050/100000 MLoss: 2.1931 GLoss: 0.8478 Sum: 3.0408999999999997\n",
      "Step 1051/100000 MLoss: 2.1859 GLoss: 0.8278 Sum: 3.0137\n",
      "Step 1052/100000 MLoss: 2.2643 GLoss: 0.8102 Sum: 3.0745\n",
      "Step 1053/100000 MLoss: 2.1484 GLoss: 0.7918 Sum: 2.9402\n",
      "Step 1054/100000 MLoss: 2.1294 GLoss: 0.8083 Sum: 2.9377\n",
      "Step 1055/100000 MLoss: 2.1834 GLoss: 0.8199 Sum: 3.0033\n",
      "Step 1056/100000 MLoss: 2.1332 GLoss: 0.8058 Sum: 2.939\n",
      "Step 1057/100000 MLoss: 2.25 GLoss: 0.8235 Sum: 3.0735\n",
      "Step 1058/100000 MLoss: 2.2241 GLoss: 0.8135 Sum: 3.0376\n",
      "Step 1059/100000 MLoss: 2.1603 GLoss: 0.8076 Sum: 2.9678999999999998\n",
      "Step 1060/100000 MLoss: 2.2965 GLoss: 0.8034 Sum: 3.0999\n",
      "Step 1061/100000 MLoss: 2.2193 GLoss: 0.8132 Sum: 3.0325\n",
      "Step 1062/100000 MLoss: 2.1774 GLoss: 0.8272 Sum: 3.0046\n",
      "Step 1063/100000 MLoss: 2.1955 GLoss: 0.8002 Sum: 2.9957000000000003\n",
      "Step 1064/100000 MLoss: 2.2411 GLoss: 0.8101 Sum: 3.0511999999999997\n",
      "Step 1065/100000 MLoss: 2.3352 GLoss: 0.8215 Sum: 3.1567\n",
      "Step 1066/100000 MLoss: 2.1836 GLoss: 0.8096 Sum: 2.9932000000000003\n",
      "Step 1067/100000 MLoss: 2.146 GLoss: 0.8076 Sum: 2.9536\n",
      "Step 1068/100000 MLoss: 2.2225 GLoss: 0.8425 Sum: 3.0650000000000004\n",
      "Step 1069/100000 MLoss: 2.2692 GLoss: 0.8086 Sum: 3.0778\n",
      "Step 1070/100000 MLoss: 2.1186 GLoss: 0.8126 Sum: 2.9311999999999996\n",
      "Step 1071/100000 MLoss: 2.2165 GLoss: 0.8195 Sum: 3.036\n",
      "Step 1072/100000 MLoss: 2.0987 GLoss: 0.8089 Sum: 2.9076\n",
      "Step 1073/100000 MLoss: 2.1064 GLoss: 0.8285 Sum: 2.9349\n",
      "Step 1074/100000 MLoss: 2.1807 GLoss: 0.8122 Sum: 2.9928999999999997\n",
      "Step 1075/100000 MLoss: 2.1368 GLoss: 0.8036 Sum: 2.9404\n",
      "Step 1076/100000 MLoss: 2.133 GLoss: 0.8083 Sum: 2.9413\n",
      "Step 1077/100000 MLoss: 2.2141 GLoss: 0.8314 Sum: 3.0455\n",
      "Step 1078/100000 MLoss: 2.236 GLoss: 0.8097 Sum: 3.0457\n",
      "Step 1079/100000 MLoss: 2.1655 GLoss: 0.8182 Sum: 2.9837000000000002\n",
      "Step 1080/100000 MLoss: 2.1065 GLoss: 0.7956 Sum: 2.9021\n",
      "Step 1081/100000 MLoss: 2.1122 GLoss: 0.7947 Sum: 2.9069000000000003\n",
      "Step 1082/100000 MLoss: 2.1705 GLoss: 0.8182 Sum: 2.9887\n",
      "Step 1083/100000 MLoss: 2.2919 GLoss: 0.8258 Sum: 3.1177\n",
      "Step 1084/100000 MLoss: 2.1746 GLoss: 0.8058 Sum: 2.9804\n",
      "Step 1085/100000 MLoss: 2.1682 GLoss: 0.8155 Sum: 2.9837000000000002\n",
      "Step 1086/100000 MLoss: 2.2132 GLoss: 0.8098 Sum: 3.023\n",
      "Step 1087/100000 MLoss: 2.166 GLoss: 0.7937 Sum: 2.9596999999999998\n",
      "Step 1088/100000 MLoss: 2.2671 GLoss: 0.8303 Sum: 3.0974000000000004\n",
      "Step 1089/100000 MLoss: 2.1859 GLoss: 0.8065 Sum: 2.9924\n",
      "Step 1090/100000 MLoss: 2.3219 GLoss: 0.8069 Sum: 3.1288\n",
      "Step 1091/100000 MLoss: 2.1923 GLoss: 0.8092 Sum: 3.0015\n",
      "Step 1092/100000 MLoss: 2.2467 GLoss: 0.7999 Sum: 3.0466\n",
      "Step 1093/100000 MLoss: 2.2457 GLoss: 0.818 Sum: 3.0637\n",
      "Step 1094/100000 MLoss: 2.2282 GLoss: 0.8152 Sum: 3.0434\n",
      "Step 1095/100000 MLoss: 2.2032 GLoss: 0.7863 Sum: 2.9894999999999996\n",
      "Step 1096/100000 MLoss: 2.2822 GLoss: 0.8606 Sum: 3.1428000000000003\n",
      "Step 1097/100000 MLoss: 2.298 GLoss: 0.8429 Sum: 3.1409000000000002\n",
      "Step 1098/100000 MLoss: 2.2378 GLoss: 0.82 Sum: 3.0578\n",
      "Step 1099/100000 MLoss: 2.2631 GLoss: 0.8222 Sum: 3.0853\n",
      "Step 1100/100000 MLoss: 2.1488 GLoss: 0.8062 Sum: 2.955\n",
      "Step 1101/100000 MLoss: 2.2409 GLoss: 0.8202 Sum: 3.0610999999999997\n",
      "Step 1102/100000 MLoss: 2.1423 GLoss: 0.8029 Sum: 2.9452\n",
      "Step 1103/100000 MLoss: 2.1948 GLoss: 0.8158 Sum: 3.0105999999999997\n",
      "Step 1104/100000 MLoss: 2.2068 GLoss: 0.8095 Sum: 3.0162999999999998\n",
      "Step 1105/100000 MLoss: 2.2432 GLoss: 0.8109 Sum: 3.0541\n",
      "Step 1106/100000 MLoss: 2.2921 GLoss: 0.8001 Sum: 3.0922\n",
      "Step 1107/100000 MLoss: 2.2529 GLoss: 0.8035 Sum: 3.0564\n",
      "Step 1108/100000 MLoss: 2.2211 GLoss: 0.8098 Sum: 3.0309\n",
      "Step 1109/100000 MLoss: 2.2192 GLoss: 0.8131 Sum: 3.0322999999999998\n",
      "Step 1110/100000 MLoss: 2.0684 GLoss: 0.7917 Sum: 2.8601\n",
      "Step 1111/100000 MLoss: 2.1813 GLoss: 0.792 Sum: 2.9733\n",
      "Step 1112/100000 MLoss: 2.1784 GLoss: 0.8437 Sum: 3.0221\n",
      "Step 1113/100000 MLoss: 2.2504 GLoss: 0.8205 Sum: 3.0709\n",
      "Step 1114/100000 MLoss: 2.1322 GLoss: 0.816 Sum: 2.9482\n",
      "Step 1115/100000 MLoss: 2.1876 GLoss: 0.8168 Sum: 3.0044000000000004\n",
      "Step 1116/100000 MLoss: 2.1225 GLoss: 0.8142 Sum: 2.9367\n",
      "Step 1117/100000 MLoss: 2.2688 GLoss: 0.8034 Sum: 3.0722\n",
      "Step 1118/100000 MLoss: 2.3194 GLoss: 0.837 Sum: 3.1563999999999997\n",
      "Step 1119/100000 MLoss: 2.1719 GLoss: 0.8103 Sum: 2.9821999999999997\n",
      "Step 1120/100000 MLoss: 2.1112 GLoss: 0.8199 Sum: 2.9311000000000003\n",
      "Step 1121/100000 MLoss: 2.238 GLoss: 0.8105 Sum: 3.0484999999999998\n",
      "Step 1122/100000 MLoss: 2.1378 GLoss: 0.8082 Sum: 2.9459999999999997\n",
      "Step 1123/100000 MLoss: 2.0635 GLoss: 0.8094 Sum: 2.8729\n",
      "Step 1124/100000 MLoss: 2.1819 GLoss: 0.8046 Sum: 2.9865000000000004\n",
      "Step 1125/100000 MLoss: 2.1895 GLoss: 0.8034 Sum: 2.9928999999999997\n",
      "Step 1126/100000 MLoss: 2.1467 GLoss: 0.8181 Sum: 2.9648000000000003\n",
      "Step 1127/100000 MLoss: 2.251 GLoss: 0.82 Sum: 3.0709999999999997\n",
      "Step 1128/100000 MLoss: 2.3392 GLoss: 0.8141 Sum: 3.1532999999999998\n",
      "Step 1129/100000 MLoss: 2.2676 GLoss: 0.8148 Sum: 3.0824\n",
      "Step 1130/100000 MLoss: 2.2794 GLoss: 0.8296 Sum: 3.109\n",
      "Step 1131/100000 MLoss: 2.3741 GLoss: 0.8324 Sum: 3.2065\n",
      "Step 1132/100000 MLoss: 2.2514 GLoss: 0.8103 Sum: 3.0617\n",
      "Step 1133/100000 MLoss: 2.2162 GLoss: 0.7974 Sum: 3.0136000000000003\n",
      "Step 1134/100000 MLoss: 2.2166 GLoss: 0.8707 Sum: 3.0873\n",
      "Step 1135/100000 MLoss: 2.2448 GLoss: 0.8396 Sum: 3.0844\n",
      "Step 1136/100000 MLoss: 2.1957 GLoss: 0.8206 Sum: 3.0163\n",
      "Step 1137/100000 MLoss: 2.2323 GLoss: 0.8219 Sum: 3.0542\n",
      "Step 1138/100000 MLoss: 2.2048 GLoss: 0.8308 Sum: 3.0356\n",
      "Step 1139/100000 MLoss: 2.1608 GLoss: 0.826 Sum: 2.9868\n",
      "Step 1140/100000 MLoss: 2.0805 GLoss: 0.8212 Sum: 2.9017\n",
      "Step 1141/100000 MLoss: 2.1634 GLoss: 0.8184 Sum: 2.9818000000000002\n",
      "Step 1142/100000 MLoss: 2.2298 GLoss: 0.804 Sum: 3.0338000000000003\n",
      "Step 1143/100000 MLoss: 2.189 GLoss: 0.8205 Sum: 3.0095\n",
      "Step 1144/100000 MLoss: 2.225 GLoss: 0.798 Sum: 3.023\n",
      "Step 1145/100000 MLoss: 2.3108 GLoss: 0.8073 Sum: 3.1181\n",
      "Step 1146/100000 MLoss: 2.2024 GLoss: 0.8111 Sum: 3.0135\n",
      "Step 1147/100000 MLoss: 2.2659 GLoss: 0.8156 Sum: 3.0814999999999997\n",
      "Step 1148/100000 MLoss: 2.2278 GLoss: 0.8258 Sum: 3.0536\n",
      "Step 1149/100000 MLoss: 2.275 GLoss: 0.8269 Sum: 3.1018999999999997\n",
      "Step 1150/100000 MLoss: 2.144 GLoss: 0.7915 Sum: 2.9355\n",
      "Step 1151/100000 MLoss: 2.1944 GLoss: 0.8483 Sum: 3.0427\n",
      "Step 1152/100000 MLoss: 2.2174 GLoss: 0.8186 Sum: 3.036\n",
      "Step 1153/100000 MLoss: 2.1923 GLoss: 0.8376 Sum: 3.0299\n",
      "Step 1154/100000 MLoss: 2.1381 GLoss: 0.8163 Sum: 2.9544\n",
      "Step 1155/100000 MLoss: 2.2736 GLoss: 0.8247 Sum: 3.0983\n",
      "Step 1156/100000 MLoss: 2.2518 GLoss: 0.8089 Sum: 3.0606999999999998\n",
      "Step 1157/100000 MLoss: 2.1968 GLoss: 0.7907 Sum: 2.9875\n",
      "Step 1158/100000 MLoss: 2.2859 GLoss: 0.8416 Sum: 3.1275\n",
      "Step 1159/100000 MLoss: 2.2614 GLoss: 0.8183 Sum: 3.0797\n",
      "Step 1160/100000 MLoss: 2.1597 GLoss: 0.8448 Sum: 3.0045\n",
      "Step 1161/100000 MLoss: 2.3248 GLoss: 0.8527 Sum: 3.1775\n",
      "Step 1162/100000 MLoss: 2.2309 GLoss: 0.8165 Sum: 3.0474\n",
      "Step 1163/100000 MLoss: 2.0954 GLoss: 0.8411 Sum: 2.9365\n",
      "Step 1164/100000 MLoss: 2.2391 GLoss: 0.854 Sum: 3.0931\n",
      "Step 1165/100000 MLoss: 2.1074 GLoss: 0.8144 Sum: 2.9218\n",
      "Step 1166/100000 MLoss: 2.2412 GLoss: 0.8251 Sum: 3.0663\n",
      "Step 1167/100000 MLoss: 2.2955 GLoss: 0.8339 Sum: 3.1294\n",
      "Step 1168/100000 MLoss: 2.2292 GLoss: 0.8138 Sum: 3.043\n",
      "Step 1169/100000 MLoss: 2.2103 GLoss: 0.8118 Sum: 3.0221\n",
      "Step 1170/100000 MLoss: 2.2821 GLoss: 0.8436 Sum: 3.1256999999999997\n",
      "Step 1171/100000 MLoss: 2.1717 GLoss: 0.8302 Sum: 3.0019\n",
      "Step 1172/100000 MLoss: 2.2176 GLoss: 0.8149 Sum: 3.0324999999999998\n",
      "Step 1173/100000 MLoss: 2.1777 GLoss: 0.8461 Sum: 3.0238\n",
      "Step 1174/100000 MLoss: 2.2225 GLoss: 0.8132 Sum: 3.0357000000000003\n",
      "Step 1175/100000 MLoss: 2.1949 GLoss: 0.8099 Sum: 3.0048\n",
      "Step 1176/100000 MLoss: 2.2244 GLoss: 0.8308 Sum: 3.0552\n",
      "Step 1177/100000 MLoss: 2.2999 GLoss: 0.827 Sum: 3.1269\n",
      "Step 1178/100000 MLoss: 2.221 GLoss: 0.8282 Sum: 3.0492\n",
      "Step 1179/100000 MLoss: 2.1731 GLoss: 0.8443 Sum: 3.0174\n",
      "Step 1180/100000 MLoss: 2.1857 GLoss: 0.7973 Sum: 2.983\n",
      "Step 1181/100000 MLoss: 2.2134 GLoss: 0.818 Sum: 3.0314\n",
      "Step 1182/100000 MLoss: 2.2582 GLoss: 0.8255 Sum: 3.0837\n",
      "Step 1183/100000 MLoss: 2.2364 GLoss: 0.8112 Sum: 3.0476\n",
      "Step 1184/100000 MLoss: 2.195 GLoss: 0.8156 Sum: 3.0105999999999997\n",
      "Step 1185/100000 MLoss: 2.2507 GLoss: 0.8231 Sum: 3.0738000000000003\n",
      "Step 1186/100000 MLoss: 2.1586 GLoss: 0.7954 Sum: 2.9539999999999997\n",
      "Step 1187/100000 MLoss: 2.1082 GLoss: 0.8066 Sum: 2.9148\n",
      "Step 1188/100000 MLoss: 2.1932 GLoss: 0.7958 Sum: 2.989\n",
      "Step 1189/100000 MLoss: 2.2275 GLoss: 0.8056 Sum: 3.0331\n",
      "Step 1190/100000 MLoss: 2.3632 GLoss: 0.8209 Sum: 3.1841\n",
      "Step 1191/100000 MLoss: 2.1781 GLoss: 0.8148 Sum: 2.9929\n",
      "Step 1192/100000 MLoss: 2.1671 GLoss: 0.8024 Sum: 2.9695\n",
      "Step 1193/100000 MLoss: 2.2556 GLoss: 0.8001 Sum: 3.0557\n",
      "Step 1194/100000 MLoss: 2.2319 GLoss: 0.8261 Sum: 3.058\n",
      "Step 1195/100000 MLoss: 2.27 GLoss: 0.8139 Sum: 3.0839\n",
      "Step 1196/100000 MLoss: 2.1699 GLoss: 0.8291 Sum: 2.999\n",
      "Step 1197/100000 MLoss: 2.138 GLoss: 0.8189 Sum: 2.9569\n",
      "Step 1198/100000 MLoss: 2.1648 GLoss: 0.8046 Sum: 2.9694000000000003\n",
      "Step 1199/100000 MLoss: 2.2552 GLoss: 0.8064 Sum: 3.0616\n",
      "Step 1200/100000 MLoss: 2.2414 GLoss: 0.7819 Sum: 3.0233\n",
      "Step 1201/100000 MLoss: 2.2342 GLoss: 0.8226 Sum: 3.0568\n",
      "Step 1202/100000 MLoss: 2.1828 GLoss: 0.8087 Sum: 2.9915\n",
      "Step 1203/100000 MLoss: 2.2336 GLoss: 0.8256 Sum: 3.0592\n",
      "Step 1204/100000 MLoss: 2.2245 GLoss: 0.8079 Sum: 3.0324\n",
      "Step 1205/100000 MLoss: 2.2287 GLoss: 0.8101 Sum: 3.0388\n",
      "Step 1206/100000 MLoss: 2.1659 GLoss: 0.8091 Sum: 2.975\n",
      "Step 1207/100000 MLoss: 2.2185 GLoss: 0.8222 Sum: 3.0407\n",
      "Step 1208/100000 MLoss: 2.1661 GLoss: 0.8155 Sum: 2.9816000000000003\n",
      "Step 1209/100000 MLoss: 2.1762 GLoss: 0.8154 Sum: 2.9916\n",
      "Step 1210/100000 MLoss: 2.257 GLoss: 0.7951 Sum: 3.0521000000000003\n",
      "Step 1211/100000 MLoss: 2.2157 GLoss: 0.8015 Sum: 3.0172\n",
      "Step 1212/100000 MLoss: 2.3186 GLoss: 0.8144 Sum: 3.133\n",
      "Step 1213/100000 MLoss: 2.1728 GLoss: 0.7964 Sum: 2.9692\n",
      "Step 1214/100000 MLoss: 2.2113 GLoss: 0.826 Sum: 3.0373\n",
      "Step 1215/100000 MLoss: 2.2618 GLoss: 0.821 Sum: 3.0827999999999998\n",
      "Step 1216/100000 MLoss: 2.2515 GLoss: 0.798 Sum: 3.0495\n",
      "Step 1217/100000 MLoss: 2.3443 GLoss: 0.827 Sum: 3.1713\n",
      "Step 1218/100000 MLoss: 2.2214 GLoss: 0.8109 Sum: 3.0323\n",
      "Step 1219/100000 MLoss: 2.1935 GLoss: 0.8166 Sum: 3.0100999999999996\n",
      "Step 1220/100000 MLoss: 2.2455 GLoss: 0.8278 Sum: 3.0732999999999997\n",
      "Step 1221/100000 MLoss: 2.2097 GLoss: 0.7893 Sum: 2.999\n",
      "Step 1222/100000 MLoss: 2.1501 GLoss: 0.8177 Sum: 2.9678\n",
      "Step 1223/100000 MLoss: 2.2004 GLoss: 0.7896 Sum: 2.99\n",
      "Step 1224/100000 MLoss: 2.1943 GLoss: 0.8418 Sum: 3.0361000000000002\n",
      "Step 1225/100000 MLoss: 2.235 GLoss: 0.8057 Sum: 3.0406999999999997\n",
      "Step 1226/100000 MLoss: 2.3029 GLoss: 0.8112 Sum: 3.1141\n",
      "Step 1227/100000 MLoss: 2.2054 GLoss: 0.8035 Sum: 3.0089\n",
      "Step 1228/100000 MLoss: 2.2415 GLoss: 0.8039 Sum: 3.0454\n",
      "Step 1229/100000 MLoss: 2.1737 GLoss: 0.8074 Sum: 2.9811\n",
      "Step 1230/100000 MLoss: 2.2415 GLoss: 0.8516 Sum: 3.0930999999999997\n",
      "Step 1231/100000 MLoss: 2.1493 GLoss: 0.8242 Sum: 2.9735000000000005\n",
      "Step 1232/100000 MLoss: 2.2259 GLoss: 0.7955 Sum: 3.0214000000000003\n",
      "Step 1233/100000 MLoss: 2.1956 GLoss: 0.7973 Sum: 2.9929\n",
      "Step 1234/100000 MLoss: 2.1905 GLoss: 0.7928 Sum: 2.9833\n",
      "Step 1235/100000 MLoss: 2.2693 GLoss: 0.7978 Sum: 3.0671\n",
      "Step 1236/100000 MLoss: 2.2225 GLoss: 0.7911 Sum: 3.0136000000000003\n",
      "Step 1237/100000 MLoss: 2.1536 GLoss: 0.8018 Sum: 2.9554\n",
      "Step 1238/100000 MLoss: 2.2198 GLoss: 0.7966 Sum: 3.0164\n",
      "Step 1239/100000 MLoss: 2.2438 GLoss: 0.8051 Sum: 3.0488999999999997\n",
      "Step 1240/100000 MLoss: 2.1795 GLoss: 0.7941 Sum: 2.9736000000000002\n",
      "Step 1241/100000 MLoss: 2.2512 GLoss: 0.7876 Sum: 3.0387999999999997\n",
      "Step 1242/100000 MLoss: 2.0995 GLoss: 0.8139 Sum: 2.9133999999999998\n",
      "Step 1243/100000 MLoss: 2.2324 GLoss: 0.8164 Sum: 3.0488\n",
      "Step 1244/100000 MLoss: 2.2622 GLoss: 0.7889 Sum: 3.0511\n",
      "Step 1245/100000 MLoss: 2.1766 GLoss: 0.8068 Sum: 2.9834\n",
      "Step 1246/100000 MLoss: 2.1594 GLoss: 0.7927 Sum: 2.9521\n",
      "Step 1247/100000 MLoss: 2.195 GLoss: 0.8144 Sum: 3.0094\n",
      "Step 1248/100000 MLoss: 2.1188 GLoss: 0.7859 Sum: 2.9047\n",
      "Step 1249/100000 MLoss: 2.2212 GLoss: 0.8156 Sum: 3.0368\n",
      "Step 1250/100000 MLoss: 2.17 GLoss: 0.7863 Sum: 2.9562999999999997\n",
      "Step 1251/100000 MLoss: 2.2339 GLoss: 0.8081 Sum: 3.0420000000000003\n",
      "Step 1252/100000 MLoss: 2.2099 GLoss: 0.8042 Sum: 3.0141\n",
      "Step 1253/100000 MLoss: 2.1658 GLoss: 0.8039 Sum: 2.9697\n",
      "Step 1254/100000 MLoss: 2.3682 GLoss: 0.8021 Sum: 3.1703\n",
      "Step 1255/100000 MLoss: 2.2796 GLoss: 0.7937 Sum: 3.0732999999999997\n",
      "Step 1256/100000 MLoss: 2.2085 GLoss: 0.7976 Sum: 3.0061\n",
      "Step 1257/100000 MLoss: 2.2321 GLoss: 0.7943 Sum: 3.0263999999999998\n",
      "Step 1258/100000 MLoss: 2.1514 GLoss: 0.8003 Sum: 2.9517\n",
      "Step 1259/100000 MLoss: 2.0713 GLoss: 0.8026 Sum: 2.8739\n",
      "Step 1260/100000 MLoss: 2.2773 GLoss: 0.8014 Sum: 3.0787\n",
      "Step 1261/100000 MLoss: 2.2017 GLoss: 0.8048 Sum: 3.0065\n",
      "Step 1262/100000 MLoss: 2.4632 GLoss: 0.8053 Sum: 3.2685\n",
      "Step 1263/100000 MLoss: 2.2362 GLoss: 0.7848 Sum: 3.0210000000000004\n",
      "Step 1264/100000 MLoss: 2.1955 GLoss: 0.7846 Sum: 2.9801\n",
      "Step 1265/100000 MLoss: 2.2598 GLoss: 0.7996 Sum: 3.0593999999999997\n",
      "Step 1266/100000 MLoss: 2.2419 GLoss: 0.7984 Sum: 3.0403\n",
      "Step 1267/100000 MLoss: 2.1872 GLoss: 0.8195 Sum: 3.0067\n",
      "Step 1268/100000 MLoss: 2.313 GLoss: 0.7926 Sum: 3.1056\n",
      "Step 1269/100000 MLoss: 2.1221 GLoss: 0.8058 Sum: 2.9279\n",
      "Step 1270/100000 MLoss: 2.1712 GLoss: 0.7821 Sum: 2.9532999999999996\n",
      "Step 1271/100000 MLoss: 2.2106 GLoss: 0.8076 Sum: 3.0181999999999998\n",
      "Step 1272/100000 MLoss: 2.2087 GLoss: 0.8003 Sum: 3.009\n",
      "Step 1273/100000 MLoss: 2.1696 GLoss: 0.7965 Sum: 2.9661\n",
      "Step 1274/100000 MLoss: 2.192 GLoss: 0.8001 Sum: 2.9921\n",
      "Step 1275/100000 MLoss: 2.2555 GLoss: 0.7921 Sum: 3.0476\n",
      "Step 1276/100000 MLoss: 2.1954 GLoss: 0.8105 Sum: 3.0058999999999996\n",
      "Step 1277/100000 MLoss: 2.2227 GLoss: 0.7987 Sum: 3.0214\n",
      "Step 1278/100000 MLoss: 2.1226 GLoss: 0.8038 Sum: 2.9263999999999997\n",
      "Step 1279/100000 MLoss: 2.2885 GLoss: 0.7897 Sum: 3.0782\n",
      "Step 1280/100000 MLoss: 2.0868 GLoss: 0.7848 Sum: 2.8716000000000004\n",
      "Step 1281/100000 MLoss: 2.308 GLoss: 0.7992 Sum: 3.1071999999999997\n",
      "Step 1282/100000 MLoss: 2.2497 GLoss: 0.7849 Sum: 3.0345999999999997\n",
      "Step 1283/100000 MLoss: 2.2788 GLoss: 0.781 Sum: 3.0598\n",
      "Step 1284/100000 MLoss: 2.2448 GLoss: 0.7967 Sum: 3.0415\n",
      "Step 1285/100000 MLoss: 2.1546 GLoss: 0.7992 Sum: 2.9537999999999998\n",
      "Step 1286/100000 MLoss: 2.1666 GLoss: 0.7972 Sum: 2.9638\n",
      "Step 1287/100000 MLoss: 2.1538 GLoss: 0.8396 Sum: 2.9934\n",
      "Step 1288/100000 MLoss: 2.171 GLoss: 0.8443 Sum: 3.0153\n",
      "Step 1289/100000 MLoss: 2.2885 GLoss: 0.7968 Sum: 3.0853\n",
      "Step 1290/100000 MLoss: 2.325 GLoss: 0.811 Sum: 3.136\n",
      "Step 1291/100000 MLoss: 2.3236 GLoss: 0.815 Sum: 3.1386\n",
      "Step 1292/100000 MLoss: 2.1785 GLoss: 0.8063 Sum: 2.9848\n",
      "Step 1293/100000 MLoss: 2.1549 GLoss: 0.805 Sum: 2.9599\n",
      "Step 1294/100000 MLoss: 2.2274 GLoss: 0.8277 Sum: 3.0551\n",
      "Step 1295/100000 MLoss: 2.1882 GLoss: 0.7924 Sum: 2.9806\n",
      "Step 1296/100000 MLoss: 2.207 GLoss: 0.8167 Sum: 3.0237\n",
      "Step 1297/100000 MLoss: 2.2325 GLoss: 0.8336 Sum: 3.0661\n",
      "Step 1298/100000 MLoss: 2.299 GLoss: 0.8121 Sum: 3.1111\n",
      "Step 1299/100000 MLoss: 2.2293 GLoss: 0.7983 Sum: 3.0275999999999996\n",
      "Step 1300/100000 MLoss: 2.0851 GLoss: 0.8335 Sum: 2.9186\n",
      "Step 1301/100000 MLoss: 2.1356 GLoss: 0.8195 Sum: 2.9551000000000003\n",
      "Step 1302/100000 MLoss: 2.2306 GLoss: 0.8106 Sum: 3.0412\n",
      "Step 1303/100000 MLoss: 2.1575 GLoss: 0.8198 Sum: 2.9773\n",
      "Step 1304/100000 MLoss: 2.2198 GLoss: 0.8295 Sum: 3.0493\n",
      "Step 1305/100000 MLoss: 2.2753 GLoss: 0.805 Sum: 3.0803000000000003\n",
      "Step 1306/100000 MLoss: 2.1688 GLoss: 0.8207 Sum: 2.9895\n",
      "Step 1307/100000 MLoss: 2.6076 GLoss: 0.8056 Sum: 3.4132000000000002\n",
      "Step 1308/100000 MLoss: 2.1351 GLoss: 0.812 Sum: 2.9471\n",
      "Step 1309/100000 MLoss: 2.2418 GLoss: 0.8006 Sum: 3.0423999999999998\n",
      "Step 1310/100000 MLoss: 2.2489 GLoss: 0.8356 Sum: 3.0845\n",
      "Step 1311/100000 MLoss: 2.21 GLoss: 0.8126 Sum: 3.0225999999999997\n",
      "Step 1312/100000 MLoss: 2.1919 GLoss: 0.8035 Sum: 2.9954\n",
      "Step 1313/100000 MLoss: 2.1752 GLoss: 0.8118 Sum: 2.9869999999999997\n",
      "Step 1314/100000 MLoss: 2.2541 GLoss: 0.8064 Sum: 3.0605\n",
      "Step 1315/100000 MLoss: 2.2658 GLoss: 0.803 Sum: 3.0688\n",
      "Step 1316/100000 MLoss: 2.198 GLoss: 0.7822 Sum: 2.9802\n",
      "Step 1317/100000 MLoss: 2.2167 GLoss: 0.8112 Sum: 3.0279\n",
      "Step 1318/100000 MLoss: 2.1711 GLoss: 0.7852 Sum: 2.9563\n",
      "Step 1319/100000 MLoss: 2.1934 GLoss: 0.7788 Sum: 2.9722\n",
      "Step 1320/100000 MLoss: 2.2288 GLoss: 0.825 Sum: 3.0538\n",
      "Step 1321/100000 MLoss: 2.069 GLoss: 0.7915 Sum: 2.8605\n",
      "Step 1322/100000 MLoss: 2.18 GLoss: 0.8079 Sum: 2.9879000000000002\n",
      "Step 1323/100000 MLoss: 2.3481 GLoss: 0.783 Sum: 3.1311\n",
      "Step 1324/100000 MLoss: 2.1972 GLoss: 0.8097 Sum: 3.0069\n",
      "Step 1325/100000 MLoss: 2.2058 GLoss: 0.8202 Sum: 3.026\n",
      "Step 1326/100000 MLoss: 2.4065 GLoss: 0.7952 Sum: 3.2016999999999998\n",
      "Step 1327/100000 MLoss: 2.3071 GLoss: 0.8388 Sum: 3.1459\n",
      "Step 1328/100000 MLoss: 2.2993 GLoss: 0.83 Sum: 3.1293\n",
      "Step 1329/100000 MLoss: 2.1529 GLoss: 0.7987 Sum: 2.9516\n",
      "Step 1330/100000 MLoss: 2.4832 GLoss: 0.8048 Sum: 3.2880000000000003\n",
      "Step 1331/100000 MLoss: 2.2333 GLoss: 0.829 Sum: 3.0622999999999996\n",
      "Step 1332/100000 MLoss: 2.2381 GLoss: 0.8099 Sum: 3.048\n",
      "Step 1333/100000 MLoss: 2.2272 GLoss: 0.8097 Sum: 3.0368999999999997\n",
      "Step 1334/100000 MLoss: 2.2749 GLoss: 0.8351 Sum: 3.1100000000000003\n",
      "Step 1335/100000 MLoss: 2.161 GLoss: 0.818 Sum: 2.979\n",
      "Step 1336/100000 MLoss: 2.3052 GLoss: 0.8006 Sum: 3.1058000000000003\n",
      "Step 1337/100000 MLoss: 2.2236 GLoss: 0.8136 Sum: 3.0372\n",
      "Step 1338/100000 MLoss: 2.1594 GLoss: 0.7895 Sum: 2.9489\n",
      "Step 1339/100000 MLoss: 2.2727 GLoss: 0.8048 Sum: 3.0774999999999997\n",
      "Step 1340/100000 MLoss: 2.1161 GLoss: 0.8323 Sum: 2.9484\n",
      "Step 1341/100000 MLoss: 2.1193 GLoss: 0.7855 Sum: 2.9048\n",
      "Step 1342/100000 MLoss: 2.1691 GLoss: 0.8036 Sum: 2.9726999999999997\n",
      "Step 1343/100000 MLoss: 2.1818 GLoss: 0.8027 Sum: 2.9844999999999997\n",
      "Step 1344/100000 MLoss: 2.178 GLoss: 0.7911 Sum: 2.9691\n",
      "Step 1345/100000 MLoss: 2.1988 GLoss: 0.8097 Sum: 3.0084999999999997\n",
      "Step 1346/100000 MLoss: 2.1712 GLoss: 0.8195 Sum: 2.9907\n",
      "Step 1347/100000 MLoss: 2.1858 GLoss: 0.8102 Sum: 2.996\n",
      "Step 1348/100000 MLoss: 2.1262 GLoss: 0.803 Sum: 2.9292\n",
      "Step 1349/100000 MLoss: 2.2703 GLoss: 0.8042 Sum: 3.0745000000000005\n",
      "Step 1350/100000 MLoss: 2.2853 GLoss: 0.804 Sum: 3.0892999999999997\n",
      "Step 1351/100000 MLoss: 2.1879 GLoss: 0.8118 Sum: 2.9997\n",
      "Step 1352/100000 MLoss: 2.1383 GLoss: 0.796 Sum: 2.9343000000000004\n",
      "Step 1353/100000 MLoss: 2.3099 GLoss: 0.8096 Sum: 3.1195\n",
      "Step 1354/100000 MLoss: 2.1428 GLoss: 0.8242 Sum: 2.9669999999999996\n",
      "Step 1355/100000 MLoss: 2.2864 GLoss: 0.7998 Sum: 3.0862\n",
      "Step 1356/100000 MLoss: 2.1359 GLoss: 0.8102 Sum: 2.9461\n",
      "Step 1357/100000 MLoss: 2.2517 GLoss: 0.7959 Sum: 3.0476\n",
      "Step 1358/100000 MLoss: 2.1863 GLoss: 0.8175 Sum: 3.0038\n",
      "Step 1359/100000 MLoss: 2.3134 GLoss: 0.8187 Sum: 3.1321000000000003\n",
      "Step 1360/100000 MLoss: 2.0236 GLoss: 0.7927 Sum: 2.8163\n",
      "Step 1361/100000 MLoss: 2.1221 GLoss: 0.8265 Sum: 2.9486\n",
      "Step 1362/100000 MLoss: 2.3707 GLoss: 0.812 Sum: 3.1826999999999996\n",
      "Step 1363/100000 MLoss: 2.274 GLoss: 0.8096 Sum: 3.0836\n",
      "Step 1364/100000 MLoss: 2.1857 GLoss: 0.8039 Sum: 2.9896000000000003\n",
      "Step 1365/100000 MLoss: 2.1437 GLoss: 0.7916 Sum: 2.9353\n",
      "Step 1366/100000 MLoss: 2.1363 GLoss: 0.8151 Sum: 2.9514\n",
      "Step 1367/100000 MLoss: 2.1822 GLoss: 0.8055 Sum: 2.9877\n",
      "Step 1368/100000 MLoss: 2.1327 GLoss: 0.8173 Sum: 2.9499999999999997\n",
      "Step 1369/100000 MLoss: 2.0915 GLoss: 0.8018 Sum: 2.8933\n",
      "Step 1370/100000 MLoss: 2.1401 GLoss: 0.7879 Sum: 2.928\n",
      "Step 1371/100000 MLoss: 2.2091 GLoss: 0.797 Sum: 3.0061\n",
      "Step 1372/100000 MLoss: 2.2289 GLoss: 0.8009 Sum: 3.0298\n",
      "Step 1373/100000 MLoss: 2.2411 GLoss: 0.8191 Sum: 3.0602\n",
      "Step 1374/100000 MLoss: 2.319 GLoss: 0.7967 Sum: 3.1157\n",
      "Step 1375/100000 MLoss: 2.2557 GLoss: 0.7897 Sum: 3.0454\n",
      "Step 1376/100000 MLoss: 2.145 GLoss: 0.7971 Sum: 2.9421\n",
      "Step 1377/100000 MLoss: 2.249 GLoss: 0.7848 Sum: 3.0338000000000003\n",
      "Step 1378/100000 MLoss: 2.2191 GLoss: 0.7724 Sum: 2.9915000000000003\n",
      "Step 1379/100000 MLoss: 2.2155 GLoss: 0.7878 Sum: 3.0033\n",
      "Step 1380/100000 MLoss: 2.2349 GLoss: 0.7969 Sum: 3.0318\n",
      "Step 1381/100000 MLoss: 2.2336 GLoss: 0.7838 Sum: 3.0174000000000003\n",
      "Step 1382/100000 MLoss: 2.1409 GLoss: 0.8071 Sum: 2.948\n",
      "Step 1383/100000 MLoss: 2.1506 GLoss: 0.8204 Sum: 2.971\n",
      "Step 1384/100000 MLoss: 2.1553 GLoss: 0.8178 Sum: 2.9731\n",
      "Step 1385/100000 MLoss: 2.2749 GLoss: 0.7935 Sum: 3.0684\n",
      "Step 1386/100000 MLoss: 2.1536 GLoss: 0.8009 Sum: 2.9545\n",
      "Step 1387/100000 MLoss: 2.1875 GLoss: 0.7886 Sum: 2.9760999999999997\n",
      "Step 1388/100000 MLoss: 2.1968 GLoss: 0.7977 Sum: 2.9945\n",
      "Step 1389/100000 MLoss: 2.1783 GLoss: 0.8108 Sum: 2.9891\n",
      "Step 1390/100000 MLoss: 2.4483 GLoss: 0.7937 Sum: 3.242\n",
      "Step 1391/100000 MLoss: 2.23 GLoss: 0.7888 Sum: 3.0187999999999997\n",
      "Step 1392/100000 MLoss: 2.0936 GLoss: 0.7878 Sum: 2.8813999999999997\n",
      "Step 1393/100000 MLoss: 2.188 GLoss: 0.8158 Sum: 3.0038\n",
      "Step 1394/100000 MLoss: 2.1277 GLoss: 0.7856 Sum: 2.9133\n",
      "Step 1395/100000 MLoss: 2.1995 GLoss: 0.8058 Sum: 3.0053\n",
      "Step 1396/100000 MLoss: 2.1191 GLoss: 0.7883 Sum: 2.9074\n",
      "Step 1397/100000 MLoss: 2.2543 GLoss: 0.8111 Sum: 3.0654000000000003\n",
      "Step 1398/100000 MLoss: 2.2455 GLoss: 0.8131 Sum: 3.0585999999999998\n",
      "Step 1399/100000 MLoss: 2.2151 GLoss: 0.7866 Sum: 3.0017\n",
      "Step 1400/100000 MLoss: 2.2873 GLoss: 0.8106 Sum: 3.0979\n",
      "Step 1401/100000 MLoss: 2.2125 GLoss: 0.8029 Sum: 3.0153999999999996\n",
      "Step 1402/100000 MLoss: 2.2284 GLoss: 0.8049 Sum: 3.0333\n",
      "Step 1403/100000 MLoss: 2.2213 GLoss: 0.8118 Sum: 3.0330999999999997\n",
      "Step 1404/100000 MLoss: 2.2923 GLoss: 0.8121 Sum: 3.1044\n",
      "Step 1405/100000 MLoss: 2.1916 GLoss: 0.803 Sum: 2.9946\n",
      "Step 1406/100000 MLoss: 2.2255 GLoss: 0.8121 Sum: 3.0376\n",
      "Step 1407/100000 MLoss: 2.1518 GLoss: 0.8124 Sum: 2.9642\n",
      "Step 1408/100000 MLoss: 2.1509 GLoss: 0.7999 Sum: 2.9508\n",
      "Step 1409/100000 MLoss: 2.2808 GLoss: 0.7982 Sum: 3.079\n",
      "Step 1410/100000 MLoss: 2.347 GLoss: 0.8115 Sum: 3.1585\n",
      "Step 1411/100000 MLoss: 2.0901 GLoss: 0.79 Sum: 2.8801\n",
      "Step 1412/100000 MLoss: 2.1757 GLoss: 0.8237 Sum: 2.9994\n",
      "Step 1413/100000 MLoss: 2.1489 GLoss: 0.8096 Sum: 2.9585\n",
      "Step 1414/100000 MLoss: 2.2 GLoss: 0.799 Sum: 2.999\n",
      "Step 1415/100000 MLoss: 2.1927 GLoss: 0.7868 Sum: 2.9795\n",
      "Step 1416/100000 MLoss: 2.0788 GLoss: 0.7935 Sum: 2.8723\n",
      "Step 1417/100000 MLoss: 2.1896 GLoss: 0.7918 Sum: 2.9814\n",
      "Step 1418/100000 MLoss: 2.241 GLoss: 0.7851 Sum: 3.0261\n",
      "Step 1419/100000 MLoss: 2.2056 GLoss: 0.8098 Sum: 3.0154\n",
      "Step 1420/100000 MLoss: 2.2664 GLoss: 0.8241 Sum: 3.0905\n",
      "Step 1421/100000 MLoss: 2.1882 GLoss: 0.7966 Sum: 2.9848\n",
      "Step 1422/100000 MLoss: 2.1246 GLoss: 0.7974 Sum: 2.922\n",
      "Step 1423/100000 MLoss: 2.2958 GLoss: 0.7963 Sum: 3.0921\n",
      "Step 1424/100000 MLoss: 2.1166 GLoss: 0.8037 Sum: 2.9203\n",
      "Step 1425/100000 MLoss: 2.2667 GLoss: 0.7871 Sum: 3.0538000000000003\n",
      "Step 1426/100000 MLoss: 2.2333 GLoss: 0.7873 Sum: 3.0206\n",
      "Step 1427/100000 MLoss: 2.2641 GLoss: 0.7984 Sum: 3.0625\n",
      "Step 1428/100000 MLoss: 2.1197 GLoss: 0.7871 Sum: 2.9068\n",
      "Step 1429/100000 MLoss: 2.2936 GLoss: 0.7969 Sum: 3.0905\n",
      "Step 1430/100000 MLoss: 2.3173 GLoss: 0.7747 Sum: 3.092\n",
      "Step 1431/100000 MLoss: 2.1681 GLoss: 0.7822 Sum: 2.9503\n",
      "Step 1432/100000 MLoss: 2.234 GLoss: 0.7926 Sum: 3.0266\n",
      "Step 1433/100000 MLoss: 2.187 GLoss: 0.7962 Sum: 2.9832\n",
      "Step 1434/100000 MLoss: 2.1995 GLoss: 0.7817 Sum: 2.9812\n",
      "Step 1435/100000 MLoss: 2.1596 GLoss: 0.8149 Sum: 2.9745\n",
      "Step 1436/100000 MLoss: 2.0674 GLoss: 0.7997 Sum: 2.8671\n",
      "Step 1437/100000 MLoss: 2.1994 GLoss: 0.8122 Sum: 3.0115999999999996\n",
      "Step 1438/100000 MLoss: 2.206 GLoss: 0.8207 Sum: 3.0267\n",
      "Step 1439/100000 MLoss: 2.1831 GLoss: 0.79 Sum: 2.9731\n",
      "Step 1440/100000 MLoss: 2.285 GLoss: 0.7855 Sum: 3.0705\n",
      "Step 1441/100000 MLoss: 2.3274 GLoss: 0.8057 Sum: 3.1330999999999998\n",
      "Step 1442/100000 MLoss: 2.2651 GLoss: 0.8089 Sum: 3.074\n",
      "Step 1443/100000 MLoss: 2.2207 GLoss: 0.8169 Sum: 3.0376\n",
      "Step 1444/100000 MLoss: 2.2724 GLoss: 0.8107 Sum: 3.0831\n",
      "Step 1445/100000 MLoss: 2.1128 GLoss: 0.7864 Sum: 2.8992\n",
      "Step 1446/100000 MLoss: 2.1576 GLoss: 0.8102 Sum: 2.9678\n",
      "Step 1447/100000 MLoss: 2.2241 GLoss: 0.8026 Sum: 3.0267\n",
      "Step 1448/100000 MLoss: 2.2595 GLoss: 0.8068 Sum: 3.0663\n",
      "Step 1449/100000 MLoss: 2.1766 GLoss: 0.7823 Sum: 2.9589\n",
      "Step 1450/100000 MLoss: 2.3009 GLoss: 0.7931 Sum: 3.094\n",
      "Step 1451/100000 MLoss: 2.2447 GLoss: 0.825 Sum: 3.0697\n",
      "Step 1452/100000 MLoss: 2.2026 GLoss: 0.8166 Sum: 3.0191999999999997\n",
      "Step 1453/100000 MLoss: 2.1304 GLoss: 0.7861 Sum: 2.9165\n",
      "Step 1454/100000 MLoss: 2.2355 GLoss: 0.8263 Sum: 3.0618\n",
      "Step 1455/100000 MLoss: 2.2217 GLoss: 0.8175 Sum: 3.0391999999999997\n",
      "Step 1456/100000 MLoss: 2.218 GLoss: 0.7845 Sum: 3.0025\n",
      "Step 1457/100000 MLoss: 2.3102 GLoss: 0.8184 Sum: 3.1286\n",
      "Step 1458/100000 MLoss: 2.093 GLoss: 0.787 Sum: 2.88\n",
      "Step 1459/100000 MLoss: 2.3121 GLoss: 0.7902 Sum: 3.1023\n",
      "Step 1460/100000 MLoss: 2.2834 GLoss: 0.8015 Sum: 3.0848999999999998\n",
      "Step 1461/100000 MLoss: 2.2347 GLoss: 0.7889 Sum: 3.0236\n",
      "Step 1462/100000 MLoss: 2.1286 GLoss: 0.785 Sum: 2.9136\n",
      "Step 1463/100000 MLoss: 2.1865 GLoss: 0.8049 Sum: 2.9914\n",
      "Step 1464/100000 MLoss: 2.2279 GLoss: 0.8048 Sum: 3.0327\n",
      "Step 1465/100000 MLoss: 2.1699 GLoss: 0.8149 Sum: 2.9848\n",
      "Step 1466/100000 MLoss: 2.152 GLoss: 0.7922 Sum: 2.9442000000000004\n",
      "Step 1467/100000 MLoss: 2.1684 GLoss: 0.7978 Sum: 2.9662\n",
      "Step 1468/100000 MLoss: 2.0836 GLoss: 0.7998 Sum: 2.8834\n",
      "Step 1469/100000 MLoss: 2.1469 GLoss: 0.8051 Sum: 2.952\n",
      "Step 1470/100000 MLoss: 1.9655 GLoss: 0.776 Sum: 2.7415000000000003\n",
      "Step 1471/100000 MLoss: 2.2046 GLoss: 0.7911 Sum: 2.9957000000000003\n",
      "Step 1472/100000 MLoss: 2.1328 GLoss: 0.7974 Sum: 2.9302\n",
      "Step 1473/100000 MLoss: 2.185 GLoss: 0.8009 Sum: 2.9859\n",
      "Step 1474/100000 MLoss: 2.0958 GLoss: 0.7856 Sum: 2.8814\n",
      "Step 1475/100000 MLoss: 2.0675 GLoss: 0.7887 Sum: 2.8562\n",
      "Step 1476/100000 MLoss: 2.1913 GLoss: 0.789 Sum: 2.9803\n",
      "Step 1477/100000 MLoss: 2.1995 GLoss: 0.7916 Sum: 2.9911\n",
      "Step 1478/100000 MLoss: 2.3041 GLoss: 0.7935 Sum: 3.0976\n",
      "Step 1479/100000 MLoss: 2.1825 GLoss: 0.7873 Sum: 2.9698\n",
      "Step 1480/100000 MLoss: 2.096 GLoss: 0.7825 Sum: 2.8785\n",
      "Step 1481/100000 MLoss: 2.3051 GLoss: 0.7968 Sum: 3.1018999999999997\n",
      "Step 1482/100000 MLoss: 2.2469 GLoss: 0.8011 Sum: 3.048\n",
      "Step 1483/100000 MLoss: 2.2085 GLoss: 0.7997 Sum: 3.0082\n",
      "Step 1484/100000 MLoss: 2.1813 GLoss: 0.7902 Sum: 2.9715\n",
      "Step 1485/100000 MLoss: 2.2106 GLoss: 0.7913 Sum: 3.0019\n",
      "Step 1486/100000 MLoss: 2.2732 GLoss: 0.7822 Sum: 3.0554\n",
      "Step 1487/100000 MLoss: 2.2022 GLoss: 0.8286 Sum: 3.0308\n",
      "Step 1488/100000 MLoss: 2.113 GLoss: 0.8075 Sum: 2.9205\n",
      "Step 1489/100000 MLoss: 2.2055 GLoss: 0.7778 Sum: 2.9833\n",
      "Step 1490/100000 MLoss: 1.9761 GLoss: 0.7731 Sum: 2.7492\n",
      "Step 1491/100000 MLoss: 2.2361 GLoss: 0.8031 Sum: 3.0392\n",
      "Step 1492/100000 MLoss: 2.1494 GLoss: 0.802 Sum: 2.9514\n",
      "Step 1493/100000 MLoss: 2.221 GLoss: 0.7848 Sum: 3.0058000000000002\n",
      "Step 1494/100000 MLoss: 2.1778 GLoss: 0.7897 Sum: 2.9675\n",
      "Step 1495/100000 MLoss: 2.149 GLoss: 0.8118 Sum: 2.9608\n",
      "Step 1496/100000 MLoss: 2.1499 GLoss: 0.7789 Sum: 2.9288000000000003\n",
      "Step 1497/100000 MLoss: 2.1317 GLoss: 0.7909 Sum: 2.9226\n",
      "Step 1498/100000 MLoss: 2.145 GLoss: 0.7906 Sum: 2.9356\n",
      "Step 1499/100000 MLoss: 2.194 GLoss: 0.7811 Sum: 2.9751\n",
      "Step 1500/100000 MLoss: 2.1937 GLoss: 0.7793 Sum: 2.9730000000000003\n",
      "Step 1501/100000 MLoss: 2.164 GLoss: 0.7862 Sum: 2.9502\n",
      "Step 1502/100000 MLoss: 2.1937 GLoss: 0.7978 Sum: 2.9915000000000003\n",
      "Step 1503/100000 MLoss: 2.1794 GLoss: 0.8024 Sum: 2.9818\n",
      "Step 1504/100000 MLoss: 2.2411 GLoss: 0.7765 Sum: 3.0176\n",
      "Step 1505/100000 MLoss: 2.3398 GLoss: 0.7985 Sum: 3.1383\n",
      "Step 1506/100000 MLoss: 2.1639 GLoss: 0.7921 Sum: 2.956\n",
      "Step 1507/100000 MLoss: 2.0898 GLoss: 0.7966 Sum: 2.8864\n",
      "Step 1508/100000 MLoss: 2.1901 GLoss: 0.8134 Sum: 3.0035000000000003\n",
      "Step 1509/100000 MLoss: 2.2821 GLoss: 0.7907 Sum: 3.0728\n",
      "Step 1510/100000 MLoss: 2.272 GLoss: 0.8058 Sum: 3.0778\n",
      "Step 1511/100000 MLoss: 2.2165 GLoss: 0.795 Sum: 3.0115\n",
      "Step 1512/100000 MLoss: 2.153 GLoss: 0.7906 Sum: 2.9436\n",
      "Step 1513/100000 MLoss: 2.1921 GLoss: 0.7984 Sum: 2.9905\n",
      "Step 1514/100000 MLoss: 2.2502 GLoss: 0.8036 Sum: 3.0538\n",
      "Step 1515/100000 MLoss: 2.2714 GLoss: 0.7789 Sum: 3.0503\n",
      "Step 1516/100000 MLoss: 2.0774 GLoss: 0.7891 Sum: 2.8665\n",
      "Step 1517/100000 MLoss: 2.1911 GLoss: 0.8002 Sum: 2.9913\n",
      "Step 1518/100000 MLoss: 2.2396 GLoss: 0.7742 Sum: 3.0138\n",
      "Step 1519/100000 MLoss: 2.1645 GLoss: 0.7904 Sum: 2.9549\n",
      "Step 1520/100000 MLoss: 2.406 GLoss: 0.8015 Sum: 3.2075\n",
      "Step 1521/100000 MLoss: 2.2498 GLoss: 0.7937 Sum: 3.0435\n",
      "Step 1522/100000 MLoss: 2.2228 GLoss: 0.7929 Sum: 3.0157\n",
      "Step 1523/100000 MLoss: 2.1983 GLoss: 0.7827 Sum: 2.981\n",
      "Step 1524/100000 MLoss: 2.2626 GLoss: 0.7885 Sum: 3.0511\n",
      "Step 1525/100000 MLoss: 2.1736 GLoss: 0.7944 Sum: 2.968\n",
      "Step 1526/100000 MLoss: 2.1179 GLoss: 0.7943 Sum: 2.9122000000000003\n",
      "Step 1527/100000 MLoss: 2.1346 GLoss: 0.7827 Sum: 2.9173\n",
      "Step 1528/100000 MLoss: 2.1216 GLoss: 0.7891 Sum: 2.9107\n",
      "Step 1529/100000 MLoss: 2.0972 GLoss: 0.8047 Sum: 2.9019\n",
      "Step 1530/100000 MLoss: 2.2563 GLoss: 0.7886 Sum: 3.0449\n",
      "Step 1531/100000 MLoss: 2.1533 GLoss: 0.8098 Sum: 2.9631000000000003\n",
      "Step 1532/100000 MLoss: 2.1746 GLoss: 0.8084 Sum: 2.9829999999999997\n",
      "Step 1533/100000 MLoss: 2.1544 GLoss: 0.7794 Sum: 2.9337999999999997\n",
      "Step 1534/100000 MLoss: 2.1497 GLoss: 0.7823 Sum: 2.9320000000000004\n",
      "Step 1535/100000 MLoss: 2.301 GLoss: 0.7933 Sum: 3.0943\n",
      "Step 1536/100000 MLoss: 2.2493 GLoss: 0.7977 Sum: 3.0469999999999997\n",
      "Step 1537/100000 MLoss: 2.2784 GLoss: 0.7906 Sum: 3.069\n",
      "Step 1538/100000 MLoss: 2.2258 GLoss: 0.807 Sum: 3.0328\n",
      "Step 1539/100000 MLoss: 2.1945 GLoss: 0.8055 Sum: 3.0\n",
      "Step 1540/100000 MLoss: 2.0634 GLoss: 0.7961 Sum: 2.8595\n",
      "Step 1541/100000 MLoss: 2.2434 GLoss: 0.8067 Sum: 3.0500999999999996\n",
      "Step 1542/100000 MLoss: 2.2008 GLoss: 0.7962 Sum: 2.997\n",
      "Step 1543/100000 MLoss: 2.3704 GLoss: 0.8008 Sum: 3.1712\n",
      "Step 1544/100000 MLoss: 2.1925 GLoss: 0.8082 Sum: 3.0007\n",
      "Step 1545/100000 MLoss: 2.2073 GLoss: 0.7884 Sum: 2.9957000000000003\n",
      "Step 1546/100000 MLoss: 2.2216 GLoss: 0.801 Sum: 3.0226\n",
      "Step 1547/100000 MLoss: 2.1841 GLoss: 0.774 Sum: 2.9581\n",
      "Step 1548/100000 MLoss: 2.1965 GLoss: 0.7983 Sum: 2.9947999999999997\n",
      "Step 1549/100000 MLoss: 2.2868 GLoss: 0.7945 Sum: 3.0812999999999997\n",
      "Step 1550/100000 MLoss: 2.0809 GLoss: 0.7987 Sum: 2.8796\n",
      "Step 1551/100000 MLoss: 2.1555 GLoss: 0.7838 Sum: 2.9393000000000002\n",
      "Step 1552/100000 MLoss: 2.2352 GLoss: 0.7972 Sum: 3.0324\n",
      "Step 1553/100000 MLoss: 2.1394 GLoss: 0.7952 Sum: 2.9346\n",
      "Step 1554/100000 MLoss: 2.1321 GLoss: 0.7921 Sum: 2.9242\n",
      "Step 1555/100000 MLoss: 2.2693 GLoss: 0.798 Sum: 3.0673\n",
      "Step 1556/100000 MLoss: 2.1444 GLoss: 0.7735 Sum: 2.9179\n",
      "Step 1557/100000 MLoss: 2.2949 GLoss: 0.7838 Sum: 3.0787000000000004\n",
      "Step 1558/100000 MLoss: 2.1251 GLoss: 0.7826 Sum: 2.9077\n",
      "Step 1559/100000 MLoss: 2.1797 GLoss: 0.802 Sum: 2.9817\n",
      "Step 1560/100000 MLoss: 2.3946 GLoss: 0.8129 Sum: 3.2075\n",
      "Step 1561/100000 MLoss: 2.1374 GLoss: 0.7849 Sum: 2.9223\n",
      "Step 1562/100000 MLoss: 2.2161 GLoss: 0.7878 Sum: 3.0039\n",
      "Step 1563/100000 MLoss: 2.1678 GLoss: 0.7711 Sum: 2.9389000000000003\n",
      "Step 1564/100000 MLoss: 2.0899 GLoss: 0.8041 Sum: 2.894\n",
      "Step 1565/100000 MLoss: 2.2273 GLoss: 0.8059 Sum: 3.0332\n",
      "Step 1566/100000 MLoss: 2.2845 GLoss: 0.7937 Sum: 3.0782\n",
      "Step 1567/100000 MLoss: 2.1985 GLoss: 0.7968 Sum: 2.9953000000000003\n",
      "Step 1568/100000 MLoss: 2.2377 GLoss: 0.7918 Sum: 3.0294999999999996\n",
      "Step 1569/100000 MLoss: 2.1466 GLoss: 0.8026 Sum: 2.9492\n",
      "Step 1570/100000 MLoss: 2.0343 GLoss: 0.8044 Sum: 2.8387000000000002\n",
      "Step 1571/100000 MLoss: 2.298 GLoss: 0.7709 Sum: 3.0689\n",
      "Step 1572/100000 MLoss: 2.184 GLoss: 0.7822 Sum: 2.9662\n",
      "Step 1573/100000 MLoss: 2.1623 GLoss: 0.7819 Sum: 2.9442000000000004\n",
      "Step 1574/100000 MLoss: 2.2341 GLoss: 0.7933 Sum: 3.0274\n",
      "Step 1575/100000 MLoss: 2.1796 GLoss: 0.7861 Sum: 2.9657\n",
      "Step 1576/100000 MLoss: 2.1786 GLoss: 0.7976 Sum: 2.9762\n",
      "Step 1577/100000 MLoss: 2.1625 GLoss: 0.7974 Sum: 2.9599\n",
      "Step 1578/100000 MLoss: 2.1699 GLoss: 0.7841 Sum: 2.954\n",
      "Step 1579/100000 MLoss: 2.1595 GLoss: 0.7987 Sum: 2.9581999999999997\n",
      "Step 1580/100000 MLoss: 2.103 GLoss: 0.8222 Sum: 2.9252000000000002\n",
      "Step 1581/100000 MLoss: 2.1725 GLoss: 0.8053 Sum: 2.9778\n",
      "Step 1582/100000 MLoss: 2.1603 GLoss: 0.7993 Sum: 2.9596\n",
      "Step 1583/100000 MLoss: 2.2289 GLoss: 0.7893 Sum: 3.0181999999999998\n",
      "Step 1584/100000 MLoss: 2.1178 GLoss: 0.7831 Sum: 2.9009\n",
      "Step 1585/100000 MLoss: 2.225 GLoss: 0.7971 Sum: 3.0221\n",
      "Step 1586/100000 MLoss: 2.2515 GLoss: 0.7923 Sum: 3.0438\n",
      "Step 1587/100000 MLoss: 2.1399 GLoss: 0.7702 Sum: 2.9101\n",
      "Step 1588/100000 MLoss: 2.3041 GLoss: 0.7938 Sum: 3.0979\n",
      "Step 1589/100000 MLoss: 2.1987 GLoss: 0.7782 Sum: 2.9769\n",
      "Step 1590/100000 MLoss: 2.0553 GLoss: 0.8052 Sum: 2.8605\n",
      "Step 1591/100000 MLoss: 2.2914 GLoss: 0.7979 Sum: 3.0892999999999997\n",
      "Step 1592/100000 MLoss: 2.1524 GLoss: 0.7873 Sum: 2.9397\n",
      "Step 1593/100000 MLoss: 2.2268 GLoss: 0.8032 Sum: 3.03\n",
      "Step 1594/100000 MLoss: 2.1465 GLoss: 0.7844 Sum: 2.9309000000000003\n",
      "Step 1595/100000 MLoss: 2.1512 GLoss: 0.7939 Sum: 2.9451\n",
      "Step 1596/100000 MLoss: 2.2114 GLoss: 0.7917 Sum: 3.0031\n",
      "Step 1597/100000 MLoss: 2.216 GLoss: 0.7805 Sum: 2.9965\n",
      "Step 1598/100000 MLoss: 2.1752 GLoss: 0.8166 Sum: 2.9917999999999996\n",
      "Step 1599/100000 MLoss: 2.144 GLoss: 0.8022 Sum: 2.9462\n",
      "Step 1600/100000 MLoss: 2.1118 GLoss: 0.7792 Sum: 2.891\n",
      "Step 1601/100000 MLoss: 2.2569 GLoss: 0.7733 Sum: 3.0302\n",
      "Step 1602/100000 MLoss: 2.2236 GLoss: 0.7859 Sum: 3.0095\n",
      "Step 1603/100000 MLoss: 2.1844 GLoss: 0.7805 Sum: 2.9649\n",
      "Step 1604/100000 MLoss: 2.1924 GLoss: 0.7964 Sum: 2.9888000000000003\n",
      "Step 1605/100000 MLoss: 2.24 GLoss: 0.7926 Sum: 3.0326000000000004\n",
      "Step 1606/100000 MLoss: 2.1497 GLoss: 0.7822 Sum: 2.9319\n",
      "Step 1607/100000 MLoss: 2.06 GLoss: 0.8003 Sum: 2.8603\n",
      "Step 1608/100000 MLoss: 2.1878 GLoss: 0.7957 Sum: 2.9835000000000003\n",
      "Step 1609/100000 MLoss: 2.1738 GLoss: 0.7848 Sum: 2.9586\n",
      "Step 1610/100000 MLoss: 2.1835 GLoss: 0.781 Sum: 2.9645\n",
      "Step 1611/100000 MLoss: 2.2335 GLoss: 0.8128 Sum: 3.0462999999999996\n",
      "Step 1612/100000 MLoss: 2.1654 GLoss: 0.7744 Sum: 2.9398\n",
      "Step 1613/100000 MLoss: 2.1901 GLoss: 0.7907 Sum: 2.9808000000000003\n",
      "Step 1614/100000 MLoss: 2.2174 GLoss: 0.7921 Sum: 3.0095\n",
      "Step 1615/100000 MLoss: 2.1731 GLoss: 0.799 Sum: 2.9720999999999997\n",
      "Step 1616/100000 MLoss: 2.1215 GLoss: 0.7792 Sum: 2.9007\n",
      "Step 1617/100000 MLoss: 2.2076 GLoss: 0.8016 Sum: 3.0092\n",
      "Step 1618/100000 MLoss: 2.1923 GLoss: 0.7808 Sum: 2.9731\n",
      "Step 1619/100000 MLoss: 2.224 GLoss: 0.8211 Sum: 3.0451\n",
      "Step 1620/100000 MLoss: 2.369 GLoss: 0.8172 Sum: 3.1862000000000004\n",
      "Step 1621/100000 MLoss: 2.1626 GLoss: 0.7909 Sum: 2.9535\n",
      "Step 1622/100000 MLoss: 2.2181 GLoss: 0.8258 Sum: 3.0439000000000003\n",
      "Step 1623/100000 MLoss: 2.2067 GLoss: 0.823 Sum: 3.0297\n",
      "Step 1624/100000 MLoss: 2.1137 GLoss: 0.789 Sum: 2.9027000000000003\n",
      "Step 1625/100000 MLoss: 2.1272 GLoss: 0.8008 Sum: 2.928\n",
      "Step 1626/100000 MLoss: 2.2814 GLoss: 0.8284 Sum: 3.1098\n",
      "Step 1627/100000 MLoss: 2.2265 GLoss: 0.8051 Sum: 3.0316\n",
      "Step 1628/100000 MLoss: 2.2721 GLoss: 0.8235 Sum: 3.0956\n",
      "Step 1629/100000 MLoss: 2.1634 GLoss: 0.8339 Sum: 2.9973\n",
      "Step 1630/100000 MLoss: 2.0955 GLoss: 0.8424 Sum: 2.9379\n",
      "Step 1631/100000 MLoss: 2.127 GLoss: 0.7997 Sum: 2.9267\n",
      "Step 1632/100000 MLoss: 2.1161 GLoss: 0.8238 Sum: 2.9398999999999997\n",
      "Step 1633/100000 MLoss: 2.1452 GLoss: 0.8148 Sum: 2.96\n",
      "Step 1634/100000 MLoss: 2.2522 GLoss: 0.7796 Sum: 3.0318\n",
      "Step 1635/100000 MLoss: 2.2016 GLoss: 0.7964 Sum: 2.998\n",
      "Step 1636/100000 MLoss: 2.1913 GLoss: 0.796 Sum: 2.9873000000000003\n",
      "Step 1637/100000 MLoss: 2.3194 GLoss: 0.7992 Sum: 3.1186\n",
      "Step 1638/100000 MLoss: 2.2117 GLoss: 0.8068 Sum: 3.0185\n",
      "Step 1639/100000 MLoss: 2.2811 GLoss: 0.8101 Sum: 3.0911999999999997\n",
      "Step 1640/100000 MLoss: 2.0749 GLoss: 0.7957 Sum: 2.8706\n",
      "Step 1641/100000 MLoss: 2.1856 GLoss: 0.7859 Sum: 2.9715\n",
      "Step 1642/100000 MLoss: 2.2201 GLoss: 0.8374 Sum: 3.0575\n",
      "Step 1643/100000 MLoss: 2.2188 GLoss: 0.8176 Sum: 3.0364\n",
      "Step 1644/100000 MLoss: 2.1533 GLoss: 0.8106 Sum: 2.9639\n",
      "Step 1645/100000 MLoss: 2.219 GLoss: 0.8153 Sum: 3.0343\n",
      "Step 1646/100000 MLoss: 2.1443 GLoss: 0.8021 Sum: 2.9463999999999997\n",
      "Step 1647/100000 MLoss: 2.1438 GLoss: 0.8131 Sum: 2.9569\n",
      "Step 1648/100000 MLoss: 2.1252 GLoss: 0.7911 Sum: 2.9163\n",
      "Step 1649/100000 MLoss: 2.1604 GLoss: 0.7955 Sum: 2.9559\n",
      "Step 1650/100000 MLoss: 2.2165 GLoss: 0.7764 Sum: 2.9928999999999997\n",
      "Step 1651/100000 MLoss: 2.0991 GLoss: 0.8036 Sum: 2.9027\n",
      "Step 1652/100000 MLoss: 2.1936 GLoss: 0.7908 Sum: 2.9844\n",
      "Step 1653/100000 MLoss: 2.0591 GLoss: 0.7978 Sum: 2.8569\n",
      "Step 1654/100000 MLoss: 2.2012 GLoss: 0.7815 Sum: 2.9827\n",
      "Step 1655/100000 MLoss: 2.2069 GLoss: 0.7868 Sum: 2.9937\n",
      "Step 1656/100000 MLoss: 2.2292 GLoss: 0.7931 Sum: 3.0223\n",
      "Step 1657/100000 MLoss: 2.1604 GLoss: 0.7889 Sum: 2.9493\n",
      "Step 1658/100000 MLoss: 2.2097 GLoss: 0.7953 Sum: 3.0050000000000003\n",
      "Step 1659/100000 MLoss: 2.1858 GLoss: 0.771 Sum: 2.9568\n",
      "Step 1660/100000 MLoss: 2.2069 GLoss: 0.827 Sum: 3.0339\n",
      "Step 1661/100000 MLoss: 2.257 GLoss: 0.7814 Sum: 3.0384\n",
      "Step 1662/100000 MLoss: 2.1863 GLoss: 0.7904 Sum: 2.9767\n",
      "Step 1663/100000 MLoss: 2.1685 GLoss: 0.795 Sum: 2.9635\n",
      "Step 1664/100000 MLoss: 2.0645 GLoss: 0.7875 Sum: 2.852\n",
      "Step 1665/100000 MLoss: 2.119 GLoss: 0.7759 Sum: 2.8949000000000003\n",
      "Step 1666/100000 MLoss: 2.1695 GLoss: 0.7901 Sum: 2.9596\n",
      "Step 1667/100000 MLoss: 2.1954 GLoss: 0.7743 Sum: 2.9696999999999996\n",
      "Step 1668/100000 MLoss: 2.2264 GLoss: 0.7976 Sum: 3.024\n",
      "Step 1669/100000 MLoss: 2.1558 GLoss: 0.799 Sum: 2.9548\n",
      "Step 1670/100000 MLoss: 2.0867 GLoss: 0.7606 Sum: 2.8473\n",
      "Step 1671/100000 MLoss: 2.2012 GLoss: 0.7941 Sum: 2.9953000000000003\n",
      "Step 1672/100000 MLoss: 2.0765 GLoss: 0.7942 Sum: 2.8707\n",
      "Step 1673/100000 MLoss: 2.2565 GLoss: 0.7817 Sum: 3.0382\n",
      "Step 1674/100000 MLoss: 2.2829 GLoss: 0.7843 Sum: 3.0672\n",
      "Step 1675/100000 MLoss: 2.2999 GLoss: 0.7831 Sum: 3.083\n",
      "Step 1676/100000 MLoss: 2.27 GLoss: 0.793 Sum: 3.063\n",
      "Step 1677/100000 MLoss: 2.2853 GLoss: 0.7877 Sum: 3.073\n",
      "Step 1678/100000 MLoss: 2.208 GLoss: 0.7968 Sum: 3.0048000000000004\n",
      "Step 1679/100000 MLoss: 2.1033 GLoss: 0.7808 Sum: 2.8841\n",
      "Step 1680/100000 MLoss: 2.2531 GLoss: 0.7702 Sum: 3.0233\n",
      "Step 1681/100000 MLoss: 2.2097 GLoss: 0.7836 Sum: 2.9933\n",
      "Step 1682/100000 MLoss: 2.1617 GLoss: 0.7766 Sum: 2.9383\n",
      "Step 1683/100000 MLoss: 2.1549 GLoss: 0.808 Sum: 2.9629000000000003\n",
      "Step 1684/100000 MLoss: 2.2501 GLoss: 0.7901 Sum: 3.0402000000000005\n",
      "Step 1685/100000 MLoss: 2.2967 GLoss: 0.8011 Sum: 3.0978\n",
      "Step 1686/100000 MLoss: 2.0935 GLoss: 0.8223 Sum: 2.9158\n",
      "Step 1687/100000 MLoss: 2.2019 GLoss: 0.7622 Sum: 2.9641\n",
      "Step 1688/100000 MLoss: 2.1239 GLoss: 0.8015 Sum: 2.9254\n",
      "Step 1689/100000 MLoss: 2.2205 GLoss: 0.7991 Sum: 3.0196\n",
      "Step 1690/100000 MLoss: 2.2514 GLoss: 0.7868 Sum: 3.0382\n",
      "Step 1691/100000 MLoss: 2.2162 GLoss: 0.7862 Sum: 3.0024\n",
      "Step 1692/100000 MLoss: 2.1544 GLoss: 0.7868 Sum: 2.9412\n",
      "Step 1693/100000 MLoss: 2.2438 GLoss: 0.7879 Sum: 3.0317\n",
      "Step 1694/100000 MLoss: 2.2074 GLoss: 0.7958 Sum: 3.0031999999999996\n",
      "Step 1695/100000 MLoss: 2.2353 GLoss: 0.7793 Sum: 3.0146\n",
      "Step 1696/100000 MLoss: 2.7825 GLoss: 0.7782 Sum: 3.5607\n",
      "Step 1697/100000 MLoss: 2.1322 GLoss: 0.7841 Sum: 2.9163\n",
      "Step 1698/100000 MLoss: 2.1848 GLoss: 0.7925 Sum: 2.9773\n",
      "Step 1699/100000 MLoss: 2.1074 GLoss: 0.781 Sum: 2.8884000000000003\n",
      "Step 1700/100000 MLoss: 2.2127 GLoss: 0.8345 Sum: 3.0472\n",
      "Step 1701/100000 MLoss: 2.134 GLoss: 0.7746 Sum: 2.9086\n",
      "Step 1702/100000 MLoss: 2.1323 GLoss: 0.7835 Sum: 2.9158\n",
      "Step 1703/100000 MLoss: 2.1242 GLoss: 0.7946 Sum: 2.9188\n",
      "Step 1704/100000 MLoss: 2.1542 GLoss: 0.7794 Sum: 2.9335999999999998\n",
      "Step 1705/100000 MLoss: 2.2283 GLoss: 0.7813 Sum: 3.0096\n",
      "Step 1706/100000 MLoss: 2.1906 GLoss: 0.767 Sum: 2.9576\n",
      "Step 1707/100000 MLoss: 2.1436 GLoss: 0.7716 Sum: 2.9152\n",
      "Step 1708/100000 MLoss: 2.2648 GLoss: 0.7694 Sum: 3.0342000000000002\n",
      "Step 1709/100000 MLoss: 2.2406 GLoss: 0.8038 Sum: 3.0444\n",
      "Step 1710/100000 MLoss: 2.0225 GLoss: 0.7356 Sum: 2.7580999999999998\n",
      "Step 1711/100000 MLoss: 2.1222 GLoss: 0.797 Sum: 2.9192\n",
      "Step 1712/100000 MLoss: 2.076 GLoss: 0.7911 Sum: 2.8671\n",
      "Step 1713/100000 MLoss: 2.1702 GLoss: 0.8018 Sum: 2.972\n",
      "Step 1714/100000 MLoss: 2.1616 GLoss: 0.793 Sum: 2.9546\n",
      "Step 1715/100000 MLoss: 2.1748 GLoss: 0.7937 Sum: 2.9684999999999997\n",
      "Step 1716/100000 MLoss: 2.1009 GLoss: 0.7988 Sum: 2.8997\n",
      "Step 1717/100000 MLoss: 2.1415 GLoss: 0.7523 Sum: 2.8938\n",
      "Step 1718/100000 MLoss: 2.2173 GLoss: 0.7997 Sum: 3.017\n",
      "Step 1719/100000 MLoss: 2.204 GLoss: 0.7685 Sum: 2.9725\n",
      "Step 1720/100000 MLoss: 2.1176 GLoss: 0.7537 Sum: 2.8712999999999997\n",
      "Step 1721/100000 MLoss: 2.2578 GLoss: 0.7731 Sum: 3.0309\n",
      "Step 1722/100000 MLoss: 2.1241 GLoss: 0.7513 Sum: 2.8754\n",
      "Step 1723/100000 MLoss: 2.2113 GLoss: 0.7934 Sum: 3.0047\n",
      "Step 1724/100000 MLoss: 2.1843 GLoss: 0.7813 Sum: 2.9656\n",
      "Step 1725/100000 MLoss: 2.1693 GLoss: 0.7773 Sum: 2.9465999999999997\n",
      "Step 1726/100000 MLoss: 2.1842 GLoss: 0.7685 Sum: 2.9527\n",
      "Step 1727/100000 MLoss: 2.2927 GLoss: 0.7805 Sum: 3.0732\n",
      "Step 1728/100000 MLoss: 2.2133 GLoss: 0.7949 Sum: 3.0082\n",
      "Step 1729/100000 MLoss: 2.3523 GLoss: 0.7723 Sum: 3.1246\n",
      "Step 1730/100000 MLoss: 2.2185 GLoss: 0.7872 Sum: 3.0057\n",
      "Step 1731/100000 MLoss: 2.2125 GLoss: 0.747 Sum: 2.9595\n",
      "Step 1732/100000 MLoss: 2.2264 GLoss: 0.8083 Sum: 3.0347\n",
      "Step 1733/100000 MLoss: 2.3491 GLoss: 0.8251 Sum: 3.1742\n",
      "Step 1734/100000 MLoss: 2.1375 GLoss: 0.759 Sum: 2.8965\n",
      "Step 1735/100000 MLoss: 2.3007 GLoss: 0.8457 Sum: 3.1464\n",
      "Step 1736/100000 MLoss: 2.1669 GLoss: 0.7725 Sum: 2.9394\n",
      "Step 1737/100000 MLoss: 2.1204 GLoss: 0.7816 Sum: 2.902\n",
      "Step 1738/100000 MLoss: 2.1487 GLoss: 0.7748 Sum: 2.9234999999999998\n",
      "Step 1739/100000 MLoss: 2.2852 GLoss: 0.7678 Sum: 3.053\n",
      "Step 1740/100000 MLoss: 2.4085 GLoss: 0.7562 Sum: 3.1647\n",
      "Step 1741/100000 MLoss: 2.2317 GLoss: 0.7774 Sum: 3.0091\n",
      "Step 1742/100000 MLoss: 2.1962 GLoss: 0.7627 Sum: 2.9589000000000003\n",
      "Step 1743/100000 MLoss: 2.158 GLoss: 0.7624 Sum: 2.9204\n",
      "Step 1744/100000 MLoss: 2.1298 GLoss: 0.767 Sum: 2.8968\n",
      "Step 1745/100000 MLoss: 2.1543 GLoss: 0.7521 Sum: 2.9064\n",
      "Step 1746/100000 MLoss: 2.3531 GLoss: 0.8229 Sum: 3.176\n",
      "Step 1747/100000 MLoss: 2.1461 GLoss: 0.7774 Sum: 2.9235\n",
      "Step 1748/100000 MLoss: 2.2109 GLoss: 0.7676 Sum: 2.9785\n",
      "Step 1749/100000 MLoss: 2.1656 GLoss: 0.7649 Sum: 2.9305\n",
      "Step 1750/100000 MLoss: 1.9118 GLoss: 0.8037 Sum: 2.7155\n",
      "Step 1751/100000 MLoss: 2.1808 GLoss: 0.8107 Sum: 2.9915000000000003\n",
      "Step 1752/100000 MLoss: 2.2207 GLoss: 0.7596 Sum: 2.9802999999999997\n",
      "Step 1753/100000 MLoss: 2.2158 GLoss: 0.7758 Sum: 2.9916\n",
      "Step 1754/100000 MLoss: 2.2244 GLoss: 0.7602 Sum: 2.9846000000000004\n",
      "Step 1755/100000 MLoss: 2.2015 GLoss: 0.7683 Sum: 2.9697999999999998\n",
      "Step 1756/100000 MLoss: 2.165 GLoss: 0.7551 Sum: 2.9201\n",
      "Step 1757/100000 MLoss: 2.1174 GLoss: 0.7346 Sum: 2.852\n",
      "Step 1758/100000 MLoss: 2.1919 GLoss: 0.7616 Sum: 2.9535\n",
      "Step 1759/100000 MLoss: 2.4816 GLoss: 0.7395 Sum: 3.2211\n",
      "Step 1760/100000 MLoss: 2.0853 GLoss: 0.735 Sum: 2.8203\n",
      "Step 1761/100000 MLoss: 2.1219 GLoss: 0.761 Sum: 2.8829000000000002\n",
      "Step 1762/100000 MLoss: 2.2445 GLoss: 0.7346 Sum: 2.9791\n",
      "Step 1763/100000 MLoss: 2.1443 GLoss: 0.7683 Sum: 2.9126\n",
      "Step 1764/100000 MLoss: 2.1812 GLoss: 0.7505 Sum: 2.9317\n",
      "Step 1765/100000 MLoss: 2.1246 GLoss: 0.7681 Sum: 2.8927\n",
      "Step 1766/100000 MLoss: 2.2258 GLoss: 0.7544 Sum: 2.9802\n",
      "Step 1767/100000 MLoss: 2.1278 GLoss: 0.7598 Sum: 2.8876\n",
      "Step 1768/100000 MLoss: 2.0391 GLoss: 0.7448 Sum: 2.7839\n",
      "Step 1769/100000 MLoss: 2.1673 GLoss: 0.7476 Sum: 2.9149000000000003\n",
      "Step 1770/100000 MLoss: 2.439 GLoss: 0.7292 Sum: 3.1682\n",
      "Step 1771/100000 MLoss: 2.1221 GLoss: 0.7576 Sum: 2.8797\n",
      "Step 1772/100000 MLoss: 2.2544 GLoss: 0.7675 Sum: 3.0219\n",
      "Step 1773/100000 MLoss: 2.268 GLoss: 0.7542 Sum: 3.0221999999999998\n",
      "Step 1774/100000 MLoss: 2.1421 GLoss: 0.7604 Sum: 2.9025\n",
      "Step 1775/100000 MLoss: 2.2206 GLoss: 0.7834 Sum: 3.004\n",
      "Step 1776/100000 MLoss: 2.2281 GLoss: 0.7871 Sum: 3.0152\n",
      "Step 1777/100000 MLoss: 2.2023 GLoss: 0.771 Sum: 2.9733\n",
      "Step 1778/100000 MLoss: 2.0929 GLoss: 0.7364 Sum: 2.8293000000000004\n",
      "Step 1779/100000 MLoss: 2.3539 GLoss: 0.751 Sum: 3.1048999999999998\n",
      "Step 1780/100000 MLoss: 2.6258 GLoss: 0.7931 Sum: 3.4189\n",
      "Step 1781/100000 MLoss: 2.225 GLoss: 0.7221 Sum: 2.9471\n",
      "Step 1782/100000 MLoss: 2.1855 GLoss: 0.7604 Sum: 2.9459\n",
      "Step 1783/100000 MLoss: 2.2857 GLoss: 0.7378 Sum: 3.0235\n",
      "Step 1784/100000 MLoss: 2.1781 GLoss: 0.7358 Sum: 2.9139\n",
      "Step 1785/100000 MLoss: 2.2747 GLoss: 0.7567 Sum: 3.0314\n",
      "Step 1786/100000 MLoss: 2.1965 GLoss: 0.7407 Sum: 2.9372\n",
      "Step 1787/100000 MLoss: 2.2126 GLoss: 0.7192 Sum: 2.9318\n",
      "Step 1788/100000 MLoss: 2.2629 GLoss: 0.7595 Sum: 3.0224\n",
      "Step 1789/100000 MLoss: 2.283 GLoss: 0.7609 Sum: 3.0439\n",
      "Step 1790/100000 MLoss: 2.3714 GLoss: 0.7334 Sum: 3.1048\n",
      "Step 1791/100000 MLoss: 2.2819 GLoss: 0.8878 Sum: 3.1696999999999997\n",
      "Step 1792/100000 MLoss: 2.3288 GLoss: 0.8065 Sum: 3.1353\n",
      "Step 1793/100000 MLoss: 2.2074 GLoss: 0.7983 Sum: 3.0057\n",
      "Step 1794/100000 MLoss: 2.0932 GLoss: 0.8131 Sum: 2.9063\n",
      "Step 1795/100000 MLoss: 2.1227 GLoss: 0.7706 Sum: 2.8933\n",
      "Step 1796/100000 MLoss: 2.1289 GLoss: 0.7705 Sum: 2.8994\n",
      "Step 1797/100000 MLoss: 2.0755 GLoss: 0.7556 Sum: 2.8311\n",
      "Step 1798/100000 MLoss: 2.2542 GLoss: 0.7681 Sum: 3.0223\n",
      "Step 1799/100000 MLoss: 2.1616 GLoss: 0.7742 Sum: 2.9358\n",
      "Step 1800/100000 MLoss: 2.1259 GLoss: 0.7649 Sum: 2.8908\n",
      "Step 1801/100000 MLoss: 2.2223 GLoss: 0.7481 Sum: 2.9704\n",
      "Step 1802/100000 MLoss: 2.168 GLoss: 0.7527 Sum: 2.9207\n",
      "Step 1803/100000 MLoss: 2.1376 GLoss: 0.7641 Sum: 2.9017\n",
      "Step 1804/100000 MLoss: 2.1207 GLoss: 0.7544 Sum: 2.8750999999999998\n",
      "Step 1805/100000 MLoss: 2.256 GLoss: 0.754 Sum: 3.01\n",
      "Step 1806/100000 MLoss: 2.1699 GLoss: 0.7356 Sum: 2.9055\n",
      "Step 1807/100000 MLoss: 2.2343 GLoss: 0.7263 Sum: 2.9606000000000003\n",
      "Step 1808/100000 MLoss: 2.2002 GLoss: 0.7441 Sum: 2.9443\n",
      "Step 1809/100000 MLoss: 2.1798 GLoss: 0.7434 Sum: 2.9232\n",
      "Step 1810/100000 MLoss: 2.2028 GLoss: 0.7244 Sum: 2.9272\n",
      "Step 1811/100000 MLoss: 2.1265 GLoss: 0.7196 Sum: 2.8461\n",
      "Step 1812/100000 MLoss: 2.2598 GLoss: 0.7859 Sum: 3.0457\n",
      "Step 1813/100000 MLoss: 2.1063 GLoss: 0.7338 Sum: 2.8401\n",
      "Step 1814/100000 MLoss: 2.1788 GLoss: 0.7395 Sum: 2.9183\n",
      "Step 1815/100000 MLoss: 2.2332 GLoss: 0.7852 Sum: 3.0184\n",
      "Step 1816/100000 MLoss: 2.2263 GLoss: 0.7364 Sum: 2.9627000000000003\n",
      "Step 1817/100000 MLoss: 2.231 GLoss: 0.8074 Sum: 3.0383999999999998\n",
      "Step 1818/100000 MLoss: 2.1239 GLoss: 0.7483 Sum: 2.8722\n",
      "Step 1819/100000 MLoss: 2.1843 GLoss: 0.8512 Sum: 3.0355\n",
      "Step 1820/100000 MLoss: 2.0768 GLoss: 0.8235 Sum: 2.9003\n",
      "Step 1821/100000 MLoss: 2.2863 GLoss: 0.7226 Sum: 3.0089\n",
      "Step 1822/100000 MLoss: 2.1113 GLoss: 0.748 Sum: 2.8593\n",
      "Step 1823/100000 MLoss: 2.1848 GLoss: 0.743 Sum: 2.9278\n",
      "Step 1824/100000 MLoss: 2.1286 GLoss: 0.7139 Sum: 2.8425000000000002\n",
      "Step 1825/100000 MLoss: 2.256 GLoss: 0.7727 Sum: 3.0286999999999997\n",
      "Step 1826/100000 MLoss: 2.1793 GLoss: 0.7383 Sum: 2.9176\n",
      "Step 1827/100000 MLoss: 2.301 GLoss: 0.7844 Sum: 3.0854\n",
      "Step 1828/100000 MLoss: 2.425 GLoss: 0.7547 Sum: 3.1797\n",
      "Step 1829/100000 MLoss: 2.1812 GLoss: 0.7474 Sum: 2.9286\n",
      "Step 1830/100000 MLoss: 2.254 GLoss: 0.7625 Sum: 3.0164999999999997\n",
      "Step 1831/100000 MLoss: 2.1916 GLoss: 0.7286 Sum: 2.9202000000000004\n",
      "Step 1832/100000 MLoss: 2.1864 GLoss: 0.7501 Sum: 2.9364999999999997\n",
      "Step 1833/100000 MLoss: 2.2624 GLoss: 0.7264 Sum: 2.9888\n",
      "Step 1834/100000 MLoss: 2.1392 GLoss: 0.7288 Sum: 2.8680000000000003\n",
      "Step 1835/100000 MLoss: 2.0847 GLoss: 0.7189 Sum: 2.8036000000000003\n",
      "Step 1836/100000 MLoss: 2.2974 GLoss: 0.7333 Sum: 3.0307\n",
      "Step 1837/100000 MLoss: 2.1069 GLoss: 0.7054 Sum: 2.8123\n",
      "Step 1838/100000 MLoss: 2.1313 GLoss: 0.7033 Sum: 2.8346\n",
      "Step 1839/100000 MLoss: 2.2164 GLoss: 0.7218 Sum: 2.9382\n",
      "Step 1840/100000 MLoss: 2.1168 GLoss: 0.7992 Sum: 2.916\n",
      "Step 1841/100000 MLoss: 2.2467 GLoss: 0.7269 Sum: 2.9736000000000002\n",
      "Step 1842/100000 MLoss: 2.1834 GLoss: 0.885 Sum: 3.0683999999999996\n",
      "Step 1843/100000 MLoss: 2.2332 GLoss: 0.9219 Sum: 3.1551\n",
      "Step 1844/100000 MLoss: 2.1705 GLoss: 0.7231 Sum: 2.8936\n",
      "Step 1845/100000 MLoss: 2.2344 GLoss: 0.7986 Sum: 3.033\n",
      "Step 1846/100000 MLoss: 2.213 GLoss: 0.7528 Sum: 2.9658\n",
      "Step 1847/100000 MLoss: 2.242 GLoss: 0.8042 Sum: 3.0462\n",
      "Step 1848/100000 MLoss: 2.105 GLoss: 0.8146 Sum: 2.9196\n",
      "Step 1849/100000 MLoss: 2.2343 GLoss: 0.7221 Sum: 2.9564000000000004\n",
      "Step 1850/100000 MLoss: 2.1127 GLoss: 0.7493 Sum: 2.8619999999999997\n",
      "Step 1851/100000 MLoss: 2.2324 GLoss: 0.7159 Sum: 2.9483\n",
      "Step 1852/100000 MLoss: 2.2568 GLoss: 0.7331 Sum: 2.9899\n",
      "Step 1853/100000 MLoss: 2.1928 GLoss: 0.7178 Sum: 2.9106\n",
      "Step 1854/100000 MLoss: 2.1485 GLoss: 0.7254 Sum: 2.8739\n",
      "Step 1855/100000 MLoss: 2.2337 GLoss: 0.7555 Sum: 2.9892\n",
      "Step 1856/100000 MLoss: 2.1478 GLoss: 0.7465 Sum: 2.8943000000000003\n",
      "Step 1857/100000 MLoss: 2.1447 GLoss: 0.7426 Sum: 2.8872999999999998\n",
      "Step 1858/100000 MLoss: 2.2061 GLoss: 0.7328 Sum: 2.9389000000000003\n",
      "Step 1859/100000 MLoss: 2.1692 GLoss: 0.7399 Sum: 2.9091\n",
      "Step 1860/100000 MLoss: 2.2106 GLoss: 0.7348 Sum: 2.9454\n",
      "Step 1861/100000 MLoss: 2.1854 GLoss: 0.7426 Sum: 2.928\n",
      "Step 1862/100000 MLoss: 2.2076 GLoss: 0.7123 Sum: 2.9198999999999997\n",
      "Step 1863/100000 MLoss: 2.1651 GLoss: 0.7248 Sum: 2.8899\n",
      "Step 1864/100000 MLoss: 2.1085 GLoss: 0.7641 Sum: 2.8726\n",
      "Step 1865/100000 MLoss: 2.1625 GLoss: 0.7498 Sum: 2.9123\n",
      "Step 1866/100000 MLoss: 2.1994 GLoss: 0.7385 Sum: 2.9379\n",
      "Step 1867/100000 MLoss: 2.1973 GLoss: 0.6928 Sum: 2.8901\n",
      "Step 1868/100000 MLoss: 2.1835 GLoss: 0.8541 Sum: 3.0376\n",
      "Step 1869/100000 MLoss: 2.2527 GLoss: 0.8499 Sum: 3.1026\n",
      "Step 1870/100000 MLoss: 1.9883 GLoss: 0.7202 Sum: 2.7085\n",
      "Step 1871/100000 MLoss: 2.2089 GLoss: 0.8999 Sum: 3.1088\n",
      "Step 1872/100000 MLoss: 2.254 GLoss: 1.0041 Sum: 3.2580999999999998\n",
      "Step 1873/100000 MLoss: 2.2081 GLoss: 0.8056 Sum: 3.0137\n",
      "Step 1874/100000 MLoss: 2.1932 GLoss: 0.7575 Sum: 2.9507\n",
      "Step 1875/100000 MLoss: 2.1574 GLoss: 0.7933 Sum: 2.9507\n",
      "Step 1876/100000 MLoss: 2.1824 GLoss: 0.7615 Sum: 2.9438999999999997\n",
      "Step 1877/100000 MLoss: 2.1723 GLoss: 0.7637 Sum: 2.936\n",
      "Step 1878/100000 MLoss: 2.2254 GLoss: 0.7696 Sum: 2.995\n",
      "Step 1879/100000 MLoss: 2.1524 GLoss: 0.7564 Sum: 2.9088000000000003\n",
      "Step 1880/100000 MLoss: 2.2357 GLoss: 0.7707 Sum: 3.0064\n",
      "Step 1881/100000 MLoss: 2.3346 GLoss: 0.7639 Sum: 3.0985\n",
      "Step 1882/100000 MLoss: 2.1954 GLoss: 0.7631 Sum: 2.9585\n",
      "Step 1883/100000 MLoss: 2.254 GLoss: 0.7488 Sum: 3.0028\n",
      "Step 1884/100000 MLoss: 2.2213 GLoss: 0.7676 Sum: 2.9888999999999997\n",
      "Step 1885/100000 MLoss: 2.1431 GLoss: 0.749 Sum: 2.8921\n",
      "Step 1886/100000 MLoss: 2.2285 GLoss: 0.7619 Sum: 2.9904\n",
      "Step 1887/100000 MLoss: 2.243 GLoss: 0.7599 Sum: 3.0029\n",
      "Step 1888/100000 MLoss: 2.2981 GLoss: 0.738 Sum: 3.0361\n",
      "Step 1889/100000 MLoss: 2.2209 GLoss: 0.738 Sum: 2.9589\n",
      "Step 1890/100000 MLoss: 2.074 GLoss: 0.7425 Sum: 2.8165\n",
      "Step 1891/100000 MLoss: 2.2465 GLoss: 0.7404 Sum: 2.9869000000000003\n",
      "Step 1892/100000 MLoss: 2.1823 GLoss: 0.736 Sum: 2.9183000000000003\n",
      "Step 1893/100000 MLoss: 2.1592 GLoss: 0.7263 Sum: 2.8854999999999995\n",
      "Step 1894/100000 MLoss: 2.1293 GLoss: 0.714 Sum: 2.8433\n",
      "Step 1895/100000 MLoss: 2.2285 GLoss: 0.7109 Sum: 2.9394\n",
      "Step 1896/100000 MLoss: 2.2674 GLoss: 0.7263 Sum: 2.9936999999999996\n",
      "Step 1897/100000 MLoss: 2.2156 GLoss: 0.7033 Sum: 2.9189\n",
      "Step 1898/100000 MLoss: 2.1443 GLoss: 0.7127 Sum: 2.8569999999999998\n",
      "Step 1899/100000 MLoss: 2.1825 GLoss: 0.7467 Sum: 2.9292000000000002\n",
      "Step 1900/100000 MLoss: 2.3958 GLoss: 0.7029 Sum: 3.0987\n",
      "Step 1901/100000 MLoss: 2.3039 GLoss: 0.7746 Sum: 3.0785\n",
      "Step 1902/100000 MLoss: 2.1812 GLoss: 0.7243 Sum: 2.9055\n",
      "Step 1903/100000 MLoss: 2.2236 GLoss: 0.8477 Sum: 3.0713\n",
      "Step 1904/100000 MLoss: 2.2167 GLoss: 0.875 Sum: 3.0917\n",
      "Step 1905/100000 MLoss: 2.168 GLoss: 0.7127 Sum: 2.8807\n",
      "Step 1906/100000 MLoss: 2.2149 GLoss: 0.764 Sum: 2.9789000000000003\n",
      "Step 1907/100000 MLoss: 2.2766 GLoss: 0.7038 Sum: 2.9804000000000004\n",
      "Step 1908/100000 MLoss: 2.1948 GLoss: 0.746 Sum: 2.9408\n",
      "Step 1909/100000 MLoss: 2.1512 GLoss: 0.733 Sum: 2.8842\n",
      "Step 1910/100000 MLoss: 2.0071 GLoss: 0.7717 Sum: 2.7788\n",
      "Step 1911/100000 MLoss: 2.2171 GLoss: 0.7445 Sum: 2.9616\n",
      "Step 1912/100000 MLoss: 2.1347 GLoss: 0.7451 Sum: 2.8798\n",
      "Step 1913/100000 MLoss: 2.103 GLoss: 0.7387 Sum: 2.8417000000000003\n",
      "Step 1914/100000 MLoss: 2.1517 GLoss: 0.724 Sum: 2.8757\n",
      "Step 1915/100000 MLoss: 2.223 GLoss: 0.7378 Sum: 2.9608\n",
      "Step 1916/100000 MLoss: 2.1101 GLoss: 0.7039 Sum: 2.814\n",
      "Step 1917/100000 MLoss: 2.0701 GLoss: 0.7318 Sum: 2.8019\n",
      "Step 1918/100000 MLoss: 2.1965 GLoss: 0.7238 Sum: 2.9203\n",
      "Step 1919/100000 MLoss: 2.1848 GLoss: 0.7151 Sum: 2.8999\n",
      "Step 1920/100000 MLoss: 2.2324 GLoss: 0.7016 Sum: 2.934\n",
      "Step 1921/100000 MLoss: 2.0956 GLoss: 0.7039 Sum: 2.7995\n",
      "Step 1922/100000 MLoss: 2.2217 GLoss: 0.7027 Sum: 2.9244\n",
      "Step 1923/100000 MLoss: 2.2736 GLoss: 0.7098 Sum: 2.9834\n",
      "Step 1924/100000 MLoss: 2.1348 GLoss: 0.6917 Sum: 2.8265\n",
      "Step 1925/100000 MLoss: 2.1608 GLoss: 0.6931 Sum: 2.8539000000000003\n",
      "Step 1926/100000 MLoss: 2.1792 GLoss: 0.7028 Sum: 2.8819999999999997\n",
      "Step 1927/100000 MLoss: 2.1887 GLoss: 0.7307 Sum: 2.9194\n",
      "Step 1928/100000 MLoss: 2.1617 GLoss: 0.7086 Sum: 2.8703000000000003\n",
      "Step 1929/100000 MLoss: 2.1402 GLoss: 0.7175 Sum: 2.8577000000000004\n",
      "Step 1930/100000 MLoss: 2.1223 GLoss: 0.7837 Sum: 2.906\n",
      "Step 1931/100000 MLoss: 2.15 GLoss: 0.7304 Sum: 2.8804\n",
      "Step 1932/100000 MLoss: 2.206 GLoss: 0.7698 Sum: 2.9758\n",
      "Step 1933/100000 MLoss: 2.1142 GLoss: 0.7582 Sum: 2.8724\n",
      "Step 1934/100000 MLoss: 2.1008 GLoss: 0.7376 Sum: 2.8384\n",
      "Step 1935/100000 MLoss: 2.2066 GLoss: 0.7284 Sum: 2.935\n",
      "Step 1936/100000 MLoss: 2.1062 GLoss: 0.7175 Sum: 2.8236999999999997\n",
      "Step 1937/100000 MLoss: 2.2076 GLoss: 0.7112 Sum: 2.9188\n",
      "Step 1938/100000 MLoss: 2.1927 GLoss: 0.7161 Sum: 2.9088\n",
      "Step 1939/100000 MLoss: 2.1616 GLoss: 0.7111 Sum: 2.8727\n",
      "Step 1940/100000 MLoss: 2.231 GLoss: 0.7236 Sum: 2.9546\n",
      "Step 1941/100000 MLoss: 2.3644 GLoss: 0.7188 Sum: 3.0831999999999997\n",
      "Step 1942/100000 MLoss: 2.1658 GLoss: 0.7378 Sum: 2.9036\n",
      "Step 1943/100000 MLoss: 2.2379 GLoss: 0.7292 Sum: 2.9671\n",
      "Step 1944/100000 MLoss: 2.1354 GLoss: 0.7444 Sum: 2.8798000000000004\n",
      "Step 1945/100000 MLoss: 2.171 GLoss: 0.7134 Sum: 2.8844\n",
      "Step 1946/100000 MLoss: 2.2636 GLoss: 0.765 Sum: 3.0286\n",
      "Step 1947/100000 MLoss: 2.149 GLoss: 0.7537 Sum: 2.9027000000000003\n",
      "Step 1948/100000 MLoss: 2.1053 GLoss: 0.6995 Sum: 2.8048\n",
      "Step 1949/100000 MLoss: 2.22 GLoss: 0.7424 Sum: 2.9624\n",
      "Step 1950/100000 MLoss: 2.4464 GLoss: 0.7389 Sum: 3.1853000000000002\n",
      "Step 1951/100000 MLoss: 2.1692 GLoss: 0.7295 Sum: 2.8987\n",
      "Step 1952/100000 MLoss: 2.1561 GLoss: 0.709 Sum: 2.8651\n",
      "Step 1953/100000 MLoss: 2.2242 GLoss: 0.7103 Sum: 2.9345000000000003\n",
      "Step 1954/100000 MLoss: 2.1514 GLoss: 0.6968 Sum: 2.8482000000000003\n",
      "Step 1955/100000 MLoss: 2.1916 GLoss: 0.6982 Sum: 2.8898\n",
      "Step 1956/100000 MLoss: 2.3207 GLoss: 0.7143 Sum: 3.035\n",
      "Step 1957/100000 MLoss: 2.2096 GLoss: 0.703 Sum: 2.9126\n",
      "Step 1958/100000 MLoss: 2.1799 GLoss: 0.7189 Sum: 2.8988\n",
      "Step 1959/100000 MLoss: 2.1575 GLoss: 0.6919 Sum: 2.8494\n",
      "Step 1960/100000 MLoss: 2.2463 GLoss: 0.7057 Sum: 2.952\n",
      "Step 1961/100000 MLoss: 2.1894 GLoss: 0.7236 Sum: 2.9130000000000003\n",
      "Step 1962/100000 MLoss: 2.1225 GLoss: 0.6882 Sum: 2.8107\n",
      "Step 1963/100000 MLoss: 2.1742 GLoss: 0.7143 Sum: 2.8885\n",
      "Step 1964/100000 MLoss: 2.2353 GLoss: 0.7073 Sum: 2.9426\n",
      "Step 1965/100000 MLoss: 2.2781 GLoss: 0.7058 Sum: 2.9838999999999998\n",
      "Step 1966/100000 MLoss: 2.1615 GLoss: 0.7147 Sum: 2.8762000000000003\n",
      "Step 1967/100000 MLoss: 2.1983 GLoss: 0.703 Sum: 2.9013\n",
      "Step 1968/100000 MLoss: 2.0461 GLoss: 0.6902 Sum: 2.7363\n",
      "Step 1969/100000 MLoss: 2.1812 GLoss: 0.716 Sum: 2.8971999999999998\n",
      "Step 1970/100000 MLoss: 2.3008 GLoss: 0.7149 Sum: 3.0157000000000003\n",
      "Step 1971/100000 MLoss: 2.1495 GLoss: 0.6959 Sum: 2.8454\n",
      "Step 1972/100000 MLoss: 2.1523 GLoss: 0.7603 Sum: 2.9126\n",
      "Step 1973/100000 MLoss: 2.2483 GLoss: 0.719 Sum: 2.9673\n",
      "Step 1974/100000 MLoss: 2.1389 GLoss: 0.7592 Sum: 2.8981\n",
      "Step 1975/100000 MLoss: 2.2613 GLoss: 0.7421 Sum: 3.0034\n",
      "Step 1976/100000 MLoss: 2.3051 GLoss: 0.7252 Sum: 3.0303\n",
      "Step 1977/100000 MLoss: 2.1507 GLoss: 0.7351 Sum: 2.8858\n",
      "Step 1978/100000 MLoss: 2.1449 GLoss: 0.7221 Sum: 2.867\n",
      "Step 1979/100000 MLoss: 2.0678 GLoss: 0.7037 Sum: 2.7715\n",
      "Step 1980/100000 MLoss: 2.3099 GLoss: 0.7606 Sum: 3.0705\n",
      "Step 1981/100000 MLoss: 2.2296 GLoss: 0.7562 Sum: 2.9858000000000002\n",
      "Step 1982/100000 MLoss: 2.1438 GLoss: 0.6992 Sum: 2.843\n",
      "Step 1983/100000 MLoss: 2.1474 GLoss: 0.7149 Sum: 2.8623000000000003\n",
      "Step 1984/100000 MLoss: 2.3274 GLoss: 0.7168 Sum: 3.0442\n",
      "Step 1985/100000 MLoss: 2.1572 GLoss: 0.7015 Sum: 2.8587\n",
      "Step 1986/100000 MLoss: 2.2298 GLoss: 0.7309 Sum: 2.9607\n",
      "Step 1987/100000 MLoss: 2.3234 GLoss: 0.717 Sum: 3.0404\n",
      "Step 1988/100000 MLoss: 2.2239 GLoss: 0.6892 Sum: 2.9131\n",
      "Step 1989/100000 MLoss: 2.2396 GLoss: 0.7015 Sum: 2.9410999999999996\n",
      "Step 1990/100000 MLoss: 2.3396 GLoss: 0.7063 Sum: 3.0459\n",
      "Step 1991/100000 MLoss: 2.2652 GLoss: 0.7269 Sum: 2.9921\n",
      "Step 1992/100000 MLoss: 2.1454 GLoss: 0.7075 Sum: 2.8529\n",
      "Step 1993/100000 MLoss: 2.2657 GLoss: 0.7012 Sum: 2.9669\n",
      "Step 1994/100000 MLoss: 2.1049 GLoss: 0.702 Sum: 2.8069\n",
      "Step 1995/100000 MLoss: 2.1857 GLoss: 0.7301 Sum: 2.9158\n",
      "Step 1996/100000 MLoss: 2.1483 GLoss: 0.7063 Sum: 2.8546\n",
      "Step 1997/100000 MLoss: 2.1159 GLoss: 0.6981 Sum: 2.814\n",
      "Step 1998/100000 MLoss: 2.16 GLoss: 0.7093 Sum: 2.8693\n",
      "Step 1999/100000 MLoss: 2.2964 GLoss: 0.6992 Sum: 2.9956000000000005\n",
      "Step 2000/100000 MLoss: 2.3403 GLoss: 0.7085 Sum: 3.0488\n",
      "Step 2001/100000 MLoss: 2.192 GLoss: 0.7217 Sum: 2.9137000000000004\n",
      "Step 2002/100000 MLoss: 2.1608 GLoss: 0.7026 Sum: 2.8634\n",
      "Step 2003/100000 MLoss: 2.2099 GLoss: 0.6964 Sum: 2.9063000000000003\n",
      "Step 2004/100000 MLoss: 2.181 GLoss: 0.6916 Sum: 2.8726000000000003\n",
      "Step 2005/100000 MLoss: 2.1696 GLoss: 0.7157 Sum: 2.8853\n",
      "Step 2006/100000 MLoss: 2.1868 GLoss: 0.7062 Sum: 2.893\n",
      "Step 2007/100000 MLoss: 2.243 GLoss: 0.6897 Sum: 2.9326999999999996\n",
      "Step 2008/100000 MLoss: 2.1698 GLoss: 0.706 Sum: 2.8758\n",
      "Step 2009/100000 MLoss: 2.1971 GLoss: 0.682 Sum: 2.8790999999999998\n",
      "Step 2010/100000 MLoss: 2.1144 GLoss: 0.7185 Sum: 2.8329\n",
      "Step 2011/100000 MLoss: 2.1339 GLoss: 0.7046 Sum: 2.8385000000000002\n",
      "Step 2012/100000 MLoss: 2.2574 GLoss: 0.6982 Sum: 2.9556\n",
      "Step 2013/100000 MLoss: 2.247 GLoss: 0.6911 Sum: 2.9381\n",
      "Step 2014/100000 MLoss: 2.1406 GLoss: 0.6989 Sum: 2.8395\n",
      "Step 2015/100000 MLoss: 2.0991 GLoss: 0.704 Sum: 2.8030999999999997\n",
      "Step 2016/100000 MLoss: 2.1992 GLoss: 0.6987 Sum: 2.8979\n",
      "Step 2017/100000 MLoss: 2.1476 GLoss: 0.6874 Sum: 2.835\n",
      "Step 2018/100000 MLoss: 2.1558 GLoss: 0.6896 Sum: 2.8454\n",
      "Step 2019/100000 MLoss: 2.1532 GLoss: 0.7028 Sum: 2.856\n",
      "Step 2020/100000 MLoss: 2.1937 GLoss: 0.6772 Sum: 2.8709000000000002\n",
      "Step 2021/100000 MLoss: 2.2872 GLoss: 0.6969 Sum: 2.9840999999999998\n",
      "Step 2022/100000 MLoss: 2.1912 GLoss: 0.7099 Sum: 2.9010999999999996\n",
      "Step 2023/100000 MLoss: 2.2333 GLoss: 0.7152 Sum: 2.9484999999999997\n",
      "Step 2024/100000 MLoss: 2.1569 GLoss: 0.6981 Sum: 2.855\n",
      "Step 2025/100000 MLoss: 2.1728 GLoss: 0.7563 Sum: 2.9291\n",
      "Step 2026/100000 MLoss: 2.2421 GLoss: 0.7695 Sum: 3.0116\n",
      "Step 2027/100000 MLoss: 2.1247 GLoss: 0.7499 Sum: 2.8746\n",
      "Step 2028/100000 MLoss: 2.1477 GLoss: 0.7031 Sum: 2.8508\n",
      "Step 2029/100000 MLoss: 2.1457 GLoss: 0.8148 Sum: 2.9605\n",
      "Step 2030/100000 MLoss: 2.1421 GLoss: 0.8365 Sum: 2.9786\n",
      "Step 2031/100000 MLoss: 2.1702 GLoss: 0.7462 Sum: 2.9164\n",
      "Step 2032/100000 MLoss: 2.3127 GLoss: 0.7649 Sum: 3.0776\n",
      "Step 2033/100000 MLoss: 2.0889 GLoss: 0.7095 Sum: 2.7984\n",
      "Step 2034/100000 MLoss: 2.2027 GLoss: 0.8059 Sum: 3.0086\n",
      "Step 2035/100000 MLoss: 2.1283 GLoss: 0.8505 Sum: 2.9787999999999997\n",
      "Step 2036/100000 MLoss: 2.3518 GLoss: 0.7762 Sum: 3.128\n",
      "Step 2037/100000 MLoss: 2.1907 GLoss: 0.7623 Sum: 2.9530000000000003\n",
      "Step 2038/100000 MLoss: 2.1647 GLoss: 0.747 Sum: 2.9116999999999997\n",
      "Step 2039/100000 MLoss: 2.3485 GLoss: 0.7319 Sum: 3.0804\n",
      "Step 2040/100000 MLoss: 2.475 GLoss: 0.7665 Sum: 3.2415000000000003\n",
      "Step 2041/100000 MLoss: 2.2664 GLoss: 0.7187 Sum: 2.9851\n",
      "Step 2042/100000 MLoss: 2.2176 GLoss: 0.721 Sum: 2.9386\n",
      "Step 2043/100000 MLoss: 2.148 GLoss: 0.7098 Sum: 2.8578\n",
      "Step 2044/100000 MLoss: 2.1693 GLoss: 0.7262 Sum: 2.8954999999999997\n",
      "Step 2045/100000 MLoss: 2.2179 GLoss: 0.7065 Sum: 2.9244000000000003\n",
      "Step 2046/100000 MLoss: 2.1488 GLoss: 0.7293 Sum: 2.8781\n",
      "Step 2047/100000 MLoss: 2.0914 GLoss: 0.6869 Sum: 2.7783\n",
      "Step 2048/100000 MLoss: 2.516 GLoss: 0.7102 Sum: 3.2262\n",
      "Step 2049/100000 MLoss: 2.1491 GLoss: 0.7164 Sum: 2.8655\n",
      "Step 2050/100000 MLoss: 2.0033 GLoss: 0.7225 Sum: 2.7258\n",
      "Step 2051/100000 MLoss: 2.2882 GLoss: 0.7154 Sum: 3.0035999999999996\n",
      "Step 2052/100000 MLoss: 2.1071 GLoss: 0.702 Sum: 2.8091\n",
      "Step 2053/100000 MLoss: 2.2391 GLoss: 0.6885 Sum: 2.9276\n",
      "Step 2054/100000 MLoss: 2.2195 GLoss: 0.707 Sum: 2.9265\n",
      "Step 2055/100000 MLoss: 2.1531 GLoss: 0.7182 Sum: 2.8712999999999997\n",
      "Step 2056/100000 MLoss: 2.1911 GLoss: 0.7066 Sum: 2.8977\n",
      "Step 2057/100000 MLoss: 2.1238 GLoss: 0.7087 Sum: 2.8325\n",
      "Step 2058/100000 MLoss: 2.1252 GLoss: 0.7087 Sum: 2.8339\n",
      "Step 2059/100000 MLoss: 2.2017 GLoss: 0.7123 Sum: 2.914\n",
      "Step 2060/100000 MLoss: 2.0388 GLoss: 0.6903 Sum: 2.7291000000000003\n",
      "Step 2061/100000 MLoss: 2.0755 GLoss: 0.7036 Sum: 2.7790999999999997\n",
      "Step 2062/100000 MLoss: 2.2952 GLoss: 0.707 Sum: 3.0021999999999998\n",
      "Step 2063/100000 MLoss: 2.202 GLoss: 0.6876 Sum: 2.8895999999999997\n",
      "Step 2064/100000 MLoss: 2.1487 GLoss: 0.6869 Sum: 2.8356\n",
      "Step 2065/100000 MLoss: 2.1266 GLoss: 0.6864 Sum: 2.8129999999999997\n",
      "Step 2066/100000 MLoss: 2.2612 GLoss: 0.7112 Sum: 2.9724000000000004\n",
      "Step 2067/100000 MLoss: 2.1371 GLoss: 0.7069 Sum: 2.8440000000000003\n",
      "Step 2068/100000 MLoss: 2.2521 GLoss: 0.7367 Sum: 2.9888\n",
      "Step 2069/100000 MLoss: 2.0836 GLoss: 0.7044 Sum: 2.7880000000000003\n",
      "Step 2070/100000 MLoss: 2.1216 GLoss: 0.7846 Sum: 2.9062\n",
      "Step 2071/100000 MLoss: 2.1586 GLoss: 0.7476 Sum: 2.9062\n",
      "Step 2072/100000 MLoss: 2.0978 GLoss: 0.7104 Sum: 2.8082\n",
      "Step 2073/100000 MLoss: 2.1173 GLoss: 0.7354 Sum: 2.8527000000000005\n",
      "Step 2074/100000 MLoss: 2.2468 GLoss: 0.7109 Sum: 2.9577\n",
      "Step 2075/100000 MLoss: 2.2415 GLoss: 0.7082 Sum: 2.9497\n",
      "Step 2076/100000 MLoss: 2.1923 GLoss: 0.7043 Sum: 2.8966\n",
      "Step 2077/100000 MLoss: 2.2379 GLoss: 0.7131 Sum: 2.9509999999999996\n",
      "Step 2078/100000 MLoss: 2.2303 GLoss: 0.6993 Sum: 2.9296\n",
      "Step 2079/100000 MLoss: 2.2296 GLoss: 0.6927 Sum: 2.9223\n",
      "Step 2080/100000 MLoss: 2.1112 GLoss: 0.7129 Sum: 2.8241\n",
      "Step 2081/100000 MLoss: 2.2562 GLoss: 0.6904 Sum: 2.9466\n",
      "Step 2082/100000 MLoss: 2.2204 GLoss: 0.7013 Sum: 2.9217000000000004\n",
      "Step 2083/100000 MLoss: 2.3457 GLoss: 0.699 Sum: 3.0446999999999997\n",
      "Step 2084/100000 MLoss: 2.3203 GLoss: 0.6969 Sum: 3.0172\n",
      "Step 2085/100000 MLoss: 2.132 GLoss: 0.7022 Sum: 2.8342\n",
      "Step 2086/100000 MLoss: 2.1452 GLoss: 0.7096 Sum: 2.8548\n",
      "Step 2087/100000 MLoss: 2.1918 GLoss: 0.7032 Sum: 2.8950000000000005\n",
      "Step 2088/100000 MLoss: 2.1317 GLoss: 0.696 Sum: 2.8277\n",
      "Step 2089/100000 MLoss: 2.1503 GLoss: 0.7046 Sum: 2.8549\n",
      "Step 2090/100000 MLoss: 2.4804 GLoss: 0.6937 Sum: 3.1741\n",
      "Step 2091/100000 MLoss: 2.175 GLoss: 0.6897 Sum: 2.8647\n",
      "Step 2092/100000 MLoss: 2.1892 GLoss: 0.7233 Sum: 2.9125\n",
      "Step 2093/100000 MLoss: 2.1186 GLoss: 0.7139 Sum: 2.8324999999999996\n",
      "Step 2094/100000 MLoss: 2.2255 GLoss: 0.756 Sum: 2.9814999999999996\n",
      "Step 2095/100000 MLoss: 2.1354 GLoss: 0.687 Sum: 2.8224\n",
      "Step 2096/100000 MLoss: 2.2262 GLoss: 0.7843 Sum: 3.0105\n",
      "Step 2097/100000 MLoss: 2.1395 GLoss: 0.8073 Sum: 2.9468\n",
      "Step 2098/100000 MLoss: 2.0972 GLoss: 0.7174 Sum: 2.8146\n",
      "Step 2099/100000 MLoss: 2.3057 GLoss: 0.7609 Sum: 3.0665999999999998\n",
      "Step 2100/100000 MLoss: 2.1688 GLoss: 0.7941 Sum: 2.9629000000000003\n",
      "Step 2101/100000 MLoss: 2.2404 GLoss: 0.738 Sum: 2.9784\n",
      "Step 2102/100000 MLoss: 2.1521 GLoss: 0.7593 Sum: 2.9114\n",
      "Step 2103/100000 MLoss: 2.205 GLoss: 0.7524 Sum: 2.9574\n",
      "Step 2104/100000 MLoss: 2.1854 GLoss: 0.7268 Sum: 2.9122\n",
      "Step 2105/100000 MLoss: 2.1652 GLoss: 0.7535 Sum: 2.9187\n",
      "Step 2106/100000 MLoss: 2.2146 GLoss: 0.7436 Sum: 2.9581999999999997\n",
      "Step 2107/100000 MLoss: 2.1938 GLoss: 0.7213 Sum: 2.9151\n",
      "Step 2108/100000 MLoss: 2.088 GLoss: 0.7356 Sum: 2.8236\n",
      "Step 2109/100000 MLoss: 2.1754 GLoss: 0.7255 Sum: 2.9009\n",
      "Step 2110/100000 MLoss: 1.9447 GLoss: 0.6931 Sum: 2.6378000000000004\n",
      "Step 2111/100000 MLoss: 2.1282 GLoss: 0.7119 Sum: 2.8401\n",
      "Step 2112/100000 MLoss: 2.1419 GLoss: 0.6974 Sum: 2.8393\n",
      "Step 2113/100000 MLoss: 2.0437 GLoss: 0.7246 Sum: 2.7683\n",
      "Step 2114/100000 MLoss: 2.1837 GLoss: 0.7188 Sum: 2.9025\n",
      "Step 2115/100000 MLoss: 2.2482 GLoss: 0.707 Sum: 2.9552\n",
      "Step 2116/100000 MLoss: 2.5017 GLoss: 0.7269 Sum: 3.2286\n",
      "Step 2117/100000 MLoss: 2.0743 GLoss: 0.7117 Sum: 2.786\n",
      "Step 2118/100000 MLoss: 2.1368 GLoss: 0.7236 Sum: 2.8604000000000003\n",
      "Step 2119/100000 MLoss: 2.2044 GLoss: 0.6912 Sum: 2.8956\n",
      "Step 2120/100000 MLoss: 2.1176 GLoss: 0.7399 Sum: 2.8575\n",
      "Step 2121/100000 MLoss: 2.2056 GLoss: 0.7178 Sum: 2.9234\n",
      "Step 2122/100000 MLoss: 2.1948 GLoss: 0.7453 Sum: 2.9400999999999997\n",
      "Step 2123/100000 MLoss: 2.2887 GLoss: 0.7407 Sum: 3.0294\n",
      "Step 2124/100000 MLoss: 2.2076 GLoss: 0.7087 Sum: 2.9162999999999997\n",
      "Step 2125/100000 MLoss: 2.2552 GLoss: 0.7419 Sum: 2.9970999999999997\n",
      "Step 2126/100000 MLoss: 2.2063 GLoss: 0.7147 Sum: 2.9210000000000003\n",
      "Step 2127/100000 MLoss: 2.2703 GLoss: 0.7132 Sum: 2.9835000000000003\n",
      "Step 2128/100000 MLoss: 2.0937 GLoss: 0.7078 Sum: 2.8015\n",
      "Step 2129/100000 MLoss: 2.2828 GLoss: 0.7148 Sum: 2.9976\n",
      "Step 2130/100000 MLoss: 2.0318 GLoss: 0.6968 Sum: 2.7286\n",
      "Step 2131/100000 MLoss: 2.1136 GLoss: 0.6974 Sum: 2.811\n",
      "Step 2132/100000 MLoss: 2.1164 GLoss: 0.7165 Sum: 2.8329\n",
      "Step 2133/100000 MLoss: 2.1609 GLoss: 0.7051 Sum: 2.8659999999999997\n",
      "Step 2134/100000 MLoss: 2.192 GLoss: 0.6979 Sum: 2.8899\n",
      "Step 2135/100000 MLoss: 2.2126 GLoss: 0.7069 Sum: 2.9195\n",
      "Step 2136/100000 MLoss: 2.1131 GLoss: 0.7038 Sum: 2.8169000000000004\n",
      "Step 2137/100000 MLoss: 2.1477 GLoss: 0.6902 Sum: 2.8379\n",
      "Step 2138/100000 MLoss: 2.1522 GLoss: 0.7048 Sum: 2.857\n",
      "Step 2139/100000 MLoss: 2.2714 GLoss: 0.6902 Sum: 2.9616\n",
      "Step 2140/100000 MLoss: 2.1784 GLoss: 0.7205 Sum: 2.8989\n",
      "Step 2141/100000 MLoss: 2.1099 GLoss: 0.6911 Sum: 2.801\n",
      "Step 2142/100000 MLoss: 2.1914 GLoss: 0.6907 Sum: 2.8821\n",
      "Step 2143/100000 MLoss: 2.1617 GLoss: 0.6986 Sum: 2.8603\n",
      "Step 2144/100000 MLoss: 2.2042 GLoss: 0.6905 Sum: 2.8947000000000003\n",
      "Step 2145/100000 MLoss: 2.1331 GLoss: 0.6801 Sum: 2.8132\n",
      "Step 2146/100000 MLoss: 2.1631 GLoss: 0.7236 Sum: 2.8867000000000003\n",
      "Step 2147/100000 MLoss: 2.2662 GLoss: 0.7115 Sum: 2.9777\n",
      "Step 2148/100000 MLoss: 2.271 GLoss: 0.7153 Sum: 2.9863\n",
      "Step 2149/100000 MLoss: 2.1489 GLoss: 0.6872 Sum: 2.8361\n",
      "Step 2150/100000 MLoss: 2.2347 GLoss: 0.6949 Sum: 2.9296\n",
      "Step 2151/100000 MLoss: 2.2726 GLoss: 0.6989 Sum: 2.9715000000000003\n",
      "Step 2152/100000 MLoss: 2.1625 GLoss: 0.6982 Sum: 2.8607\n",
      "Step 2153/100000 MLoss: 2.178 GLoss: 0.6846 Sum: 2.8626\n",
      "Step 2154/100000 MLoss: 2.1684 GLoss: 0.6902 Sum: 2.8586\n",
      "Step 2155/100000 MLoss: 2.1821 GLoss: 0.711 Sum: 2.8931\n",
      "Step 2156/100000 MLoss: 2.136 GLoss: 0.6941 Sum: 2.8301000000000003\n",
      "Step 2157/100000 MLoss: 2.2119 GLoss: 0.7227 Sum: 2.9346\n",
      "Step 2158/100000 MLoss: 2.2274 GLoss: 0.7053 Sum: 2.9326999999999996\n",
      "Step 2159/100000 MLoss: 2.1444 GLoss: 0.6945 Sum: 2.8389\n",
      "Step 2160/100000 MLoss: 2.1082 GLoss: 0.6985 Sum: 2.8067\n",
      "Step 2161/100000 MLoss: 2.2036 GLoss: 0.6922 Sum: 2.8958\n",
      "Step 2162/100000 MLoss: 2.1489 GLoss: 0.7149 Sum: 2.8638\n",
      "Step 2163/100000 MLoss: 2.2292 GLoss: 0.7048 Sum: 2.934\n",
      "Step 2164/100000 MLoss: 2.2101 GLoss: 0.7373 Sum: 2.9474\n",
      "Step 2165/100000 MLoss: 2.1273 GLoss: 0.6822 Sum: 2.8095\n",
      "Step 2166/100000 MLoss: 2.1902 GLoss: 0.7652 Sum: 2.9554\n",
      "Step 2167/100000 MLoss: 2.2092 GLoss: 0.7902 Sum: 2.9994\n",
      "Step 2168/100000 MLoss: 2.0859 GLoss: 0.7037 Sum: 2.7896\n",
      "Step 2169/100000 MLoss: 2.137 GLoss: 0.7479 Sum: 2.8849\n",
      "Step 2170/100000 MLoss: 2.1413 GLoss: 0.7497 Sum: 2.891\n",
      "Step 2171/100000 MLoss: 2.2227 GLoss: 0.7529 Sum: 2.9756\n",
      "Step 2172/100000 MLoss: 2.2085 GLoss: 0.7325 Sum: 2.941\n",
      "Step 2173/100000 MLoss: 2.1141 GLoss: 0.6925 Sum: 2.8066\n",
      "Step 2174/100000 MLoss: 2.1754 GLoss: 0.7543 Sum: 2.9296999999999995\n",
      "Step 2175/100000 MLoss: 2.2223 GLoss: 0.7604 Sum: 2.9827000000000004\n",
      "Step 2176/100000 MLoss: 2.08 GLoss: 0.7187 Sum: 2.7987\n",
      "Step 2177/100000 MLoss: 2.1652 GLoss: 0.7451 Sum: 2.9103\n",
      "Step 2178/100000 MLoss: 2.2183 GLoss: 0.7534 Sum: 2.9717000000000002\n",
      "Step 2179/100000 MLoss: 2.0849 GLoss: 0.7211 Sum: 2.806\n",
      "Step 2180/100000 MLoss: 1.8929 GLoss: 0.6808 Sum: 2.5737\n",
      "Step 2181/100000 MLoss: 2.229 GLoss: 0.7136 Sum: 2.9426\n",
      "Step 2182/100000 MLoss: 2.6658 GLoss: 0.7155 Sum: 3.3813\n",
      "Step 2183/100000 MLoss: 2.1947 GLoss: 0.7364 Sum: 2.9311000000000003\n",
      "Step 2184/100000 MLoss: 2.1538 GLoss: 0.6828 Sum: 2.8366\n",
      "Step 2185/100000 MLoss: 2.2125 GLoss: 0.7187 Sum: 2.9312\n",
      "Step 2186/100000 MLoss: 2.1339 GLoss: 0.7214 Sum: 2.8553\n",
      "Step 2187/100000 MLoss: 2.1721 GLoss: 0.707 Sum: 2.8790999999999998\n",
      "Step 2188/100000 MLoss: 2.2203 GLoss: 0.6896 Sum: 2.9099\n",
      "Step 2189/100000 MLoss: 2.0931 GLoss: 0.7092 Sum: 2.8023000000000002\n",
      "Step 2190/100000 MLoss: 2.222 GLoss: 0.6839 Sum: 2.9059\n",
      "Step 2191/100000 MLoss: 2.2085 GLoss: 0.6994 Sum: 2.9078999999999997\n",
      "Step 2192/100000 MLoss: 2.1935 GLoss: 0.6843 Sum: 2.8777999999999997\n",
      "Step 2193/100000 MLoss: 2.2131 GLoss: 0.689 Sum: 2.9021\n",
      "Step 2194/100000 MLoss: 2.212 GLoss: 0.6954 Sum: 2.9074\n",
      "Step 2195/100000 MLoss: 2.2114 GLoss: 0.7027 Sum: 2.9141\n",
      "Step 2196/100000 MLoss: 2.1121 GLoss: 0.6811 Sum: 2.7931999999999997\n",
      "Step 2197/100000 MLoss: 2.1785 GLoss: 0.6814 Sum: 2.8599\n",
      "Step 2198/100000 MLoss: 2.2196 GLoss: 0.6938 Sum: 2.9133999999999998\n",
      "Step 2199/100000 MLoss: 2.2514 GLoss: 0.6992 Sum: 2.9505999999999997\n",
      "Step 2200/100000 MLoss: 2.2016 GLoss: 0.6911 Sum: 2.8927\n",
      "Step 2201/100000 MLoss: 2.1885 GLoss: 0.6904 Sum: 2.8789\n",
      "Step 2202/100000 MLoss: 2.1612 GLoss: 0.6999 Sum: 2.8611\n",
      "Step 2203/100000 MLoss: 2.1681 GLoss: 0.6971 Sum: 2.8651999999999997\n",
      "Step 2204/100000 MLoss: 2.1587 GLoss: 0.687 Sum: 2.8457\n",
      "Step 2205/100000 MLoss: 2.2011 GLoss: 0.6895 Sum: 2.8906\n",
      "Step 2206/100000 MLoss: 2.1494 GLoss: 0.684 Sum: 2.8334\n",
      "Step 2207/100000 MLoss: 2.1455 GLoss: 0.6782 Sum: 2.8237\n",
      "Step 2208/100000 MLoss: 2.1659 GLoss: 0.6824 Sum: 2.8483\n",
      "Step 2209/100000 MLoss: 2.1954 GLoss: 0.7163 Sum: 2.9116999999999997\n",
      "Step 2210/100000 MLoss: 2.1304 GLoss: 0.6962 Sum: 2.8266\n",
      "Step 2211/100000 MLoss: 2.112 GLoss: 0.7049 Sum: 2.8169\n",
      "Step 2212/100000 MLoss: 2.1966 GLoss: 0.7114 Sum: 2.9080000000000004\n",
      "Step 2213/100000 MLoss: 2.2414 GLoss: 0.7058 Sum: 2.9472\n",
      "Step 2214/100000 MLoss: 2.2438 GLoss: 0.6857 Sum: 2.9295\n",
      "Step 2215/100000 MLoss: 2.1927 GLoss: 0.7013 Sum: 2.894\n",
      "Step 2216/100000 MLoss: 2.1734 GLoss: 0.6856 Sum: 2.859\n",
      "Step 2217/100000 MLoss: 2.2166 GLoss: 0.7084 Sum: 2.9250000000000003\n",
      "Step 2218/100000 MLoss: 2.0837 GLoss: 0.692 Sum: 2.7756999999999996\n",
      "Step 2219/100000 MLoss: 2.2027 GLoss: 0.7052 Sum: 2.9079\n",
      "Step 2220/100000 MLoss: 2.0511 GLoss: 0.6714 Sum: 2.7225\n",
      "Step 2221/100000 MLoss: 2.3083 GLoss: 0.7047 Sum: 3.013\n",
      "Step 2222/100000 MLoss: 2.162 GLoss: 0.6842 Sum: 2.8462\n",
      "Step 2223/100000 MLoss: 2.1951 GLoss: 0.7098 Sum: 2.9049\n",
      "Step 2224/100000 MLoss: 2.2239 GLoss: 0.6858 Sum: 2.9097\n",
      "Step 2225/100000 MLoss: 2.1382 GLoss: 0.6989 Sum: 2.8371\n",
      "Step 2226/100000 MLoss: 2.1351 GLoss: 0.7144 Sum: 2.8495\n",
      "Step 2227/100000 MLoss: 2.1415 GLoss: 0.7008 Sum: 2.8423000000000003\n",
      "Step 2228/100000 MLoss: 2.1843 GLoss: 0.7062 Sum: 2.8905\n",
      "Step 2229/100000 MLoss: 2.1451 GLoss: 0.7064 Sum: 2.8514999999999997\n",
      "Step 2230/100000 MLoss: 2.2355 GLoss: 0.6958 Sum: 2.9313000000000002\n",
      "Step 2231/100000 MLoss: 2.1573 GLoss: 0.706 Sum: 2.8633\n",
      "Step 2232/100000 MLoss: 2.1992 GLoss: 0.688 Sum: 2.8872\n",
      "Step 2233/100000 MLoss: 2.0746 GLoss: 0.7526 Sum: 2.8272000000000004\n",
      "Step 2234/100000 MLoss: 2.1813 GLoss: 0.7401 Sum: 2.9213999999999998\n",
      "Step 2235/100000 MLoss: 2.1684 GLoss: 0.728 Sum: 2.8964\n",
      "Step 2236/100000 MLoss: 2.2114 GLoss: 0.7464 Sum: 2.9577999999999998\n",
      "Step 2237/100000 MLoss: 2.1583 GLoss: 0.6893 Sum: 2.8476\n",
      "Step 2238/100000 MLoss: 2.2469 GLoss: 0.7235 Sum: 2.9704\n",
      "Step 2239/100000 MLoss: 2.2067 GLoss: 0.7004 Sum: 2.9071000000000002\n",
      "Step 2240/100000 MLoss: 2.0307 GLoss: 0.6886 Sum: 2.7193\n",
      "Step 2241/100000 MLoss: 2.2616 GLoss: 0.6955 Sum: 2.9571\n",
      "Step 2242/100000 MLoss: 2.2738 GLoss: 0.7081 Sum: 2.9819\n",
      "Step 2243/100000 MLoss: 2.1877 GLoss: 0.6951 Sum: 2.8828\n",
      "Step 2244/100000 MLoss: 2.1228 GLoss: 0.7096 Sum: 2.8324\n",
      "Step 2245/100000 MLoss: 2.1572 GLoss: 0.7207 Sum: 2.8779\n",
      "Step 2246/100000 MLoss: 2.1984 GLoss: 0.6891 Sum: 2.8875\n",
      "Step 2247/100000 MLoss: 2.1422 GLoss: 0.6842 Sum: 2.8264\n",
      "Step 2248/100000 MLoss: 2.1482 GLoss: 0.7083 Sum: 2.8565\n",
      "Step 2249/100000 MLoss: 2.1334 GLoss: 0.71 Sum: 2.8434\n",
      "Step 2250/100000 MLoss: 2.1455 GLoss: 0.6997 Sum: 2.8452\n",
      "Step 2251/100000 MLoss: 2.1957 GLoss: 0.7309 Sum: 2.9266\n",
      "Step 2252/100000 MLoss: 2.1879 GLoss: 0.708 Sum: 2.8959\n",
      "Step 2253/100000 MLoss: 2.1383 GLoss: 0.6925 Sum: 2.8308\n",
      "Step 2254/100000 MLoss: 2.2411 GLoss: 0.709 Sum: 2.9501\n",
      "Step 2255/100000 MLoss: 2.1801 GLoss: 0.703 Sum: 2.8830999999999998\n",
      "Step 2256/100000 MLoss: 2.1493 GLoss: 0.6945 Sum: 2.8438000000000003\n",
      "Step 2257/100000 MLoss: 2.2632 GLoss: 0.6985 Sum: 2.9617\n",
      "Step 2258/100000 MLoss: 2.1502 GLoss: 0.7223 Sum: 2.8725\n",
      "Step 2259/100000 MLoss: 2.206 GLoss: 0.6919 Sum: 2.8979\n",
      "Step 2260/100000 MLoss: 2.0812 GLoss: 0.711 Sum: 2.7922\n",
      "Step 2261/100000 MLoss: 2.1763 GLoss: 0.6938 Sum: 2.8701\n",
      "Step 2262/100000 MLoss: 2.1547 GLoss: 0.6911 Sum: 2.8458\n",
      "Step 2263/100000 MLoss: 2.1268 GLoss: 0.6867 Sum: 2.8135\n",
      "Step 2264/100000 MLoss: 2.1896 GLoss: 0.6868 Sum: 2.8764\n",
      "Step 2265/100000 MLoss: 2.1715 GLoss: 0.6907 Sum: 2.8622\n",
      "Step 2266/100000 MLoss: 2.1775 GLoss: 0.693 Sum: 2.8705000000000003\n",
      "Step 2267/100000 MLoss: 2.1373 GLoss: 0.6778 Sum: 2.8151\n",
      "Step 2268/100000 MLoss: 2.0552 GLoss: 0.7001 Sum: 2.7553\n",
      "Step 2269/100000 MLoss: 2.237 GLoss: 0.6981 Sum: 2.9351000000000003\n",
      "Step 2270/100000 MLoss: 2.3608 GLoss: 0.6674 Sum: 3.0282\n",
      "Step 2271/100000 MLoss: 2.0633 GLoss: 0.7006 Sum: 2.7639\n",
      "Step 2272/100000 MLoss: 2.1837 GLoss: 0.7067 Sum: 2.8904\n",
      "Step 2273/100000 MLoss: 2.1519 GLoss: 0.6845 Sum: 2.8364\n",
      "Step 2274/100000 MLoss: 2.2612 GLoss: 0.6925 Sum: 2.9537\n",
      "Step 2275/100000 MLoss: 2.1372 GLoss: 0.7102 Sum: 2.8474\n",
      "Step 2276/100000 MLoss: 2.1471 GLoss: 0.6953 Sum: 2.8424\n",
      "Step 2277/100000 MLoss: 2.1133 GLoss: 0.699 Sum: 2.8123\n",
      "Step 2278/100000 MLoss: 2.2242 GLoss: 0.6918 Sum: 2.9160000000000004\n",
      "Step 2279/100000 MLoss: 2.2829 GLoss: 0.6948 Sum: 2.9777\n",
      "Step 2280/100000 MLoss: 2.3413 GLoss: 0.7324 Sum: 3.0737\n",
      "Step 2281/100000 MLoss: 2.185 GLoss: 0.6898 Sum: 2.8748\n",
      "Step 2282/100000 MLoss: 2.1156 GLoss: 0.6976 Sum: 2.8132\n",
      "Step 2283/100000 MLoss: 2.2305 GLoss: 0.692 Sum: 2.9225000000000003\n",
      "Step 2284/100000 MLoss: 2.095 GLoss: 0.7013 Sum: 2.7963000000000005\n",
      "Step 2285/100000 MLoss: 2.1628 GLoss: 0.6722 Sum: 2.835\n",
      "Step 2286/100000 MLoss: 2.1535 GLoss: 0.6931 Sum: 2.8466000000000005\n",
      "Step 2287/100000 MLoss: 2.2258 GLoss: 0.6815 Sum: 2.9073\n",
      "Step 2288/100000 MLoss: 2.2165 GLoss: 0.7019 Sum: 2.9184\n",
      "Step 2289/100000 MLoss: 2.1161 GLoss: 0.6729 Sum: 2.7889999999999997\n",
      "Step 2290/100000 MLoss: 2.1486 GLoss: 0.6858 Sum: 2.8344\n",
      "Step 2291/100000 MLoss: 2.1311 GLoss: 0.6919 Sum: 2.823\n",
      "Step 2292/100000 MLoss: 2.1451 GLoss: 0.6844 Sum: 2.8295\n",
      "Step 2293/100000 MLoss: 2.1897 GLoss: 0.6831 Sum: 2.8728000000000002\n",
      "Step 2294/100000 MLoss: 2.203 GLoss: 0.7022 Sum: 2.9052\n",
      "Step 2295/100000 MLoss: 2.1498 GLoss: 0.6714 Sum: 2.8212\n",
      "Step 2296/100000 MLoss: 2.1409 GLoss: 0.6847 Sum: 2.8255999999999997\n",
      "Step 2297/100000 MLoss: 2.2249 GLoss: 0.6773 Sum: 2.9021999999999997\n",
      "Step 2298/100000 MLoss: 2.1072 GLoss: 0.682 Sum: 2.7892\n",
      "Step 2299/100000 MLoss: 2.24 GLoss: 0.6877 Sum: 2.9277\n",
      "Step 2300/100000 MLoss: 2.2756 GLoss: 0.6954 Sum: 2.971\n",
      "Step 2301/100000 MLoss: 2.2287 GLoss: 0.6986 Sum: 2.9273\n",
      "Step 2302/100000 MLoss: 2.0975 GLoss: 0.6893 Sum: 2.7868000000000004\n",
      "Step 2303/100000 MLoss: 2.1353 GLoss: 0.6929 Sum: 2.8282\n",
      "Step 2304/100000 MLoss: 2.2503 GLoss: 0.689 Sum: 2.9393000000000002\n",
      "Step 2305/100000 MLoss: 2.1445 GLoss: 0.7059 Sum: 2.8503999999999996\n",
      "Step 2306/100000 MLoss: 2.2642 GLoss: 0.7015 Sum: 2.9657\n",
      "Step 2307/100000 MLoss: 2.2982 GLoss: 0.7144 Sum: 3.0126\n",
      "Step 2308/100000 MLoss: 2.1206 GLoss: 0.6776 Sum: 2.7982\n",
      "Step 2309/100000 MLoss: 2.1405 GLoss: 0.7326 Sum: 2.8731\n",
      "Step 2310/100000 MLoss: 2.2973 GLoss: 0.6926 Sum: 2.9899\n",
      "Step 2311/100000 MLoss: 2.1582 GLoss: 0.711 Sum: 2.8691999999999998\n",
      "Step 2312/100000 MLoss: 2.2286 GLoss: 0.7013 Sum: 2.9299\n",
      "Step 2313/100000 MLoss: 2.0939 GLoss: 0.703 Sum: 2.7969\n",
      "Step 2314/100000 MLoss: 2.1482 GLoss: 0.7051 Sum: 2.8533\n",
      "Step 2315/100000 MLoss: 2.2138 GLoss: 0.6864 Sum: 2.9002\n",
      "Step 2316/100000 MLoss: 2.1562 GLoss: 0.7067 Sum: 2.8629000000000002\n",
      "Step 2317/100000 MLoss: 2.1867 GLoss: 0.6882 Sum: 2.8749000000000002\n",
      "Step 2318/100000 MLoss: 2.1263 GLoss: 0.683 Sum: 2.8093000000000004\n",
      "Step 2319/100000 MLoss: 2.1554 GLoss: 0.7122 Sum: 2.8676000000000004\n",
      "Step 2320/100000 MLoss: 2.1335 GLoss: 0.725 Sum: 2.8585000000000003\n",
      "Step 2321/100000 MLoss: 2.2112 GLoss: 0.7025 Sum: 2.9137\n",
      "Step 2322/100000 MLoss: 2.1594 GLoss: 0.6877 Sum: 2.8471\n",
      "Step 2323/100000 MLoss: 2.1926 GLoss: 0.7074 Sum: 2.9000000000000004\n",
      "Step 2324/100000 MLoss: 2.095 GLoss: 0.6986 Sum: 2.7936\n",
      "Step 2325/100000 MLoss: 2.1947 GLoss: 0.6966 Sum: 2.8913\n",
      "Step 2326/100000 MLoss: 2.0769 GLoss: 0.6935 Sum: 2.7704000000000004\n",
      "Step 2327/100000 MLoss: 2.1593 GLoss: 0.6893 Sum: 2.8486000000000002\n",
      "Step 2328/100000 MLoss: 2.1682 GLoss: 0.676 Sum: 2.8442000000000003\n",
      "Step 2329/100000 MLoss: 2.189 GLoss: 0.6986 Sum: 2.8876\n",
      "Step 2330/100000 MLoss: 2.4292 GLoss: 0.6943 Sum: 3.1235\n",
      "Step 2331/100000 MLoss: 2.2035 GLoss: 0.6772 Sum: 2.8807\n",
      "Step 2332/100000 MLoss: 2.1619 GLoss: 0.6972 Sum: 2.8591\n",
      "Step 2333/100000 MLoss: 2.1817 GLoss: 0.6967 Sum: 2.8784\n",
      "Step 2334/100000 MLoss: 2.1708 GLoss: 0.6925 Sum: 2.8632999999999997\n",
      "Step 2335/100000 MLoss: 2.2848 GLoss: 0.7074 Sum: 2.9922000000000004\n",
      "Step 2336/100000 MLoss: 2.1809 GLoss: 0.7323 Sum: 2.9132\n",
      "Step 2337/100000 MLoss: 2.1194 GLoss: 0.6906 Sum: 2.81\n",
      "Step 2338/100000 MLoss: 2.1185 GLoss: 0.6838 Sum: 2.8023\n",
      "Step 2339/100000 MLoss: 2.2526 GLoss: 0.7154 Sum: 2.968\n",
      "Step 2340/100000 MLoss: 2.3013 GLoss: 0.708 Sum: 3.0092999999999996\n",
      "Step 2341/100000 MLoss: 2.1537 GLoss: 0.6937 Sum: 2.8474000000000004\n",
      "Step 2342/100000 MLoss: 2.1755 GLoss: 0.6804 Sum: 2.8559\n",
      "Step 2343/100000 MLoss: 2.187 GLoss: 0.6963 Sum: 2.8832999999999998\n",
      "Step 2344/100000 MLoss: 2.1903 GLoss: 0.6779 Sum: 2.8682\n",
      "Step 2345/100000 MLoss: 2.2491 GLoss: 0.6984 Sum: 2.9475\n",
      "Step 2346/100000 MLoss: 2.2243 GLoss: 0.7021 Sum: 2.9264\n",
      "Step 2347/100000 MLoss: 2.0462 GLoss: 0.6878 Sum: 2.734\n",
      "Step 2348/100000 MLoss: 2.1468 GLoss: 0.706 Sum: 2.8528\n",
      "Step 2349/100000 MLoss: 2.1013 GLoss: 0.7181 Sum: 2.8194\n",
      "Step 2350/100000 MLoss: 2.236 GLoss: 0.65 Sum: 2.886\n",
      "Step 2351/100000 MLoss: 2.2899 GLoss: 0.7135 Sum: 3.0034\n",
      "Step 2352/100000 MLoss: 2.2103 GLoss: 0.7205 Sum: 2.9308\n",
      "Step 2353/100000 MLoss: 2.1431 GLoss: 0.6939 Sum: 2.8369999999999997\n",
      "Step 2354/100000 MLoss: 2.1892 GLoss: 0.6873 Sum: 2.8765\n",
      "Step 2355/100000 MLoss: 2.1392 GLoss: 0.7165 Sum: 2.8557\n",
      "Step 2356/100000 MLoss: 2.2187 GLoss: 0.6814 Sum: 2.9001\n",
      "Step 2357/100000 MLoss: 2.1561 GLoss: 0.7071 Sum: 2.8632\n",
      "Step 2358/100000 MLoss: 2.1903 GLoss: 0.7071 Sum: 2.8974\n",
      "Step 2359/100000 MLoss: 2.3849 GLoss: 0.7227 Sum: 3.1076\n",
      "Step 2360/100000 MLoss: 2.305 GLoss: 0.6854 Sum: 2.9904\n",
      "Step 2361/100000 MLoss: 2.1944 GLoss: 0.7 Sum: 2.8944\n",
      "Step 2362/100000 MLoss: 2.1814 GLoss: 0.7079 Sum: 2.8893\n",
      "Step 2363/100000 MLoss: 2.315 GLoss: 0.7106 Sum: 3.0256\n",
      "Step 2364/100000 MLoss: 2.1691 GLoss: 0.6961 Sum: 2.8651999999999997\n",
      "Step 2365/100000 MLoss: 2.2274 GLoss: 0.7104 Sum: 2.9377999999999997\n",
      "Step 2366/100000 MLoss: 2.2459 GLoss: 0.7007 Sum: 2.9465999999999997\n",
      "Step 2367/100000 MLoss: 2.2417 GLoss: 0.7267 Sum: 2.9684\n",
      "Step 2368/100000 MLoss: 2.146 GLoss: 0.7153 Sum: 2.8613\n",
      "Step 2369/100000 MLoss: 2.2434 GLoss: 0.6897 Sum: 2.9330999999999996\n",
      "Step 2370/100000 MLoss: 2.1927 GLoss: 0.6913 Sum: 2.884\n",
      "Step 2371/100000 MLoss: 2.1666 GLoss: 0.7012 Sum: 2.8678\n",
      "Step 2372/100000 MLoss: 2.1915 GLoss: 0.6862 Sum: 2.8777\n",
      "Step 2373/100000 MLoss: 2.1582 GLoss: 0.7049 Sum: 2.8630999999999998\n",
      "Step 2374/100000 MLoss: 2.1938 GLoss: 0.7183 Sum: 2.9121\n",
      "Step 2375/100000 MLoss: 2.1355 GLoss: 0.7038 Sum: 2.8392999999999997\n",
      "Step 2376/100000 MLoss: 2.1369 GLoss: 0.6876 Sum: 2.8244999999999996\n",
      "Step 2377/100000 MLoss: 2.1765 GLoss: 0.6984 Sum: 2.8749\n",
      "Step 2378/100000 MLoss: 2.168 GLoss: 0.6941 Sum: 2.8621000000000003\n",
      "Step 2379/100000 MLoss: 2.2127 GLoss: 0.7025 Sum: 2.9152\n",
      "Step 2380/100000 MLoss: 1.9921 GLoss: 0.6986 Sum: 2.6907\n",
      "Step 2381/100000 MLoss: 2.1699 GLoss: 0.7038 Sum: 2.8737000000000004\n",
      "Step 2382/100000 MLoss: 2.1451 GLoss: 0.6928 Sum: 2.8379\n",
      "Step 2383/100000 MLoss: 2.1458 GLoss: 0.7253 Sum: 2.8710999999999998\n",
      "Step 2384/100000 MLoss: 2.2537 GLoss: 0.7187 Sum: 2.9724\n",
      "Step 2385/100000 MLoss: 2.2209 GLoss: 0.6903 Sum: 2.9112\n",
      "Step 2386/100000 MLoss: 2.1317 GLoss: 0.7057 Sum: 2.8373999999999997\n",
      "Step 2387/100000 MLoss: 2.1253 GLoss: 0.6783 Sum: 2.8036000000000003\n",
      "Step 2388/100000 MLoss: 2.2313 GLoss: 0.6895 Sum: 2.9208\n",
      "Step 2389/100000 MLoss: 2.1223 GLoss: 0.6907 Sum: 2.813\n",
      "Step 2390/100000 MLoss: 2.3131 GLoss: 0.6767 Sum: 2.9898\n",
      "Step 2391/100000 MLoss: 2.1165 GLoss: 0.6898 Sum: 2.8063\n",
      "Step 2392/100000 MLoss: 2.2066 GLoss: 0.6836 Sum: 2.8902\n",
      "Step 2393/100000 MLoss: 2.1787 GLoss: 0.6976 Sum: 2.8763\n",
      "Step 2394/100000 MLoss: 2.1076 GLoss: 0.695 Sum: 2.8026\n",
      "Step 2395/100000 MLoss: 2.1508 GLoss: 0.704 Sum: 2.8548\n",
      "Step 2396/100000 MLoss: 2.095 GLoss: 0.7082 Sum: 2.8032000000000004\n",
      "Step 2397/100000 MLoss: 2.1546 GLoss: 0.6783 Sum: 2.8329\n",
      "Step 2398/100000 MLoss: 2.241 GLoss: 0.7053 Sum: 2.9463\n",
      "Step 2399/100000 MLoss: 2.1574 GLoss: 0.7019 Sum: 2.8593\n",
      "Step 2400/100000 MLoss: 2.0013 GLoss: 0.6967 Sum: 2.698\n",
      "Step 2401/100000 MLoss: 2.1253 GLoss: 0.687 Sum: 2.8123000000000005\n",
      "Step 2402/100000 MLoss: 2.2295 GLoss: 0.7196 Sum: 2.9490999999999996\n",
      "Step 2403/100000 MLoss: 2.2043 GLoss: 0.7021 Sum: 2.9063999999999997\n",
      "Step 2404/100000 MLoss: 2.1595 GLoss: 0.7048 Sum: 2.8643\n",
      "Step 2405/100000 MLoss: 2.284 GLoss: 0.707 Sum: 2.9909999999999997\n",
      "Step 2406/100000 MLoss: 2.2582 GLoss: 0.696 Sum: 2.9542\n",
      "Step 2407/100000 MLoss: 2.2147 GLoss: 0.6825 Sum: 2.8972\n",
      "Step 2408/100000 MLoss: 2.2019 GLoss: 0.6948 Sum: 2.8967\n",
      "Step 2409/100000 MLoss: 2.2084 GLoss: 0.6852 Sum: 2.8936\n",
      "Step 2410/100000 MLoss: 2.0785 GLoss: 0.7044 Sum: 2.7829\n",
      "Step 2411/100000 MLoss: 2.1203 GLoss: 0.6908 Sum: 2.8110999999999997\n",
      "Step 2412/100000 MLoss: 2.2403 GLoss: 0.7045 Sum: 2.9448\n",
      "Step 2413/100000 MLoss: 2.1963 GLoss: 0.6939 Sum: 2.8902\n",
      "Step 2414/100000 MLoss: 2.09 GLoss: 0.6691 Sum: 2.7591\n",
      "Step 2415/100000 MLoss: 2.2132 GLoss: 0.7067 Sum: 2.9199\n",
      "Step 2416/100000 MLoss: 2.1628 GLoss: 0.687 Sum: 2.8498\n",
      "Step 2417/100000 MLoss: 2.1202 GLoss: 0.7248 Sum: 2.845\n",
      "Step 2418/100000 MLoss: 2.155 GLoss: 0.7156 Sum: 2.8705999999999996\n",
      "Step 2419/100000 MLoss: 2.1184 GLoss: 0.7046 Sum: 2.823\n",
      "Step 2420/100000 MLoss: 1.9851 GLoss: 0.6666 Sum: 2.6517\n",
      "Step 2421/100000 MLoss: 2.1597 GLoss: 0.7295 Sum: 2.8891999999999998\n",
      "Step 2422/100000 MLoss: 2.1694 GLoss: 0.6946 Sum: 2.864\n",
      "Step 2423/100000 MLoss: 2.1409 GLoss: 0.7118 Sum: 2.8526999999999996\n",
      "Step 2424/100000 MLoss: 2.1494 GLoss: 0.7214 Sum: 2.8708\n",
      "Step 2425/100000 MLoss: 2.1488 GLoss: 0.6999 Sum: 2.8487\n",
      "Step 2426/100000 MLoss: 2.2692 GLoss: 0.6927 Sum: 2.9619\n",
      "Step 2427/100000 MLoss: 2.2247 GLoss: 0.7025 Sum: 2.9272\n",
      "Step 2428/100000 MLoss: 2.2325 GLoss: 0.698 Sum: 2.9305\n",
      "Step 2429/100000 MLoss: 2.2249 GLoss: 0.7029 Sum: 2.9278\n",
      "Step 2430/100000 MLoss: 2.1646 GLoss: 0.6854 Sum: 2.85\n",
      "Step 2431/100000 MLoss: 2.2294 GLoss: 0.6813 Sum: 2.9107000000000003\n",
      "Step 2432/100000 MLoss: 2.2307 GLoss: 0.6859 Sum: 2.9166\n",
      "Step 2433/100000 MLoss: 2.1425 GLoss: 0.6858 Sum: 2.8283\n",
      "Step 2434/100000 MLoss: 2.081 GLoss: 0.6936 Sum: 2.7746\n",
      "Step 2435/100000 MLoss: 2.0612 GLoss: 0.6881 Sum: 2.7493\n",
      "Step 2436/100000 MLoss: 2.1556 GLoss: 0.6895 Sum: 2.8451000000000004\n",
      "Step 2437/100000 MLoss: 2.1038 GLoss: 0.6921 Sum: 2.7959\n",
      "Step 2438/100000 MLoss: 2.1319 GLoss: 0.6908 Sum: 2.8226999999999998\n",
      "Step 2439/100000 MLoss: 2.1509 GLoss: 0.7136 Sum: 2.8645\n",
      "Step 2440/100000 MLoss: 2.0453 GLoss: 0.6735 Sum: 2.7188\n",
      "Step 2441/100000 MLoss: 2.0847 GLoss: 0.7003 Sum: 2.785\n",
      "Step 2442/100000 MLoss: 2.1397 GLoss: 0.6845 Sum: 2.8242\n",
      "Step 2443/100000 MLoss: 2.1859 GLoss: 0.6834 Sum: 2.8693\n",
      "Step 2444/100000 MLoss: 2.2404 GLoss: 0.6824 Sum: 2.9228\n",
      "Step 2445/100000 MLoss: 2.1773 GLoss: 0.6809 Sum: 2.8581999999999996\n",
      "Step 2446/100000 MLoss: 2.1926 GLoss: 0.667 Sum: 2.8596000000000004\n",
      "Step 2447/100000 MLoss: 2.1728 GLoss: 0.6875 Sum: 2.8603\n",
      "Step 2448/100000 MLoss: 2.1002 GLoss: 0.6842 Sum: 2.7844\n",
      "Step 2449/100000 MLoss: 2.1432 GLoss: 0.6678 Sum: 2.811\n",
      "Step 2450/100000 MLoss: 2.092 GLoss: 0.6777 Sum: 2.7697000000000003\n",
      "Step 2451/100000 MLoss: 2.1586 GLoss: 0.6772 Sum: 2.8358\n",
      "Step 2452/100000 MLoss: 2.1546 GLoss: 0.6718 Sum: 2.8263999999999996\n",
      "Step 2453/100000 MLoss: 2.2191 GLoss: 0.6989 Sum: 2.918\n",
      "Step 2454/100000 MLoss: 2.21 GLoss: 0.6938 Sum: 2.9038\n",
      "Step 2455/100000 MLoss: 2.1509 GLoss: 0.6973 Sum: 2.8482000000000003\n",
      "Step 2456/100000 MLoss: 2.2207 GLoss: 0.689 Sum: 2.9097\n",
      "Step 2457/100000 MLoss: 2.2273 GLoss: 0.6999 Sum: 2.9272\n",
      "Step 2458/100000 MLoss: 2.1981 GLoss: 0.6975 Sum: 2.8956\n",
      "Step 2459/100000 MLoss: 2.1234 GLoss: 0.6814 Sum: 2.8048\n",
      "Step 2460/100000 MLoss: 1.9758 GLoss: 0.7149 Sum: 2.6907\n",
      "Step 2461/100000 MLoss: 2.1446 GLoss: 0.6987 Sum: 2.8433\n",
      "Step 2462/100000 MLoss: 2.1315 GLoss: 0.6951 Sum: 2.8266\n",
      "Step 2463/100000 MLoss: 2.2355 GLoss: 0.6996 Sum: 2.9351000000000003\n",
      "Step 2464/100000 MLoss: 2.1598 GLoss: 0.6957 Sum: 2.8555\n",
      "Step 2465/100000 MLoss: 2.1256 GLoss: 0.6999 Sum: 2.8255\n",
      "Step 2466/100000 MLoss: 2.0971 GLoss: 0.6943 Sum: 2.7914000000000003\n",
      "Step 2467/100000 MLoss: 2.2515 GLoss: 0.6995 Sum: 2.951\n",
      "Step 2468/100000 MLoss: 2.0663 GLoss: 0.7013 Sum: 2.7676\n",
      "Step 2469/100000 MLoss: 2.1313 GLoss: 0.6769 Sum: 2.8082\n",
      "Step 2470/100000 MLoss: 2.3697 GLoss: 0.7261 Sum: 3.0957999999999997\n",
      "Step 2471/100000 MLoss: 2.101 GLoss: 0.7275 Sum: 2.8285\n",
      "Step 2472/100000 MLoss: 2.1283 GLoss: 0.6761 Sum: 2.8044\n",
      "Step 2473/100000 MLoss: 2.2068 GLoss: 0.7066 Sum: 2.9133999999999998\n",
      "Step 2474/100000 MLoss: 2.212 GLoss: 0.6813 Sum: 2.8933\n",
      "Step 2475/100000 MLoss: 2.1541 GLoss: 0.7303 Sum: 2.8844000000000003\n",
      "Step 2476/100000 MLoss: 2.1488 GLoss: 0.7173 Sum: 2.8661000000000003\n",
      "Step 2477/100000 MLoss: 2.3197 GLoss: 0.6859 Sum: 3.0056000000000003\n",
      "Step 2478/100000 MLoss: 2.2523 GLoss: 0.6998 Sum: 2.9520999999999997\n",
      "Step 2479/100000 MLoss: 2.2008 GLoss: 0.7155 Sum: 2.9163\n",
      "Step 2480/100000 MLoss: 2.1761 GLoss: 0.7082 Sum: 2.8843\n",
      "Step 2481/100000 MLoss: 2.1037 GLoss: 0.712 Sum: 2.8156999999999996\n",
      "Step 2482/100000 MLoss: 2.208 GLoss: 0.7072 Sum: 2.9152000000000005\n",
      "Step 2483/100000 MLoss: 2.2574 GLoss: 0.7408 Sum: 2.9982\n",
      "Step 2484/100000 MLoss: 2.2392 GLoss: 0.7157 Sum: 2.9549\n",
      "Step 2485/100000 MLoss: 2.1819 GLoss: 0.709 Sum: 2.8909000000000002\n",
      "Step 2486/100000 MLoss: 2.1933 GLoss: 0.7169 Sum: 2.9101999999999997\n",
      "Step 2487/100000 MLoss: 2.1638 GLoss: 0.707 Sum: 2.8708\n",
      "Step 2488/100000 MLoss: 2.1755 GLoss: 0.6962 Sum: 2.8717\n",
      "Step 2489/100000 MLoss: 2.2216 GLoss: 0.6968 Sum: 2.9184\n",
      "Step 2490/100000 MLoss: 2.1962 GLoss: 0.6917 Sum: 2.8879\n",
      "Step 2491/100000 MLoss: 2.292 GLoss: 0.7146 Sum: 3.0065999999999997\n",
      "Step 2492/100000 MLoss: 2.2476 GLoss: 0.7098 Sum: 2.9574\n",
      "Step 2493/100000 MLoss: 2.1254 GLoss: 0.6835 Sum: 2.8089\n",
      "Step 2494/100000 MLoss: 2.0947 GLoss: 0.7002 Sum: 2.7949\n",
      "Step 2495/100000 MLoss: 2.1759 GLoss: 0.718 Sum: 2.8939\n",
      "Step 2496/100000 MLoss: 2.1482 GLoss: 0.6918 Sum: 2.84\n",
      "Step 2497/100000 MLoss: 2.1191 GLoss: 0.6937 Sum: 2.8128\n",
      "Step 2498/100000 MLoss: 2.1588 GLoss: 0.7073 Sum: 2.8661\n",
      "Step 2499/100000 MLoss: 2.1657 GLoss: 0.6849 Sum: 2.8506\n",
      "Step 2500/100000 MLoss: 2.2216 GLoss: 0.701 Sum: 2.9226\n",
      "Step 2501/100000 MLoss: 2.2024 GLoss: 0.7059 Sum: 2.9082999999999997\n",
      "Step 2502/100000 MLoss: 2.1214 GLoss: 0.6941 Sum: 2.8155\n",
      "Step 2503/100000 MLoss: 2.2501 GLoss: 0.7062 Sum: 2.9563\n",
      "Step 2504/100000 MLoss: 2.1503 GLoss: 0.7009 Sum: 2.8512\n",
      "Step 2505/100000 MLoss: 2.2041 GLoss: 0.6943 Sum: 2.8984\n",
      "Step 2506/100000 MLoss: 2.1997 GLoss: 0.6931 Sum: 2.8928000000000003\n",
      "Step 2507/100000 MLoss: 2.295 GLoss: 0.692 Sum: 2.987\n",
      "Step 2508/100000 MLoss: 2.0649 GLoss: 0.679 Sum: 2.7439\n",
      "Step 2509/100000 MLoss: 2.194 GLoss: 0.7005 Sum: 2.8945\n",
      "Step 2510/100000 MLoss: 2.1044 GLoss: 0.6739 Sum: 2.7783\n",
      "Step 2511/100000 MLoss: 2.0948 GLoss: 0.6902 Sum: 2.785\n",
      "Step 2512/100000 MLoss: 2.0938 GLoss: 0.6979 Sum: 2.7916999999999996\n",
      "Step 2513/100000 MLoss: 2.2315 GLoss: 0.7104 Sum: 2.9419\n",
      "Step 2514/100000 MLoss: 2.11 GLoss: 0.7033 Sum: 2.8133\n",
      "Step 2515/100000 MLoss: 2.2375 GLoss: 0.6861 Sum: 2.9236\n",
      "Step 2516/100000 MLoss: 2.1551 GLoss: 0.7072 Sum: 2.8623000000000003\n",
      "Step 2517/100000 MLoss: 2.1286 GLoss: 0.7267 Sum: 2.8553\n",
      "Step 2518/100000 MLoss: 2.1612 GLoss: 0.6874 Sum: 2.8486000000000002\n",
      "Step 2519/100000 MLoss: 2.1123 GLoss: 0.6983 Sum: 2.8106\n",
      "Step 2520/100000 MLoss: 2.0433 GLoss: 0.6878 Sum: 2.7310999999999996\n",
      "Step 2521/100000 MLoss: 2.1811 GLoss: 0.6844 Sum: 2.8655\n",
      "Step 2522/100000 MLoss: 2.1127 GLoss: 0.698 Sum: 2.8106999999999998\n",
      "Step 2523/100000 MLoss: 2.1512 GLoss: 0.6857 Sum: 2.8369\n",
      "Step 2524/100000 MLoss: 2.2023 GLoss: 0.6957 Sum: 2.898\n",
      "Step 2525/100000 MLoss: 2.105 GLoss: 0.6777 Sum: 2.7827\n",
      "Step 2526/100000 MLoss: 2.2687 GLoss: 0.7034 Sum: 2.9721\n",
      "Step 2527/100000 MLoss: 2.2126 GLoss: 0.6733 Sum: 2.8859000000000004\n",
      "Step 2528/100000 MLoss: 2.197 GLoss: 0.7187 Sum: 2.9157\n",
      "Step 2529/100000 MLoss: 2.2381 GLoss: 0.7117 Sum: 2.9498\n",
      "Step 2530/100000 MLoss: 2.2144 GLoss: 0.6842 Sum: 2.8986\n",
      "Step 2531/100000 MLoss: 2.1249 GLoss: 0.6817 Sum: 2.8065999999999995\n",
      "Step 2532/100000 MLoss: 2.2164 GLoss: 0.6918 Sum: 2.9082\n",
      "Step 2533/100000 MLoss: 2.1413 GLoss: 0.6927 Sum: 2.834\n",
      "Step 2534/100000 MLoss: 2.1134 GLoss: 0.7057 Sum: 2.8190999999999997\n",
      "Step 2535/100000 MLoss: 2.2308 GLoss: 0.7151 Sum: 2.9459\n",
      "Step 2536/100000 MLoss: 2.0214 GLoss: 0.6858 Sum: 2.7072\n",
      "Step 2537/100000 MLoss: 2.1505 GLoss: 0.7161 Sum: 2.8666\n",
      "Step 2538/100000 MLoss: 2.128 GLoss: 0.684 Sum: 2.8120000000000003\n",
      "Step 2539/100000 MLoss: 2.1439 GLoss: 0.7099 Sum: 2.8537999999999997\n",
      "Step 2540/100000 MLoss: 2.1949 GLoss: 0.7032 Sum: 2.8981000000000003\n",
      "Step 2541/100000 MLoss: 2.063 GLoss: 0.6874 Sum: 2.7504\n",
      "Step 2542/100000 MLoss: 2.1645 GLoss: 0.7003 Sum: 2.8648\n",
      "Step 2543/100000 MLoss: 2.2082 GLoss: 0.6934 Sum: 2.9016\n",
      "Step 2544/100000 MLoss: 2.1401 GLoss: 0.6876 Sum: 2.8277\n",
      "Step 2545/100000 MLoss: 2.1228 GLoss: 0.6858 Sum: 2.8085999999999998\n",
      "Step 2546/100000 MLoss: 2.169 GLoss: 0.6926 Sum: 2.8616\n",
      "Step 2547/100000 MLoss: 2.1076 GLoss: 0.708 Sum: 2.8156\n",
      "Step 2548/100000 MLoss: 2.1475 GLoss: 0.6944 Sum: 2.8419\n",
      "Step 2549/100000 MLoss: 2.2336 GLoss: 0.6823 Sum: 2.9159\n",
      "Step 2550/100000 MLoss: 2.7625 GLoss: 0.703 Sum: 3.4655\n",
      "Step 2551/100000 MLoss: 2.2786 GLoss: 0.6979 Sum: 2.9764999999999997\n",
      "Step 2552/100000 MLoss: 2.1584 GLoss: 0.6933 Sum: 2.8517\n",
      "Step 2553/100000 MLoss: 2.2659 GLoss: 0.6886 Sum: 2.9545\n",
      "Step 2554/100000 MLoss: 2.2023 GLoss: 0.6817 Sum: 2.8840000000000003\n",
      "Step 2555/100000 MLoss: 2.1368 GLoss: 0.6808 Sum: 2.8176\n",
      "Step 2556/100000 MLoss: 2.2522 GLoss: 0.6939 Sum: 2.9461000000000004\n",
      "Step 2557/100000 MLoss: 2.2416 GLoss: 0.6766 Sum: 2.9182\n",
      "Step 2558/100000 MLoss: 2.1329 GLoss: 0.6929 Sum: 2.8257999999999996\n",
      "Step 2559/100000 MLoss: 2.1523 GLoss: 0.6813 Sum: 2.8335999999999997\n",
      "Step 2560/100000 MLoss: 2.1143 GLoss: 0.7133 Sum: 2.8276000000000003\n",
      "Step 2561/100000 MLoss: 2.2565 GLoss: 0.7031 Sum: 2.9596\n",
      "Step 2562/100000 MLoss: 2.173 GLoss: 0.6777 Sum: 2.8507\n",
      "Step 2563/100000 MLoss: 2.1838 GLoss: 0.6848 Sum: 2.8686000000000003\n",
      "Step 2564/100000 MLoss: 2.0996 GLoss: 0.6821 Sum: 2.7817000000000003\n",
      "Step 2565/100000 MLoss: 2.1209 GLoss: 0.6798 Sum: 2.8007\n",
      "Step 2566/100000 MLoss: 2.2323 GLoss: 0.6966 Sum: 2.9289\n",
      "Step 2567/100000 MLoss: 2.2022 GLoss: 0.6884 Sum: 2.8906\n",
      "Step 2568/100000 MLoss: 2.0777 GLoss: 0.6912 Sum: 2.7689000000000004\n",
      "Step 2569/100000 MLoss: 2.1818 GLoss: 0.6831 Sum: 2.8649\n",
      "Step 2570/100000 MLoss: 2.2416 GLoss: 0.6876 Sum: 2.9292\n",
      "Step 2571/100000 MLoss: 2.2052 GLoss: 0.7072 Sum: 2.9124\n",
      "Step 2572/100000 MLoss: 2.1821 GLoss: 0.6894 Sum: 2.8715\n",
      "Step 2573/100000 MLoss: 2.165 GLoss: 0.6853 Sum: 2.8503\n",
      "Step 2574/100000 MLoss: 2.144 GLoss: 0.7033 Sum: 2.8473\n",
      "Step 2575/100000 MLoss: 2.284 GLoss: 0.6855 Sum: 2.9695\n",
      "Step 2576/100000 MLoss: 2.1144 GLoss: 0.6913 Sum: 2.8057\n",
      "Step 2577/100000 MLoss: 2.313 GLoss: 0.6777 Sum: 2.9907000000000004\n",
      "Step 2578/100000 MLoss: 2.2053 GLoss: 0.7115 Sum: 2.9168\n",
      "Step 2579/100000 MLoss: 2.3136 GLoss: 0.701 Sum: 3.0146\n",
      "Step 2580/100000 MLoss: 2.1951 GLoss: 0.7003 Sum: 2.8954\n",
      "Step 2581/100000 MLoss: 2.1724 GLoss: 0.7015 Sum: 2.8739\n",
      "Step 2582/100000 MLoss: 2.2075 GLoss: 0.7109 Sum: 2.9184\n",
      "Step 2583/100000 MLoss: 2.1523 GLoss: 0.6956 Sum: 2.8479\n",
      "Step 2584/100000 MLoss: 2.1438 GLoss: 0.6887 Sum: 2.8325\n",
      "Step 2585/100000 MLoss: 2.2313 GLoss: 0.6941 Sum: 2.9254000000000002\n",
      "Step 2586/100000 MLoss: 2.2118 GLoss: 0.7101 Sum: 2.9219\n",
      "Step 2587/100000 MLoss: 2.1251 GLoss: 0.6931 Sum: 2.8182\n",
      "Step 2588/100000 MLoss: 2.212 GLoss: 0.6965 Sum: 2.9085\n",
      "Step 2589/100000 MLoss: 2.0508 GLoss: 0.7026 Sum: 2.7534\n",
      "Step 2590/100000 MLoss: 2.2807 GLoss: 0.6964 Sum: 2.9771\n",
      "Step 2591/100000 MLoss: 2.1098 GLoss: 0.6965 Sum: 2.8063\n",
      "Step 2592/100000 MLoss: 2.1037 GLoss: 0.7054 Sum: 2.8091\n",
      "Step 2593/100000 MLoss: 2.237 GLoss: 0.6938 Sum: 2.9308\n",
      "Step 2594/100000 MLoss: 2.1735 GLoss: 0.6937 Sum: 2.8672000000000004\n",
      "Step 2595/100000 MLoss: 2.1738 GLoss: 0.6809 Sum: 2.8547\n",
      "Step 2596/100000 MLoss: 2.0989 GLoss: 0.6873 Sum: 2.7862\n",
      "Step 2597/100000 MLoss: 2.0979 GLoss: 0.6761 Sum: 2.774\n",
      "Step 2598/100000 MLoss: 2.1948 GLoss: 0.6948 Sum: 2.8895999999999997\n",
      "Step 2599/100000 MLoss: 2.0849 GLoss: 0.6806 Sum: 2.7655000000000003\n",
      "Step 2600/100000 MLoss: 2.1914 GLoss: 0.7039 Sum: 2.8952999999999998\n",
      "Step 2601/100000 MLoss: 2.2348 GLoss: 0.6933 Sum: 2.9280999999999997\n",
      "Step 2602/100000 MLoss: 2.1371 GLoss: 0.6967 Sum: 2.8338\n",
      "Step 2603/100000 MLoss: 2.1792 GLoss: 0.6898 Sum: 2.8689999999999998\n",
      "Step 2604/100000 MLoss: 2.0966 GLoss: 0.7097 Sum: 2.8063000000000002\n",
      "Step 2605/100000 MLoss: 2.0926 GLoss: 0.6907 Sum: 2.7833\n",
      "Step 2606/100000 MLoss: 2.2066 GLoss: 0.6926 Sum: 2.8992\n",
      "Step 2607/100000 MLoss: 2.1335 GLoss: 0.6966 Sum: 2.8301000000000003\n",
      "Step 2608/100000 MLoss: 2.0757 GLoss: 0.6861 Sum: 2.7618\n",
      "Step 2609/100000 MLoss: 2.2649 GLoss: 0.689 Sum: 2.9539\n",
      "Step 2610/100000 MLoss: 2.0499 GLoss: 0.6754 Sum: 2.7253\n",
      "Step 2611/100000 MLoss: 2.1305 GLoss: 0.6878 Sum: 2.8183\n",
      "Step 2612/100000 MLoss: 2.2231 GLoss: 0.6929 Sum: 2.916\n",
      "Step 2613/100000 MLoss: 2.1233 GLoss: 0.6913 Sum: 2.8146\n",
      "Step 2614/100000 MLoss: 2.1737 GLoss: 0.6948 Sum: 2.8685\n",
      "Step 2615/100000 MLoss: 2.0919 GLoss: 0.6958 Sum: 2.7877\n",
      "Step 2616/100000 MLoss: 2.1244 GLoss: 0.6918 Sum: 2.8162000000000003\n",
      "Step 2617/100000 MLoss: 2.0833 GLoss: 0.6811 Sum: 2.7644\n",
      "Step 2618/100000 MLoss: 2.1332 GLoss: 0.7041 Sum: 2.8373\n",
      "Step 2619/100000 MLoss: 2.1588 GLoss: 0.6755 Sum: 2.8343\n",
      "Step 2620/100000 MLoss: 2.0923 GLoss: 0.6805 Sum: 2.7727999999999997\n",
      "Step 2621/100000 MLoss: 2.298 GLoss: 0.6947 Sum: 2.9927\n",
      "Step 2622/100000 MLoss: 2.1443 GLoss: 0.7174 Sum: 2.8617\n",
      "Step 2623/100000 MLoss: 2.1919 GLoss: 0.7078 Sum: 2.8997\n",
      "Step 2624/100000 MLoss: 2.1526 GLoss: 0.6868 Sum: 2.8394\n",
      "Step 2625/100000 MLoss: 2.1953 GLoss: 0.6818 Sum: 2.8771\n",
      "Step 2626/100000 MLoss: 2.2489 GLoss: 0.7099 Sum: 2.9588\n",
      "Step 2627/100000 MLoss: 2.1103 GLoss: 0.7043 Sum: 2.8146\n",
      "Step 2628/100000 MLoss: 2.2041 GLoss: 0.6978 Sum: 2.9019\n",
      "Step 2629/100000 MLoss: 2.1598 GLoss: 0.6948 Sum: 2.8546\n",
      "Step 2630/100000 MLoss: 2.1172 GLoss: 0.6584 Sum: 2.7756\n",
      "Step 2631/100000 MLoss: 2.1356 GLoss: 0.7198 Sum: 2.8554000000000004\n",
      "Step 2632/100000 MLoss: 2.1493 GLoss: 0.7199 Sum: 2.8692\n"
     ]
    }
   ],
   "source": [
    "tabddpm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cmap(n, name='hsv'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)\n",
    "    \n",
    "cmap = get_cmap(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 491
    },
    "executionInfo": {
     "elapsed": 1353,
     "status": "ok",
     "timestamp": 1742849876457,
     "user": {
      "displayName": "Elina Telesheva",
      "userId": "03968090829384653347"
     },
     "user_tz": -180
    },
    "id": "J_2etdriv20a",
    "outputId": "fdb4781b-139c-46e1-f722-e17f7a4f375a"
   },
   "outputs": [],
   "source": [
    "loss = pd.read_csv(f'./models/{model_name}/ckpt/{dataname}/loss.csv')\n",
    "max_v, min_v = -np.inf, np.inf\n",
    "window = 250\n",
    "\n",
    "start_step = 100\n",
    "for i, l in enumerate(loss.columns[1:]):\n",
    "    plt.plot(loss['step'][start_step:], loss[l][start_step:], alpha=0.25, color=cmap(i))\n",
    "    smoothed = np.convolve(loss[l][start_step:], np.ones(window)/window, 'valid')  \n",
    "    plt.plot(loss['step'][start_step+window-1:], smoothed, label=l, color=cmap(i))\n",
    "\n",
    "    max_v = np.max([np.quantile(loss[l][start_step:], 0.99), max_v])\n",
    "    min_v = np.min([np.quantile(loss[l][start_step:], 0.01), min_v])\n",
    "\n",
    "plt.ylim([min_v-0.1, max_v+0.1]) \n",
    "plt.legend()\n",
    "plt.title(f\"Model name: {model_name.upper()}\\nLoss by steps from step #{start_step}\")\n",
    "plt.savefig(f'./models/{model_name}/ckpt/{dataname}/loss_image.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1742849876500,
     "user": {
      "displayName": "Elina Telesheva",
      "userId": "03968090829384653347"
     },
     "user_tz": -180
    },
    "id": "_dh1_KeYveNz"
   },
   "outputs": [],
   "source": [
    "tabddpm.sample(sample_save_path=CONFIG.get_arg('sample_save_path'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pRj_6inEVEL"
   },
   "source": [
    "### Расчет метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 12806,
     "status": "ok",
     "timestamp": 1742849889325,
     "user": {
      "displayName": "Elina Telesheva",
      "userId": "03968090829384653347"
     },
     "user_tz": -180
    },
    "id": "TgJLMonR8Q-E"
   },
   "outputs": [],
   "source": [
    "from eval.base_metrics import calculate_base_metrics\n",
    "from eval.similarity import calculate_similarity\n",
    "from eval.mle import calculate_mle\n",
    "from eval.alpha_beta import calculate_alpha_beta\n",
    "from eval.detection import calculate_detection\n",
    "from eval.dcr import calculate_DCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_metrics = {}\n",
    "overall_metrics[model_name] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataname': 'beijing',\n",
       " 'method': 'tabddpm',\n",
       " 'device': 'cuda',\n",
       " 'mode': 'train',\n",
       " 'train': 1,\n",
       " 'sample_save_path': 'synthetic/beijing/tabddpm.csv',\n",
       " 'sigma_scheduller_name': 'constant',\n",
       " 'sigma_value': 0.001,\n",
       " 'num_noise': 66,\n",
       " 'real_path': 'synthetic/beijing/real.csv',\n",
       " 'test_path': 'synthetic/beijing/test.csv',\n",
       " 'info_path': 'data/beijing/info.json',\n",
       " 'save_path': './synthetic/shoppers_ON_QnSC_200k/initial_tabddpm_ON_QnSC_200k_mult_9.csv',\n",
       " 'num_clusters': 25,\n",
       " 'save_cat': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG.get_all_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>cbwd</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>145.703610</td>\n",
       "      <td>-14.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1028.0000</td>\n",
       "      <td>cv</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1002.0000</td>\n",
       "      <td>SE</td>\n",
       "      <td>21.910000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>68.414580</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1017.0000</td>\n",
       "      <td>cv</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>504.721470</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1028.0000</td>\n",
       "      <td>cv</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>24.092388</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1035.0000</td>\n",
       "      <td>NW</td>\n",
       "      <td>10.280000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37576</th>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1017.7278</td>\n",
       "      <td>NE</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37577</th>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-2.758127</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1010.0000</td>\n",
       "      <td>NW</td>\n",
       "      <td>2.680000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37578</th>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>235.505400</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1014.0000</td>\n",
       "      <td>SE</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37579</th>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>-18.000000</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1041.6565</td>\n",
       "      <td>cv</td>\n",
       "      <td>3.444402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37580</th>\n",
       "      <td>2012</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1019.0000</td>\n",
       "      <td>SE</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37581 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  month  day  hour       pm2.5       DEWP  TEMP       PRES cbwd  \\\n",
       "0      2013     11   30     1  145.703610 -14.000000  -1.0  1028.0000   cv   \n",
       "1      2014      7    7    20   78.000000  21.000000  31.0  1002.0000   SE   \n",
       "2      2013     10   16    10   68.414580   4.000000  15.0  1017.0000   cv   \n",
       "3      2014      2   21    17  504.721470  -3.000000   6.0  1028.0000   cv   \n",
       "4      2013     10   24    11   24.092388  -5.000000  14.0  1035.0000   NW   \n",
       "...     ...    ...  ...   ...         ...        ...   ...        ...  ...   \n",
       "37576  2014     10    4     4   62.000000  12.000000  15.0  1017.7278   NE   \n",
       "37577  2010      5   14    12   10.000000  -2.758127  26.0  1010.0000   NW   \n",
       "37578  2010     11   23    15  235.505400  -2.000000   9.0  1014.0000   SE   \n",
       "37579  2011      1   27    23   29.000000 -18.000000  -5.0  1041.6565   cv   \n",
       "37580  2012     11   23    15  189.000000  -9.000000   6.0  1019.0000   SE   \n",
       "\n",
       "             Iws   Is   Ir  \n",
       "0       0.450000  0.0  0.0  \n",
       "1      21.910000  0.0  0.0  \n",
       "2       1.790000  0.0  0.0  \n",
       "3       1.790000  0.0  0.0  \n",
       "4      10.280000  0.0  0.0  \n",
       "...          ...  ...  ...  \n",
       "37576   1.790000  0.0  0.0  \n",
       "37577   2.680000  0.0  0.0  \n",
       "37578   1.790000  0.0  0.0  \n",
       "37579   3.444402  0.0  0.0  \n",
       "37580   1.790000  0.0  0.0  \n",
       "\n",
       "[37581 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(CONFIG.get_arg('sample_save_path'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>cbwd</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>cv</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>148.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>cv</td>\n",
       "      <td>2.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>422.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>55.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>53.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37576</th>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>cv</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37577</th>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>70.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37578</th>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>73.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37579</th>\n",
       "      <td>2012</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>44.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>10.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37580</th>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>42.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37581 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  month  day  hour  pm2.5  DEWP  TEMP    PRES cbwd     Iws   Is  \\\n",
       "0      2012      3   24    23   45.0 -11.0   4.0  1022.0   cv    0.89  0.0   \n",
       "1      2012      6    6     7  148.0  14.0  23.0  1002.0   cv    2.23  0.0   \n",
       "2      2012      3   30    23   37.0 -11.0  10.0  1017.0   SE    3.13  0.0   \n",
       "3      2011      1    6    21   21.0 -19.0  -6.0  1037.0   NW  422.42  0.0   \n",
       "4      2014     10   16    20   55.0  -1.0  13.0  1018.0   SE   53.64  0.0   \n",
       "...     ...    ...  ...   ...    ...   ...   ...     ...  ...     ...  ...   \n",
       "37576  2013      3   13    15   12.0 -19.0   8.0  1028.0   cv    2.68  0.0   \n",
       "37577  2013      6   15     5   70.0  14.0  20.0  1008.0   SE    1.79  0.0   \n",
       "37578  2011      1   14    10   20.0 -20.0  -4.0  1035.0   NW   73.76  0.0   \n",
       "37579  2012      8   27    15   44.0  22.0  29.0  1008.0   SE   10.29  0.0   \n",
       "37580  2014      3    1    14   12.0 -24.0  11.0  1022.0   NW   42.91  0.0   \n",
       "\n",
       "        Ir  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "...    ...  \n",
       "37576  0.0  \n",
       "37577  0.0  \n",
       "37578  0.0  \n",
       "37579  0.0  \n",
       "37580  0.0  \n",
       "\n",
       "[37581 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(CONFIG.get_arg('real_path'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VPqKYB_6OxEo"
   },
   "source": [
    "#### Метрики из статьи TabSyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALCULATING COLUMN-WISE DENSITY ESTIMATION & PAIR-WISE COLUMN CORRELATION...\n",
      "Generating report ...\n",
      "\n",
      "(1/2) Evaluating Column Shapes: |██████████| 12/12 [00:00<00:00, 38.47it/s]|\n",
      "Column Shapes Score: 99.05%\n",
      "\n",
      "(2/2) Evaluating Column Pair Trends: |██████████| 66/66 [00:00<00:00, 66.94it/s]|\n",
      "Column Pair Trends Score: 97.47%\n",
      "\n",
      "Overall Score (Average): 98.26%\n",
      "\n",
      "Error rate (%) of column-wise density estimation TABDDPM: 0.950 ± 0.380\n",
      "Error rate (%) of pair-wise column correlation score TABDDPM: 2.533 ± 1.930\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_12.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"920px\"\n",
       "    height=\"920\"\n",
       "    src=\"iframe_figures/figure_12.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE! \n",
      "\n",
      "DRAW COLUMN VALUES DISTRIBUTIONS...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_12.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_12.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_12.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_12.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_12.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_12.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_12.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_12.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_12.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_12.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_12.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_12.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "overall_metrics[model_name]['similarity'] = calculate_similarity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1eBqfgraJlp"
   },
   "source": [
    "#### MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:23<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving scores to  eval/mle/beijing/tabddpm.json\n",
      "RMSE обучения на синтетических данных TABDDPM: 0.635 ± 0.044\n"
     ]
    }
   ],
   "source": [
    "overall_metrics[model_name]['mle'] = calculate_mle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lcrk8gbLdDS-"
   },
   "source": [
    "#### Detection: classifier two sample tests (C2ST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beijing, tabddpm: 0.977025902489196\n"
     ]
    }
   ],
   "source": [
    "overall_metrics[model_name]['detection'] = calculate_detection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ROQgcQGLeP02"
   },
   "source": [
    "#### DCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_clusters: 25\n",
      "DCR Score, a value closer to 0.5 is better\n",
      "beijing-tabddpm, DCR Score = 0.5071711769245097\n"
     ]
    }
   ],
   "source": [
    "overall_metrics[model_name]['DCR'] = calculate_DCR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKRNoZmzbpTm"
   },
   "source": [
    "#### Alpha precision & Beta recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== All Features ===========\n",
      "Data shape:  (37581, 83)\n",
      "alpha precision: 0.990344, beta recall: 0.541752\n"
     ]
    }
   ],
   "source": [
    "overall_metrics[model_name]['quality'] = calculate_alpha_beta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Табличка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_metrics_table = []\n",
    "for m in overall_metrics.keys():\n",
    "    # Сбор таблички результатов\n",
    "    tmp = pd.DataFrame([{'Model':'TabDDPM', 'Type':m, 'Data':dataname}])\n",
    "    tmp.columns = pd.MultiIndex.from_tuples([('', i) for i in tmp.columns])\n",
    "    result = [tmp]\n",
    "    \n",
    "    for metric_group in overall_metrics[m].keys():\n",
    "        tmp = pd.DataFrame([overall_metrics[m][metric_group]])\n",
    "        tmp.columns = pd.MultiIndex.from_tuples([(metric_group, i) for i in tmp.columns])\n",
    "        result.append(tmp)\n",
    "    result = pd.concat(result, axis = 1)\n",
    "    final_metrics_table.append(result)\n",
    "    \n",
    "final_metrics_table = pd.concat(final_metrics_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\"></th>\n",
       "      <th colspan=\"7\" halign=\"left\">similarity</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mle</th>\n",
       "      <th>detection</th>\n",
       "      <th>DCR</th>\n",
       "      <th colspan=\"2\" halign=\"left\">quality</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Data</th>\n",
       "      <th>Column Shapes Score, %</th>\n",
       "      <th>Column Pair Trends Score, %</th>\n",
       "      <th>Overall Score (Average), %</th>\n",
       "      <th>Error rate (%) of column-wise density estimation, %</th>\n",
       "      <th>Error rate (%) of column-wise density estimation std, %</th>\n",
       "      <th>Error rate (%) of pair-wise column correlation score, %</th>\n",
       "      <th>Error rate (%) of pair-wise column correlation score std, %</th>\n",
       "      <th>RMSE обучения на синтетических данных</th>\n",
       "      <th>RMSE обучения на синтетических данных, std</th>\n",
       "      <th>Score</th>\n",
       "      <th>Score</th>\n",
       "      <th>alpha precision</th>\n",
       "      <th>beta recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TabDDPM</td>\n",
       "      <td>tabddpm</td>\n",
       "      <td>beijing</td>\n",
       "      <td>99.0503</td>\n",
       "      <td>97.4674</td>\n",
       "      <td>98.2588</td>\n",
       "      <td>0.9497</td>\n",
       "      <td>0.3803</td>\n",
       "      <td>2.5326</td>\n",
       "      <td>1.9302</td>\n",
       "      <td>0.6349</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.5072</td>\n",
       "      <td>0.9903</td>\n",
       "      <td>0.5418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         similarity  \\\n",
       "     Model     Type     Data Column Shapes Score, %   \n",
       "0  TabDDPM  tabddpm  beijing                99.0503   \n",
       "\n",
       "                                                          \\\n",
       "  Column Pair Trends Score, % Overall Score (Average), %   \n",
       "0                     97.4674                    98.2588   \n",
       "\n",
       "                                                       \\\n",
       "  Error rate (%) of column-wise density estimation, %   \n",
       "0                                              0.9497   \n",
       "\n",
       "                                                           \\\n",
       "  Error rate (%) of column-wise density estimation std, %   \n",
       "0                                                  0.3803   \n",
       "\n",
       "                                                           \\\n",
       "  Error rate (%) of pair-wise column correlation score, %   \n",
       "0                                                  2.5326   \n",
       "\n",
       "                                                               \\\n",
       "  Error rate (%) of pair-wise column correlation score std, %   \n",
       "0                                                      1.9302   \n",
       "\n",
       "                                    mle  \\\n",
       "  RMSE обучения на синтетических данных   \n",
       "0                                0.6349   \n",
       "\n",
       "                                             detection     DCR  \\\n",
       "  RMSE обучения на синтетических данных, std     Score   Score   \n",
       "0                                      0.044     0.977  0.5072   \n",
       "\n",
       "          quality              \n",
       "  alpha precision beta recall  \n",
       "0          0.9903      0.5418  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "final_metrics_table.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(f'./eval/total/{dataname}'):\n",
    "    os.makedirs(f'./eval/total/{dataname}')\n",
    "final_metrics_table.to_csv(f'./eval/total/{dataname}/{model_short}_final_metrics_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM87OAyAZDeZ/KEr1BVC60/",
   "mount_file_id": "1-H09AG2TbV5ZzQ-ytJRNbFUCirBvOV9p",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
