{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2d7PvQcc2I3",
        "outputId": "c4ede048-19cf-4fdc-b7fc-92bc7cc4efad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'tabsyn' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/amazon-science/tabsyn.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd tabsyn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwFHuKsHdBAo",
        "outputId": "e9055533-4713-486e-84ff-1c29a1cffe68"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tabsyn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --extra-index-url https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install -r requirements.txt\n",
        "!pip install dgl -f https://data.dgl.ai/wheels/cu117/repo.html\n",
        "!pip install torch_geometric\n",
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.1+cu117.html\n",
        "!pip install tomli"
      ],
      "metadata": {
        "id": "IhJcZ3QS8HJQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python download_dataset.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPrk1zsn-AFY",
        "outputId": "716b08d3-24cf-4459-b1c9-95aabe9ad398"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start processing dataset adult from UCI.\n",
            "Finish downloading dataset from https://archive.ics.uci.edu/static/public/2/adult.zip, data has been saved to data/adult.\n",
            "Finish unzipping adult.\n",
            "Start processing dataset default from UCI.\n",
            "Finish downloading dataset from https://archive.ics.uci.edu/static/public/350/default+of+credit+card+clients.zip, data has been saved to data/default.\n",
            "Finish unzipping default.\n",
            "Start processing dataset magic from UCI.\n",
            "Finish downloading dataset from https://archive.ics.uci.edu/static/public/159/magic+gamma+telescope.zip, data has been saved to data/magic.\n",
            "Finish unzipping magic.\n",
            "Start processing dataset shoppers from UCI.\n",
            "Finish downloading dataset from https://archive.ics.uci.edu/static/public/468/online+shoppers+purchasing+intention+dataset.zip, data has been saved to data/shoppers.\n",
            "Finish unzipping shoppers.\n",
            "Start processing dataset beijing from UCI.\n",
            "Finish downloading dataset from https://archive.ics.uci.edu/static/public/381/beijing+pm2+5+data.zip, data has been saved to data/beijing.\n",
            "Finish unzipping beijing.\n",
            "Start processing dataset news from UCI.\n",
            "Finish downloading dataset from https://archive.ics.uci.edu/static/public/332/online+news+popularity.zip, data has been saved to data/news.\n",
            "Finish unzipping news.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python process_dataset.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JISw4PYDHR6S",
        "outputId": "27ef43b0-5b67-4403-a7bf-c76822be4fae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adult (32561, 15) (16281, 15) (32561, 15)\n",
            "Numerical (32561, 6)\n",
            "Categorical (32561, 8)\n",
            "Processing and Saving adult Successfully!\n",
            "adult\n",
            "Total 48842\n",
            "Train 32561\n",
            "Test 16281\n",
            "Num 6\n",
            "Cat 9\n",
            "default (27000, 24) (3000, 24) (30000, 24)\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "Numerical (27000, 14)\n",
            "Categorical (27000, 9)\n",
            "Processing and Saving default Successfully!\n",
            "default\n",
            "Total 30000\n",
            "Train 27000\n",
            "Test 3000\n",
            "Num 14\n",
            "Cat 10\n",
            "shoppers (11097, 18) (1233, 18) (12330, 18)\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "Numerical (11097, 10)\n",
            "Categorical (11097, 7)\n",
            "Processing and Saving shoppers Successfully!\n",
            "shoppers\n",
            "Total 12330\n",
            "Train 11097\n",
            "Test 1233\n",
            "Num 10\n",
            "Cat 8\n",
            "magic (17117, 11) (1902, 11) (19019, 11)\n",
            "Numerical (17117, 10)\n",
            "Categorical (17117, 0)\n",
            "Processing and Saving magic Successfully!\n",
            "magic\n",
            "Total 19019\n",
            "Train 17117\n",
            "Test 1902\n",
            "Num 10\n",
            "Cat 1\n",
            "beijing (37581, 12) (4176, 12) (41757, 12)\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "Numerical (37581, 6)\n",
            "Categorical (37581, 5)\n",
            "Processing and Saving beijing Successfully!\n",
            "beijing\n",
            "Total 41757\n",
            "Train 37581\n",
            "Test 4176\n",
            "Num 7\n",
            "Cat 5\n",
            "news (35679, 48) (3965, 48) (39644, 48)\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "Numerical (35679, 45)\n",
            "Categorical (35679, 2)\n",
            "Processing and Saving news Successfully!\n",
            "news\n",
            "Total 39644\n",
            "Train 35679\n",
            "Test 3965\n",
            "Num 46\n",
            "Cat 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from baselines.stasy import main"
      ],
      "metadata": {
        "id": "KmEXs0EhEyi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from baselines.stasy.configs.config import get_config\n",
        "config = get_config('beijing')"
      ],
      "metadata": {
        "id": "aTkoGVs9lgiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config.training.epoch = 1000"
      ],
      "metadata": {
        "id": "PTWQOkJ4F6K0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "config.device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "gTUb5lCRlzX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname beijing --method stasy --mode train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHh5OeNg-NzX",
        "outputId": "7066915c-c592-4b9d-896a-c708815899fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No NaNs in numerical features, skipping\n",
            "83\n",
            "NCSNpp(\n",
            "  (act): ELU(alpha=1.0)\n",
            "  (all_modules): ModuleList(\n",
            "    (0): GaussianFourierProjection()\n",
            "    (1): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (3): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=83, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (4): ELU(alpha=1.0)\n",
            "    (5): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=1107, out_features=2048, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=2048, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=2048, bias=True)\n",
            "    )\n",
            "    (6): ELU(alpha=1.0)\n",
            "    (7): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=3155, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (8): ELU(alpha=1.0)\n",
            "    (9): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=4179, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (10): ELU(alpha=1.0)\n",
            "    (11): Linear(in_features=5203, out_features=83, bias=True)\n",
            "  )\n",
            ")\n",
            "the number of parameters 10413436\n",
            "epoch: 0, iter: 37, training_loss: 2.35737e+00\n",
            "epoch: 1, iter: 37, training_loss: 1.31796e+00\n",
            "epoch: 2, iter: 37, training_loss: 1.26301e+00\n",
            "epoch: 3, iter: 37, training_loss: 1.28356e+00\n",
            "epoch: 4, iter: 37, training_loss: 1.21963e+00\n",
            "epoch: 5, iter: 37, training_loss: 1.18148e+00\n",
            "epoch: 6, iter: 37, training_loss: 1.14680e+00\n",
            "epoch: 7, iter: 37, training_loss: 1.17967e+00\n",
            "epoch: 8, iter: 37, training_loss: 1.12768e+00\n",
            "epoch: 9, iter: 37, training_loss: 1.07225e+00\n",
            "epoch: 10, iter: 37, training_loss: 1.08494e+00\n",
            "epoch: 11, iter: 37, training_loss: 1.04127e+00\n",
            "epoch: 12, iter: 37, training_loss: 1.07721e+00\n",
            "epoch: 13, iter: 37, training_loss: 1.06228e+00\n",
            "epoch: 14, iter: 37, training_loss: 1.08833e+00\n",
            "epoch: 15, iter: 37, training_loss: 1.07058e+00\n",
            "epoch: 16, iter: 37, training_loss: 1.03821e+00\n",
            "epoch: 17, iter: 37, training_loss: 1.04622e+00\n",
            "epoch: 18, iter: 37, training_loss: 1.06641e+00\n",
            "epoch: 19, iter: 37, training_loss: 1.09427e+00\n",
            "epoch: 20, iter: 37, training_loss: 1.17260e+00\n",
            "epoch: 21, iter: 37, training_loss: 1.06527e+00\n",
            "epoch: 22, iter: 37, training_loss: 1.11064e+00\n",
            "epoch: 23, iter: 37, training_loss: 1.17618e+00\n",
            "epoch: 24, iter: 37, training_loss: 1.21357e+00\n",
            "epoch: 25, iter: 37, training_loss: 1.15877e+00\n",
            "epoch: 26, iter: 37, training_loss: 1.20348e+00\n",
            "epoch: 27, iter: 37, training_loss: 1.30700e+00\n",
            "epoch: 28, iter: 37, training_loss: 1.35784e+00\n",
            "epoch: 29, iter: 37, training_loss: 1.20501e+00\n",
            "epoch: 30, iter: 37, training_loss: 1.26043e+00\n",
            "epoch: 31, iter: 37, training_loss: 1.35397e+00\n",
            "epoch: 32, iter: 37, training_loss: 1.52228e+00\n",
            "epoch: 33, iter: 37, training_loss: 1.33201e+00\n",
            "epoch: 34, iter: 37, training_loss: 1.59206e+00\n",
            "epoch: 35, iter: 37, training_loss: 1.47736e+00\n",
            "epoch: 36, iter: 37, training_loss: 1.38652e+00\n",
            "epoch: 37, iter: 37, training_loss: 1.48433e+00\n",
            "epoch: 38, iter: 37, training_loss: 1.37342e+00\n",
            "epoch: 39, iter: 37, training_loss: 1.39102e+00\n",
            "epoch: 40, iter: 37, training_loss: 1.46074e+00\n",
            "epoch: 41, iter: 37, training_loss: 1.48300e+00\n",
            "epoch: 42, iter: 37, training_loss: 1.43399e+00\n",
            "epoch: 43, iter: 37, training_loss: 1.61781e+00\n",
            "epoch: 44, iter: 37, training_loss: 1.47964e+00\n",
            "epoch: 45, iter: 37, training_loss: 1.55285e+00\n",
            "epoch: 46, iter: 37, training_loss: 1.53037e+00\n",
            "epoch: 47, iter: 37, training_loss: 1.56305e+00\n",
            "epoch: 48, iter: 37, training_loss: 1.57510e+00\n",
            "epoch: 49, iter: 37, training_loss: 1.58114e+00\n",
            "epoch: 50, iter: 37, training_loss: 1.62474e+00\n",
            "epoch: 51, iter: 37, training_loss: 1.82366e+00\n",
            "epoch: 52, iter: 37, training_loss: 1.64626e+00\n",
            "epoch: 53, iter: 37, training_loss: 1.87937e+00\n",
            "epoch: 54, iter: 37, training_loss: 1.86335e+00\n",
            "epoch: 55, iter: 37, training_loss: 2.13148e+00\n",
            "epoch: 56, iter: 37, training_loss: 2.12848e+00\n",
            "epoch: 57, iter: 37, training_loss: 1.73825e+00\n",
            "epoch: 58, iter: 37, training_loss: 1.85645e+00\n",
            "epoch: 59, iter: 37, training_loss: 1.96184e+00\n",
            "epoch: 60, iter: 37, training_loss: 1.67989e+00\n",
            "epoch: 61, iter: 37, training_loss: 1.84726e+00\n",
            "epoch: 62, iter: 37, training_loss: 2.06913e+00\n",
            "epoch: 63, iter: 37, training_loss: 2.16762e+00\n",
            "epoch: 64, iter: 37, training_loss: 2.10824e+00\n",
            "epoch: 65, iter: 37, training_loss: 1.88128e+00\n",
            "epoch: 66, iter: 37, training_loss: 2.03587e+00\n",
            "epoch: 67, iter: 37, training_loss: 1.99069e+00\n",
            "epoch: 68, iter: 37, training_loss: 2.00747e+00\n",
            "epoch: 69, iter: 37, training_loss: 1.84262e+00\n",
            "epoch: 70, iter: 37, training_loss: 2.81392e+00\n",
            "epoch: 71, iter: 37, training_loss: 2.15445e+00\n",
            "epoch: 72, iter: 37, training_loss: 2.18634e+00\n",
            "epoch: 73, iter: 37, training_loss: 2.15016e+00\n",
            "epoch: 74, iter: 37, training_loss: 2.06416e+00\n",
            "epoch: 75, iter: 37, training_loss: 2.12451e+00\n",
            "epoch: 76, iter: 37, training_loss: 2.06678e+00\n",
            "epoch: 77, iter: 37, training_loss: 2.20795e+00\n",
            "epoch: 78, iter: 37, training_loss: 2.18029e+00\n",
            "epoch: 79, iter: 37, training_loss: 2.44299e+00\n",
            "epoch: 80, iter: 37, training_loss: 2.18186e+00\n",
            "epoch: 81, iter: 37, training_loss: 2.53105e+00\n",
            "epoch: 82, iter: 37, training_loss: 2.35170e+00\n",
            "epoch: 83, iter: 37, training_loss: 2.55627e+00\n",
            "epoch: 84, iter: 37, training_loss: 2.35044e+00\n",
            "epoch: 85, iter: 37, training_loss: 2.66104e+00\n",
            "epoch: 86, iter: 37, training_loss: 2.27777e+00\n",
            "epoch: 87, iter: 37, training_loss: 2.44751e+00\n",
            "epoch: 88, iter: 37, training_loss: 2.13125e+00\n",
            "epoch: 89, iter: 37, training_loss: 2.72002e+00\n",
            "epoch: 90, iter: 37, training_loss: 2.56924e+00\n",
            "epoch: 91, iter: 37, training_loss: 2.47852e+00\n",
            "epoch: 92, iter: 37, training_loss: 2.69629e+00\n",
            "epoch: 93, iter: 37, training_loss: 3.46790e+00\n",
            "epoch: 94, iter: 37, training_loss: 3.34106e+00\n",
            "epoch: 95, iter: 37, training_loss: 2.85383e+00\n",
            "epoch: 96, iter: 37, training_loss: 2.75759e+00\n",
            "epoch: 97, iter: 37, training_loss: 2.46752e+00\n",
            "epoch: 98, iter: 37, training_loss: 2.94532e+00\n",
            "epoch: 99, iter: 37, training_loss: 3.05647e+00\n",
            "epoch: 100, iter: 37, training_loss: 2.92494e+00\n",
            "epoch: 101, iter: 37, training_loss: 2.80826e+00\n",
            "epoch: 102, iter: 37, training_loss: 2.81845e+00\n",
            "epoch: 103, iter: 37, training_loss: 2.77490e+00\n",
            "epoch: 104, iter: 37, training_loss: 2.56975e+00\n",
            "epoch: 105, iter: 37, training_loss: 3.26448e+00\n",
            "epoch: 106, iter: 37, training_loss: 3.15486e+00\n",
            "epoch: 107, iter: 37, training_loss: 3.09961e+00\n",
            "epoch: 108, iter: 37, training_loss: 3.15215e+00\n",
            "epoch: 109, iter: 37, training_loss: 3.33392e+00\n",
            "epoch: 110, iter: 37, training_loss: 3.40997e+00\n",
            "epoch: 111, iter: 37, training_loss: 3.36612e+00\n",
            "epoch: 112, iter: 37, training_loss: 3.23384e+00\n",
            "epoch: 113, iter: 37, training_loss: 3.63528e+00\n",
            "epoch: 114, iter: 37, training_loss: 3.03932e+00\n",
            "epoch: 115, iter: 37, training_loss: 2.81767e+00\n",
            "epoch: 116, iter: 37, training_loss: 2.52846e+00\n",
            "epoch: 117, iter: 37, training_loss: 3.21818e+00\n",
            "epoch: 118, iter: 37, training_loss: 3.26806e+00\n",
            "epoch: 119, iter: 37, training_loss: 3.16951e+00\n",
            "epoch: 120, iter: 37, training_loss: 2.79513e+00\n",
            "epoch: 121, iter: 37, training_loss: 2.83294e+00\n",
            "epoch: 122, iter: 37, training_loss: 2.80953e+00\n",
            "epoch: 123, iter: 37, training_loss: 3.03807e+00\n",
            "epoch: 124, iter: 37, training_loss: 2.88104e+00\n",
            "epoch: 125, iter: 37, training_loss: 2.62385e+00\n",
            "epoch: 126, iter: 37, training_loss: 2.74757e+00\n",
            "epoch: 127, iter: 37, training_loss: 2.42729e+00\n",
            "epoch: 128, iter: 37, training_loss: 2.72058e+00\n",
            "epoch: 129, iter: 37, training_loss: 3.28668e+00\n",
            "epoch: 130, iter: 37, training_loss: 3.34804e+00\n",
            "epoch: 131, iter: 37, training_loss: 3.44914e+00\n",
            "epoch: 132, iter: 37, training_loss: 3.45750e+00\n",
            "epoch: 133, iter: 37, training_loss: 3.02971e+00\n",
            "epoch: 134, iter: 37, training_loss: 3.77325e+00\n",
            "epoch: 135, iter: 37, training_loss: 2.97107e+00\n",
            "epoch: 136, iter: 37, training_loss: 2.82609e+00\n",
            "epoch: 137, iter: 37, training_loss: 2.40145e+00\n",
            "epoch: 138, iter: 37, training_loss: 2.64814e+00\n",
            "epoch: 139, iter: 37, training_loss: 2.60232e+00\n",
            "epoch: 140, iter: 37, training_loss: 2.64043e+00\n",
            "epoch: 141, iter: 37, training_loss: 2.72718e+00\n",
            "epoch: 142, iter: 37, training_loss: 2.08063e+00\n",
            "epoch: 143, iter: 37, training_loss: 1.99883e+00\n",
            "epoch: 144, iter: 37, training_loss: 2.07613e+00\n",
            "epoch: 145, iter: 37, training_loss: 2.39250e+00\n",
            "epoch: 146, iter: 37, training_loss: 1.91334e+00\n",
            "epoch: 147, iter: 37, training_loss: 1.75745e+00\n",
            "epoch: 148, iter: 37, training_loss: 1.83750e+00\n",
            "epoch: 149, iter: 37, training_loss: 1.65918e+00\n",
            "epoch: 150, iter: 37, training_loss: 1.85843e+00\n",
            "epoch: 151, iter: 37, training_loss: 1.70174e+00\n",
            "epoch: 152, iter: 37, training_loss: 1.59670e+00\n",
            "epoch: 153, iter: 37, training_loss: 1.71249e+00\n",
            "epoch: 154, iter: 37, training_loss: 1.47435e+00\n",
            "epoch: 155, iter: 37, training_loss: 1.40161e+00\n",
            "epoch: 156, iter: 37, training_loss: 1.37070e+00\n",
            "epoch: 157, iter: 37, training_loss: 1.12139e+00\n",
            "epoch: 158, iter: 37, training_loss: 1.16570e+00\n",
            "epoch: 159, iter: 37, training_loss: 1.09179e+00\n",
            "epoch: 160, iter: 37, training_loss: 1.19415e+00\n",
            "epoch: 161, iter: 37, training_loss: 1.23205e+00\n",
            "epoch: 162, iter: 37, training_loss: 1.03551e+00\n",
            "epoch: 163, iter: 37, training_loss: 1.11335e+00\n",
            "epoch: 164, iter: 37, training_loss: 1.01246e+00\n",
            "epoch: 165, iter: 37, training_loss: 9.58243e-01\n",
            "epoch: 166, iter: 37, training_loss: 9.52824e-01\n",
            "epoch: 167, iter: 37, training_loss: 8.86929e-01\n",
            "epoch: 168, iter: 37, training_loss: 9.09041e-01\n",
            "epoch: 169, iter: 37, training_loss: 8.73425e-01\n",
            "epoch: 170, iter: 37, training_loss: 8.96214e-01\n",
            "epoch: 171, iter: 37, training_loss: 9.05645e-01\n",
            "epoch: 172, iter: 37, training_loss: 1.09832e+00\n",
            "epoch: 173, iter: 37, training_loss: 9.10925e-01\n",
            "epoch: 174, iter: 37, training_loss: 9.60133e-01\n",
            "epoch: 175, iter: 37, training_loss: 9.38486e-01\n",
            "epoch: 176, iter: 37, training_loss: 9.71634e-01\n",
            "epoch: 177, iter: 37, training_loss: 8.12426e-01\n",
            "epoch: 178, iter: 37, training_loss: 9.11102e-01\n",
            "epoch: 179, iter: 37, training_loss: 8.38996e-01\n",
            "epoch: 180, iter: 37, training_loss: 8.23251e-01\n",
            "epoch: 181, iter: 37, training_loss: 7.55945e-01\n",
            "epoch: 182, iter: 37, training_loss: 8.01995e-01\n",
            "epoch: 183, iter: 37, training_loss: 7.86006e-01\n",
            "epoch: 184, iter: 37, training_loss: 7.64515e-01\n",
            "epoch: 185, iter: 37, training_loss: 7.26474e-01\n",
            "epoch: 186, iter: 37, training_loss: 7.47647e-01\n",
            "epoch: 187, iter: 37, training_loss: 7.11066e-01\n",
            "epoch: 188, iter: 37, training_loss: 7.54337e-01\n",
            "epoch: 189, iter: 37, training_loss: 7.35887e-01\n",
            "epoch: 190, iter: 37, training_loss: 6.89441e-01\n",
            "epoch: 191, iter: 37, training_loss: 7.41248e-01\n",
            "epoch: 192, iter: 37, training_loss: 8.87692e-01\n",
            "epoch: 193, iter: 37, training_loss: 7.22768e-01\n",
            "epoch: 194, iter: 37, training_loss: 6.66927e-01\n",
            "epoch: 195, iter: 37, training_loss: 7.29295e-01\n",
            "epoch: 196, iter: 37, training_loss: 7.00392e-01\n",
            "epoch: 197, iter: 37, training_loss: 6.38939e-01\n",
            "epoch: 198, iter: 37, training_loss: 6.65613e-01\n",
            "epoch: 199, iter: 37, training_loss: 6.46121e-01\n",
            "epoch: 200, iter: 37, training_loss: 7.36178e-01\n",
            "epoch: 201, iter: 37, training_loss: 6.46143e-01\n",
            "epoch: 202, iter: 37, training_loss: 6.74684e-01\n",
            "epoch: 203, iter: 37, training_loss: 7.49406e-01\n",
            "epoch: 204, iter: 37, training_loss: 7.22427e-01\n",
            "epoch: 205, iter: 37, training_loss: 8.40515e-01\n",
            "epoch: 206, iter: 37, training_loss: 9.25529e-01\n",
            "epoch: 207, iter: 37, training_loss: 6.22945e-01\n",
            "epoch: 208, iter: 37, training_loss: 6.94748e-01\n",
            "epoch: 209, iter: 37, training_loss: 6.57979e-01\n",
            "epoch: 210, iter: 37, training_loss: 7.28724e-01\n",
            "epoch: 211, iter: 37, training_loss: 5.97610e-01\n",
            "epoch: 212, iter: 37, training_loss: 7.20975e-01\n",
            "epoch: 213, iter: 37, training_loss: 5.99710e-01\n",
            "epoch: 214, iter: 37, training_loss: 5.59984e-01\n",
            "epoch: 215, iter: 37, training_loss: 5.91131e-01\n",
            "epoch: 216, iter: 37, training_loss: 5.82036e-01\n",
            "epoch: 217, iter: 37, training_loss: 5.85200e-01\n",
            "epoch: 218, iter: 37, training_loss: 6.18411e-01\n",
            "epoch: 219, iter: 37, training_loss: 5.35381e-01\n",
            "epoch: 220, iter: 37, training_loss: 4.87906e-01\n",
            "epoch: 221, iter: 37, training_loss: 4.74625e-01\n",
            "epoch: 222, iter: 37, training_loss: 4.62599e-01\n",
            "epoch: 223, iter: 37, training_loss: 3.88051e-01\n",
            "epoch: 224, iter: 37, training_loss: 5.29662e-01\n",
            "epoch: 225, iter: 37, training_loss: 4.44340e-01\n",
            "epoch: 226, iter: 37, training_loss: 4.65891e-01\n",
            "epoch: 227, iter: 37, training_loss: 4.89265e-01\n",
            "epoch: 228, iter: 37, training_loss: 4.09828e-01\n",
            "epoch: 229, iter: 37, training_loss: 3.94818e-01\n",
            "epoch: 230, iter: 37, training_loss: 3.65181e-01\n",
            "epoch: 231, iter: 37, training_loss: 4.62878e-01\n",
            "epoch: 232, iter: 37, training_loss: 4.36622e-01\n",
            "epoch: 233, iter: 37, training_loss: 3.91285e-01\n",
            "epoch: 234, iter: 37, training_loss: 4.63888e-01\n",
            "epoch: 235, iter: 37, training_loss: 3.87514e-01\n",
            "epoch: 236, iter: 37, training_loss: 3.44625e-01\n",
            "epoch: 237, iter: 37, training_loss: 4.45516e-01\n",
            "epoch: 238, iter: 37, training_loss: 4.05618e-01\n",
            "epoch: 239, iter: 37, training_loss: 3.92602e-01\n",
            "epoch: 240, iter: 37, training_loss: 3.43513e-01\n",
            "epoch: 241, iter: 37, training_loss: 3.33645e-01\n",
            "epoch: 242, iter: 37, training_loss: 3.35891e-01\n",
            "epoch: 243, iter: 37, training_loss: 3.52487e-01\n",
            "epoch: 244, iter: 37, training_loss: 3.82014e-01\n",
            "epoch: 245, iter: 37, training_loss: 3.60702e-01\n",
            "epoch: 246, iter: 37, training_loss: 3.91868e-01\n",
            "epoch: 247, iter: 37, training_loss: 4.28883e-01\n",
            "epoch: 248, iter: 37, training_loss: 3.35877e-01\n",
            "epoch: 249, iter: 37, training_loss: 3.27609e-01\n",
            "epoch: 250, iter: 37, training_loss: 3.73202e-01\n",
            "epoch: 251, iter: 37, training_loss: 3.73717e-01\n",
            "epoch: 252, iter: 37, training_loss: 3.74068e-01\n",
            "epoch: 253, iter: 37, training_loss: 3.50253e-01\n",
            "epoch: 254, iter: 37, training_loss: 3.17814e-01\n",
            "epoch: 255, iter: 37, training_loss: 3.99026e-01\n",
            "epoch: 256, iter: 37, training_loss: 3.50025e-01\n",
            "epoch: 257, iter: 37, training_loss: 3.50787e-01\n",
            "epoch: 258, iter: 37, training_loss: 4.18566e-01\n",
            "epoch: 259, iter: 37, training_loss: 3.85876e-01\n",
            "epoch: 260, iter: 37, training_loss: 3.62313e-01\n",
            "epoch: 261, iter: 37, training_loss: 4.27137e-01\n",
            "epoch: 262, iter: 37, training_loss: 4.03387e-01\n",
            "epoch: 263, iter: 37, training_loss: 3.47038e-01\n",
            "epoch: 264, iter: 37, training_loss: 3.22386e-01\n",
            "epoch: 265, iter: 37, training_loss: 4.24957e-01\n",
            "epoch: 266, iter: 37, training_loss: 4.14597e-01\n",
            "epoch: 267, iter: 37, training_loss: 3.31579e-01\n",
            "epoch: 268, iter: 37, training_loss: 4.18347e-01\n",
            "epoch: 269, iter: 37, training_loss: 4.57704e-01\n",
            "epoch: 270, iter: 37, training_loss: 3.57614e-01\n",
            "epoch: 271, iter: 37, training_loss: 3.55792e-01\n",
            "epoch: 272, iter: 37, training_loss: 3.44961e-01\n",
            "epoch: 273, iter: 37, training_loss: 3.88642e-01\n",
            "epoch: 274, iter: 37, training_loss: 3.70123e-01\n",
            "epoch: 275, iter: 37, training_loss: 3.41198e-01\n",
            "epoch: 276, iter: 37, training_loss: 3.19697e-01\n",
            "epoch: 277, iter: 37, training_loss: 3.40969e-01\n",
            "epoch: 278, iter: 37, training_loss: 3.25030e-01\n",
            "epoch: 279, iter: 37, training_loss: 3.70535e-01\n",
            "epoch: 280, iter: 37, training_loss: 3.46906e-01\n",
            "epoch: 281, iter: 37, training_loss: 3.10081e-01\n",
            "epoch: 282, iter: 37, training_loss: 4.57767e-01\n",
            "epoch: 283, iter: 37, training_loss: 3.39546e-01\n",
            "epoch: 284, iter: 37, training_loss: 3.56341e-01\n",
            "epoch: 285, iter: 37, training_loss: 3.96382e-01\n",
            "epoch: 286, iter: 37, training_loss: 3.50323e-01\n",
            "epoch: 287, iter: 37, training_loss: 3.33970e-01\n",
            "epoch: 288, iter: 37, training_loss: 3.86582e-01\n",
            "epoch: 289, iter: 37, training_loss: 3.43894e-01\n",
            "epoch: 290, iter: 37, training_loss: 3.56179e-01\n",
            "epoch: 291, iter: 37, training_loss: 3.58743e-01\n",
            "epoch: 292, iter: 37, training_loss: 3.33429e-01\n",
            "epoch: 293, iter: 37, training_loss: 2.99448e-01\n",
            "epoch: 294, iter: 37, training_loss: 4.24960e-01\n",
            "epoch: 295, iter: 37, training_loss: 3.68173e-01\n",
            "epoch: 296, iter: 37, training_loss: 3.53700e-01\n",
            "epoch: 297, iter: 37, training_loss: 3.01247e-01\n",
            "epoch: 298, iter: 37, training_loss: 3.69475e-01\n",
            "epoch: 299, iter: 37, training_loss: 3.20160e-01\n",
            "epoch: 300, iter: 37, training_loss: 2.71115e-01\n",
            "epoch: 301, iter: 37, training_loss: 4.32433e-01\n",
            "epoch: 302, iter: 37, training_loss: 3.33494e-01\n",
            "epoch: 303, iter: 37, training_loss: 2.80918e-01\n",
            "epoch: 304, iter: 37, training_loss: 4.01941e-01\n",
            "epoch: 305, iter: 37, training_loss: 3.74599e-01\n",
            "epoch: 306, iter: 37, training_loss: 2.89767e-01\n",
            "epoch: 307, iter: 37, training_loss: 4.05357e-01\n",
            "epoch: 308, iter: 37, training_loss: 3.00368e-01\n",
            "epoch: 309, iter: 37, training_loss: 2.94855e-01\n",
            "epoch: 310, iter: 37, training_loss: 2.62779e-01\n",
            "epoch: 311, iter: 37, training_loss: 2.68776e-01\n",
            "epoch: 312, iter: 37, training_loss: 2.71999e-01\n",
            "epoch: 313, iter: 37, training_loss: 3.29139e-01\n",
            "epoch: 314, iter: 37, training_loss: 3.57156e-01\n",
            "epoch: 315, iter: 37, training_loss: 3.10392e-01\n",
            "epoch: 316, iter: 37, training_loss: 3.44565e-01\n",
            "epoch: 317, iter: 37, training_loss: 2.79835e-01\n",
            "epoch: 318, iter: 37, training_loss: 3.35878e-01\n",
            "epoch: 319, iter: 37, training_loss: 3.39880e-01\n",
            "epoch: 320, iter: 37, training_loss: 3.07263e-01\n",
            "epoch: 321, iter: 37, training_loss: 3.42848e-01\n",
            "epoch: 322, iter: 37, training_loss: 2.86876e-01\n",
            "epoch: 323, iter: 37, training_loss: 3.49834e-01\n",
            "epoch: 324, iter: 37, training_loss: 3.48514e-01\n",
            "epoch: 325, iter: 37, training_loss: 2.85523e-01\n",
            "epoch: 326, iter: 37, training_loss: 3.09644e-01\n",
            "epoch: 327, iter: 37, training_loss: 3.08583e-01\n",
            "epoch: 328, iter: 37, training_loss: 2.71947e-01\n",
            "epoch: 329, iter: 37, training_loss: 3.32760e-01\n",
            "epoch: 330, iter: 37, training_loss: 3.39856e-01\n",
            "epoch: 331, iter: 37, training_loss: 3.05036e-01\n",
            "epoch: 332, iter: 37, training_loss: 2.67209e-01\n",
            "epoch: 333, iter: 37, training_loss: 3.11922e-01\n",
            "epoch: 334, iter: 37, training_loss: 3.02752e-01\n",
            "epoch: 335, iter: 37, training_loss: 3.05690e-01\n",
            "epoch: 336, iter: 37, training_loss: 2.77390e-01\n",
            "epoch: 337, iter: 37, training_loss: 2.86018e-01\n",
            "epoch: 338, iter: 37, training_loss: 3.63167e-01\n",
            "epoch: 339, iter: 37, training_loss: 3.34787e-01\n",
            "epoch: 340, iter: 37, training_loss: 2.79133e-01\n",
            "epoch: 341, iter: 37, training_loss: 2.54399e-01\n",
            "epoch: 342, iter: 37, training_loss: 3.37541e-01\n",
            "epoch: 343, iter: 37, training_loss: 2.93660e-01\n",
            "epoch: 344, iter: 37, training_loss: 3.19135e-01\n",
            "epoch: 345, iter: 37, training_loss: 2.67360e-01\n",
            "epoch: 346, iter: 37, training_loss: 3.33257e-01\n",
            "epoch: 347, iter: 37, training_loss: 3.50841e-01\n",
            "epoch: 348, iter: 37, training_loss: 3.31622e-01\n",
            "epoch: 349, iter: 37, training_loss: 2.84547e-01\n",
            "epoch: 350, iter: 37, training_loss: 2.47800e-01\n",
            "epoch: 351, iter: 37, training_loss: 3.19334e-01\n",
            "epoch: 352, iter: 37, training_loss: 2.90814e-01\n",
            "epoch: 353, iter: 37, training_loss: 2.34861e-01\n",
            "epoch: 354, iter: 37, training_loss: 3.54504e-01\n",
            "epoch: 355, iter: 37, training_loss: 3.00567e-01\n",
            "epoch: 356, iter: 37, training_loss: 3.02279e-01\n",
            "epoch: 357, iter: 37, training_loss: 2.92779e-01\n",
            "epoch: 358, iter: 37, training_loss: 2.49608e-01\n",
            "epoch: 359, iter: 37, training_loss: 2.87451e-01\n",
            "epoch: 360, iter: 37, training_loss: 2.95964e-01\n",
            "epoch: 361, iter: 37, training_loss: 2.54193e-01\n",
            "epoch: 362, iter: 37, training_loss: 2.57961e-01\n",
            "epoch: 363, iter: 37, training_loss: 3.08344e-01\n",
            "epoch: 364, iter: 37, training_loss: 2.79310e-01\n",
            "epoch: 365, iter: 37, training_loss: 3.44114e-01\n",
            "epoch: 366, iter: 37, training_loss: 3.43551e-01\n",
            "epoch: 367, iter: 37, training_loss: 2.74695e-01\n",
            "epoch: 368, iter: 37, training_loss: 2.63148e-01\n",
            "epoch: 369, iter: 37, training_loss: 3.32141e-01\n",
            "epoch: 370, iter: 37, training_loss: 3.41117e-01\n",
            "epoch: 371, iter: 37, training_loss: 3.23032e-01\n",
            "epoch: 372, iter: 37, training_loss: 3.24682e-01\n",
            "epoch: 373, iter: 37, training_loss: 3.17977e-01\n",
            "epoch: 374, iter: 37, training_loss: 2.79999e-01\n",
            "epoch: 375, iter: 37, training_loss: 2.89942e-01\n",
            "epoch: 376, iter: 37, training_loss: 2.46872e-01\n",
            "epoch: 377, iter: 37, training_loss: 2.68994e-01\n",
            "epoch: 378, iter: 37, training_loss: 2.93102e-01\n",
            "epoch: 379, iter: 37, training_loss: 2.46601e-01\n",
            "epoch: 380, iter: 37, training_loss: 2.56077e-01\n",
            "epoch: 381, iter: 37, training_loss: 3.11555e-01\n",
            "epoch: 382, iter: 37, training_loss: 2.63483e-01\n",
            "epoch: 383, iter: 37, training_loss: 2.27167e-01\n",
            "epoch: 384, iter: 37, training_loss: 2.46699e-01\n",
            "epoch: 385, iter: 37, training_loss: 2.98961e-01\n",
            "epoch: 386, iter: 37, training_loss: 3.10883e-01\n",
            "epoch: 387, iter: 37, training_loss: 3.11081e-01\n",
            "epoch: 388, iter: 37, training_loss: 2.37339e-01\n",
            "epoch: 389, iter: 37, training_loss: 2.72362e-01\n",
            "epoch: 390, iter: 37, training_loss: 2.94730e-01\n",
            "epoch: 391, iter: 37, training_loss: 2.75113e-01\n",
            "epoch: 392, iter: 37, training_loss: 2.92969e-01\n",
            "epoch: 393, iter: 37, training_loss: 3.37396e-01\n",
            "epoch: 394, iter: 37, training_loss: 2.84203e-01\n",
            "epoch: 395, iter: 37, training_loss: 2.86949e-01\n",
            "epoch: 396, iter: 37, training_loss: 2.64913e-01\n",
            "epoch: 397, iter: 37, training_loss: 2.54840e-01\n",
            "epoch: 398, iter: 37, training_loss: 2.41606e-01\n",
            "epoch: 399, iter: 37, training_loss: 2.77956e-01\n",
            "epoch: 400, iter: 37, training_loss: 2.53340e-01\n",
            "epoch: 401, iter: 37, training_loss: 2.54406e-01\n",
            "epoch: 402, iter: 37, training_loss: 2.49431e-01\n",
            "epoch: 403, iter: 37, training_loss: 2.37927e-01\n",
            "epoch: 404, iter: 37, training_loss: 2.67460e-01\n",
            "epoch: 405, iter: 37, training_loss: 2.37061e-01\n",
            "epoch: 406, iter: 37, training_loss: 2.85585e-01\n",
            "epoch: 407, iter: 37, training_loss: 2.47260e-01\n",
            "epoch: 408, iter: 37, training_loss: 2.20190e-01\n",
            "epoch: 409, iter: 37, training_loss: 2.33516e-01\n",
            "epoch: 410, iter: 37, training_loss: 2.29314e-01\n",
            "epoch: 411, iter: 37, training_loss: 3.17786e-01\n",
            "epoch: 412, iter: 37, training_loss: 2.27426e-01\n",
            "epoch: 413, iter: 37, training_loss: 2.08969e-01\n",
            "epoch: 414, iter: 37, training_loss: 2.57170e-01\n",
            "epoch: 415, iter: 37, training_loss: 2.97033e-01\n",
            "epoch: 416, iter: 37, training_loss: 2.51011e-01\n",
            "epoch: 417, iter: 37, training_loss: 2.48641e-01\n",
            "epoch: 418, iter: 37, training_loss: 2.51447e-01\n",
            "epoch: 419, iter: 37, training_loss: 2.20947e-01\n",
            "epoch: 420, iter: 37, training_loss: 2.40072e-01\n",
            "epoch: 421, iter: 37, training_loss: 2.44868e-01\n",
            "epoch: 422, iter: 37, training_loss: 2.59913e-01\n",
            "epoch: 423, iter: 37, training_loss: 2.66870e-01\n",
            "epoch: 424, iter: 37, training_loss: 2.39358e-01\n",
            "epoch: 425, iter: 37, training_loss: 2.41597e-01\n",
            "epoch: 426, iter: 37, training_loss: 2.66000e-01\n",
            "epoch: 427, iter: 37, training_loss: 2.79673e-01\n",
            "epoch: 428, iter: 37, training_loss: 2.55380e-01\n",
            "epoch: 429, iter: 37, training_loss: 2.34188e-01\n",
            "epoch: 430, iter: 37, training_loss: 2.27227e-01\n",
            "epoch: 431, iter: 37, training_loss: 2.97950e-01\n",
            "epoch: 432, iter: 37, training_loss: 2.71132e-01\n",
            "epoch: 433, iter: 37, training_loss: 2.49923e-01\n",
            "epoch: 434, iter: 37, training_loss: 2.37634e-01\n",
            "epoch: 435, iter: 37, training_loss: 2.53913e-01\n",
            "epoch: 436, iter: 37, training_loss: 2.27912e-01\n",
            "epoch: 437, iter: 37, training_loss: 2.16641e-01\n",
            "epoch: 438, iter: 37, training_loss: 2.54286e-01\n",
            "epoch: 439, iter: 37, training_loss: 3.70457e-01\n",
            "epoch: 440, iter: 37, training_loss: 2.48370e-01\n",
            "epoch: 441, iter: 37, training_loss: 2.35975e-01\n",
            "epoch: 442, iter: 37, training_loss: 2.74785e-01\n",
            "epoch: 443, iter: 37, training_loss: 2.74872e-01\n",
            "epoch: 444, iter: 37, training_loss: 2.36111e-01\n",
            "epoch: 445, iter: 37, training_loss: 2.38094e-01\n",
            "epoch: 446, iter: 37, training_loss: 2.53783e-01\n",
            "epoch: 447, iter: 37, training_loss: 2.62972e-01\n",
            "epoch: 448, iter: 37, training_loss: 2.42261e-01\n",
            "epoch: 449, iter: 37, training_loss: 2.75019e-01\n",
            "epoch: 450, iter: 37, training_loss: 2.38050e-01\n",
            "epoch: 451, iter: 37, training_loss: 2.45292e-01\n",
            "epoch: 452, iter: 37, training_loss: 2.55045e-01\n",
            "epoch: 453, iter: 37, training_loss: 2.42213e-01\n",
            "epoch: 454, iter: 37, training_loss: 2.08378e-01\n",
            "epoch: 455, iter: 37, training_loss: 2.49989e-01\n",
            "epoch: 456, iter: 37, training_loss: 2.28890e-01\n",
            "epoch: 457, iter: 37, training_loss: 2.11182e-01\n",
            "epoch: 458, iter: 37, training_loss: 2.36570e-01\n",
            "epoch: 459, iter: 37, training_loss: 3.08229e-01\n",
            "epoch: 460, iter: 37, training_loss: 2.52332e-01\n",
            "epoch: 461, iter: 37, training_loss: 2.16355e-01\n",
            "epoch: 462, iter: 37, training_loss: 2.57469e-01\n",
            "epoch: 463, iter: 37, training_loss: 2.42840e-01\n",
            "epoch: 464, iter: 37, training_loss: 2.49250e-01\n",
            "epoch: 465, iter: 37, training_loss: 2.26166e-01\n",
            "epoch: 466, iter: 37, training_loss: 2.51269e-01\n",
            "epoch: 467, iter: 37, training_loss: 2.09418e-01\n",
            "epoch: 468, iter: 37, training_loss: 2.22374e-01\n",
            "epoch: 469, iter: 37, training_loss: 2.04292e-01\n",
            "epoch: 470, iter: 37, training_loss: 2.01704e-01\n",
            "epoch: 471, iter: 37, training_loss: 2.01760e-01\n",
            "epoch: 472, iter: 37, training_loss: 1.95258e-01\n",
            "epoch: 473, iter: 37, training_loss: 2.32536e-01\n",
            "epoch: 474, iter: 37, training_loss: 3.40733e-01\n",
            "epoch: 475, iter: 37, training_loss: 2.46376e-01\n",
            "epoch: 476, iter: 37, training_loss: 2.38006e-01\n",
            "epoch: 477, iter: 37, training_loss: 2.06837e-01\n",
            "epoch: 478, iter: 37, training_loss: 2.35985e-01\n",
            "epoch: 479, iter: 37, training_loss: 2.28639e-01\n",
            "epoch: 480, iter: 37, training_loss: 2.13122e-01\n",
            "epoch: 481, iter: 37, training_loss: 1.92817e-01\n",
            "epoch: 482, iter: 37, training_loss: 2.47287e-01\n",
            "epoch: 483, iter: 37, training_loss: 2.48185e-01\n",
            "epoch: 484, iter: 37, training_loss: 1.88643e-01\n",
            "epoch: 485, iter: 37, training_loss: 2.31530e-01\n",
            "epoch: 486, iter: 37, training_loss: 2.32574e-01\n",
            "epoch: 487, iter: 37, training_loss: 2.07745e-01\n",
            "epoch: 488, iter: 37, training_loss: 2.94453e-01\n",
            "epoch: 489, iter: 37, training_loss: 2.50990e-01\n",
            "epoch: 490, iter: 37, training_loss: 2.21922e-01\n",
            "epoch: 491, iter: 37, training_loss: 1.91531e-01\n",
            "epoch: 492, iter: 37, training_loss: 2.46356e-01\n",
            "epoch: 493, iter: 37, training_loss: 2.16457e-01\n",
            "epoch: 494, iter: 37, training_loss: 2.26683e-01\n",
            "epoch: 495, iter: 37, training_loss: 2.43147e-01\n",
            "epoch: 496, iter: 37, training_loss: 2.28294e-01\n",
            "epoch: 497, iter: 37, training_loss: 2.10261e-01\n",
            "epoch: 498, iter: 37, training_loss: 1.96707e-01\n",
            "epoch: 499, iter: 37, training_loss: 2.01482e-01\n",
            "epoch: 500, iter: 37, training_loss: 2.53938e-01\n",
            "epoch: 501, iter: 37, training_loss: 2.00423e-01\n",
            "epoch: 502, iter: 37, training_loss: 2.21917e-01\n",
            "epoch: 503, iter: 37, training_loss: 2.06550e-01\n",
            "epoch: 504, iter: 37, training_loss: 2.20595e-01\n",
            "epoch: 505, iter: 37, training_loss: 2.35841e-01\n",
            "epoch: 506, iter: 37, training_loss: 2.01609e-01\n",
            "epoch: 507, iter: 37, training_loss: 2.05151e-01\n",
            "epoch: 508, iter: 37, training_loss: 2.36276e-01\n",
            "epoch: 509, iter: 37, training_loss: 2.19981e-01\n",
            "epoch: 510, iter: 37, training_loss: 2.56874e-01\n",
            "epoch: 511, iter: 37, training_loss: 2.05888e-01\n",
            "epoch: 512, iter: 37, training_loss: 1.99811e-01\n",
            "epoch: 513, iter: 37, training_loss: 2.88133e-01\n",
            "epoch: 514, iter: 37, training_loss: 2.96207e-01\n",
            "epoch: 515, iter: 37, training_loss: 2.30754e-01\n",
            "epoch: 516, iter: 37, training_loss: 2.72089e-01\n",
            "epoch: 517, iter: 37, training_loss: 2.10513e-01\n",
            "epoch: 518, iter: 37, training_loss: 1.91966e-01\n",
            "epoch: 519, iter: 37, training_loss: 2.37154e-01\n",
            "epoch: 520, iter: 37, training_loss: 2.12891e-01\n",
            "epoch: 521, iter: 37, training_loss: 2.14659e-01\n",
            "epoch: 522, iter: 37, training_loss: 1.97697e-01\n",
            "epoch: 523, iter: 37, training_loss: 2.41464e-01\n",
            "epoch: 524, iter: 37, training_loss: 2.19226e-01\n",
            "epoch: 525, iter: 37, training_loss: 1.89043e-01\n",
            "epoch: 526, iter: 37, training_loss: 2.76130e-01\n",
            "epoch: 527, iter: 37, training_loss: 2.25923e-01\n",
            "epoch: 528, iter: 37, training_loss: 2.44776e-01\n",
            "epoch: 529, iter: 37, training_loss: 1.99031e-01\n",
            "epoch: 530, iter: 37, training_loss: 2.06945e-01\n",
            "epoch: 531, iter: 37, training_loss: 2.42685e-01\n",
            "epoch: 532, iter: 37, training_loss: 2.45223e-01\n",
            "epoch: 533, iter: 37, training_loss: 2.13425e-01\n",
            "epoch: 534, iter: 37, training_loss: 2.27054e-01\n",
            "epoch: 535, iter: 37, training_loss: 2.69994e-01\n",
            "epoch: 536, iter: 37, training_loss: 2.30404e-01\n",
            "epoch: 537, iter: 37, training_loss: 2.03011e-01\n",
            "epoch: 538, iter: 37, training_loss: 2.46334e-01\n",
            "epoch: 539, iter: 37, training_loss: 2.04988e-01\n",
            "epoch: 540, iter: 37, training_loss: 2.00245e-01\n",
            "epoch: 541, iter: 37, training_loss: 2.10019e-01\n",
            "epoch: 542, iter: 37, training_loss: 1.98276e-01\n",
            "epoch: 543, iter: 37, training_loss: 1.93061e-01\n",
            "epoch: 544, iter: 37, training_loss: 1.88118e-01\n",
            "epoch: 545, iter: 37, training_loss: 2.01374e-01\n",
            "epoch: 546, iter: 37, training_loss: 2.22707e-01\n",
            "epoch: 547, iter: 37, training_loss: 2.10331e-01\n",
            "epoch: 548, iter: 37, training_loss: 1.97848e-01\n",
            "epoch: 549, iter: 37, training_loss: 1.85457e-01\n",
            "epoch: 550, iter: 37, training_loss: 1.79025e-01\n",
            "epoch: 551, iter: 37, training_loss: 2.17436e-01\n",
            "epoch: 552, iter: 37, training_loss: 2.07173e-01\n",
            "epoch: 553, iter: 37, training_loss: 2.22111e-01\n",
            "epoch: 554, iter: 37, training_loss: 2.12236e-01\n",
            "epoch: 555, iter: 37, training_loss: 2.36573e-01\n",
            "epoch: 556, iter: 37, training_loss: 1.82653e-01\n",
            "epoch: 557, iter: 37, training_loss: 2.05835e-01\n",
            "epoch: 558, iter: 37, training_loss: 1.83436e-01\n",
            "epoch: 559, iter: 37, training_loss: 2.72983e-01\n",
            "epoch: 560, iter: 37, training_loss: 1.99252e-01\n",
            "epoch: 561, iter: 37, training_loss: 1.87297e-01\n",
            "epoch: 562, iter: 37, training_loss: 2.16076e-01\n",
            "epoch: 563, iter: 37, training_loss: 1.85494e-01\n",
            "epoch: 564, iter: 37, training_loss: 1.82596e-01\n",
            "epoch: 565, iter: 37, training_loss: 2.17044e-01\n",
            "epoch: 566, iter: 37, training_loss: 2.70986e-01\n",
            "epoch: 567, iter: 37, training_loss: 1.93927e-01\n",
            "epoch: 568, iter: 37, training_loss: 2.55390e-01\n",
            "epoch: 569, iter: 37, training_loss: 2.11983e-01\n",
            "epoch: 570, iter: 37, training_loss: 2.32595e-01\n",
            "epoch: 571, iter: 37, training_loss: 2.02869e-01\n",
            "epoch: 572, iter: 37, training_loss: 1.78357e-01\n",
            "epoch: 573, iter: 37, training_loss: 1.87802e-01\n",
            "epoch: 574, iter: 37, training_loss: 2.11087e-01\n",
            "epoch: 575, iter: 37, training_loss: 2.54605e-01\n",
            "epoch: 576, iter: 37, training_loss: 2.37138e-01\n",
            "epoch: 577, iter: 37, training_loss: 1.98425e-01\n",
            "epoch: 578, iter: 37, training_loss: 2.34403e-01\n",
            "epoch: 579, iter: 37, training_loss: 2.12276e-01\n",
            "epoch: 580, iter: 37, training_loss: 1.97112e-01\n",
            "epoch: 581, iter: 37, training_loss: 2.05781e-01\n",
            "epoch: 582, iter: 37, training_loss: 2.37209e-01\n",
            "epoch: 583, iter: 37, training_loss: 2.31421e-01\n",
            "epoch: 584, iter: 37, training_loss: 1.86953e-01\n",
            "epoch: 585, iter: 37, training_loss: 2.00912e-01\n",
            "epoch: 586, iter: 37, training_loss: 1.95390e-01\n",
            "epoch: 587, iter: 37, training_loss: 2.75488e-01\n",
            "epoch: 588, iter: 37, training_loss: 2.24071e-01\n",
            "epoch: 589, iter: 37, training_loss: 1.98638e-01\n",
            "epoch: 590, iter: 37, training_loss: 1.75704e-01\n",
            "epoch: 591, iter: 37, training_loss: 2.20282e-01\n",
            "epoch: 592, iter: 37, training_loss: 2.29467e-01\n",
            "epoch: 593, iter: 37, training_loss: 1.77288e-01\n",
            "epoch: 594, iter: 37, training_loss: 1.83527e-01\n",
            "epoch: 595, iter: 37, training_loss: 2.08870e-01\n",
            "epoch: 596, iter: 37, training_loss: 1.87673e-01\n",
            "epoch: 597, iter: 37, training_loss: 2.03866e-01\n",
            "epoch: 598, iter: 37, training_loss: 1.95513e-01\n",
            "epoch: 599, iter: 37, training_loss: 1.93472e-01\n",
            "epoch: 600, iter: 37, training_loss: 1.73343e-01\n",
            "epoch: 601, iter: 37, training_loss: 1.89448e-01\n",
            "epoch: 602, iter: 37, training_loss: 2.08698e-01\n",
            "epoch: 603, iter: 37, training_loss: 2.01082e-01\n",
            "epoch: 604, iter: 37, training_loss: 2.16155e-01\n",
            "epoch: 605, iter: 37, training_loss: 2.18421e-01\n",
            "epoch: 606, iter: 37, training_loss: 1.99930e-01\n",
            "epoch: 607, iter: 37, training_loss: 1.95498e-01\n",
            "epoch: 608, iter: 37, training_loss: 1.78232e-01\n",
            "epoch: 609, iter: 37, training_loss: 1.78259e-01\n",
            "epoch: 610, iter: 37, training_loss: 1.84400e-01\n",
            "epoch: 611, iter: 37, training_loss: 1.81456e-01\n",
            "epoch: 612, iter: 37, training_loss: 1.88509e-01\n",
            "epoch: 613, iter: 37, training_loss: 1.63530e-01\n",
            "epoch: 614, iter: 37, training_loss: 2.22225e-01\n",
            "epoch: 615, iter: 37, training_loss: 1.89256e-01\n",
            "epoch: 616, iter: 37, training_loss: 1.70888e-01\n",
            "epoch: 617, iter: 37, training_loss: 1.63833e-01\n",
            "epoch: 618, iter: 37, training_loss: 2.23675e-01\n",
            "epoch: 619, iter: 37, training_loss: 2.32774e-01\n",
            "epoch: 620, iter: 37, training_loss: 2.14963e-01\n",
            "epoch: 621, iter: 37, training_loss: 1.86039e-01\n",
            "epoch: 622, iter: 37, training_loss: 2.05501e-01\n",
            "epoch: 623, iter: 37, training_loss: 1.72128e-01\n",
            "epoch: 624, iter: 37, training_loss: 1.87532e-01\n",
            "epoch: 625, iter: 37, training_loss: 2.69468e-01\n",
            "epoch: 626, iter: 37, training_loss: 1.96980e-01\n",
            "epoch: 627, iter: 37, training_loss: 2.21344e-01\n",
            "epoch: 628, iter: 37, training_loss: 1.79285e-01\n",
            "epoch: 629, iter: 37, training_loss: 2.16519e-01\n",
            "epoch: 630, iter: 37, training_loss: 2.18747e-01\n",
            "epoch: 631, iter: 37, training_loss: 1.92668e-01\n",
            "epoch: 632, iter: 37, training_loss: 1.92864e-01\n",
            "epoch: 633, iter: 37, training_loss: 1.70746e-01\n",
            "epoch: 634, iter: 37, training_loss: 1.97386e-01\n",
            "epoch: 635, iter: 37, training_loss: 1.78790e-01\n",
            "epoch: 636, iter: 37, training_loss: 1.96602e-01\n",
            "epoch: 637, iter: 37, training_loss: 1.82302e-01\n",
            "epoch: 638, iter: 37, training_loss: 2.14276e-01\n",
            "epoch: 639, iter: 37, training_loss: 1.89285e-01\n",
            "epoch: 640, iter: 37, training_loss: 1.70035e-01\n",
            "epoch: 641, iter: 37, training_loss: 1.79325e-01\n",
            "epoch: 642, iter: 37, training_loss: 1.72562e-01\n",
            "epoch: 643, iter: 37, training_loss: 1.69619e-01\n",
            "epoch: 644, iter: 37, training_loss: 1.94188e-01\n",
            "epoch: 645, iter: 37, training_loss: 2.00759e-01\n",
            "epoch: 646, iter: 37, training_loss: 1.82874e-01\n",
            "epoch: 647, iter: 37, training_loss: 1.85145e-01\n",
            "epoch: 648, iter: 37, training_loss: 2.01382e-01\n",
            "epoch: 649, iter: 37, training_loss: 1.97820e-01\n",
            "epoch: 650, iter: 37, training_loss: 1.73021e-01\n",
            "epoch: 651, iter: 37, training_loss: 1.67902e-01\n",
            "epoch: 652, iter: 37, training_loss: 1.96992e-01\n",
            "epoch: 653, iter: 37, training_loss: 1.84036e-01\n",
            "epoch: 654, iter: 37, training_loss: 1.74369e-01\n",
            "epoch: 655, iter: 37, training_loss: 1.63264e-01\n",
            "epoch: 656, iter: 37, training_loss: 1.62138e-01\n",
            "epoch: 657, iter: 37, training_loss: 2.07196e-01\n",
            "epoch: 658, iter: 37, training_loss: 2.01273e-01\n",
            "epoch: 659, iter: 37, training_loss: 1.90649e-01\n",
            "epoch: 660, iter: 37, training_loss: 1.71991e-01\n",
            "epoch: 661, iter: 37, training_loss: 2.04293e-01\n",
            "epoch: 662, iter: 37, training_loss: 1.81407e-01\n",
            "epoch: 663, iter: 37, training_loss: 1.92527e-01\n",
            "epoch: 664, iter: 37, training_loss: 1.78989e-01\n",
            "epoch: 665, iter: 37, training_loss: 1.93927e-01\n",
            "epoch: 666, iter: 37, training_loss: 1.78202e-01\n",
            "epoch: 667, iter: 37, training_loss: 1.70759e-01\n",
            "epoch: 668, iter: 37, training_loss: 1.59023e-01\n",
            "epoch: 669, iter: 37, training_loss: 2.04788e-01\n",
            "epoch: 670, iter: 37, training_loss: 2.09742e-01\n",
            "epoch: 671, iter: 37, training_loss: 1.72549e-01\n",
            "epoch: 672, iter: 37, training_loss: 1.73251e-01\n",
            "epoch: 673, iter: 37, training_loss: 1.76078e-01\n",
            "epoch: 674, iter: 37, training_loss: 2.00791e-01\n",
            "epoch: 675, iter: 37, training_loss: 1.66266e-01\n",
            "epoch: 676, iter: 37, training_loss: 1.59512e-01\n",
            "epoch: 677, iter: 37, training_loss: 1.54802e-01\n",
            "epoch: 678, iter: 37, training_loss: 1.56646e-01\n",
            "epoch: 679, iter: 37, training_loss: 2.25396e-01\n",
            "epoch: 680, iter: 37, training_loss: 3.13603e-01\n",
            "epoch: 681, iter: 37, training_loss: 1.76956e-01\n",
            "epoch: 682, iter: 37, training_loss: 2.05172e-01\n",
            "epoch: 683, iter: 37, training_loss: 1.75545e-01\n",
            "epoch: 684, iter: 37, training_loss: 2.08188e-01\n",
            "epoch: 685, iter: 37, training_loss: 1.63378e-01\n",
            "epoch: 686, iter: 37, training_loss: 1.69298e-01\n",
            "epoch: 687, iter: 37, training_loss: 1.55179e-01\n",
            "epoch: 688, iter: 37, training_loss: 1.57661e-01\n",
            "epoch: 689, iter: 37, training_loss: 1.85667e-01\n",
            "epoch: 690, iter: 37, training_loss: 1.98526e-01\n",
            "epoch: 691, iter: 37, training_loss: 1.80527e-01\n",
            "epoch: 692, iter: 37, training_loss: 2.19906e-01\n",
            "epoch: 693, iter: 37, training_loss: 1.74051e-01\n",
            "epoch: 694, iter: 37, training_loss: 1.90347e-01\n",
            "epoch: 695, iter: 37, training_loss: 1.87081e-01\n",
            "epoch: 696, iter: 37, training_loss: 1.88212e-01\n",
            "epoch: 697, iter: 37, training_loss: 1.65744e-01\n",
            "epoch: 698, iter: 37, training_loss: 1.55568e-01\n",
            "epoch: 699, iter: 37, training_loss: 1.63606e-01\n",
            "epoch: 700, iter: 37, training_loss: 1.90627e-01\n",
            "epoch: 701, iter: 37, training_loss: 1.75001e-01\n",
            "epoch: 702, iter: 37, training_loss: 1.58240e-01\n",
            "epoch: 703, iter: 37, training_loss: 1.62466e-01\n",
            "epoch: 704, iter: 37, training_loss: 1.80955e-01\n",
            "epoch: 705, iter: 37, training_loss: 1.76623e-01\n",
            "epoch: 706, iter: 37, training_loss: 1.75515e-01\n",
            "epoch: 707, iter: 37, training_loss: 1.89515e-01\n",
            "epoch: 708, iter: 37, training_loss: 1.86170e-01\n",
            "epoch: 709, iter: 37, training_loss: 1.86913e-01\n",
            "epoch: 710, iter: 37, training_loss: 1.72851e-01\n",
            "epoch: 711, iter: 37, training_loss: 1.51904e-01\n",
            "epoch: 712, iter: 37, training_loss: 2.21507e-01\n",
            "epoch: 713, iter: 37, training_loss: 1.57313e-01\n",
            "epoch: 714, iter: 37, training_loss: 1.54825e-01\n",
            "epoch: 715, iter: 37, training_loss: 2.00483e-01\n",
            "epoch: 716, iter: 37, training_loss: 2.02055e-01\n",
            "epoch: 717, iter: 37, training_loss: 1.59360e-01\n",
            "epoch: 718, iter: 37, training_loss: 1.86472e-01\n",
            "epoch: 719, iter: 37, training_loss: 1.83470e-01\n",
            "epoch: 720, iter: 37, training_loss: 1.86447e-01\n",
            "epoch: 721, iter: 37, training_loss: 1.58933e-01\n",
            "epoch: 722, iter: 37, training_loss: 1.61090e-01\n",
            "epoch: 723, iter: 37, training_loss: 1.96272e-01\n",
            "epoch: 724, iter: 37, training_loss: 1.76226e-01\n",
            "epoch: 725, iter: 37, training_loss: 2.04616e-01\n",
            "epoch: 726, iter: 37, training_loss: 1.58818e-01\n",
            "epoch: 727, iter: 37, training_loss: 1.45648e-01\n",
            "epoch: 728, iter: 37, training_loss: 1.56380e-01\n",
            "epoch: 729, iter: 37, training_loss: 1.98054e-01\n",
            "epoch: 730, iter: 37, training_loss: 1.74063e-01\n",
            "epoch: 731, iter: 37, training_loss: 2.21401e-01\n",
            "epoch: 732, iter: 37, training_loss: 2.00182e-01\n",
            "epoch: 733, iter: 37, training_loss: 1.60420e-01\n",
            "epoch: 734, iter: 37, training_loss: 1.82080e-01\n",
            "epoch: 735, iter: 37, training_loss: 1.68051e-01\n",
            "epoch: 736, iter: 37, training_loss: 1.93016e-01\n",
            "epoch: 737, iter: 37, training_loss: 1.68584e-01\n",
            "epoch: 738, iter: 37, training_loss: 1.69710e-01\n",
            "epoch: 739, iter: 37, training_loss: 1.54663e-01\n",
            "epoch: 740, iter: 37, training_loss: 1.55384e-01\n",
            "epoch: 741, iter: 37, training_loss: 1.54642e-01\n",
            "epoch: 742, iter: 37, training_loss: 1.61920e-01\n",
            "epoch: 743, iter: 37, training_loss: 1.86989e-01\n",
            "epoch: 744, iter: 37, training_loss: 1.65460e-01\n",
            "epoch: 745, iter: 37, training_loss: 1.77601e-01\n",
            "epoch: 746, iter: 37, training_loss: 2.09366e-01\n",
            "epoch: 747, iter: 37, training_loss: 1.95473e-01\n",
            "epoch: 748, iter: 37, training_loss: 1.82622e-01\n",
            "epoch: 749, iter: 37, training_loss: 1.68859e-01\n",
            "epoch: 750, iter: 37, training_loss: 1.71375e-01\n",
            "epoch: 751, iter: 37, training_loss: 1.74211e-01\n",
            "epoch: 752, iter: 37, training_loss: 1.86448e-01\n",
            "epoch: 753, iter: 37, training_loss: 1.47691e-01\n",
            "epoch: 754, iter: 37, training_loss: 1.74449e-01\n",
            "epoch: 755, iter: 37, training_loss: 1.62124e-01\n",
            "epoch: 756, iter: 37, training_loss: 1.67346e-01\n",
            "epoch: 757, iter: 37, training_loss: 1.64480e-01\n",
            "epoch: 758, iter: 37, training_loss: 1.81347e-01\n",
            "epoch: 759, iter: 37, training_loss: 2.20270e-01\n",
            "epoch: 760, iter: 37, training_loss: 1.68431e-01\n",
            "epoch: 761, iter: 37, training_loss: 1.53351e-01\n",
            "epoch: 762, iter: 37, training_loss: 1.62536e-01\n",
            "epoch: 763, iter: 37, training_loss: 1.40542e-01\n",
            "epoch: 764, iter: 37, training_loss: 1.86687e-01\n",
            "epoch: 765, iter: 37, training_loss: 1.45091e-01\n",
            "epoch: 766, iter: 37, training_loss: 1.41598e-01\n",
            "epoch: 767, iter: 37, training_loss: 1.55974e-01\n",
            "epoch: 768, iter: 37, training_loss: 1.79546e-01\n",
            "epoch: 769, iter: 37, training_loss: 1.54529e-01\n",
            "epoch: 770, iter: 37, training_loss: 1.38713e-01\n",
            "epoch: 771, iter: 37, training_loss: 1.43628e-01\n",
            "epoch: 772, iter: 37, training_loss: 1.93899e-01\n",
            "epoch: 773, iter: 37, training_loss: 1.40766e-01\n",
            "epoch: 774, iter: 37, training_loss: 1.76037e-01\n",
            "epoch: 775, iter: 37, training_loss: 1.64595e-01\n",
            "epoch: 776, iter: 37, training_loss: 1.98372e-01\n",
            "epoch: 777, iter: 37, training_loss: 1.73259e-01\n",
            "epoch: 778, iter: 37, training_loss: 1.44562e-01\n",
            "epoch: 779, iter: 37, training_loss: 1.72780e-01\n",
            "epoch: 780, iter: 37, training_loss: 1.73181e-01\n",
            "epoch: 781, iter: 37, training_loss: 1.47825e-01\n",
            "epoch: 782, iter: 37, training_loss: 1.63320e-01\n",
            "epoch: 783, iter: 37, training_loss: 1.86554e-01\n",
            "epoch: 784, iter: 37, training_loss: 1.73258e-01\n",
            "epoch: 785, iter: 37, training_loss: 1.70627e-01\n",
            "epoch: 786, iter: 37, training_loss: 1.73498e-01\n",
            "epoch: 787, iter: 37, training_loss: 1.45082e-01\n",
            "epoch: 788, iter: 37, training_loss: 1.54761e-01\n",
            "epoch: 789, iter: 37, training_loss: 1.78692e-01\n",
            "epoch: 790, iter: 37, training_loss: 1.49859e-01\n",
            "epoch: 791, iter: 37, training_loss: 1.40850e-01\n",
            "epoch: 792, iter: 37, training_loss: 1.63141e-01\n",
            "epoch: 793, iter: 37, training_loss: 1.44089e-01\n",
            "epoch: 794, iter: 37, training_loss: 1.69741e-01\n",
            "epoch: 795, iter: 37, training_loss: 1.43428e-01\n",
            "epoch: 796, iter: 37, training_loss: 1.55626e-01\n",
            "epoch: 797, iter: 37, training_loss: 1.79714e-01\n",
            "epoch: 798, iter: 37, training_loss: 1.77013e-01\n",
            "epoch: 799, iter: 37, training_loss: 1.84055e-01\n",
            "epoch: 800, iter: 37, training_loss: 1.66614e-01\n",
            "epoch: 801, iter: 37, training_loss: 1.49396e-01\n",
            "epoch: 802, iter: 37, training_loss: 1.75636e-01\n",
            "epoch: 803, iter: 37, training_loss: 1.77987e-01\n",
            "epoch: 804, iter: 37, training_loss: 1.72791e-01\n",
            "epoch: 805, iter: 37, training_loss: 1.81996e-01\n",
            "epoch: 806, iter: 37, training_loss: 1.63663e-01\n",
            "epoch: 807, iter: 37, training_loss: 1.62519e-01\n",
            "epoch: 808, iter: 37, training_loss: 1.69224e-01\n",
            "epoch: 809, iter: 37, training_loss: 1.53234e-01\n",
            "epoch: 810, iter: 37, training_loss: 1.41756e-01\n",
            "epoch: 811, iter: 37, training_loss: 1.39518e-01\n",
            "epoch: 812, iter: 37, training_loss: 1.54167e-01\n",
            "epoch: 813, iter: 37, training_loss: 1.77657e-01\n",
            "epoch: 814, iter: 37, training_loss: 1.36606e-01\n",
            "epoch: 815, iter: 37, training_loss: 1.96151e-01\n",
            "epoch: 816, iter: 37, training_loss: 1.58964e-01\n",
            "epoch: 817, iter: 37, training_loss: 1.42984e-01\n",
            "epoch: 818, iter: 37, training_loss: 1.42317e-01\n",
            "epoch: 819, iter: 37, training_loss: 1.41030e-01\n",
            "epoch: 820, iter: 37, training_loss: 1.43650e-01\n",
            "epoch: 821, iter: 37, training_loss: 1.47234e-01\n",
            "epoch: 822, iter: 37, training_loss: 1.57698e-01\n",
            "epoch: 823, iter: 37, training_loss: 2.04857e-01\n",
            "epoch: 824, iter: 37, training_loss: 1.60319e-01\n",
            "epoch: 825, iter: 37, training_loss: 1.45537e-01\n",
            "epoch: 826, iter: 37, training_loss: 1.68275e-01\n",
            "epoch: 827, iter: 37, training_loss: 1.54910e-01\n",
            "epoch: 828, iter: 37, training_loss: 1.44208e-01\n",
            "epoch: 829, iter: 37, training_loss: 1.38132e-01\n",
            "epoch: 830, iter: 37, training_loss: 1.67256e-01\n",
            "epoch: 831, iter: 37, training_loss: 1.61895e-01\n",
            "epoch: 832, iter: 37, training_loss: 1.41669e-01\n",
            "epoch: 833, iter: 37, training_loss: 1.37302e-01\n",
            "epoch: 834, iter: 37, training_loss: 1.51344e-01\n",
            "epoch: 835, iter: 37, training_loss: 1.62936e-01\n",
            "epoch: 836, iter: 37, training_loss: 2.32693e-01\n",
            "epoch: 837, iter: 37, training_loss: 1.47341e-01\n",
            "epoch: 838, iter: 37, training_loss: 1.46278e-01\n",
            "epoch: 839, iter: 37, training_loss: 1.43701e-01\n",
            "epoch: 840, iter: 37, training_loss: 1.44736e-01\n",
            "epoch: 841, iter: 37, training_loss: 1.38588e-01\n",
            "epoch: 842, iter: 37, training_loss: 1.86641e-01\n",
            "epoch: 843, iter: 37, training_loss: 1.43157e-01\n",
            "epoch: 844, iter: 37, training_loss: 1.33023e-01\n",
            "epoch: 845, iter: 37, training_loss: 1.45761e-01\n",
            "epoch: 846, iter: 37, training_loss: 1.58618e-01\n",
            "epoch: 847, iter: 37, training_loss: 1.68828e-01\n",
            "epoch: 848, iter: 37, training_loss: 1.37060e-01\n",
            "epoch: 849, iter: 37, training_loss: 1.57388e-01\n",
            "epoch: 850, iter: 37, training_loss: 1.55855e-01\n",
            "epoch: 851, iter: 37, training_loss: 1.57939e-01\n",
            "epoch: 852, iter: 37, training_loss: 2.11878e-01\n",
            "epoch: 853, iter: 37, training_loss: 1.84075e-01\n",
            "epoch: 854, iter: 37, training_loss: 1.75408e-01\n",
            "epoch: 855, iter: 37, training_loss: 1.60029e-01\n",
            "epoch: 856, iter: 37, training_loss: 1.66321e-01\n",
            "epoch: 857, iter: 37, training_loss: 1.37630e-01\n",
            "epoch: 858, iter: 37, training_loss: 1.62223e-01\n",
            "epoch: 859, iter: 37, training_loss: 1.40786e-01\n",
            "epoch: 860, iter: 37, training_loss: 1.83180e-01\n",
            "epoch: 861, iter: 37, training_loss: 1.42410e-01\n",
            "epoch: 862, iter: 37, training_loss: 1.41233e-01\n",
            "epoch: 863, iter: 37, training_loss: 1.36097e-01\n",
            "epoch: 864, iter: 37, training_loss: 1.42484e-01\n",
            "epoch: 865, iter: 37, training_loss: 1.43738e-01\n",
            "epoch: 866, iter: 37, training_loss: 1.45419e-01\n",
            "epoch: 867, iter: 37, training_loss: 1.43917e-01\n",
            "epoch: 868, iter: 37, training_loss: 1.62425e-01\n",
            "epoch: 869, iter: 37, training_loss: 1.26732e-01\n",
            "epoch: 870, iter: 37, training_loss: 1.42807e-01\n",
            "epoch: 871, iter: 37, training_loss: 1.72975e-01\n",
            "epoch: 872, iter: 37, training_loss: 1.35106e-01\n",
            "epoch: 873, iter: 37, training_loss: 1.25957e-01\n",
            "epoch: 874, iter: 37, training_loss: 1.68495e-01\n",
            "epoch: 875, iter: 37, training_loss: 1.63102e-01\n",
            "epoch: 876, iter: 37, training_loss: 1.57923e-01\n",
            "epoch: 877, iter: 37, training_loss: 1.52968e-01\n",
            "epoch: 878, iter: 37, training_loss: 1.53075e-01\n",
            "epoch: 879, iter: 37, training_loss: 1.45375e-01\n",
            "epoch: 880, iter: 37, training_loss: 1.87594e-01\n",
            "epoch: 881, iter: 37, training_loss: 1.55937e-01\n",
            "epoch: 882, iter: 37, training_loss: 1.36767e-01\n",
            "epoch: 883, iter: 37, training_loss: 1.31572e-01\n",
            "epoch: 884, iter: 37, training_loss: 1.35082e-01\n",
            "epoch: 885, iter: 37, training_loss: 1.73575e-01\n",
            "epoch: 886, iter: 37, training_loss: 1.64839e-01\n",
            "epoch: 887, iter: 37, training_loss: 1.39718e-01\n",
            "epoch: 888, iter: 37, training_loss: 1.22937e-01\n",
            "epoch: 889, iter: 37, training_loss: 1.68066e-01\n",
            "epoch: 890, iter: 37, training_loss: 1.42004e-01\n",
            "epoch: 891, iter: 37, training_loss: 1.40021e-01\n",
            "epoch: 892, iter: 37, training_loss: 1.35376e-01\n",
            "epoch: 893, iter: 37, training_loss: 1.66044e-01\n",
            "epoch: 894, iter: 37, training_loss: 1.39619e-01\n",
            "epoch: 895, iter: 37, training_loss: 1.35503e-01\n",
            "epoch: 896, iter: 37, training_loss: 1.56881e-01\n",
            "epoch: 897, iter: 37, training_loss: 1.46576e-01\n",
            "epoch: 898, iter: 37, training_loss: 1.38474e-01\n",
            "epoch: 899, iter: 37, training_loss: 1.51695e-01\n",
            "epoch: 900, iter: 37, training_loss: 1.55980e-01\n",
            "epoch: 901, iter: 37, training_loss: 1.31972e-01\n",
            "epoch: 902, iter: 37, training_loss: 1.67379e-01\n",
            "epoch: 903, iter: 37, training_loss: 1.37344e-01\n",
            "epoch: 904, iter: 37, training_loss: 1.30084e-01\n",
            "epoch: 905, iter: 37, training_loss: 1.44096e-01\n",
            "epoch: 906, iter: 37, training_loss: 1.47953e-01\n",
            "epoch: 907, iter: 37, training_loss: 1.56620e-01\n",
            "epoch: 908, iter: 37, training_loss: 1.37910e-01\n",
            "epoch: 909, iter: 37, training_loss: 1.29633e-01\n",
            "epoch: 910, iter: 37, training_loss: 1.41008e-01\n",
            "epoch: 911, iter: 37, training_loss: 1.35365e-01\n",
            "epoch: 912, iter: 37, training_loss: 1.43585e-01\n",
            "epoch: 913, iter: 37, training_loss: 1.30684e-01\n",
            "epoch: 914, iter: 37, training_loss: 1.34038e-01\n",
            "epoch: 915, iter: 37, training_loss: 1.76888e-01\n",
            "epoch: 916, iter: 37, training_loss: 1.77637e-01\n",
            "epoch: 917, iter: 37, training_loss: 1.30511e-01\n",
            "epoch: 918, iter: 37, training_loss: 1.35765e-01\n",
            "epoch: 919, iter: 37, training_loss: 1.30754e-01\n",
            "epoch: 920, iter: 37, training_loss: 1.46328e-01\n",
            "epoch: 921, iter: 37, training_loss: 1.45340e-01\n",
            "epoch: 922, iter: 37, training_loss: 1.35258e-01\n",
            "epoch: 923, iter: 37, training_loss: 1.57642e-01\n",
            "epoch: 924, iter: 37, training_loss: 1.59680e-01\n",
            "epoch: 925, iter: 37, training_loss: 1.27073e-01\n",
            "epoch: 926, iter: 37, training_loss: 1.40975e-01\n",
            "epoch: 927, iter: 37, training_loss: 1.53924e-01\n",
            "epoch: 928, iter: 37, training_loss: 1.28927e-01\n",
            "epoch: 929, iter: 37, training_loss: 1.42414e-01\n",
            "epoch: 930, iter: 37, training_loss: 1.31262e-01\n",
            "epoch: 931, iter: 37, training_loss: 1.23059e-01\n",
            "epoch: 932, iter: 37, training_loss: 1.46621e-01\n",
            "epoch: 933, iter: 37, training_loss: 1.94846e-01\n",
            "epoch: 934, iter: 37, training_loss: 1.51201e-01\n",
            "epoch: 935, iter: 37, training_loss: 1.28774e-01\n",
            "epoch: 936, iter: 37, training_loss: 1.57448e-01\n",
            "epoch: 937, iter: 37, training_loss: 1.38829e-01\n",
            "epoch: 938, iter: 37, training_loss: 1.41834e-01\n",
            "epoch: 939, iter: 37, training_loss: 1.43340e-01\n",
            "epoch: 940, iter: 37, training_loss: 1.40350e-01\n",
            "epoch: 941, iter: 37, training_loss: 1.29030e-01\n",
            "epoch: 942, iter: 37, training_loss: 1.38257e-01\n",
            "epoch: 943, iter: 37, training_loss: 1.43262e-01\n",
            "epoch: 944, iter: 37, training_loss: 1.55692e-01\n",
            "epoch: 945, iter: 37, training_loss: 1.43059e-01\n",
            "epoch: 946, iter: 37, training_loss: 1.47522e-01\n",
            "epoch: 947, iter: 37, training_loss: 1.38192e-01\n",
            "epoch: 948, iter: 37, training_loss: 1.32797e-01\n",
            "epoch: 949, iter: 37, training_loss: 1.37996e-01\n",
            "epoch: 950, iter: 37, training_loss: 1.31581e-01\n",
            "epoch: 951, iter: 37, training_loss: 1.29391e-01\n",
            "epoch: 952, iter: 37, training_loss: 1.34811e-01\n",
            "epoch: 953, iter: 37, training_loss: 1.44088e-01\n",
            "epoch: 954, iter: 37, training_loss: 1.31859e-01\n",
            "epoch: 955, iter: 37, training_loss: 1.33639e-01\n",
            "epoch: 956, iter: 37, training_loss: 1.55702e-01\n",
            "epoch: 957, iter: 37, training_loss: 1.57010e-01\n",
            "epoch: 958, iter: 37, training_loss: 1.42460e-01\n",
            "epoch: 959, iter: 37, training_loss: 1.54299e-01\n",
            "epoch: 960, iter: 37, training_loss: 1.62780e-01\n",
            "epoch: 961, iter: 37, training_loss: 1.39853e-01\n",
            "epoch: 962, iter: 37, training_loss: 1.30407e-01\n",
            "epoch: 963, iter: 37, training_loss: 1.63600e-01\n",
            "epoch: 964, iter: 37, training_loss: 1.24444e-01\n",
            "epoch: 965, iter: 37, training_loss: 1.67119e-01\n",
            "epoch: 966, iter: 37, training_loss: 1.36995e-01\n",
            "epoch: 967, iter: 37, training_loss: 1.52869e-01\n",
            "epoch: 968, iter: 37, training_loss: 1.75872e-01\n",
            "epoch: 969, iter: 37, training_loss: 1.27347e-01\n",
            "epoch: 970, iter: 37, training_loss: 1.88303e-01\n",
            "epoch: 971, iter: 37, training_loss: 1.44901e-01\n",
            "epoch: 972, iter: 37, training_loss: 1.45337e-01\n",
            "epoch: 973, iter: 37, training_loss: 1.49490e-01\n",
            "epoch: 974, iter: 37, training_loss: 1.60059e-01\n",
            "epoch: 975, iter: 37, training_loss: 1.39769e-01\n",
            "epoch: 976, iter: 37, training_loss: 1.39431e-01\n",
            "epoch: 977, iter: 37, training_loss: 1.52499e-01\n",
            "epoch: 978, iter: 37, training_loss: 1.37977e-01\n",
            "epoch: 979, iter: 37, training_loss: 1.54510e-01\n",
            "epoch: 980, iter: 37, training_loss: 1.25192e-01\n",
            "epoch: 981, iter: 37, training_loss: 1.58330e-01\n",
            "epoch: 982, iter: 37, training_loss: 1.53732e-01\n",
            "epoch: 983, iter: 37, training_loss: 1.37370e-01\n",
            "epoch: 984, iter: 37, training_loss: 1.41895e-01\n",
            "epoch: 985, iter: 37, training_loss: 1.37003e-01\n",
            "epoch: 986, iter: 37, training_loss: 1.19938e-01\n",
            "epoch: 987, iter: 37, training_loss: 1.27559e-01\n",
            "epoch: 988, iter: 37, training_loss: 1.19887e-01\n",
            "epoch: 989, iter: 37, training_loss: 1.28090e-01\n",
            "epoch: 990, iter: 37, training_loss: 1.78652e-01\n",
            "epoch: 991, iter: 37, training_loss: 1.35921e-01\n",
            "epoch: 992, iter: 37, training_loss: 1.61981e-01\n",
            "epoch: 993, iter: 37, training_loss: 1.42228e-01\n",
            "epoch: 994, iter: 37, training_loss: 1.29781e-01\n",
            "epoch: 995, iter: 37, training_loss: 1.39742e-01\n",
            "epoch: 996, iter: 37, training_loss: 1.29279e-01\n",
            "epoch: 997, iter: 37, training_loss: 1.33745e-01\n",
            "epoch: 998, iter: 37, training_loss: 1.36340e-01\n",
            "epoch: 999, iter: 37, training_loss: 1.48835e-01\n",
            "epoch: 1000, iter: 37, training_loss: 1.22800e-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname beijing --method stasy --mode sample --save_path beijing_syn.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qt3WX5N0-3Ax",
        "outputId": "2e499763-ff0d-4e96-f135-740f815a961e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No NaNs in numerical features, skipping\n",
            "Input dimension: 83\n",
            "NCSNpp(\n",
            "  (act): ELU(alpha=1.0)\n",
            "  (all_modules): ModuleList(\n",
            "    (0): GaussianFourierProjection()\n",
            "    (1): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (3): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=83, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (4): ELU(alpha=1.0)\n",
            "    (5): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=1107, out_features=2048, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=2048, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=2048, bias=True)\n",
            "    )\n",
            "    (6): ELU(alpha=1.0)\n",
            "    (7): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=3155, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (8): ELU(alpha=1.0)\n",
            "    (9): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=4179, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (10): ELU(alpha=1.0)\n",
            "    (11): Linear(in_features=5203, out_features=83, bias=True)\n",
            "  )\n",
            ")\n",
            "the number of parameters 10413436\n",
            "Loading SAVED model at from /content/tabsyn/baselines/stasy/ckpt/beijing/model.pth\n",
            "Start sampling...\n",
            "Sampling time = 67.46365642547607\n",
            "Saving sampled data to beijing_syn.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname adult --method stasy --mode train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hom4WKlGJumn",
        "outputId": "81826600-f022-4544-9a30-1c18f4861d40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No NaNs in numerical features, skipping\n",
            "110\n",
            "NCSNpp(\n",
            "  (act): ELU(alpha=1.0)\n",
            "  (all_modules): ModuleList(\n",
            "    (0): GaussianFourierProjection()\n",
            "    (1): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (3): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=110, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (4): ELU(alpha=1.0)\n",
            "    (5): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=1134, out_features=2048, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=2048, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=2048, bias=True)\n",
            "    )\n",
            "    (6): ELU(alpha=1.0)\n",
            "    (7): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=3182, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (8): ELU(alpha=1.0)\n",
            "    (9): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=4206, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (10): ELU(alpha=1.0)\n",
            "    (11): Linear(in_features=5230, out_features=110, bias=True)\n",
            "  )\n",
            ")\n",
            "the number of parameters 10695154\n",
            "epoch: 0, iter: 32, training_loss: 2.40483e+00\n",
            "epoch: 1, iter: 32, training_loss: 1.34937e+00\n",
            "epoch: 2, iter: 32, training_loss: 1.33356e+00\n",
            "epoch: 3, iter: 32, training_loss: 1.36094e+00\n",
            "epoch: 4, iter: 32, training_loss: 1.32903e+00\n",
            "epoch: 5, iter: 32, training_loss: 1.30020e+00\n",
            "epoch: 6, iter: 32, training_loss: 1.29891e+00\n",
            "epoch: 7, iter: 32, training_loss: 1.27200e+00\n",
            "epoch: 8, iter: 32, training_loss: 1.19428e+00\n",
            "epoch: 9, iter: 32, training_loss: 1.20978e+00\n",
            "epoch: 10, iter: 32, training_loss: 1.18273e+00\n",
            "epoch: 11, iter: 32, training_loss: 1.18273e+00\n",
            "epoch: 12, iter: 32, training_loss: 1.12630e+00\n",
            "epoch: 13, iter: 32, training_loss: 1.14706e+00\n",
            "epoch: 14, iter: 32, training_loss: 1.14139e+00\n",
            "epoch: 15, iter: 32, training_loss: 1.12968e+00\n",
            "epoch: 16, iter: 32, training_loss: 1.05103e+00\n",
            "epoch: 17, iter: 32, training_loss: 1.05976e+00\n",
            "epoch: 18, iter: 32, training_loss: 1.05734e+00\n",
            "epoch: 19, iter: 32, training_loss: 1.10674e+00\n",
            "epoch: 20, iter: 32, training_loss: 1.17228e+00\n",
            "epoch: 21, iter: 32, training_loss: 1.10165e+00\n",
            "epoch: 22, iter: 32, training_loss: 1.08856e+00\n",
            "epoch: 23, iter: 32, training_loss: 1.10263e+00\n",
            "epoch: 24, iter: 32, training_loss: 1.13453e+00\n",
            "epoch: 25, iter: 32, training_loss: 1.11402e+00\n",
            "epoch: 26, iter: 32, training_loss: 1.11063e+00\n",
            "epoch: 27, iter: 32, training_loss: 1.14799e+00\n",
            "epoch: 28, iter: 32, training_loss: 1.25180e+00\n",
            "epoch: 29, iter: 32, training_loss: 1.23784e+00\n",
            "epoch: 30, iter: 32, training_loss: 1.16961e+00\n",
            "epoch: 31, iter: 32, training_loss: 1.21687e+00\n",
            "epoch: 32, iter: 32, training_loss: 1.30334e+00\n",
            "epoch: 33, iter: 32, training_loss: 1.25877e+00\n",
            "epoch: 34, iter: 32, training_loss: 1.29926e+00\n",
            "epoch: 35, iter: 32, training_loss: 1.30057e+00\n",
            "epoch: 36, iter: 32, training_loss: 1.35971e+00\n",
            "epoch: 37, iter: 32, training_loss: 1.47066e+00\n",
            "epoch: 38, iter: 32, training_loss: 1.37041e+00\n",
            "epoch: 39, iter: 32, training_loss: 1.43727e+00\n",
            "epoch: 40, iter: 32, training_loss: 1.38743e+00\n",
            "epoch: 41, iter: 32, training_loss: 1.30151e+00\n",
            "epoch: 42, iter: 32, training_loss: 1.48619e+00\n",
            "epoch: 43, iter: 32, training_loss: 1.56480e+00\n",
            "epoch: 44, iter: 32, training_loss: 1.45857e+00\n",
            "epoch: 45, iter: 32, training_loss: 1.50135e+00\n",
            "epoch: 46, iter: 32, training_loss: 1.64077e+00\n",
            "epoch: 47, iter: 32, training_loss: 1.59159e+00\n",
            "epoch: 48, iter: 32, training_loss: 1.50403e+00\n",
            "epoch: 49, iter: 32, training_loss: 1.75175e+00\n",
            "epoch: 50, iter: 32, training_loss: 1.52024e+00\n",
            "epoch: 51, iter: 32, training_loss: 1.58734e+00\n",
            "epoch: 52, iter: 32, training_loss: 1.56328e+00\n",
            "epoch: 53, iter: 32, training_loss: 1.91090e+00\n",
            "epoch: 54, iter: 32, training_loss: 1.86642e+00\n",
            "epoch: 55, iter: 32, training_loss: 1.98866e+00\n",
            "epoch: 56, iter: 32, training_loss: 2.05846e+00\n",
            "epoch: 57, iter: 32, training_loss: 1.86741e+00\n",
            "epoch: 58, iter: 32, training_loss: 1.70147e+00\n",
            "epoch: 59, iter: 32, training_loss: 1.72288e+00\n",
            "epoch: 60, iter: 32, training_loss: 1.70914e+00\n",
            "epoch: 61, iter: 32, training_loss: 1.79582e+00\n",
            "epoch: 62, iter: 32, training_loss: 1.85400e+00\n",
            "epoch: 63, iter: 32, training_loss: 1.90432e+00\n",
            "epoch: 64, iter: 32, training_loss: 2.01751e+00\n",
            "epoch: 65, iter: 32, training_loss: 2.13403e+00\n",
            "epoch: 66, iter: 32, training_loss: 1.97676e+00\n",
            "epoch: 67, iter: 32, training_loss: 2.11443e+00\n",
            "epoch: 68, iter: 32, training_loss: 2.12287e+00\n",
            "epoch: 69, iter: 32, training_loss: 2.22535e+00\n",
            "epoch: 70, iter: 32, training_loss: 1.93592e+00\n",
            "epoch: 71, iter: 32, training_loss: 1.96339e+00\n",
            "epoch: 72, iter: 32, training_loss: 2.30972e+00\n",
            "epoch: 73, iter: 32, training_loss: 2.13651e+00\n",
            "epoch: 74, iter: 32, training_loss: 1.91722e+00\n",
            "epoch: 75, iter: 32, training_loss: 2.06379e+00\n",
            "epoch: 76, iter: 32, training_loss: 2.52825e+00\n",
            "epoch: 77, iter: 32, training_loss: 2.35337e+00\n",
            "epoch: 78, iter: 32, training_loss: 2.48469e+00\n",
            "epoch: 79, iter: 32, training_loss: 3.05060e+00\n",
            "epoch: 80, iter: 32, training_loss: 2.95761e+00\n",
            "epoch: 81, iter: 32, training_loss: 2.84291e+00\n",
            "epoch: 82, iter: 32, training_loss: 2.36255e+00\n",
            "epoch: 83, iter: 32, training_loss: 2.50982e+00\n",
            "epoch: 84, iter: 32, training_loss: 2.63192e+00\n",
            "epoch: 85, iter: 32, training_loss: 2.88176e+00\n",
            "epoch: 86, iter: 32, training_loss: 2.67030e+00\n",
            "epoch: 87, iter: 32, training_loss: 2.83854e+00\n",
            "epoch: 88, iter: 32, training_loss: 2.78164e+00\n",
            "epoch: 89, iter: 32, training_loss: 2.53126e+00\n",
            "epoch: 90, iter: 32, training_loss: 2.87311e+00\n",
            "epoch: 91, iter: 32, training_loss: 2.91209e+00\n",
            "epoch: 92, iter: 32, training_loss: 2.83997e+00\n",
            "epoch: 93, iter: 32, training_loss: 2.09497e+00\n",
            "epoch: 94, iter: 32, training_loss: 2.50010e+00\n",
            "epoch: 95, iter: 32, training_loss: 3.07559e+00\n",
            "epoch: 96, iter: 32, training_loss: 2.93735e+00\n",
            "epoch: 97, iter: 32, training_loss: 2.66331e+00\n",
            "epoch: 98, iter: 32, training_loss: 2.67774e+00\n",
            "epoch: 99, iter: 32, training_loss: 3.02809e+00\n",
            "epoch: 100, iter: 32, training_loss: 2.92540e+00\n",
            "epoch: 101, iter: 32, training_loss: 2.75044e+00\n",
            "epoch: 102, iter: 32, training_loss: 2.95993e+00\n",
            "epoch: 103, iter: 32, training_loss: 3.05957e+00\n",
            "epoch: 104, iter: 32, training_loss: 3.30330e+00\n",
            "epoch: 105, iter: 32, training_loss: 3.16195e+00\n",
            "epoch: 106, iter: 32, training_loss: 3.28951e+00\n",
            "epoch: 107, iter: 32, training_loss: 3.54925e+00\n",
            "epoch: 108, iter: 32, training_loss: 3.40774e+00\n",
            "epoch: 109, iter: 32, training_loss: 3.21910e+00\n",
            "epoch: 110, iter: 32, training_loss: 3.14910e+00\n",
            "epoch: 111, iter: 32, training_loss: 3.18317e+00\n",
            "epoch: 112, iter: 32, training_loss: 3.42235e+00\n",
            "epoch: 113, iter: 32, training_loss: 3.14260e+00\n",
            "epoch: 114, iter: 32, training_loss: 3.06632e+00\n",
            "epoch: 115, iter: 32, training_loss: 3.65230e+00\n",
            "epoch: 116, iter: 32, training_loss: 3.55241e+00\n",
            "epoch: 117, iter: 32, training_loss: 3.40179e+00\n",
            "epoch: 118, iter: 32, training_loss: 3.12321e+00\n",
            "epoch: 119, iter: 32, training_loss: 3.56289e+00\n",
            "epoch: 120, iter: 32, training_loss: 3.22176e+00\n",
            "epoch: 121, iter: 32, training_loss: 3.49344e+00\n",
            "epoch: 122, iter: 32, training_loss: 3.68268e+00\n",
            "epoch: 123, iter: 32, training_loss: 3.75088e+00\n",
            "epoch: 124, iter: 32, training_loss: 3.50789e+00\n",
            "epoch: 125, iter: 32, training_loss: 3.21779e+00\n",
            "epoch: 126, iter: 32, training_loss: 3.54107e+00\n",
            "epoch: 127, iter: 32, training_loss: 3.65388e+00\n",
            "epoch: 128, iter: 32, training_loss: 3.98772e+00\n",
            "epoch: 129, iter: 32, training_loss: 4.43602e+00\n",
            "epoch: 130, iter: 32, training_loss: 3.95917e+00\n",
            "epoch: 131, iter: 32, training_loss: 3.60472e+00\n",
            "epoch: 132, iter: 32, training_loss: 3.65164e+00\n",
            "epoch: 133, iter: 32, training_loss: 3.63616e+00\n",
            "epoch: 134, iter: 32, training_loss: 3.52918e+00\n",
            "epoch: 135, iter: 32, training_loss: 3.91750e+00\n",
            "epoch: 136, iter: 32, training_loss: 3.91081e+00\n",
            "epoch: 137, iter: 32, training_loss: 3.69752e+00\n",
            "epoch: 138, iter: 32, training_loss: 3.85781e+00\n",
            "epoch: 139, iter: 32, training_loss: 3.67759e+00\n",
            "epoch: 140, iter: 32, training_loss: 3.96035e+00\n",
            "epoch: 141, iter: 32, training_loss: 3.69055e+00\n",
            "epoch: 142, iter: 32, training_loss: 3.30398e+00\n",
            "epoch: 143, iter: 32, training_loss: 3.37705e+00\n",
            "epoch: 144, iter: 32, training_loss: 3.81065e+00\n",
            "epoch: 145, iter: 32, training_loss: 3.41057e+00\n",
            "epoch: 146, iter: 32, training_loss: 3.64129e+00\n",
            "epoch: 147, iter: 32, training_loss: 4.05517e+00\n",
            "epoch: 148, iter: 32, training_loss: 3.20270e+00\n",
            "epoch: 149, iter: 32, training_loss: 3.26357e+00\n",
            "epoch: 150, iter: 32, training_loss: 3.59809e+00\n",
            "epoch: 151, iter: 32, training_loss: 3.80140e+00\n",
            "epoch: 152, iter: 32, training_loss: 3.65574e+00\n",
            "epoch: 153, iter: 32, training_loss: 3.11234e+00\n",
            "epoch: 154, iter: 32, training_loss: 3.19119e+00\n",
            "epoch: 155, iter: 32, training_loss: 3.33097e+00\n",
            "epoch: 156, iter: 32, training_loss: 3.33656e+00\n",
            "epoch: 157, iter: 32, training_loss: 3.96422e+00\n",
            "epoch: 158, iter: 32, training_loss: 3.49903e+00\n",
            "epoch: 159, iter: 32, training_loss: 3.16749e+00\n",
            "epoch: 160, iter: 32, training_loss: 3.27544e+00\n",
            "epoch: 161, iter: 32, training_loss: 3.53531e+00\n",
            "epoch: 162, iter: 32, training_loss: 2.83705e+00\n",
            "epoch: 163, iter: 32, training_loss: 2.95688e+00\n",
            "epoch: 164, iter: 32, training_loss: 2.67014e+00\n",
            "epoch: 165, iter: 32, training_loss: 2.55156e+00\n",
            "epoch: 166, iter: 32, training_loss: 2.74753e+00\n",
            "epoch: 167, iter: 32, training_loss: 3.20551e+00\n",
            "epoch: 168, iter: 32, training_loss: 2.40515e+00\n",
            "epoch: 169, iter: 32, training_loss: 2.58850e+00\n",
            "epoch: 170, iter: 32, training_loss: 2.16574e+00\n",
            "epoch: 171, iter: 32, training_loss: 2.07573e+00\n",
            "epoch: 172, iter: 32, training_loss: 2.20848e+00\n",
            "epoch: 173, iter: 32, training_loss: 2.26371e+00\n",
            "epoch: 174, iter: 32, training_loss: 1.91309e+00\n",
            "epoch: 175, iter: 32, training_loss: 1.94398e+00\n",
            "epoch: 176, iter: 32, training_loss: 2.00225e+00\n",
            "epoch: 177, iter: 32, training_loss: 1.56682e+00\n",
            "epoch: 178, iter: 32, training_loss: 1.56662e+00\n",
            "epoch: 179, iter: 32, training_loss: 1.63758e+00\n",
            "epoch: 180, iter: 32, training_loss: 1.53806e+00\n",
            "epoch: 181, iter: 32, training_loss: 1.33898e+00\n",
            "epoch: 182, iter: 32, training_loss: 1.03086e+00\n",
            "epoch: 183, iter: 32, training_loss: 1.01530e+00\n",
            "epoch: 184, iter: 32, training_loss: 9.63980e-01\n",
            "epoch: 185, iter: 32, training_loss: 8.95495e-01\n",
            "epoch: 186, iter: 32, training_loss: 8.95256e-01\n",
            "epoch: 187, iter: 32, training_loss: 8.61771e-01\n",
            "epoch: 188, iter: 32, training_loss: 8.52562e-01\n",
            "epoch: 189, iter: 32, training_loss: 1.33069e+00\n",
            "epoch: 190, iter: 32, training_loss: 9.74962e-01\n",
            "epoch: 191, iter: 32, training_loss: 9.77257e-01\n",
            "epoch: 192, iter: 32, training_loss: 9.26430e-01\n",
            "epoch: 193, iter: 32, training_loss: 8.72222e-01\n",
            "epoch: 194, iter: 32, training_loss: 8.87671e-01\n",
            "epoch: 195, iter: 32, training_loss: 9.45898e-01\n",
            "epoch: 196, iter: 32, training_loss: 8.41893e-01\n",
            "epoch: 197, iter: 32, training_loss: 8.93534e-01\n",
            "epoch: 198, iter: 32, training_loss: 8.84363e-01\n",
            "epoch: 199, iter: 32, training_loss: 1.11560e+00\n",
            "epoch: 200, iter: 32, training_loss: 8.35537e-01\n",
            "epoch: 201, iter: 32, training_loss: 9.08960e-01\n",
            "epoch: 202, iter: 32, training_loss: 9.43835e-01\n",
            "epoch: 203, iter: 32, training_loss: 1.05171e+00\n",
            "epoch: 204, iter: 32, training_loss: 8.74272e-01\n",
            "epoch: 205, iter: 32, training_loss: 8.73908e-01\n",
            "epoch: 206, iter: 32, training_loss: 8.15585e-01\n",
            "epoch: 207, iter: 32, training_loss: 9.41294e-01\n",
            "epoch: 208, iter: 32, training_loss: 9.06605e-01\n",
            "epoch: 209, iter: 32, training_loss: 8.96135e-01\n",
            "epoch: 210, iter: 32, training_loss: 9.18350e-01\n",
            "epoch: 211, iter: 32, training_loss: 1.01494e+00\n",
            "epoch: 212, iter: 32, training_loss: 9.84267e-01\n",
            "epoch: 213, iter: 32, training_loss: 8.75018e-01\n",
            "epoch: 214, iter: 32, training_loss: 8.83852e-01\n",
            "epoch: 215, iter: 32, training_loss: 9.57342e-01\n",
            "epoch: 216, iter: 32, training_loss: 8.95539e-01\n",
            "epoch: 217, iter: 32, training_loss: 1.02816e+00\n",
            "epoch: 218, iter: 32, training_loss: 7.75941e-01\n",
            "epoch: 219, iter: 32, training_loss: 8.01860e-01\n",
            "epoch: 220, iter: 32, training_loss: 7.12147e-01\n",
            "epoch: 221, iter: 32, training_loss: 8.16508e-01\n",
            "epoch: 222, iter: 32, training_loss: 6.89794e-01\n",
            "epoch: 223, iter: 32, training_loss: 7.30893e-01\n",
            "epoch: 224, iter: 32, training_loss: 7.68277e-01\n",
            "epoch: 225, iter: 32, training_loss: 7.38167e-01\n",
            "epoch: 226, iter: 32, training_loss: 8.09960e-01\n",
            "epoch: 227, iter: 32, training_loss: 7.25697e-01\n",
            "epoch: 228, iter: 32, training_loss: 7.62583e-01\n",
            "epoch: 229, iter: 32, training_loss: 7.84075e-01\n",
            "epoch: 230, iter: 32, training_loss: 7.73727e-01\n",
            "epoch: 231, iter: 32, training_loss: 7.84056e-01\n",
            "epoch: 232, iter: 32, training_loss: 7.23671e-01\n",
            "epoch: 233, iter: 32, training_loss: 7.40406e-01\n",
            "epoch: 234, iter: 32, training_loss: 7.65283e-01\n",
            "epoch: 235, iter: 32, training_loss: 7.18908e-01\n",
            "epoch: 236, iter: 32, training_loss: 7.31411e-01\n",
            "epoch: 237, iter: 32, training_loss: 7.26345e-01\n",
            "epoch: 238, iter: 32, training_loss: 6.90525e-01\n",
            "epoch: 239, iter: 32, training_loss: 7.15747e-01\n",
            "epoch: 240, iter: 32, training_loss: 6.88773e-01\n",
            "epoch: 241, iter: 32, training_loss: 6.71223e-01\n",
            "epoch: 242, iter: 32, training_loss: 7.86908e-01\n",
            "epoch: 243, iter: 32, training_loss: 6.66829e-01\n",
            "epoch: 244, iter: 32, training_loss: 6.45086e-01\n",
            "epoch: 245, iter: 32, training_loss: 6.22617e-01\n",
            "epoch: 246, iter: 32, training_loss: 9.26353e-01\n",
            "epoch: 247, iter: 32, training_loss: 8.49010e-01\n",
            "epoch: 248, iter: 32, training_loss: 6.16591e-01\n",
            "epoch: 249, iter: 32, training_loss: 5.82338e-01\n",
            "epoch: 250, iter: 32, training_loss: 6.13912e-01\n",
            "epoch: 251, iter: 32, training_loss: 6.60016e-01\n",
            "epoch: 252, iter: 32, training_loss: 5.95332e-01\n",
            "epoch: 253, iter: 32, training_loss: 6.61381e-01\n",
            "epoch: 254, iter: 32, training_loss: 5.93367e-01\n",
            "epoch: 255, iter: 32, training_loss: 4.60075e-01\n",
            "epoch: 256, iter: 32, training_loss: 4.92265e-01\n",
            "epoch: 257, iter: 32, training_loss: 5.05331e-01\n",
            "epoch: 258, iter: 32, training_loss: 4.25681e-01\n",
            "epoch: 259, iter: 32, training_loss: 4.89638e-01\n",
            "epoch: 260, iter: 32, training_loss: 5.00407e-01\n",
            "epoch: 261, iter: 32, training_loss: 4.86655e-01\n",
            "epoch: 262, iter: 32, training_loss: 4.54101e-01\n",
            "epoch: 263, iter: 32, training_loss: 4.80986e-01\n",
            "epoch: 264, iter: 32, training_loss: 4.58682e-01\n",
            "epoch: 265, iter: 32, training_loss: 4.03547e-01\n",
            "epoch: 266, iter: 32, training_loss: 3.79826e-01\n",
            "epoch: 267, iter: 32, training_loss: 5.21285e-01\n",
            "epoch: 268, iter: 32, training_loss: 4.40052e-01\n",
            "epoch: 269, iter: 32, training_loss: 4.61559e-01\n",
            "epoch: 270, iter: 32, training_loss: 4.43121e-01\n",
            "epoch: 271, iter: 32, training_loss: 3.89238e-01\n",
            "epoch: 272, iter: 32, training_loss: 3.80616e-01\n",
            "epoch: 273, iter: 32, training_loss: 4.61930e-01\n",
            "epoch: 274, iter: 32, training_loss: 4.57210e-01\n",
            "epoch: 275, iter: 32, training_loss: 4.05741e-01\n",
            "epoch: 276, iter: 32, training_loss: 3.65338e-01\n",
            "epoch: 277, iter: 32, training_loss: 5.23084e-01\n",
            "epoch: 278, iter: 32, training_loss: 4.64109e-01\n",
            "epoch: 279, iter: 32, training_loss: 4.39238e-01\n",
            "epoch: 280, iter: 32, training_loss: 4.13081e-01\n",
            "epoch: 281, iter: 32, training_loss: 3.81507e-01\n",
            "epoch: 282, iter: 32, training_loss: 3.89381e-01\n",
            "epoch: 283, iter: 32, training_loss: 4.77992e-01\n",
            "epoch: 284, iter: 32, training_loss: 4.35894e-01\n",
            "epoch: 285, iter: 32, training_loss: 4.48672e-01\n",
            "epoch: 286, iter: 32, training_loss: 4.53128e-01\n",
            "epoch: 287, iter: 32, training_loss: 5.36128e-01\n",
            "epoch: 288, iter: 32, training_loss: 4.47057e-01\n",
            "epoch: 289, iter: 32, training_loss: 3.81277e-01\n",
            "epoch: 290, iter: 32, training_loss: 4.37636e-01\n",
            "epoch: 291, iter: 32, training_loss: 3.76466e-01\n",
            "epoch: 292, iter: 32, training_loss: 4.09821e-01\n",
            "epoch: 293, iter: 32, training_loss: 3.83433e-01\n",
            "epoch: 294, iter: 32, training_loss: 3.82556e-01\n",
            "epoch: 295, iter: 32, training_loss: 3.99752e-01\n",
            "epoch: 296, iter: 32, training_loss: 3.79117e-01\n",
            "epoch: 297, iter: 32, training_loss: 3.86124e-01\n",
            "epoch: 298, iter: 32, training_loss: 3.78739e-01\n",
            "epoch: 299, iter: 32, training_loss: 3.58694e-01\n",
            "epoch: 300, iter: 32, training_loss: 3.39869e-01\n",
            "epoch: 301, iter: 32, training_loss: 3.82918e-01\n",
            "epoch: 302, iter: 32, training_loss: 4.00932e-01\n",
            "epoch: 303, iter: 32, training_loss: 4.12743e-01\n",
            "epoch: 304, iter: 32, training_loss: 3.97254e-01\n",
            "epoch: 305, iter: 32, training_loss: 4.52680e-01\n",
            "epoch: 306, iter: 32, training_loss: 3.65912e-01\n",
            "epoch: 307, iter: 32, training_loss: 3.41003e-01\n",
            "epoch: 308, iter: 32, training_loss: 3.26751e-01\n",
            "epoch: 309, iter: 32, training_loss: 3.13823e-01\n",
            "epoch: 310, iter: 32, training_loss: 2.97968e-01\n",
            "epoch: 311, iter: 32, training_loss: 3.09025e-01\n",
            "epoch: 312, iter: 32, training_loss: 3.59139e-01\n",
            "epoch: 313, iter: 32, training_loss: 4.33438e-01\n",
            "epoch: 314, iter: 32, training_loss: 3.87784e-01\n",
            "epoch: 315, iter: 32, training_loss: 4.14727e-01\n",
            "epoch: 316, iter: 32, training_loss: 3.96307e-01\n",
            "epoch: 317, iter: 32, training_loss: 3.37927e-01\n",
            "epoch: 318, iter: 32, training_loss: 3.22760e-01\n",
            "epoch: 319, iter: 32, training_loss: 3.00752e-01\n",
            "epoch: 320, iter: 32, training_loss: 3.22618e-01\n",
            "epoch: 321, iter: 32, training_loss: 3.62545e-01\n",
            "epoch: 322, iter: 32, training_loss: 2.94627e-01\n",
            "epoch: 323, iter: 32, training_loss: 3.76977e-01\n",
            "epoch: 324, iter: 32, training_loss: 3.94005e-01\n",
            "epoch: 325, iter: 32, training_loss: 3.92385e-01\n",
            "epoch: 326, iter: 32, training_loss: 3.61324e-01\n",
            "epoch: 327, iter: 32, training_loss: 3.21271e-01\n",
            "epoch: 328, iter: 32, training_loss: 2.83272e-01\n",
            "epoch: 329, iter: 32, training_loss: 3.52392e-01\n",
            "epoch: 330, iter: 32, training_loss: 4.42985e-01\n",
            "epoch: 331, iter: 32, training_loss: 4.01663e-01\n",
            "epoch: 332, iter: 32, training_loss: 3.76970e-01\n",
            "epoch: 333, iter: 32, training_loss: 3.48558e-01\n",
            "epoch: 334, iter: 32, training_loss: 3.07605e-01\n",
            "epoch: 335, iter: 32, training_loss: 2.86089e-01\n",
            "epoch: 336, iter: 32, training_loss: 3.06600e-01\n",
            "epoch: 337, iter: 32, training_loss: 3.39052e-01\n",
            "epoch: 338, iter: 32, training_loss: 3.11206e-01\n",
            "epoch: 339, iter: 32, training_loss: 2.73982e-01\n",
            "epoch: 340, iter: 32, training_loss: 3.22173e-01\n",
            "epoch: 341, iter: 32, training_loss: 4.32459e-01\n",
            "epoch: 342, iter: 32, training_loss: 3.28077e-01\n",
            "epoch: 343, iter: 32, training_loss: 2.99212e-01\n",
            "epoch: 344, iter: 32, training_loss: 2.66396e-01\n",
            "epoch: 345, iter: 32, training_loss: 3.73685e-01\n",
            "epoch: 346, iter: 32, training_loss: 2.97459e-01\n",
            "epoch: 347, iter: 32, training_loss: 3.27930e-01\n",
            "epoch: 348, iter: 32, training_loss: 3.58051e-01\n",
            "epoch: 349, iter: 32, training_loss: 3.23459e-01\n",
            "epoch: 350, iter: 32, training_loss: 3.63160e-01\n",
            "epoch: 351, iter: 32, training_loss: 3.22429e-01\n",
            "epoch: 352, iter: 32, training_loss: 2.81181e-01\n",
            "epoch: 353, iter: 32, training_loss: 2.55295e-01\n",
            "epoch: 354, iter: 32, training_loss: 3.59243e-01\n",
            "epoch: 355, iter: 32, training_loss: 4.04501e-01\n",
            "epoch: 356, iter: 32, training_loss: 3.15191e-01\n",
            "epoch: 357, iter: 32, training_loss: 2.68614e-01\n",
            "epoch: 358, iter: 32, training_loss: 2.63354e-01\n",
            "epoch: 359, iter: 32, training_loss: 2.62509e-01\n",
            "epoch: 360, iter: 32, training_loss: 3.39561e-01\n",
            "epoch: 361, iter: 32, training_loss: 3.18012e-01\n",
            "epoch: 362, iter: 32, training_loss: 3.16196e-01\n",
            "epoch: 363, iter: 32, training_loss: 3.43440e-01\n",
            "epoch: 364, iter: 32, training_loss: 3.37849e-01\n",
            "epoch: 365, iter: 32, training_loss: 3.06316e-01\n",
            "epoch: 366, iter: 32, training_loss: 3.15990e-01\n",
            "epoch: 367, iter: 32, training_loss: 4.52168e-01\n",
            "epoch: 368, iter: 32, training_loss: 3.59267e-01\n",
            "epoch: 369, iter: 32, training_loss: 3.31510e-01\n",
            "epoch: 370, iter: 32, training_loss: 3.19902e-01\n",
            "epoch: 371, iter: 32, training_loss: 2.93948e-01\n",
            "epoch: 372, iter: 32, training_loss: 2.72893e-01\n",
            "epoch: 373, iter: 32, training_loss: 2.68466e-01\n",
            "epoch: 374, iter: 32, training_loss: 3.21003e-01\n",
            "epoch: 375, iter: 32, training_loss: 3.33573e-01\n",
            "epoch: 376, iter: 32, training_loss: 3.69572e-01\n",
            "epoch: 377, iter: 32, training_loss: 3.29101e-01\n",
            "epoch: 378, iter: 32, training_loss: 2.89034e-01\n",
            "epoch: 379, iter: 32, training_loss: 3.10036e-01\n",
            "epoch: 380, iter: 32, training_loss: 2.53308e-01\n",
            "epoch: 381, iter: 32, training_loss: 2.48869e-01\n",
            "epoch: 382, iter: 32, training_loss: 3.02553e-01\n",
            "epoch: 383, iter: 32, training_loss: 3.04146e-01\n",
            "epoch: 384, iter: 32, training_loss: 2.75228e-01\n",
            "epoch: 385, iter: 32, training_loss: 2.34842e-01\n",
            "epoch: 386, iter: 32, training_loss: 2.86684e-01\n",
            "epoch: 387, iter: 32, training_loss: 3.36696e-01\n",
            "epoch: 388, iter: 32, training_loss: 2.59383e-01\n",
            "epoch: 389, iter: 32, training_loss: 2.34681e-01\n",
            "epoch: 390, iter: 32, training_loss: 3.23406e-01\n",
            "epoch: 391, iter: 32, training_loss: 2.58126e-01\n",
            "epoch: 392, iter: 32, training_loss: 2.55367e-01\n",
            "epoch: 393, iter: 32, training_loss: 2.57302e-01\n",
            "epoch: 394, iter: 32, training_loss: 3.13719e-01\n",
            "epoch: 395, iter: 32, training_loss: 3.11066e-01\n",
            "epoch: 396, iter: 32, training_loss: 2.61992e-01\n",
            "epoch: 397, iter: 32, training_loss: 3.50911e-01\n",
            "epoch: 398, iter: 32, training_loss: 3.06324e-01\n",
            "epoch: 399, iter: 32, training_loss: 2.61768e-01\n",
            "epoch: 400, iter: 32, training_loss: 3.72217e-01\n",
            "epoch: 401, iter: 32, training_loss: 3.18865e-01\n",
            "epoch: 402, iter: 32, training_loss: 2.89260e-01\n",
            "epoch: 403, iter: 32, training_loss: 2.96434e-01\n",
            "epoch: 404, iter: 32, training_loss: 2.41559e-01\n",
            "epoch: 405, iter: 32, training_loss: 2.41578e-01\n",
            "epoch: 406, iter: 32, training_loss: 2.38889e-01\n",
            "epoch: 407, iter: 32, training_loss: 2.53100e-01\n",
            "epoch: 408, iter: 32, training_loss: 2.37220e-01\n",
            "epoch: 409, iter: 32, training_loss: 2.36102e-01\n",
            "epoch: 410, iter: 32, training_loss: 2.30067e-01\n",
            "epoch: 411, iter: 32, training_loss: 2.19379e-01\n",
            "epoch: 412, iter: 32, training_loss: 2.27338e-01\n",
            "epoch: 413, iter: 32, training_loss: 2.19737e-01\n",
            "epoch: 414, iter: 32, training_loss: 2.16880e-01\n",
            "epoch: 415, iter: 32, training_loss: 2.30964e-01\n",
            "epoch: 416, iter: 32, training_loss: 2.32051e-01\n",
            "epoch: 417, iter: 32, training_loss: 2.27794e-01\n",
            "epoch: 418, iter: 32, training_loss: 2.20898e-01\n",
            "epoch: 419, iter: 32, training_loss: 2.07935e-01\n",
            "epoch: 420, iter: 32, training_loss: 2.13409e-01\n",
            "epoch: 421, iter: 32, training_loss: 2.71420e-01\n",
            "epoch: 422, iter: 32, training_loss: 2.64484e-01\n",
            "epoch: 423, iter: 32, training_loss: 2.45640e-01\n",
            "epoch: 424, iter: 32, training_loss: 2.69656e-01\n",
            "epoch: 425, iter: 32, training_loss: 2.74480e-01\n",
            "epoch: 426, iter: 32, training_loss: 2.67290e-01\n",
            "epoch: 427, iter: 32, training_loss: 3.38316e-01\n",
            "epoch: 428, iter: 32, training_loss: 2.31779e-01\n",
            "epoch: 429, iter: 32, training_loss: 2.13976e-01\n",
            "epoch: 430, iter: 32, training_loss: 3.13783e-01\n",
            "epoch: 431, iter: 32, training_loss: 2.52811e-01\n",
            "epoch: 432, iter: 32, training_loss: 2.87481e-01\n",
            "epoch: 433, iter: 32, training_loss: 3.61428e-01\n",
            "epoch: 434, iter: 32, training_loss: 2.71647e-01\n",
            "epoch: 435, iter: 32, training_loss: 2.31279e-01\n",
            "epoch: 436, iter: 32, training_loss: 2.86483e-01\n",
            "epoch: 437, iter: 32, training_loss: 4.34538e-01\n",
            "epoch: 438, iter: 32, training_loss: 3.04583e-01\n",
            "epoch: 439, iter: 32, training_loss: 2.77080e-01\n",
            "epoch: 440, iter: 32, training_loss: 3.19241e-01\n",
            "epoch: 441, iter: 32, training_loss: 2.62000e-01\n",
            "epoch: 442, iter: 32, training_loss: 2.84748e-01\n",
            "epoch: 443, iter: 32, training_loss: 2.52485e-01\n",
            "epoch: 444, iter: 32, training_loss: 2.20971e-01\n",
            "epoch: 445, iter: 32, training_loss: 2.20966e-01\n",
            "epoch: 446, iter: 32, training_loss: 2.18765e-01\n",
            "epoch: 447, iter: 32, training_loss: 2.62404e-01\n",
            "epoch: 448, iter: 32, training_loss: 2.14642e-01\n",
            "epoch: 449, iter: 32, training_loss: 2.47612e-01\n",
            "epoch: 450, iter: 32, training_loss: 2.60282e-01\n",
            "epoch: 451, iter: 32, training_loss: 2.11152e-01\n",
            "epoch: 452, iter: 32, training_loss: 2.04815e-01\n",
            "epoch: 453, iter: 32, training_loss: 2.15001e-01\n",
            "epoch: 454, iter: 32, training_loss: 2.00939e-01\n",
            "epoch: 455, iter: 32, training_loss: 3.41408e-01\n",
            "epoch: 456, iter: 32, training_loss: 2.52647e-01\n",
            "epoch: 457, iter: 32, training_loss: 2.17013e-01\n",
            "epoch: 458, iter: 32, training_loss: 2.44754e-01\n",
            "epoch: 459, iter: 32, training_loss: 2.52056e-01\n",
            "epoch: 460, iter: 32, training_loss: 2.32256e-01\n",
            "epoch: 461, iter: 32, training_loss: 2.09503e-01\n",
            "epoch: 462, iter: 32, training_loss: 2.09385e-01\n",
            "epoch: 463, iter: 32, training_loss: 2.17781e-01\n",
            "epoch: 464, iter: 32, training_loss: 2.76470e-01\n",
            "epoch: 465, iter: 32, training_loss: 2.20847e-01\n",
            "epoch: 466, iter: 32, training_loss: 3.15057e-01\n",
            "epoch: 467, iter: 32, training_loss: 3.78527e-01\n",
            "epoch: 468, iter: 32, training_loss: 2.28803e-01\n",
            "epoch: 469, iter: 32, training_loss: 2.22632e-01\n",
            "epoch: 470, iter: 32, training_loss: 2.90929e-01\n",
            "epoch: 471, iter: 32, training_loss: 2.78907e-01\n",
            "epoch: 472, iter: 32, training_loss: 2.12964e-01\n",
            "epoch: 473, iter: 32, training_loss: 2.10212e-01\n",
            "epoch: 474, iter: 32, training_loss: 2.52156e-01\n",
            "epoch: 475, iter: 32, training_loss: 2.32208e-01\n",
            "epoch: 476, iter: 32, training_loss: 1.95866e-01\n",
            "epoch: 477, iter: 32, training_loss: 2.50115e-01\n",
            "epoch: 478, iter: 32, training_loss: 2.53843e-01\n",
            "epoch: 479, iter: 32, training_loss: 2.70887e-01\n",
            "epoch: 480, iter: 32, training_loss: 2.65723e-01\n",
            "epoch: 481, iter: 32, training_loss: 2.35474e-01\n",
            "epoch: 482, iter: 32, training_loss: 3.00090e-01\n",
            "epoch: 483, iter: 32, training_loss: 2.60880e-01\n",
            "epoch: 484, iter: 32, training_loss: 2.16980e-01\n",
            "epoch: 485, iter: 32, training_loss: 1.99383e-01\n",
            "epoch: 486, iter: 32, training_loss: 2.04659e-01\n",
            "epoch: 487, iter: 32, training_loss: 3.32432e-01\n",
            "epoch: 488, iter: 32, training_loss: 2.69940e-01\n",
            "epoch: 489, iter: 32, training_loss: 2.35702e-01\n",
            "epoch: 490, iter: 32, training_loss: 2.38105e-01\n",
            "epoch: 491, iter: 32, training_loss: 2.06644e-01\n",
            "epoch: 492, iter: 32, training_loss: 2.31251e-01\n",
            "epoch: 493, iter: 32, training_loss: 2.56329e-01\n",
            "epoch: 494, iter: 32, training_loss: 2.24307e-01\n",
            "epoch: 495, iter: 32, training_loss: 2.67319e-01\n",
            "epoch: 496, iter: 32, training_loss: 2.96461e-01\n",
            "epoch: 497, iter: 32, training_loss: 2.58064e-01\n",
            "epoch: 498, iter: 32, training_loss: 2.87393e-01\n",
            "epoch: 499, iter: 32, training_loss: 2.84146e-01\n",
            "epoch: 500, iter: 32, training_loss: 2.19295e-01\n",
            "epoch: 501, iter: 32, training_loss: 2.72670e-01\n",
            "epoch: 502, iter: 32, training_loss: 2.66803e-01\n",
            "epoch: 503, iter: 32, training_loss: 2.33755e-01\n",
            "epoch: 504, iter: 32, training_loss: 2.56445e-01\n",
            "epoch: 505, iter: 32, training_loss: 2.07491e-01\n",
            "epoch: 506, iter: 32, training_loss: 2.11923e-01\n",
            "epoch: 507, iter: 32, training_loss: 2.11431e-01\n",
            "epoch: 508, iter: 32, training_loss: 1.95633e-01\n",
            "epoch: 509, iter: 32, training_loss: 2.77136e-01\n",
            "epoch: 510, iter: 32, training_loss: 2.63704e-01\n",
            "epoch: 511, iter: 32, training_loss: 2.86296e-01\n",
            "epoch: 512, iter: 32, training_loss: 2.25531e-01\n",
            "epoch: 513, iter: 32, training_loss: 1.91613e-01\n",
            "epoch: 514, iter: 32, training_loss: 1.87984e-01\n",
            "epoch: 515, iter: 32, training_loss: 2.00868e-01\n",
            "epoch: 516, iter: 32, training_loss: 2.17025e-01\n",
            "epoch: 517, iter: 32, training_loss: 2.21479e-01\n",
            "epoch: 518, iter: 32, training_loss: 2.07230e-01\n",
            "epoch: 519, iter: 32, training_loss: 2.04312e-01\n",
            "epoch: 520, iter: 32, training_loss: 2.24682e-01\n",
            "epoch: 521, iter: 32, training_loss: 2.26677e-01\n",
            "epoch: 522, iter: 32, training_loss: 2.46857e-01\n",
            "epoch: 523, iter: 32, training_loss: 2.36576e-01\n",
            "epoch: 524, iter: 32, training_loss: 2.45902e-01\n",
            "epoch: 525, iter: 32, training_loss: 2.47038e-01\n",
            "epoch: 526, iter: 32, training_loss: 2.20164e-01\n",
            "epoch: 527, iter: 32, training_loss: 2.10871e-01\n",
            "epoch: 528, iter: 32, training_loss: 2.12966e-01\n",
            "epoch: 529, iter: 32, training_loss: 2.21797e-01\n",
            "epoch: 530, iter: 32, training_loss: 2.30115e-01\n",
            "epoch: 531, iter: 32, training_loss: 1.86905e-01\n",
            "epoch: 532, iter: 32, training_loss: 2.03046e-01\n",
            "epoch: 533, iter: 32, training_loss: 2.70220e-01\n",
            "epoch: 534, iter: 32, training_loss: 2.12735e-01\n",
            "epoch: 535, iter: 32, training_loss: 1.91193e-01\n",
            "epoch: 536, iter: 32, training_loss: 2.32618e-01\n",
            "epoch: 537, iter: 32, training_loss: 1.76978e-01\n",
            "epoch: 538, iter: 32, training_loss: 2.00283e-01\n",
            "epoch: 539, iter: 32, training_loss: 2.39036e-01\n",
            "epoch: 540, iter: 32, training_loss: 2.45373e-01\n",
            "epoch: 541, iter: 32, training_loss: 2.73948e-01\n",
            "epoch: 542, iter: 32, training_loss: 2.41927e-01\n",
            "epoch: 543, iter: 32, training_loss: 1.82912e-01\n",
            "epoch: 544, iter: 32, training_loss: 1.90820e-01\n",
            "epoch: 545, iter: 32, training_loss: 1.74155e-01\n",
            "epoch: 546, iter: 32, training_loss: 2.68609e-01\n",
            "epoch: 547, iter: 32, training_loss: 2.32459e-01\n",
            "epoch: 548, iter: 32, training_loss: 1.90538e-01\n",
            "epoch: 549, iter: 32, training_loss: 1.98587e-01\n",
            "epoch: 550, iter: 32, training_loss: 2.45572e-01\n",
            "epoch: 551, iter: 32, training_loss: 1.92996e-01\n",
            "epoch: 552, iter: 32, training_loss: 1.75849e-01\n",
            "epoch: 553, iter: 32, training_loss: 1.96344e-01\n",
            "epoch: 554, iter: 32, training_loss: 2.16494e-01\n",
            "epoch: 555, iter: 32, training_loss: 2.01765e-01\n",
            "epoch: 556, iter: 32, training_loss: 2.27199e-01\n",
            "epoch: 557, iter: 32, training_loss: 2.29599e-01\n",
            "epoch: 558, iter: 32, training_loss: 1.79167e-01\n",
            "epoch: 559, iter: 32, training_loss: 2.58580e-01\n",
            "epoch: 560, iter: 32, training_loss: 3.35218e-01\n",
            "epoch: 561, iter: 32, training_loss: 2.42203e-01\n",
            "epoch: 562, iter: 32, training_loss: 2.26686e-01\n",
            "epoch: 563, iter: 32, training_loss: 2.20407e-01\n",
            "epoch: 564, iter: 32, training_loss: 2.69877e-01\n",
            "epoch: 565, iter: 32, training_loss: 2.05891e-01\n",
            "epoch: 566, iter: 32, training_loss: 2.59765e-01\n",
            "epoch: 567, iter: 32, training_loss: 1.94122e-01\n",
            "epoch: 568, iter: 32, training_loss: 2.01869e-01\n",
            "epoch: 569, iter: 32, training_loss: 2.01271e-01\n",
            "epoch: 570, iter: 32, training_loss: 1.97872e-01\n",
            "epoch: 571, iter: 32, training_loss: 2.27924e-01\n",
            "epoch: 572, iter: 32, training_loss: 2.19743e-01\n",
            "epoch: 573, iter: 32, training_loss: 2.31514e-01\n",
            "epoch: 574, iter: 32, training_loss: 2.17813e-01\n",
            "epoch: 575, iter: 32, training_loss: 2.05185e-01\n",
            "epoch: 576, iter: 32, training_loss: 1.92249e-01\n",
            "epoch: 577, iter: 32, training_loss: 1.79869e-01\n",
            "epoch: 578, iter: 32, training_loss: 2.36181e-01\n",
            "epoch: 579, iter: 32, training_loss: 2.26320e-01\n",
            "epoch: 580, iter: 32, training_loss: 1.94600e-01\n",
            "epoch: 581, iter: 32, training_loss: 2.48782e-01\n",
            "epoch: 582, iter: 32, training_loss: 2.14865e-01\n",
            "epoch: 583, iter: 32, training_loss: 2.13764e-01\n",
            "epoch: 584, iter: 32, training_loss: 3.04111e-01\n",
            "epoch: 585, iter: 32, training_loss: 2.25196e-01\n",
            "epoch: 586, iter: 32, training_loss: 2.58639e-01\n",
            "epoch: 587, iter: 32, training_loss: 2.12289e-01\n",
            "epoch: 588, iter: 32, training_loss: 1.83986e-01\n",
            "epoch: 589, iter: 32, training_loss: 1.77047e-01\n",
            "epoch: 590, iter: 32, training_loss: 1.76876e-01\n",
            "epoch: 591, iter: 32, training_loss: 2.35312e-01\n",
            "epoch: 592, iter: 32, training_loss: 2.43668e-01\n",
            "epoch: 593, iter: 32, training_loss: 2.69883e-01\n",
            "epoch: 594, iter: 32, training_loss: 2.38512e-01\n",
            "epoch: 595, iter: 32, training_loss: 2.05520e-01\n",
            "epoch: 596, iter: 32, training_loss: 1.87328e-01\n",
            "epoch: 597, iter: 32, training_loss: 1.87349e-01\n",
            "epoch: 598, iter: 32, training_loss: 2.14880e-01\n",
            "epoch: 599, iter: 32, training_loss: 2.17679e-01\n",
            "epoch: 600, iter: 32, training_loss: 2.29770e-01\n",
            "epoch: 601, iter: 32, training_loss: 2.32882e-01\n",
            "epoch: 602, iter: 32, training_loss: 2.00652e-01\n",
            "epoch: 603, iter: 32, training_loss: 2.15190e-01\n",
            "epoch: 604, iter: 32, training_loss: 2.30210e-01\n",
            "epoch: 605, iter: 32, training_loss: 1.97279e-01\n",
            "epoch: 606, iter: 32, training_loss: 1.71790e-01\n",
            "epoch: 607, iter: 32, training_loss: 2.95893e-01\n",
            "epoch: 608, iter: 32, training_loss: 2.21145e-01\n",
            "epoch: 609, iter: 32, training_loss: 1.67626e-01\n",
            "epoch: 610, iter: 32, training_loss: 2.59786e-01\n",
            "epoch: 611, iter: 32, training_loss: 2.17298e-01\n",
            "epoch: 612, iter: 32, training_loss: 2.08692e-01\n",
            "epoch: 613, iter: 32, training_loss: 2.10021e-01\n",
            "epoch: 614, iter: 32, training_loss: 2.20482e-01\n",
            "epoch: 615, iter: 32, training_loss: 2.14161e-01\n",
            "epoch: 616, iter: 32, training_loss: 1.83889e-01\n",
            "epoch: 617, iter: 32, training_loss: 2.10897e-01\n",
            "epoch: 618, iter: 32, training_loss: 2.09387e-01\n",
            "epoch: 619, iter: 32, training_loss: 1.84892e-01\n",
            "epoch: 620, iter: 32, training_loss: 1.71207e-01\n",
            "epoch: 621, iter: 32, training_loss: 2.52098e-01\n",
            "epoch: 622, iter: 32, training_loss: 1.73528e-01\n",
            "epoch: 623, iter: 32, training_loss: 1.76647e-01\n",
            "epoch: 624, iter: 32, training_loss: 2.09970e-01\n",
            "epoch: 625, iter: 32, training_loss: 2.16756e-01\n",
            "epoch: 626, iter: 32, training_loss: 2.07740e-01\n",
            "epoch: 627, iter: 32, training_loss: 2.29798e-01\n",
            "epoch: 628, iter: 32, training_loss: 1.83138e-01\n",
            "epoch: 629, iter: 32, training_loss: 1.83454e-01\n",
            "epoch: 630, iter: 32, training_loss: 1.86049e-01\n",
            "epoch: 631, iter: 32, training_loss: 1.88118e-01\n",
            "epoch: 632, iter: 32, training_loss: 2.08913e-01\n",
            "epoch: 633, iter: 32, training_loss: 2.21147e-01\n",
            "epoch: 634, iter: 32, training_loss: 2.12081e-01\n",
            "epoch: 635, iter: 32, training_loss: 1.63836e-01\n",
            "epoch: 636, iter: 32, training_loss: 1.77004e-01\n",
            "epoch: 637, iter: 32, training_loss: 1.70622e-01\n",
            "epoch: 638, iter: 32, training_loss: 1.60240e-01\n",
            "epoch: 639, iter: 32, training_loss: 2.81978e-01\n",
            "epoch: 640, iter: 32, training_loss: 2.56580e-01\n",
            "epoch: 641, iter: 32, training_loss: 2.16743e-01\n",
            "epoch: 642, iter: 32, training_loss: 2.12869e-01\n",
            "epoch: 643, iter: 32, training_loss: 2.17695e-01\n",
            "epoch: 644, iter: 32, training_loss: 1.82960e-01\n",
            "epoch: 645, iter: 32, training_loss: 1.67495e-01\n",
            "epoch: 646, iter: 32, training_loss: 1.60847e-01\n",
            "epoch: 647, iter: 32, training_loss: 1.55477e-01\n",
            "epoch: 648, iter: 32, training_loss: 1.56969e-01\n",
            "epoch: 649, iter: 32, training_loss: 1.72550e-01\n",
            "epoch: 650, iter: 32, training_loss: 1.88086e-01\n",
            "epoch: 651, iter: 32, training_loss: 1.58772e-01\n",
            "epoch: 652, iter: 32, training_loss: 1.59919e-01\n",
            "epoch: 653, iter: 32, training_loss: 2.14256e-01\n",
            "epoch: 654, iter: 32, training_loss: 1.94044e-01\n",
            "epoch: 655, iter: 32, training_loss: 2.06041e-01\n",
            "epoch: 656, iter: 32, training_loss: 1.96792e-01\n",
            "epoch: 657, iter: 32, training_loss: 2.12665e-01\n",
            "epoch: 658, iter: 32, training_loss: 1.80195e-01\n",
            "epoch: 659, iter: 32, training_loss: 2.13392e-01\n",
            "epoch: 660, iter: 32, training_loss: 2.28564e-01\n",
            "epoch: 661, iter: 32, training_loss: 1.93335e-01\n",
            "epoch: 662, iter: 32, training_loss: 2.10310e-01\n",
            "epoch: 663, iter: 32, training_loss: 1.80194e-01\n",
            "epoch: 664, iter: 32, training_loss: 2.73361e-01\n",
            "epoch: 665, iter: 32, training_loss: 2.67112e-01\n",
            "epoch: 666, iter: 32, training_loss: 2.33441e-01\n",
            "epoch: 667, iter: 32, training_loss: 2.00638e-01\n",
            "epoch: 668, iter: 32, training_loss: 1.85463e-01\n",
            "epoch: 669, iter: 32, training_loss: 1.80168e-01\n",
            "epoch: 670, iter: 32, training_loss: 1.87451e-01\n",
            "epoch: 671, iter: 32, training_loss: 1.62321e-01\n",
            "epoch: 672, iter: 32, training_loss: 1.54926e-01\n",
            "epoch: 673, iter: 32, training_loss: 1.66936e-01\n",
            "epoch: 674, iter: 32, training_loss: 2.58134e-01\n",
            "epoch: 675, iter: 32, training_loss: 1.93162e-01\n",
            "epoch: 676, iter: 32, training_loss: 1.79075e-01\n",
            "epoch: 677, iter: 32, training_loss: 2.14279e-01\n",
            "epoch: 678, iter: 32, training_loss: 1.73241e-01\n",
            "epoch: 679, iter: 32, training_loss: 2.00116e-01\n",
            "epoch: 680, iter: 32, training_loss: 2.38922e-01\n",
            "epoch: 681, iter: 32, training_loss: 2.16108e-01\n",
            "epoch: 682, iter: 32, training_loss: 2.02480e-01\n",
            "epoch: 683, iter: 32, training_loss: 1.77187e-01\n",
            "epoch: 684, iter: 32, training_loss: 1.91514e-01\n",
            "epoch: 685, iter: 32, training_loss: 2.28187e-01\n",
            "epoch: 686, iter: 32, training_loss: 2.08868e-01\n",
            "epoch: 687, iter: 32, training_loss: 1.79386e-01\n",
            "epoch: 688, iter: 32, training_loss: 1.83983e-01\n",
            "epoch: 689, iter: 32, training_loss: 2.07121e-01\n",
            "epoch: 690, iter: 32, training_loss: 2.13431e-01\n",
            "epoch: 691, iter: 32, training_loss: 1.62189e-01\n",
            "epoch: 692, iter: 32, training_loss: 1.77316e-01\n",
            "epoch: 693, iter: 32, training_loss: 1.63511e-01\n",
            "epoch: 694, iter: 32, training_loss: 2.00334e-01\n",
            "epoch: 695, iter: 32, training_loss: 1.57184e-01\n",
            "epoch: 696, iter: 32, training_loss: 1.87095e-01\n",
            "epoch: 697, iter: 32, training_loss: 1.99237e-01\n",
            "epoch: 698, iter: 32, training_loss: 1.76958e-01\n",
            "epoch: 699, iter: 32, training_loss: 1.49338e-01\n",
            "epoch: 700, iter: 32, training_loss: 1.89910e-01\n",
            "epoch: 701, iter: 32, training_loss: 1.64749e-01\n",
            "epoch: 702, iter: 32, training_loss: 1.46606e-01\n",
            "epoch: 703, iter: 32, training_loss: 1.49260e-01\n",
            "epoch: 704, iter: 32, training_loss: 1.46413e-01\n",
            "epoch: 705, iter: 32, training_loss: 1.84748e-01\n",
            "epoch: 706, iter: 32, training_loss: 2.02135e-01\n",
            "epoch: 707, iter: 32, training_loss: 1.52588e-01\n",
            "epoch: 708, iter: 32, training_loss: 2.36360e-01\n",
            "epoch: 709, iter: 32, training_loss: 1.65156e-01\n",
            "epoch: 710, iter: 32, training_loss: 1.62633e-01\n",
            "epoch: 711, iter: 32, training_loss: 1.48956e-01\n",
            "epoch: 712, iter: 32, training_loss: 1.78503e-01\n",
            "epoch: 713, iter: 32, training_loss: 2.06411e-01\n",
            "epoch: 714, iter: 32, training_loss: 1.94658e-01\n",
            "epoch: 715, iter: 32, training_loss: 1.60216e-01\n",
            "epoch: 716, iter: 32, training_loss: 1.53803e-01\n",
            "epoch: 717, iter: 32, training_loss: 1.59734e-01\n",
            "epoch: 718, iter: 32, training_loss: 1.49642e-01\n",
            "epoch: 719, iter: 32, training_loss: 1.60382e-01\n",
            "epoch: 720, iter: 32, training_loss: 1.89769e-01\n",
            "epoch: 721, iter: 32, training_loss: 1.87052e-01\n",
            "epoch: 722, iter: 32, training_loss: 1.58317e-01\n",
            "epoch: 723, iter: 32, training_loss: 1.54849e-01\n",
            "epoch: 724, iter: 32, training_loss: 1.80185e-01\n",
            "epoch: 725, iter: 32, training_loss: 2.33620e-01\n",
            "epoch: 726, iter: 32, training_loss: 1.79626e-01\n",
            "epoch: 727, iter: 32, training_loss: 1.64861e-01\n",
            "epoch: 728, iter: 32, training_loss: 2.85420e-01\n",
            "epoch: 729, iter: 32, training_loss: 2.33229e-01\n",
            "epoch: 730, iter: 32, training_loss: 1.61412e-01\n",
            "epoch: 731, iter: 32, training_loss: 1.52952e-01\n",
            "epoch: 732, iter: 32, training_loss: 2.03723e-01\n",
            "epoch: 733, iter: 32, training_loss: 1.68450e-01\n",
            "epoch: 734, iter: 32, training_loss: 1.47982e-01\n",
            "epoch: 735, iter: 32, training_loss: 1.75545e-01\n",
            "epoch: 736, iter: 32, training_loss: 1.70543e-01\n",
            "epoch: 737, iter: 32, training_loss: 1.74322e-01\n",
            "epoch: 738, iter: 32, training_loss: 1.45366e-01\n",
            "epoch: 739, iter: 32, training_loss: 1.94764e-01\n",
            "epoch: 740, iter: 32, training_loss: 2.51088e-01\n",
            "epoch: 741, iter: 32, training_loss: 2.00864e-01\n",
            "epoch: 742, iter: 32, training_loss: 1.66091e-01\n",
            "epoch: 743, iter: 32, training_loss: 1.47898e-01\n",
            "epoch: 744, iter: 32, training_loss: 1.45136e-01\n",
            "epoch: 745, iter: 32, training_loss: 1.72575e-01\n",
            "epoch: 746, iter: 32, training_loss: 1.58704e-01\n",
            "epoch: 747, iter: 32, training_loss: 1.67618e-01\n",
            "epoch: 748, iter: 32, training_loss: 1.74913e-01\n",
            "epoch: 749, iter: 32, training_loss: 2.00642e-01\n",
            "epoch: 750, iter: 32, training_loss: 1.48503e-01\n",
            "epoch: 751, iter: 32, training_loss: 1.44143e-01\n",
            "epoch: 752, iter: 32, training_loss: 1.45381e-01\n",
            "epoch: 753, iter: 32, training_loss: 2.11086e-01\n",
            "epoch: 754, iter: 32, training_loss: 1.47064e-01\n",
            "epoch: 755, iter: 32, training_loss: 2.29291e-01\n",
            "epoch: 756, iter: 32, training_loss: 1.94227e-01\n",
            "epoch: 757, iter: 32, training_loss: 2.25789e-01\n",
            "epoch: 758, iter: 32, training_loss: 2.05127e-01\n",
            "epoch: 759, iter: 32, training_loss: 2.17604e-01\n",
            "epoch: 760, iter: 32, training_loss: 1.62250e-01\n",
            "epoch: 761, iter: 32, training_loss: 2.05955e-01\n",
            "epoch: 762, iter: 32, training_loss: 1.73045e-01\n",
            "epoch: 763, iter: 32, training_loss: 1.64734e-01\n",
            "epoch: 764, iter: 32, training_loss: 1.54349e-01\n",
            "epoch: 765, iter: 32, training_loss: 1.45893e-01\n",
            "epoch: 766, iter: 32, training_loss: 1.90203e-01\n",
            "epoch: 767, iter: 32, training_loss: 1.45555e-01\n",
            "epoch: 768, iter: 32, training_loss: 1.52485e-01\n",
            "epoch: 769, iter: 32, training_loss: 1.44082e-01\n",
            "epoch: 770, iter: 32, training_loss: 1.54074e-01\n",
            "epoch: 771, iter: 32, training_loss: 1.65938e-01\n",
            "epoch: 772, iter: 32, training_loss: 1.90425e-01\n",
            "epoch: 773, iter: 32, training_loss: 2.02454e-01\n",
            "epoch: 774, iter: 32, training_loss: 1.84115e-01\n",
            "epoch: 775, iter: 32, training_loss: 1.69053e-01\n",
            "epoch: 776, iter: 32, training_loss: 1.76624e-01\n",
            "epoch: 777, iter: 32, training_loss: 2.09693e-01\n",
            "epoch: 778, iter: 32, training_loss: 1.87231e-01\n",
            "epoch: 779, iter: 32, training_loss: 2.55452e-01\n",
            "epoch: 780, iter: 32, training_loss: 2.08425e-01\n",
            "epoch: 781, iter: 32, training_loss: 1.86378e-01\n",
            "epoch: 782, iter: 32, training_loss: 1.56621e-01\n",
            "epoch: 783, iter: 32, training_loss: 1.52183e-01\n",
            "epoch: 784, iter: 32, training_loss: 1.64800e-01\n",
            "epoch: 785, iter: 32, training_loss: 1.78591e-01\n",
            "epoch: 786, iter: 32, training_loss: 1.51497e-01\n",
            "epoch: 787, iter: 32, training_loss: 1.40058e-01\n",
            "epoch: 788, iter: 32, training_loss: 1.85007e-01\n",
            "epoch: 789, iter: 32, training_loss: 1.83690e-01\n",
            "epoch: 790, iter: 32, training_loss: 1.56022e-01\n",
            "epoch: 791, iter: 32, training_loss: 1.78875e-01\n",
            "epoch: 792, iter: 32, training_loss: 1.79021e-01\n",
            "epoch: 793, iter: 32, training_loss: 1.83847e-01\n",
            "epoch: 794, iter: 32, training_loss: 1.48779e-01\n",
            "epoch: 795, iter: 32, training_loss: 1.56041e-01\n",
            "epoch: 796, iter: 32, training_loss: 1.93850e-01\n",
            "epoch: 797, iter: 32, training_loss: 1.47102e-01\n",
            "epoch: 798, iter: 32, training_loss: 1.38163e-01\n",
            "epoch: 799, iter: 32, training_loss: 1.79355e-01\n",
            "epoch: 800, iter: 32, training_loss: 1.51693e-01\n",
            "epoch: 801, iter: 32, training_loss: 1.49789e-01\n",
            "epoch: 802, iter: 32, training_loss: 1.74973e-01\n",
            "epoch: 803, iter: 32, training_loss: 1.56672e-01\n",
            "epoch: 804, iter: 32, training_loss: 1.41669e-01\n",
            "epoch: 805, iter: 32, training_loss: 1.29612e-01\n",
            "epoch: 806, iter: 32, training_loss: 2.28807e-01\n",
            "epoch: 807, iter: 32, training_loss: 2.22179e-01\n",
            "epoch: 808, iter: 32, training_loss: 1.47440e-01\n",
            "epoch: 809, iter: 32, training_loss: 1.27334e-01\n",
            "epoch: 810, iter: 32, training_loss: 1.44441e-01\n",
            "epoch: 811, iter: 32, training_loss: 1.66861e-01\n",
            "epoch: 812, iter: 32, training_loss: 1.62429e-01\n",
            "epoch: 813, iter: 32, training_loss: 1.40108e-01\n",
            "epoch: 814, iter: 32, training_loss: 1.30351e-01\n",
            "epoch: 815, iter: 32, training_loss: 1.28960e-01\n",
            "epoch: 816, iter: 32, training_loss: 1.49084e-01\n",
            "epoch: 817, iter: 32, training_loss: 1.69515e-01\n",
            "epoch: 818, iter: 32, training_loss: 1.37690e-01\n",
            "epoch: 819, iter: 32, training_loss: 1.89084e-01\n",
            "epoch: 820, iter: 32, training_loss: 2.26145e-01\n",
            "epoch: 821, iter: 32, training_loss: 1.50412e-01\n",
            "epoch: 822, iter: 32, training_loss: 1.33765e-01\n",
            "epoch: 823, iter: 32, training_loss: 1.32703e-01\n",
            "epoch: 824, iter: 32, training_loss: 1.81655e-01\n",
            "epoch: 825, iter: 32, training_loss: 1.71153e-01\n",
            "epoch: 826, iter: 32, training_loss: 1.57039e-01\n",
            "epoch: 827, iter: 32, training_loss: 1.40980e-01\n",
            "epoch: 828, iter: 32, training_loss: 1.34169e-01\n",
            "epoch: 829, iter: 32, training_loss: 1.29257e-01\n",
            "epoch: 830, iter: 32, training_loss: 1.52058e-01\n",
            "epoch: 831, iter: 32, training_loss: 1.44075e-01\n",
            "epoch: 832, iter: 32, training_loss: 1.90133e-01\n",
            "epoch: 833, iter: 32, training_loss: 1.79342e-01\n",
            "epoch: 834, iter: 32, training_loss: 1.58366e-01\n",
            "epoch: 835, iter: 32, training_loss: 1.31075e-01\n",
            "epoch: 836, iter: 32, training_loss: 1.60186e-01\n",
            "epoch: 837, iter: 32, training_loss: 2.04613e-01\n",
            "epoch: 838, iter: 32, training_loss: 1.71084e-01\n",
            "epoch: 839, iter: 32, training_loss: 1.43111e-01\n",
            "epoch: 840, iter: 32, training_loss: 1.52030e-01\n",
            "epoch: 841, iter: 32, training_loss: 1.73752e-01\n",
            "epoch: 842, iter: 32, training_loss: 1.62249e-01\n",
            "epoch: 843, iter: 32, training_loss: 2.17586e-01\n",
            "epoch: 844, iter: 32, training_loss: 1.77860e-01\n",
            "epoch: 845, iter: 32, training_loss: 1.64057e-01\n",
            "epoch: 846, iter: 32, training_loss: 1.51247e-01\n",
            "epoch: 847, iter: 32, training_loss: 1.36237e-01\n",
            "epoch: 848, iter: 32, training_loss: 1.39381e-01\n",
            "epoch: 849, iter: 32, training_loss: 1.29127e-01\n",
            "epoch: 850, iter: 32, training_loss: 1.74555e-01\n",
            "epoch: 851, iter: 32, training_loss: 1.57418e-01\n",
            "epoch: 852, iter: 32, training_loss: 1.44081e-01\n",
            "epoch: 853, iter: 32, training_loss: 1.48546e-01\n",
            "epoch: 854, iter: 32, training_loss: 1.42525e-01\n",
            "epoch: 855, iter: 32, training_loss: 1.39657e-01\n",
            "epoch: 856, iter: 32, training_loss: 1.33843e-01\n",
            "epoch: 857, iter: 32, training_loss: 1.22573e-01\n",
            "epoch: 858, iter: 32, training_loss: 1.40345e-01\n",
            "epoch: 859, iter: 32, training_loss: 1.91265e-01\n",
            "epoch: 860, iter: 32, training_loss: 1.40762e-01\n",
            "epoch: 861, iter: 32, training_loss: 1.45362e-01\n",
            "epoch: 862, iter: 32, training_loss: 1.45452e-01\n",
            "epoch: 863, iter: 32, training_loss: 1.29675e-01\n",
            "epoch: 864, iter: 32, training_loss: 1.30366e-01\n",
            "epoch: 865, iter: 32, training_loss: 1.62300e-01\n",
            "epoch: 866, iter: 32, training_loss: 1.36609e-01\n",
            "epoch: 867, iter: 32, training_loss: 1.50745e-01\n",
            "epoch: 868, iter: 32, training_loss: 1.33808e-01\n",
            "epoch: 869, iter: 32, training_loss: 1.27269e-01\n",
            "epoch: 870, iter: 32, training_loss: 1.36471e-01\n",
            "epoch: 871, iter: 32, training_loss: 2.32229e-01\n",
            "epoch: 872, iter: 32, training_loss: 1.91140e-01\n",
            "epoch: 873, iter: 32, training_loss: 1.94374e-01\n",
            "epoch: 874, iter: 32, training_loss: 1.59073e-01\n",
            "epoch: 875, iter: 32, training_loss: 1.81916e-01\n",
            "epoch: 876, iter: 32, training_loss: 1.47178e-01\n",
            "epoch: 877, iter: 32, training_loss: 1.31828e-01\n",
            "epoch: 878, iter: 32, training_loss: 1.29107e-01\n",
            "epoch: 879, iter: 32, training_loss: 1.31356e-01\n",
            "epoch: 880, iter: 32, training_loss: 1.59358e-01\n",
            "epoch: 881, iter: 32, training_loss: 1.44254e-01\n",
            "epoch: 882, iter: 32, training_loss: 1.77337e-01\n",
            "epoch: 883, iter: 32, training_loss: 1.78735e-01\n",
            "epoch: 884, iter: 32, training_loss: 1.31300e-01\n",
            "epoch: 885, iter: 32, training_loss: 1.30934e-01\n",
            "epoch: 886, iter: 32, training_loss: 1.79304e-01\n",
            "epoch: 887, iter: 32, training_loss: 1.55979e-01\n",
            "epoch: 888, iter: 32, training_loss: 1.39583e-01\n",
            "epoch: 889, iter: 32, training_loss: 1.36849e-01\n",
            "epoch: 890, iter: 32, training_loss: 1.68836e-01\n",
            "epoch: 891, iter: 32, training_loss: 1.58729e-01\n",
            "epoch: 892, iter: 32, training_loss: 1.59274e-01\n",
            "epoch: 893, iter: 32, training_loss: 1.63263e-01\n",
            "epoch: 894, iter: 32, training_loss: 1.31440e-01\n",
            "epoch: 895, iter: 32, training_loss: 2.77204e-01\n",
            "epoch: 896, iter: 32, training_loss: 1.92474e-01\n",
            "epoch: 897, iter: 32, training_loss: 2.22231e-01\n",
            "epoch: 898, iter: 32, training_loss: 1.51961e-01\n",
            "epoch: 899, iter: 32, training_loss: 1.36507e-01\n",
            "epoch: 900, iter: 32, training_loss: 2.02325e-01\n",
            "epoch: 901, iter: 32, training_loss: 1.55981e-01\n",
            "epoch: 902, iter: 32, training_loss: 1.56000e-01\n",
            "epoch: 903, iter: 32, training_loss: 1.48118e-01\n",
            "epoch: 904, iter: 32, training_loss: 1.93287e-01\n",
            "epoch: 905, iter: 32, training_loss: 1.68755e-01\n",
            "epoch: 906, iter: 32, training_loss: 1.56437e-01\n",
            "epoch: 907, iter: 32, training_loss: 1.40321e-01\n",
            "epoch: 908, iter: 32, training_loss: 1.63547e-01\n",
            "epoch: 909, iter: 32, training_loss: 1.40249e-01\n",
            "epoch: 910, iter: 32, training_loss: 1.30570e-01\n",
            "epoch: 911, iter: 32, training_loss: 1.37337e-01\n",
            "epoch: 912, iter: 32, training_loss: 1.26337e-01\n",
            "epoch: 913, iter: 32, training_loss: 1.71290e-01\n",
            "epoch: 914, iter: 32, training_loss: 1.93896e-01\n",
            "epoch: 915, iter: 32, training_loss: 1.79211e-01\n",
            "epoch: 916, iter: 32, training_loss: 1.33169e-01\n",
            "epoch: 917, iter: 32, training_loss: 1.30144e-01\n",
            "epoch: 918, iter: 32, training_loss: 1.23179e-01\n",
            "epoch: 919, iter: 32, training_loss: 1.79475e-01\n",
            "epoch: 920, iter: 32, training_loss: 1.41439e-01\n",
            "epoch: 921, iter: 32, training_loss: 1.29321e-01\n",
            "epoch: 922, iter: 32, training_loss: 1.42433e-01\n",
            "epoch: 923, iter: 32, training_loss: 1.47539e-01\n",
            "epoch: 924, iter: 32, training_loss: 1.66017e-01\n",
            "epoch: 925, iter: 32, training_loss: 1.41850e-01\n",
            "epoch: 926, iter: 32, training_loss: 1.37697e-01\n",
            "epoch: 927, iter: 32, training_loss: 1.48086e-01\n",
            "epoch: 928, iter: 32, training_loss: 1.45545e-01\n",
            "epoch: 929, iter: 32, training_loss: 1.31467e-01\n",
            "epoch: 930, iter: 32, training_loss: 1.29147e-01\n",
            "epoch: 931, iter: 32, training_loss: 1.74507e-01\n",
            "epoch: 932, iter: 32, training_loss: 1.57089e-01\n",
            "epoch: 933, iter: 32, training_loss: 1.28000e-01\n",
            "epoch: 934, iter: 32, training_loss: 1.75813e-01\n",
            "epoch: 935, iter: 32, training_loss: 1.86830e-01\n",
            "epoch: 936, iter: 32, training_loss: 1.67404e-01\n",
            "epoch: 937, iter: 32, training_loss: 1.42393e-01\n",
            "epoch: 938, iter: 32, training_loss: 1.40409e-01\n",
            "epoch: 939, iter: 32, training_loss: 1.29097e-01\n",
            "epoch: 940, iter: 32, training_loss: 1.22406e-01\n",
            "epoch: 941, iter: 32, training_loss: 1.47050e-01\n",
            "epoch: 942, iter: 32, training_loss: 1.42401e-01\n",
            "epoch: 943, iter: 32, training_loss: 1.37083e-01\n",
            "epoch: 944, iter: 32, training_loss: 1.87844e-01\n",
            "epoch: 945, iter: 32, training_loss: 1.71558e-01\n",
            "epoch: 946, iter: 32, training_loss: 1.44639e-01\n",
            "epoch: 947, iter: 32, training_loss: 1.23700e-01\n",
            "epoch: 948, iter: 32, training_loss: 1.67515e-01\n",
            "epoch: 949, iter: 32, training_loss: 1.48669e-01\n",
            "epoch: 950, iter: 32, training_loss: 1.58835e-01\n",
            "epoch: 951, iter: 32, training_loss: 1.27019e-01\n",
            "epoch: 952, iter: 32, training_loss: 1.59551e-01\n",
            "epoch: 953, iter: 32, training_loss: 1.61023e-01\n",
            "epoch: 954, iter: 32, training_loss: 1.47407e-01\n",
            "epoch: 955, iter: 32, training_loss: 1.36754e-01\n",
            "epoch: 956, iter: 32, training_loss: 1.31940e-01\n",
            "epoch: 957, iter: 32, training_loss: 1.32061e-01\n",
            "epoch: 958, iter: 32, training_loss: 1.40494e-01\n",
            "epoch: 959, iter: 32, training_loss: 1.28294e-01\n",
            "epoch: 960, iter: 32, training_loss: 1.21679e-01\n",
            "epoch: 961, iter: 32, training_loss: 1.49558e-01\n",
            "epoch: 962, iter: 32, training_loss: 1.63976e-01\n",
            "epoch: 963, iter: 32, training_loss: 1.40841e-01\n",
            "epoch: 964, iter: 32, training_loss: 1.39804e-01\n",
            "epoch: 965, iter: 32, training_loss: 1.18414e-01\n",
            "epoch: 966, iter: 32, training_loss: 1.56184e-01\n",
            "epoch: 967, iter: 32, training_loss: 1.46661e-01\n",
            "epoch: 968, iter: 32, training_loss: 1.20057e-01\n",
            "epoch: 969, iter: 32, training_loss: 1.21170e-01\n",
            "epoch: 970, iter: 32, training_loss: 1.23605e-01\n",
            "epoch: 971, iter: 32, training_loss: 1.47288e-01\n",
            "epoch: 972, iter: 32, training_loss: 1.24719e-01\n",
            "epoch: 973, iter: 32, training_loss: 1.10800e-01\n",
            "epoch: 974, iter: 32, training_loss: 1.72437e-01\n",
            "epoch: 975, iter: 32, training_loss: 1.46239e-01\n",
            "epoch: 976, iter: 32, training_loss: 1.55705e-01\n",
            "epoch: 977, iter: 32, training_loss: 1.58336e-01\n",
            "epoch: 978, iter: 32, training_loss: 1.32835e-01\n",
            "epoch: 979, iter: 32, training_loss: 1.35187e-01\n",
            "epoch: 980, iter: 32, training_loss: 1.27247e-01\n",
            "epoch: 981, iter: 32, training_loss: 1.33271e-01\n",
            "epoch: 982, iter: 32, training_loss: 1.19177e-01\n",
            "epoch: 983, iter: 32, training_loss: 1.53537e-01\n",
            "epoch: 984, iter: 32, training_loss: 1.71010e-01\n",
            "epoch: 985, iter: 32, training_loss: 1.26335e-01\n",
            "epoch: 986, iter: 32, training_loss: 1.44492e-01\n",
            "epoch: 987, iter: 32, training_loss: 1.38707e-01\n",
            "epoch: 988, iter: 32, training_loss: 1.35530e-01\n",
            "epoch: 989, iter: 32, training_loss: 1.43253e-01\n",
            "epoch: 990, iter: 32, training_loss: 1.28909e-01\n",
            "epoch: 991, iter: 32, training_loss: 1.21983e-01\n",
            "epoch: 992, iter: 32, training_loss: 1.43863e-01\n",
            "epoch: 993, iter: 32, training_loss: 1.60144e-01\n",
            "epoch: 994, iter: 32, training_loss: 1.48769e-01\n",
            "epoch: 995, iter: 32, training_loss: 1.42192e-01\n",
            "epoch: 996, iter: 32, training_loss: 1.57906e-01\n",
            "epoch: 997, iter: 32, training_loss: 1.45148e-01\n",
            "epoch: 998, iter: 32, training_loss: 1.74185e-01\n",
            "epoch: 999, iter: 32, training_loss: 1.36232e-01\n",
            "epoch: 1000, iter: 32, training_loss: 1.42582e-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname adult --method stasy --mode sample --save_path adult_syn.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2uH7t8_UYeg",
        "outputId": "01575d2f-5764-478e-c186-ea763b19e1c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No NaNs in numerical features, skipping\n",
            "Input dimension: 110\n",
            "NCSNpp(\n",
            "  (act): ELU(alpha=1.0)\n",
            "  (all_modules): ModuleList(\n",
            "    (0): GaussianFourierProjection()\n",
            "    (1): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (3): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=110, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (4): ELU(alpha=1.0)\n",
            "    (5): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=1134, out_features=2048, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=2048, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=2048, bias=True)\n",
            "    )\n",
            "    (6): ELU(alpha=1.0)\n",
            "    (7): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=3182, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (8): ELU(alpha=1.0)\n",
            "    (9): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=4206, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (10): ELU(alpha=1.0)\n",
            "    (11): Linear(in_features=5230, out_features=110, bias=True)\n",
            "  )\n",
            ")\n",
            "the number of parameters 10695154\n",
            "Loading SAVED model at from /content/tabsyn/baselines/stasy/ckpt/adult/model.pth\n",
            "Start sampling...\n",
            "(32561, 9)\n",
            "Sampling time = 58.91957092285156\n",
            "Saving sampled data to adult_syn.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname magic --method stasy --mode train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-_mux8C-4xN",
        "outputId": "0b76ca7f-2c4c-4ac3-8377-057d4e673df2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No NaNs in numerical features, skipping\n",
            "12\n",
            "NCSNpp(\n",
            "  (act): ELU(alpha=1.0)\n",
            "  (all_modules): ModuleList(\n",
            "    (0): GaussianFourierProjection()\n",
            "    (1): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (3): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=12, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (4): ELU(alpha=1.0)\n",
            "    (5): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=1036, out_features=2048, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=2048, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=2048, bias=True)\n",
            "    )\n",
            "    (6): ELU(alpha=1.0)\n",
            "    (7): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=3084, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (8): ELU(alpha=1.0)\n",
            "    (9): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=4108, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (10): ELU(alpha=1.0)\n",
            "    (11): Linear(in_features=5132, out_features=12, bias=True)\n",
            "  )\n",
            ")\n",
            "the number of parameters 9679580\n",
            "epoch: 0, iter: 17, training_loss: 2.98496e+00\n",
            "epoch: 1, iter: 17, training_loss: 1.19238e+00\n",
            "epoch: 2, iter: 17, training_loss: 1.06764e+00\n",
            "epoch: 3, iter: 17, training_loss: 1.01781e+00\n",
            "epoch: 4, iter: 17, training_loss: 9.30309e-01\n",
            "epoch: 5, iter: 17, training_loss: 8.86004e-01\n",
            "epoch: 6, iter: 17, training_loss: 8.36056e-01\n",
            "epoch: 7, iter: 17, training_loss: 9.02443e-01\n",
            "epoch: 8, iter: 17, training_loss: 8.81824e-01\n",
            "epoch: 9, iter: 17, training_loss: 8.89109e-01\n",
            "epoch: 10, iter: 17, training_loss: 9.23137e-01\n",
            "epoch: 11, iter: 17, training_loss: 8.92498e-01\n",
            "epoch: 12, iter: 17, training_loss: 9.85869e-01\n",
            "epoch: 13, iter: 17, training_loss: 1.01547e+00\n",
            "epoch: 14, iter: 17, training_loss: 1.04378e+00\n",
            "epoch: 15, iter: 17, training_loss: 1.15113e+00\n",
            "epoch: 16, iter: 17, training_loss: 1.23489e+00\n",
            "epoch: 17, iter: 17, training_loss: 1.03259e+00\n",
            "epoch: 18, iter: 17, training_loss: 9.99357e-01\n",
            "epoch: 19, iter: 17, training_loss: 9.49625e-01\n",
            "epoch: 20, iter: 17, training_loss: 1.08361e+00\n",
            "epoch: 21, iter: 17, training_loss: 1.07912e+00\n",
            "epoch: 22, iter: 17, training_loss: 1.47499e+00\n",
            "epoch: 23, iter: 17, training_loss: 1.15331e+00\n",
            "epoch: 24, iter: 17, training_loss: 1.03223e+00\n",
            "epoch: 25, iter: 17, training_loss: 1.21411e+00\n",
            "epoch: 26, iter: 17, training_loss: 1.43867e+00\n",
            "epoch: 27, iter: 17, training_loss: 1.20020e+00\n",
            "epoch: 28, iter: 17, training_loss: 1.19474e+00\n",
            "epoch: 29, iter: 17, training_loss: 1.20464e+00\n",
            "epoch: 30, iter: 17, training_loss: 1.25415e+00\n",
            "epoch: 31, iter: 17, training_loss: 1.36146e+00\n",
            "epoch: 32, iter: 17, training_loss: 1.26653e+00\n",
            "epoch: 33, iter: 17, training_loss: 1.11257e+00\n",
            "epoch: 34, iter: 17, training_loss: 9.12066e-01\n",
            "epoch: 35, iter: 17, training_loss: 1.06170e+00\n",
            "epoch: 36, iter: 17, training_loss: 1.38565e+00\n",
            "epoch: 37, iter: 17, training_loss: 1.08540e+00\n",
            "epoch: 38, iter: 17, training_loss: 1.20562e+00\n",
            "epoch: 39, iter: 17, training_loss: 1.35516e+00\n",
            "epoch: 40, iter: 17, training_loss: 1.28241e+00\n",
            "epoch: 41, iter: 17, training_loss: 1.16978e+00\n",
            "epoch: 42, iter: 17, training_loss: 1.28579e+00\n",
            "epoch: 43, iter: 17, training_loss: 1.36284e+00\n",
            "epoch: 44, iter: 17, training_loss: 1.42640e+00\n",
            "epoch: 45, iter: 17, training_loss: 1.17996e+00\n",
            "epoch: 46, iter: 17, training_loss: 1.17401e+00\n",
            "epoch: 47, iter: 17, training_loss: 1.08684e+00\n",
            "epoch: 48, iter: 17, training_loss: 1.13631e+00\n",
            "epoch: 49, iter: 17, training_loss: 1.16271e+00\n",
            "epoch: 50, iter: 17, training_loss: 1.22355e+00\n",
            "epoch: 51, iter: 17, training_loss: 1.11728e+00\n",
            "epoch: 52, iter: 17, training_loss: 1.22413e+00\n",
            "epoch: 53, iter: 17, training_loss: 1.45977e+00\n",
            "epoch: 54, iter: 17, training_loss: 1.40942e+00\n",
            "epoch: 55, iter: 17, training_loss: 1.01166e+00\n",
            "epoch: 56, iter: 17, training_loss: 1.12434e+00\n",
            "epoch: 57, iter: 17, training_loss: 1.24039e+00\n",
            "epoch: 58, iter: 17, training_loss: 1.10955e+00\n",
            "epoch: 59, iter: 17, training_loss: 1.33056e+00\n",
            "epoch: 60, iter: 17, training_loss: 1.48328e+00\n",
            "epoch: 61, iter: 17, training_loss: 1.49674e+00\n",
            "epoch: 62, iter: 17, training_loss: 1.32983e+00\n",
            "epoch: 63, iter: 17, training_loss: 1.45279e+00\n",
            "epoch: 64, iter: 17, training_loss: 1.32667e+00\n",
            "epoch: 65, iter: 17, training_loss: 1.43418e+00\n",
            "epoch: 66, iter: 17, training_loss: 1.14672e+00\n",
            "epoch: 67, iter: 17, training_loss: 1.16161e+00\n",
            "epoch: 68, iter: 17, training_loss: 1.50653e+00\n",
            "epoch: 69, iter: 17, training_loss: 1.80919e+00\n",
            "epoch: 70, iter: 17, training_loss: 1.17722e+00\n",
            "epoch: 71, iter: 17, training_loss: 1.32331e+00\n",
            "epoch: 72, iter: 17, training_loss: 1.58998e+00\n",
            "epoch: 73, iter: 17, training_loss: 1.64033e+00\n",
            "epoch: 74, iter: 17, training_loss: 1.70812e+00\n",
            "epoch: 75, iter: 17, training_loss: 1.34099e+00\n",
            "epoch: 76, iter: 17, training_loss: 1.45862e+00\n",
            "epoch: 77, iter: 17, training_loss: 1.53111e+00\n",
            "epoch: 78, iter: 17, training_loss: 2.88849e+00\n",
            "epoch: 79, iter: 17, training_loss: 2.56149e+00\n",
            "epoch: 80, iter: 17, training_loss: 1.64654e+00\n",
            "epoch: 81, iter: 17, training_loss: 1.36703e+00\n",
            "epoch: 82, iter: 17, training_loss: 1.70403e+00\n",
            "epoch: 83, iter: 17, training_loss: 1.95972e+00\n",
            "epoch: 84, iter: 17, training_loss: 1.61818e+00\n",
            "epoch: 85, iter: 17, training_loss: 1.48520e+00\n",
            "epoch: 86, iter: 17, training_loss: 1.57174e+00\n",
            "epoch: 87, iter: 17, training_loss: 1.64235e+00\n",
            "epoch: 88, iter: 17, training_loss: 1.59778e+00\n",
            "epoch: 89, iter: 17, training_loss: 1.35624e+00\n",
            "epoch: 90, iter: 17, training_loss: 1.18619e+00\n",
            "epoch: 91, iter: 17, training_loss: 1.48734e+00\n",
            "epoch: 92, iter: 17, training_loss: 1.45192e+00\n",
            "epoch: 93, iter: 17, training_loss: 2.12397e+00\n",
            "epoch: 94, iter: 17, training_loss: 1.90887e+00\n",
            "epoch: 95, iter: 17, training_loss: 1.71957e+00\n",
            "epoch: 96, iter: 17, training_loss: 1.80077e+00\n",
            "epoch: 97, iter: 17, training_loss: 1.52946e+00\n",
            "epoch: 98, iter: 17, training_loss: 3.49140e+00\n",
            "epoch: 99, iter: 17, training_loss: 3.59004e+00\n",
            "epoch: 100, iter: 17, training_loss: 2.67667e+00\n",
            "epoch: 101, iter: 17, training_loss: 1.70692e+00\n",
            "epoch: 102, iter: 17, training_loss: 1.73024e+00\n",
            "epoch: 103, iter: 17, training_loss: 2.00765e+00\n",
            "epoch: 104, iter: 17, training_loss: 2.91040e+00\n",
            "epoch: 105, iter: 17, training_loss: 1.91068e+00\n",
            "epoch: 106, iter: 17, training_loss: 3.14145e+00\n",
            "epoch: 107, iter: 17, training_loss: 3.30543e+00\n",
            "epoch: 108, iter: 17, training_loss: 1.74528e+00\n",
            "epoch: 109, iter: 17, training_loss: 1.69182e+00\n",
            "epoch: 110, iter: 17, training_loss: 1.82674e+00\n",
            "epoch: 111, iter: 17, training_loss: 1.39042e+00\n",
            "epoch: 112, iter: 17, training_loss: 1.69042e+00\n",
            "epoch: 113, iter: 17, training_loss: 1.80623e+00\n",
            "epoch: 114, iter: 17, training_loss: 1.94456e+00\n",
            "epoch: 115, iter: 17, training_loss: 2.67348e+00\n",
            "epoch: 116, iter: 17, training_loss: 1.58718e+00\n",
            "epoch: 117, iter: 17, training_loss: 1.71921e+00\n",
            "epoch: 118, iter: 17, training_loss: 1.35513e+00\n",
            "epoch: 119, iter: 17, training_loss: 1.88553e+00\n",
            "epoch: 120, iter: 17, training_loss: 1.83867e+00\n",
            "epoch: 121, iter: 17, training_loss: 2.02362e+00\n",
            "epoch: 122, iter: 17, training_loss: 2.11291e+00\n",
            "epoch: 123, iter: 17, training_loss: 2.48994e+00\n",
            "epoch: 124, iter: 17, training_loss: 2.47646e+00\n",
            "epoch: 125, iter: 17, training_loss: 2.92037e+00\n",
            "epoch: 126, iter: 17, training_loss: 2.02980e+00\n",
            "epoch: 127, iter: 17, training_loss: 1.82728e+00\n",
            "epoch: 128, iter: 17, training_loss: 1.99064e+00\n",
            "epoch: 129, iter: 17, training_loss: 1.88923e+00\n",
            "epoch: 130, iter: 17, training_loss: 1.72656e+00\n",
            "epoch: 131, iter: 17, training_loss: 1.66243e+00\n",
            "epoch: 132, iter: 17, training_loss: 2.02419e+00\n",
            "epoch: 133, iter: 17, training_loss: 2.60313e+00\n",
            "epoch: 134, iter: 17, training_loss: 2.05287e+00\n",
            "epoch: 135, iter: 17, training_loss: 3.30499e+00\n",
            "epoch: 136, iter: 17, training_loss: 3.23386e+00\n",
            "epoch: 137, iter: 17, training_loss: 3.39168e+00\n",
            "epoch: 138, iter: 17, training_loss: 1.87776e+00\n",
            "epoch: 139, iter: 17, training_loss: 2.12219e+00\n",
            "epoch: 140, iter: 17, training_loss: 2.23547e+00\n",
            "epoch: 141, iter: 17, training_loss: 3.08250e+00\n",
            "epoch: 142, iter: 17, training_loss: 2.41171e+00\n",
            "epoch: 143, iter: 17, training_loss: 3.08033e+00\n",
            "epoch: 144, iter: 17, training_loss: 3.05206e+00\n",
            "epoch: 145, iter: 17, training_loss: 2.52789e+00\n",
            "epoch: 146, iter: 17, training_loss: 2.44503e+00\n",
            "epoch: 147, iter: 17, training_loss: 2.07218e+00\n",
            "epoch: 148, iter: 17, training_loss: 1.87372e+00\n",
            "epoch: 149, iter: 17, training_loss: 3.15233e+00\n",
            "epoch: 150, iter: 17, training_loss: 3.81334e+00\n",
            "epoch: 151, iter: 17, training_loss: 1.65718e+00\n",
            "epoch: 152, iter: 17, training_loss: 1.69137e+00\n",
            "epoch: 153, iter: 17, training_loss: 1.92676e+00\n",
            "epoch: 154, iter: 17, training_loss: 2.02721e+00\n",
            "epoch: 155, iter: 17, training_loss: 1.79402e+00\n",
            "epoch: 156, iter: 17, training_loss: 1.93409e+00\n",
            "epoch: 157, iter: 17, training_loss: 2.28602e+00\n",
            "epoch: 158, iter: 17, training_loss: 1.72987e+00\n",
            "epoch: 159, iter: 17, training_loss: 2.26676e+00\n",
            "epoch: 160, iter: 17, training_loss: 2.41374e+00\n",
            "epoch: 161, iter: 17, training_loss: 2.32802e+00\n",
            "epoch: 162, iter: 17, training_loss: 2.32626e+00\n",
            "epoch: 163, iter: 17, training_loss: 2.19400e+00\n",
            "epoch: 164, iter: 17, training_loss: 4.03381e+00\n",
            "epoch: 165, iter: 17, training_loss: 3.35954e+00\n",
            "epoch: 166, iter: 17, training_loss: 2.19024e+00\n",
            "epoch: 167, iter: 17, training_loss: 1.93480e+00\n",
            "epoch: 168, iter: 17, training_loss: 2.72694e+00\n",
            "epoch: 169, iter: 17, training_loss: 2.67744e+00\n",
            "epoch: 170, iter: 17, training_loss: 2.07017e+00\n",
            "epoch: 171, iter: 17, training_loss: 3.36885e+00\n",
            "epoch: 172, iter: 17, training_loss: 3.02445e+00\n",
            "epoch: 173, iter: 17, training_loss: 1.94741e+00\n",
            "epoch: 174, iter: 17, training_loss: 2.43701e+00\n",
            "epoch: 175, iter: 17, training_loss: 1.76538e+00\n",
            "epoch: 176, iter: 17, training_loss: 1.97247e+00\n",
            "epoch: 177, iter: 17, training_loss: 3.55822e+00\n",
            "epoch: 178, iter: 17, training_loss: 4.28892e+00\n",
            "epoch: 179, iter: 17, training_loss: 2.31672e+00\n",
            "epoch: 180, iter: 17, training_loss: 2.38131e+00\n",
            "epoch: 181, iter: 17, training_loss: 3.78648e+00\n",
            "epoch: 182, iter: 17, training_loss: 2.45352e+00\n",
            "epoch: 183, iter: 17, training_loss: 2.91044e+00\n",
            "epoch: 184, iter: 17, training_loss: 1.98415e+00\n",
            "epoch: 185, iter: 17, training_loss: 2.63828e+00\n",
            "epoch: 186, iter: 17, training_loss: 2.16924e+00\n",
            "epoch: 187, iter: 17, training_loss: 2.22900e+00\n",
            "epoch: 188, iter: 17, training_loss: 2.10739e+00\n",
            "epoch: 189, iter: 17, training_loss: 1.89301e+00\n",
            "epoch: 190, iter: 17, training_loss: 2.27840e+00\n",
            "epoch: 191, iter: 17, training_loss: 2.20501e+00\n",
            "epoch: 192, iter: 17, training_loss: 1.76407e+00\n",
            "epoch: 193, iter: 17, training_loss: 2.23363e+00\n",
            "epoch: 194, iter: 17, training_loss: 2.83263e+00\n",
            "epoch: 195, iter: 17, training_loss: 2.19649e+00\n",
            "epoch: 196, iter: 17, training_loss: 1.81616e+00\n",
            "epoch: 197, iter: 17, training_loss: 2.21588e+00\n",
            "epoch: 198, iter: 17, training_loss: 2.00709e+00\n",
            "epoch: 199, iter: 17, training_loss: 1.96153e+00\n",
            "epoch: 200, iter: 17, training_loss: 2.01590e+00\n",
            "epoch: 201, iter: 17, training_loss: 1.77482e+00\n",
            "epoch: 202, iter: 17, training_loss: 1.58149e+00\n",
            "epoch: 203, iter: 17, training_loss: 1.73156e+00\n",
            "epoch: 204, iter: 17, training_loss: 2.10036e+00\n",
            "epoch: 205, iter: 17, training_loss: 2.61526e+00\n",
            "epoch: 206, iter: 17, training_loss: 1.91221e+00\n",
            "epoch: 207, iter: 17, training_loss: 3.55575e+00\n",
            "epoch: 208, iter: 17, training_loss: 3.35729e+00\n",
            "epoch: 209, iter: 17, training_loss: 2.07388e+00\n",
            "epoch: 210, iter: 17, training_loss: 2.07036e+00\n",
            "epoch: 211, iter: 17, training_loss: 1.41968e+00\n",
            "epoch: 212, iter: 17, training_loss: 1.46694e+00\n",
            "epoch: 213, iter: 17, training_loss: 2.39529e+00\n",
            "epoch: 214, iter: 17, training_loss: 1.69903e+00\n",
            "epoch: 215, iter: 17, training_loss: 2.36948e+00\n",
            "epoch: 216, iter: 17, training_loss: 3.46606e+00\n",
            "epoch: 217, iter: 17, training_loss: 2.05107e+00\n",
            "epoch: 218, iter: 17, training_loss: 1.99731e+00\n",
            "epoch: 219, iter: 17, training_loss: 1.63932e+00\n",
            "epoch: 220, iter: 17, training_loss: 1.93314e+00\n",
            "epoch: 221, iter: 17, training_loss: 1.94725e+00\n",
            "epoch: 222, iter: 17, training_loss: 1.78205e+00\n",
            "epoch: 223, iter: 17, training_loss: 2.25881e+00\n",
            "epoch: 224, iter: 17, training_loss: 2.17091e+00\n",
            "epoch: 225, iter: 17, training_loss: 2.20630e+00\n",
            "epoch: 226, iter: 17, training_loss: 1.63376e+00\n",
            "epoch: 227, iter: 17, training_loss: 1.51383e+00\n",
            "epoch: 228, iter: 17, training_loss: 1.65115e+00\n",
            "epoch: 229, iter: 17, training_loss: 1.39233e+00\n",
            "epoch: 230, iter: 17, training_loss: 2.16827e+00\n",
            "epoch: 231, iter: 17, training_loss: 1.49355e+00\n",
            "epoch: 232, iter: 17, training_loss: 1.81634e+00\n",
            "epoch: 233, iter: 17, training_loss: 2.21401e+00\n",
            "epoch: 234, iter: 17, training_loss: 1.67008e+00\n",
            "epoch: 235, iter: 17, training_loss: 1.41849e+00\n",
            "epoch: 236, iter: 17, training_loss: 1.96760e+00\n",
            "epoch: 237, iter: 17, training_loss: 1.63238e+00\n",
            "epoch: 238, iter: 17, training_loss: 1.67326e+00\n",
            "epoch: 239, iter: 17, training_loss: 1.46596e+00\n",
            "epoch: 240, iter: 17, training_loss: 1.64333e+00\n",
            "epoch: 241, iter: 17, training_loss: 2.22383e+00\n",
            "epoch: 242, iter: 17, training_loss: 1.98094e+00\n",
            "epoch: 243, iter: 17, training_loss: 1.70560e+00\n",
            "epoch: 244, iter: 17, training_loss: 1.81086e+00\n",
            "epoch: 245, iter: 17, training_loss: 1.76886e+00\n",
            "epoch: 246, iter: 17, training_loss: 1.74652e+00\n",
            "epoch: 247, iter: 17, training_loss: 1.71519e+00\n",
            "epoch: 248, iter: 17, training_loss: 1.59617e+00\n",
            "epoch: 249, iter: 17, training_loss: 1.46844e+00\n",
            "epoch: 250, iter: 17, training_loss: 1.43195e+00\n",
            "epoch: 251, iter: 17, training_loss: 1.73935e+00\n",
            "epoch: 252, iter: 17, training_loss: 2.06409e+00\n",
            "epoch: 253, iter: 17, training_loss: 1.70180e+00\n",
            "epoch: 254, iter: 17, training_loss: 1.57434e+00\n",
            "epoch: 255, iter: 17, training_loss: 1.55305e+00\n",
            "epoch: 256, iter: 17, training_loss: 1.45957e+00\n",
            "epoch: 257, iter: 17, training_loss: 1.59329e+00\n",
            "epoch: 258, iter: 17, training_loss: 1.68824e+00\n",
            "epoch: 259, iter: 17, training_loss: 1.64061e+00\n",
            "epoch: 260, iter: 17, training_loss: 1.44994e+00\n",
            "epoch: 261, iter: 17, training_loss: 2.33634e+00\n",
            "epoch: 262, iter: 17, training_loss: 1.99484e+00\n",
            "epoch: 263, iter: 17, training_loss: 1.82010e+00\n",
            "epoch: 264, iter: 17, training_loss: 2.45746e+00\n",
            "epoch: 265, iter: 17, training_loss: 1.88152e+00\n",
            "epoch: 266, iter: 17, training_loss: 1.48554e+00\n",
            "epoch: 267, iter: 17, training_loss: 1.72668e+00\n",
            "epoch: 268, iter: 17, training_loss: 1.47540e+00\n",
            "epoch: 269, iter: 17, training_loss: 1.81061e+00\n",
            "epoch: 270, iter: 17, training_loss: 1.79186e+00\n",
            "epoch: 271, iter: 17, training_loss: 2.31273e+00\n",
            "epoch: 272, iter: 17, training_loss: 1.91190e+00\n",
            "epoch: 273, iter: 17, training_loss: 1.62242e+00\n",
            "epoch: 274, iter: 17, training_loss: 1.52947e+00\n",
            "epoch: 275, iter: 17, training_loss: 1.44372e+00\n",
            "epoch: 276, iter: 17, training_loss: 1.47524e+00\n",
            "epoch: 277, iter: 17, training_loss: 1.16329e+00\n",
            "epoch: 278, iter: 17, training_loss: 1.28810e+00\n",
            "epoch: 279, iter: 17, training_loss: 1.21322e+00\n",
            "epoch: 280, iter: 17, training_loss: 1.70578e+00\n",
            "epoch: 281, iter: 17, training_loss: 1.81317e+00\n",
            "epoch: 282, iter: 17, training_loss: 1.90635e+00\n",
            "epoch: 283, iter: 17, training_loss: 1.95747e+00\n",
            "epoch: 284, iter: 17, training_loss: 1.52115e+00\n",
            "epoch: 285, iter: 17, training_loss: 1.29720e+00\n",
            "epoch: 286, iter: 17, training_loss: 1.59427e+00\n",
            "epoch: 287, iter: 17, training_loss: 1.65341e+00\n",
            "epoch: 288, iter: 17, training_loss: 2.10369e+00\n",
            "epoch: 289, iter: 17, training_loss: 1.85551e+00\n",
            "epoch: 290, iter: 17, training_loss: 1.31779e+00\n",
            "epoch: 291, iter: 17, training_loss: 1.28187e+00\n",
            "epoch: 292, iter: 17, training_loss: 1.35777e+00\n",
            "epoch: 293, iter: 17, training_loss: 1.85175e+00\n",
            "epoch: 294, iter: 17, training_loss: 1.70000e+00\n",
            "epoch: 295, iter: 17, training_loss: 2.03981e+00\n",
            "epoch: 296, iter: 17, training_loss: 2.14596e+00\n",
            "epoch: 297, iter: 17, training_loss: 2.45102e+00\n",
            "epoch: 298, iter: 17, training_loss: 1.43812e+00\n",
            "epoch: 299, iter: 17, training_loss: 1.75229e+00\n",
            "epoch: 300, iter: 17, training_loss: 1.17434e+00\n",
            "epoch: 301, iter: 17, training_loss: 1.25352e+00\n",
            "epoch: 302, iter: 17, training_loss: 1.78372e+00\n",
            "epoch: 303, iter: 17, training_loss: 1.71523e+00\n",
            "epoch: 304, iter: 17, training_loss: 1.30328e+00\n",
            "epoch: 305, iter: 17, training_loss: 1.82091e+00\n",
            "epoch: 306, iter: 17, training_loss: 1.14829e+00\n",
            "epoch: 307, iter: 17, training_loss: 1.16255e+00\n",
            "epoch: 308, iter: 17, training_loss: 1.48377e+00\n",
            "epoch: 309, iter: 17, training_loss: 1.96745e+00\n",
            "epoch: 310, iter: 17, training_loss: 1.27894e+00\n",
            "epoch: 311, iter: 17, training_loss: 1.60514e+00\n",
            "epoch: 312, iter: 17, training_loss: 1.43386e+00\n",
            "epoch: 313, iter: 17, training_loss: 1.85268e+00\n",
            "epoch: 314, iter: 17, training_loss: 1.70741e+00\n",
            "epoch: 315, iter: 17, training_loss: 1.82898e+00\n",
            "epoch: 316, iter: 17, training_loss: 1.28516e+00\n",
            "epoch: 317, iter: 17, training_loss: 1.34734e+00\n",
            "epoch: 318, iter: 17, training_loss: 1.19832e+00\n",
            "epoch: 319, iter: 17, training_loss: 1.07604e+00\n",
            "epoch: 320, iter: 17, training_loss: 1.27280e+00\n",
            "epoch: 321, iter: 17, training_loss: 1.04934e+00\n",
            "epoch: 322, iter: 17, training_loss: 1.26022e+00\n",
            "epoch: 323, iter: 17, training_loss: 1.27518e+00\n",
            "epoch: 324, iter: 17, training_loss: 1.67097e+00\n",
            "epoch: 325, iter: 17, training_loss: 1.29588e+00\n",
            "epoch: 326, iter: 17, training_loss: 1.59646e+00\n",
            "epoch: 327, iter: 17, training_loss: 1.06209e+00\n",
            "epoch: 328, iter: 17, training_loss: 1.13760e+00\n",
            "epoch: 329, iter: 17, training_loss: 1.30651e+00\n",
            "epoch: 330, iter: 17, training_loss: 1.35867e+00\n",
            "epoch: 331, iter: 17, training_loss: 1.11447e+00\n",
            "epoch: 332, iter: 17, training_loss: 9.80990e-01\n",
            "epoch: 333, iter: 17, training_loss: 8.81259e-01\n",
            "epoch: 334, iter: 17, training_loss: 1.00150e+00\n",
            "epoch: 335, iter: 17, training_loss: 9.42278e-01\n",
            "epoch: 336, iter: 17, training_loss: 1.55253e+00\n",
            "epoch: 337, iter: 17, training_loss: 1.11629e+00\n",
            "epoch: 338, iter: 17, training_loss: 9.13836e-01\n",
            "epoch: 339, iter: 17, training_loss: 9.92734e-01\n",
            "epoch: 340, iter: 17, training_loss: 9.19119e-01\n",
            "epoch: 341, iter: 17, training_loss: 9.02946e-01\n",
            "epoch: 342, iter: 17, training_loss: 9.11667e-01\n",
            "epoch: 343, iter: 17, training_loss: 1.42993e+00\n",
            "epoch: 344, iter: 17, training_loss: 1.11174e+00\n",
            "epoch: 345, iter: 17, training_loss: 1.00705e+00\n",
            "epoch: 346, iter: 17, training_loss: 9.03487e-01\n",
            "epoch: 347, iter: 17, training_loss: 1.15640e+00\n",
            "epoch: 348, iter: 17, training_loss: 1.09424e+00\n",
            "epoch: 349, iter: 17, training_loss: 1.45407e+00\n",
            "epoch: 350, iter: 17, training_loss: 9.65762e-01\n",
            "epoch: 351, iter: 17, training_loss: 9.01132e-01\n",
            "epoch: 352, iter: 17, training_loss: 8.51006e-01\n",
            "epoch: 353, iter: 17, training_loss: 8.80234e-01\n",
            "epoch: 354, iter: 17, training_loss: 1.17716e+00\n",
            "epoch: 355, iter: 17, training_loss: 9.02515e-01\n",
            "epoch: 356, iter: 17, training_loss: 1.12915e+00\n",
            "epoch: 357, iter: 17, training_loss: 1.20043e+00\n",
            "epoch: 358, iter: 17, training_loss: 9.53812e-01\n",
            "epoch: 359, iter: 17, training_loss: 1.12131e+00\n",
            "epoch: 360, iter: 17, training_loss: 9.95464e-01\n",
            "epoch: 361, iter: 17, training_loss: 9.43983e-01\n",
            "epoch: 362, iter: 17, training_loss: 8.54477e-01\n",
            "epoch: 363, iter: 17, training_loss: 9.17550e-01\n",
            "epoch: 364, iter: 17, training_loss: 1.34888e+00\n",
            "epoch: 365, iter: 17, training_loss: 1.26979e+00\n",
            "epoch: 366, iter: 17, training_loss: 1.24645e+00\n",
            "epoch: 367, iter: 17, training_loss: 1.32014e+00\n",
            "epoch: 368, iter: 17, training_loss: 1.03717e+00\n",
            "epoch: 369, iter: 17, training_loss: 1.10358e+00\n",
            "epoch: 370, iter: 17, training_loss: 1.00702e+00\n",
            "epoch: 371, iter: 17, training_loss: 1.09261e+00\n",
            "epoch: 372, iter: 17, training_loss: 9.09332e-01\n",
            "epoch: 373, iter: 17, training_loss: 8.87803e-01\n",
            "epoch: 374, iter: 17, training_loss: 1.07646e+00\n",
            "epoch: 375, iter: 17, training_loss: 1.10552e+00\n",
            "epoch: 376, iter: 17, training_loss: 1.16466e+00\n",
            "epoch: 377, iter: 17, training_loss: 8.85146e-01\n",
            "epoch: 378, iter: 17, training_loss: 8.90378e-01\n",
            "epoch: 379, iter: 17, training_loss: 9.31359e-01\n",
            "epoch: 380, iter: 17, training_loss: 8.99858e-01\n",
            "epoch: 381, iter: 17, training_loss: 9.82251e-01\n",
            "epoch: 382, iter: 17, training_loss: 9.36104e-01\n",
            "epoch: 383, iter: 17, training_loss: 8.79513e-01\n",
            "epoch: 384, iter: 17, training_loss: 9.28235e-01\n",
            "epoch: 385, iter: 17, training_loss: 9.48722e-01\n",
            "epoch: 386, iter: 17, training_loss: 8.65006e-01\n",
            "epoch: 387, iter: 17, training_loss: 9.31177e-01\n",
            "epoch: 388, iter: 17, training_loss: 1.36816e+00\n",
            "epoch: 389, iter: 17, training_loss: 1.03273e+00\n",
            "epoch: 390, iter: 17, training_loss: 1.13532e+00\n",
            "epoch: 391, iter: 17, training_loss: 8.95907e-01\n",
            "epoch: 392, iter: 17, training_loss: 8.57313e-01\n",
            "epoch: 393, iter: 17, training_loss: 9.00130e-01\n",
            "epoch: 394, iter: 17, training_loss: 8.51805e-01\n",
            "epoch: 395, iter: 17, training_loss: 8.64876e-01\n",
            "epoch: 396, iter: 17, training_loss: 8.12470e-01\n",
            "epoch: 397, iter: 17, training_loss: 8.29998e-01\n",
            "epoch: 398, iter: 17, training_loss: 8.51073e-01\n",
            "epoch: 399, iter: 17, training_loss: 8.55620e-01\n",
            "epoch: 400, iter: 17, training_loss: 9.15348e-01\n",
            "epoch: 401, iter: 17, training_loss: 1.20764e+00\n",
            "epoch: 402, iter: 17, training_loss: 1.72156e+00\n",
            "epoch: 403, iter: 17, training_loss: 1.10547e+00\n",
            "epoch: 404, iter: 17, training_loss: 1.51918e+00\n",
            "epoch: 405, iter: 17, training_loss: 1.32343e+00\n",
            "epoch: 406, iter: 17, training_loss: 1.61917e+00\n",
            "epoch: 407, iter: 17, training_loss: 1.12540e+00\n",
            "epoch: 408, iter: 17, training_loss: 1.04850e+00\n",
            "epoch: 409, iter: 17, training_loss: 9.04752e-01\n",
            "epoch: 410, iter: 17, training_loss: 1.41453e+00\n",
            "epoch: 411, iter: 17, training_loss: 8.78379e-01\n",
            "epoch: 412, iter: 17, training_loss: 8.87388e-01\n",
            "epoch: 413, iter: 17, training_loss: 8.61107e-01\n",
            "epoch: 414, iter: 17, training_loss: 8.30851e-01\n",
            "epoch: 415, iter: 17, training_loss: 8.54626e-01\n",
            "epoch: 416, iter: 17, training_loss: 8.98593e-01\n",
            "epoch: 417, iter: 17, training_loss: 1.00125e+00\n",
            "epoch: 418, iter: 17, training_loss: 1.00856e+00\n",
            "epoch: 419, iter: 17, training_loss: 9.83144e-01\n",
            "epoch: 420, iter: 17, training_loss: 1.07880e+00\n",
            "epoch: 421, iter: 17, training_loss: 9.56772e-01\n",
            "epoch: 422, iter: 17, training_loss: 8.29741e-01\n",
            "epoch: 423, iter: 17, training_loss: 8.83474e-01\n",
            "epoch: 424, iter: 17, training_loss: 8.39067e-01\n",
            "epoch: 425, iter: 17, training_loss: 9.10825e-01\n",
            "epoch: 426, iter: 17, training_loss: 8.36780e-01\n",
            "epoch: 427, iter: 17, training_loss: 8.31981e-01\n",
            "epoch: 428, iter: 17, training_loss: 8.76544e-01\n",
            "epoch: 429, iter: 17, training_loss: 7.96141e-01\n",
            "epoch: 430, iter: 17, training_loss: 1.24869e+00\n",
            "epoch: 431, iter: 17, training_loss: 7.76032e-01\n",
            "epoch: 432, iter: 17, training_loss: 9.08996e-01\n",
            "epoch: 433, iter: 17, training_loss: 9.99354e-01\n",
            "epoch: 434, iter: 17, training_loss: 8.19932e-01\n",
            "epoch: 435, iter: 17, training_loss: 8.38750e-01\n",
            "epoch: 436, iter: 17, training_loss: 8.05764e-01\n",
            "epoch: 437, iter: 17, training_loss: 9.92570e-01\n",
            "epoch: 438, iter: 17, training_loss: 9.65929e-01\n",
            "epoch: 439, iter: 17, training_loss: 8.26976e-01\n",
            "epoch: 440, iter: 17, training_loss: 8.62060e-01\n",
            "epoch: 441, iter: 17, training_loss: 1.02128e+00\n",
            "epoch: 442, iter: 17, training_loss: 8.77695e-01\n",
            "epoch: 443, iter: 17, training_loss: 1.00125e+00\n",
            "epoch: 444, iter: 17, training_loss: 8.60627e-01\n",
            "epoch: 445, iter: 17, training_loss: 8.40797e-01\n",
            "epoch: 446, iter: 17, training_loss: 8.21810e-01\n",
            "epoch: 447, iter: 17, training_loss: 8.33247e-01\n",
            "epoch: 448, iter: 17, training_loss: 7.87946e-01\n",
            "epoch: 449, iter: 17, training_loss: 8.09462e-01\n",
            "epoch: 450, iter: 17, training_loss: 8.41266e-01\n",
            "epoch: 451, iter: 17, training_loss: 8.88321e-01\n",
            "epoch: 452, iter: 17, training_loss: 8.14182e-01\n",
            "epoch: 453, iter: 17, training_loss: 7.39206e-01\n",
            "epoch: 454, iter: 17, training_loss: 7.15504e-01\n",
            "epoch: 455, iter: 17, training_loss: 6.93821e-01\n",
            "epoch: 456, iter: 17, training_loss: 7.77532e-01\n",
            "epoch: 457, iter: 17, training_loss: 6.88647e-01\n",
            "epoch: 458, iter: 17, training_loss: 7.73993e-01\n",
            "epoch: 459, iter: 17, training_loss: 8.36526e-01\n",
            "epoch: 460, iter: 17, training_loss: 7.86402e-01\n",
            "epoch: 461, iter: 17, training_loss: 7.07010e-01\n",
            "epoch: 462, iter: 17, training_loss: 8.63082e-01\n",
            "epoch: 463, iter: 17, training_loss: 8.03796e-01\n",
            "epoch: 464, iter: 17, training_loss: 8.46823e-01\n",
            "epoch: 465, iter: 17, training_loss: 7.27681e-01\n",
            "epoch: 466, iter: 17, training_loss: 8.06359e-01\n",
            "epoch: 467, iter: 17, training_loss: 7.55467e-01\n",
            "epoch: 468, iter: 17, training_loss: 6.82572e-01\n",
            "epoch: 469, iter: 17, training_loss: 6.68278e-01\n",
            "epoch: 470, iter: 17, training_loss: 7.47648e-01\n",
            "epoch: 471, iter: 17, training_loss: 6.99550e-01\n",
            "epoch: 472, iter: 17, training_loss: 7.13756e-01\n",
            "epoch: 473, iter: 17, training_loss: 8.17676e-01\n",
            "epoch: 474, iter: 17, training_loss: 7.41388e-01\n",
            "epoch: 475, iter: 17, training_loss: 6.71433e-01\n",
            "epoch: 476, iter: 17, training_loss: 6.59412e-01\n",
            "epoch: 477, iter: 17, training_loss: 7.59794e-01\n",
            "epoch: 478, iter: 17, training_loss: 9.11397e-01\n",
            "epoch: 479, iter: 17, training_loss: 7.67094e-01\n",
            "epoch: 480, iter: 17, training_loss: 7.16775e-01\n",
            "epoch: 481, iter: 17, training_loss: 7.69435e-01\n",
            "epoch: 482, iter: 17, training_loss: 6.91557e-01\n",
            "epoch: 483, iter: 17, training_loss: 6.82900e-01\n",
            "epoch: 484, iter: 17, training_loss: 8.56700e-01\n",
            "epoch: 485, iter: 17, training_loss: 7.59795e-01\n",
            "epoch: 486, iter: 17, training_loss: 7.73900e-01\n",
            "epoch: 487, iter: 17, training_loss: 9.29167e-01\n",
            "epoch: 488, iter: 17, training_loss: 8.11547e-01\n",
            "epoch: 489, iter: 17, training_loss: 7.57686e-01\n",
            "epoch: 490, iter: 17, training_loss: 9.14138e-01\n",
            "epoch: 491, iter: 17, training_loss: 1.04185e+00\n",
            "epoch: 492, iter: 17, training_loss: 1.11072e+00\n",
            "epoch: 493, iter: 17, training_loss: 9.19894e-01\n",
            "epoch: 494, iter: 17, training_loss: 8.47648e-01\n",
            "epoch: 495, iter: 17, training_loss: 8.18768e-01\n",
            "epoch: 496, iter: 17, training_loss: 8.60892e-01\n",
            "epoch: 497, iter: 17, training_loss: 8.39618e-01\n",
            "epoch: 498, iter: 17, training_loss: 7.97379e-01\n",
            "epoch: 499, iter: 17, training_loss: 7.19181e-01\n",
            "epoch: 500, iter: 17, training_loss: 6.96402e-01\n",
            "epoch: 501, iter: 17, training_loss: 8.37371e-01\n",
            "epoch: 502, iter: 17, training_loss: 8.08810e-01\n",
            "epoch: 503, iter: 17, training_loss: 7.00459e-01\n",
            "epoch: 504, iter: 17, training_loss: 7.09528e-01\n",
            "epoch: 505, iter: 17, training_loss: 7.42798e-01\n",
            "epoch: 506, iter: 17, training_loss: 7.23733e-01\n",
            "epoch: 507, iter: 17, training_loss: 6.71921e-01\n",
            "epoch: 508, iter: 17, training_loss: 7.18794e-01\n",
            "epoch: 509, iter: 17, training_loss: 7.18400e-01\n",
            "epoch: 510, iter: 17, training_loss: 7.05696e-01\n",
            "epoch: 511, iter: 17, training_loss: 7.83261e-01\n",
            "epoch: 512, iter: 17, training_loss: 9.35441e-01\n",
            "epoch: 513, iter: 17, training_loss: 7.80374e-01\n",
            "epoch: 514, iter: 17, training_loss: 7.41220e-01\n",
            "epoch: 515, iter: 17, training_loss: 7.16029e-01\n",
            "epoch: 516, iter: 17, training_loss: 1.16227e+00\n",
            "epoch: 517, iter: 17, training_loss: 7.97568e-01\n",
            "epoch: 518, iter: 17, training_loss: 6.94360e-01\n",
            "epoch: 519, iter: 17, training_loss: 9.77584e-01\n",
            "epoch: 520, iter: 17, training_loss: 7.46304e-01\n",
            "epoch: 521, iter: 17, training_loss: 9.52493e-01\n",
            "epoch: 522, iter: 17, training_loss: 6.83148e-01\n",
            "epoch: 523, iter: 17, training_loss: 8.53042e-01\n",
            "epoch: 524, iter: 17, training_loss: 8.86876e-01\n",
            "epoch: 525, iter: 17, training_loss: 6.92654e-01\n",
            "epoch: 526, iter: 17, training_loss: 6.92583e-01\n",
            "epoch: 527, iter: 17, training_loss: 8.28541e-01\n",
            "epoch: 528, iter: 17, training_loss: 1.01425e+00\n",
            "epoch: 529, iter: 17, training_loss: 1.04685e+00\n",
            "epoch: 530, iter: 17, training_loss: 7.14103e-01\n",
            "epoch: 531, iter: 17, training_loss: 7.45618e-01\n",
            "epoch: 532, iter: 17, training_loss: 7.09952e-01\n",
            "epoch: 533, iter: 17, training_loss: 6.68111e-01\n",
            "epoch: 534, iter: 17, training_loss: 6.35232e-01\n",
            "epoch: 535, iter: 17, training_loss: 6.04028e-01\n",
            "epoch: 536, iter: 17, training_loss: 6.53888e-01\n",
            "epoch: 537, iter: 17, training_loss: 1.02033e+00\n",
            "epoch: 538, iter: 17, training_loss: 7.26824e-01\n",
            "epoch: 539, iter: 17, training_loss: 6.99431e-01\n",
            "epoch: 540, iter: 17, training_loss: 6.74334e-01\n",
            "epoch: 541, iter: 17, training_loss: 6.44517e-01\n",
            "epoch: 542, iter: 17, training_loss: 6.25172e-01\n",
            "epoch: 543, iter: 17, training_loss: 6.12832e-01\n",
            "epoch: 544, iter: 17, training_loss: 5.98615e-01\n",
            "epoch: 545, iter: 17, training_loss: 8.43171e-01\n",
            "epoch: 546, iter: 17, training_loss: 1.04143e+00\n",
            "epoch: 547, iter: 17, training_loss: 7.13534e-01\n",
            "epoch: 548, iter: 17, training_loss: 6.73610e-01\n",
            "epoch: 549, iter: 17, training_loss: 6.66206e-01\n",
            "epoch: 550, iter: 17, training_loss: 6.62917e-01\n",
            "epoch: 551, iter: 17, training_loss: 6.68750e-01\n",
            "epoch: 552, iter: 17, training_loss: 6.22187e-01\n",
            "epoch: 553, iter: 17, training_loss: 6.14915e-01\n",
            "epoch: 554, iter: 17, training_loss: 6.08756e-01\n",
            "epoch: 555, iter: 17, training_loss: 6.31540e-01\n",
            "epoch: 556, iter: 17, training_loss: 6.98740e-01\n",
            "epoch: 557, iter: 17, training_loss: 7.10269e-01\n",
            "epoch: 558, iter: 17, training_loss: 6.68894e-01\n",
            "epoch: 559, iter: 17, training_loss: 6.56609e-01\n",
            "epoch: 560, iter: 17, training_loss: 6.21868e-01\n",
            "epoch: 561, iter: 17, training_loss: 6.08248e-01\n",
            "epoch: 562, iter: 17, training_loss: 7.33246e-01\n",
            "epoch: 563, iter: 17, training_loss: 6.75708e-01\n",
            "epoch: 564, iter: 17, training_loss: 5.97180e-01\n",
            "epoch: 565, iter: 17, training_loss: 6.48082e-01\n",
            "epoch: 566, iter: 17, training_loss: 6.10602e-01\n",
            "epoch: 567, iter: 17, training_loss: 7.37180e-01\n",
            "epoch: 568, iter: 17, training_loss: 7.25171e-01\n",
            "epoch: 569, iter: 17, training_loss: 6.74270e-01\n",
            "epoch: 570, iter: 17, training_loss: 7.03518e-01\n",
            "epoch: 571, iter: 17, training_loss: 6.58697e-01\n",
            "epoch: 572, iter: 17, training_loss: 6.63528e-01\n",
            "epoch: 573, iter: 17, training_loss: 7.42886e-01\n",
            "epoch: 574, iter: 17, training_loss: 1.13342e+00\n",
            "epoch: 575, iter: 17, training_loss: 8.88518e-01\n",
            "epoch: 576, iter: 17, training_loss: 7.10347e-01\n",
            "epoch: 577, iter: 17, training_loss: 6.57006e-01\n",
            "epoch: 578, iter: 17, training_loss: 6.42034e-01\n",
            "epoch: 579, iter: 17, training_loss: 6.60705e-01\n",
            "epoch: 580, iter: 17, training_loss: 6.97789e-01\n",
            "epoch: 581, iter: 17, training_loss: 6.68508e-01\n",
            "epoch: 582, iter: 17, training_loss: 6.66127e-01\n",
            "epoch: 583, iter: 17, training_loss: 6.54655e-01\n",
            "epoch: 584, iter: 17, training_loss: 6.11200e-01\n",
            "epoch: 585, iter: 17, training_loss: 6.12288e-01\n",
            "epoch: 586, iter: 17, training_loss: 7.48759e-01\n",
            "epoch: 587, iter: 17, training_loss: 8.37793e-01\n",
            "epoch: 588, iter: 17, training_loss: 6.17000e-01\n",
            "epoch: 589, iter: 17, training_loss: 6.92916e-01\n",
            "epoch: 590, iter: 17, training_loss: 6.87809e-01\n",
            "epoch: 591, iter: 17, training_loss: 6.20439e-01\n",
            "epoch: 592, iter: 17, training_loss: 6.28276e-01\n",
            "epoch: 593, iter: 17, training_loss: 6.49601e-01\n",
            "epoch: 594, iter: 17, training_loss: 6.26915e-01\n",
            "epoch: 595, iter: 17, training_loss: 6.44958e-01\n",
            "epoch: 596, iter: 17, training_loss: 6.83013e-01\n",
            "epoch: 597, iter: 17, training_loss: 6.61924e-01\n",
            "epoch: 598, iter: 17, training_loss: 9.32782e-01\n",
            "epoch: 599, iter: 17, training_loss: 1.00514e+00\n",
            "epoch: 600, iter: 17, training_loss: 9.68982e-01\n",
            "epoch: 601, iter: 17, training_loss: 9.42091e-01\n",
            "epoch: 602, iter: 17, training_loss: 8.48985e-01\n",
            "epoch: 603, iter: 17, training_loss: 8.30516e-01\n",
            "epoch: 604, iter: 17, training_loss: 7.05904e-01\n",
            "epoch: 605, iter: 17, training_loss: 6.43353e-01\n",
            "epoch: 606, iter: 17, training_loss: 6.43848e-01\n",
            "epoch: 607, iter: 17, training_loss: 7.50630e-01\n",
            "epoch: 608, iter: 17, training_loss: 7.20306e-01\n",
            "epoch: 609, iter: 17, training_loss: 6.05901e-01\n",
            "epoch: 610, iter: 17, training_loss: 6.14500e-01\n",
            "epoch: 611, iter: 17, training_loss: 6.56657e-01\n",
            "epoch: 612, iter: 17, training_loss: 6.54609e-01\n",
            "epoch: 613, iter: 17, training_loss: 6.34629e-01\n",
            "epoch: 614, iter: 17, training_loss: 7.23931e-01\n",
            "epoch: 615, iter: 17, training_loss: 6.33401e-01\n",
            "epoch: 616, iter: 17, training_loss: 6.15777e-01\n",
            "epoch: 617, iter: 17, training_loss: 6.70426e-01\n",
            "epoch: 618, iter: 17, training_loss: 6.40839e-01\n",
            "epoch: 619, iter: 17, training_loss: 6.71050e-01\n",
            "epoch: 620, iter: 17, training_loss: 6.80420e-01\n",
            "epoch: 621, iter: 17, training_loss: 6.97143e-01\n",
            "epoch: 622, iter: 17, training_loss: 1.21050e+00\n",
            "epoch: 623, iter: 17, training_loss: 9.06259e-01\n",
            "epoch: 624, iter: 17, training_loss: 7.77283e-01\n",
            "epoch: 625, iter: 17, training_loss: 6.92659e-01\n",
            "epoch: 626, iter: 17, training_loss: 6.32496e-01\n",
            "epoch: 627, iter: 17, training_loss: 5.98873e-01\n",
            "epoch: 628, iter: 17, training_loss: 6.36401e-01\n",
            "epoch: 629, iter: 17, training_loss: 6.33109e-01\n",
            "epoch: 630, iter: 17, training_loss: 7.09531e-01\n",
            "epoch: 631, iter: 17, training_loss: 6.60061e-01\n",
            "epoch: 632, iter: 17, training_loss: 6.43640e-01\n",
            "epoch: 633, iter: 17, training_loss: 6.34146e-01\n",
            "epoch: 634, iter: 17, training_loss: 6.42542e-01\n",
            "epoch: 635, iter: 17, training_loss: 6.70817e-01\n",
            "epoch: 636, iter: 17, training_loss: 6.94392e-01\n",
            "epoch: 637, iter: 17, training_loss: 7.06573e-01\n",
            "epoch: 638, iter: 17, training_loss: 6.89299e-01\n",
            "epoch: 639, iter: 17, training_loss: 6.55389e-01\n",
            "epoch: 640, iter: 17, training_loss: 6.23055e-01\n",
            "epoch: 641, iter: 17, training_loss: 6.04310e-01\n",
            "epoch: 642, iter: 17, training_loss: 6.65575e-01\n",
            "epoch: 643, iter: 17, training_loss: 7.20788e-01\n",
            "epoch: 644, iter: 17, training_loss: 6.81987e-01\n",
            "epoch: 645, iter: 17, training_loss: 6.89046e-01\n",
            "epoch: 646, iter: 17, training_loss: 7.68283e-01\n",
            "epoch: 647, iter: 17, training_loss: 6.40322e-01\n",
            "epoch: 648, iter: 17, training_loss: 6.18918e-01\n",
            "epoch: 649, iter: 17, training_loss: 6.43111e-01\n",
            "epoch: 650, iter: 17, training_loss: 6.64739e-01\n",
            "epoch: 651, iter: 17, training_loss: 6.30160e-01\n",
            "epoch: 652, iter: 17, training_loss: 6.59990e-01\n",
            "epoch: 653, iter: 17, training_loss: 6.41608e-01\n",
            "epoch: 654, iter: 17, training_loss: 6.19183e-01\n",
            "epoch: 655, iter: 17, training_loss: 5.94232e-01\n",
            "epoch: 656, iter: 17, training_loss: 5.83353e-01\n",
            "epoch: 657, iter: 17, training_loss: 6.54841e-01\n",
            "epoch: 658, iter: 17, training_loss: 6.84621e-01\n",
            "epoch: 659, iter: 17, training_loss: 6.44976e-01\n",
            "epoch: 660, iter: 17, training_loss: 6.14110e-01\n",
            "epoch: 661, iter: 17, training_loss: 5.97311e-01\n",
            "epoch: 662, iter: 17, training_loss: 5.87036e-01\n",
            "epoch: 663, iter: 17, training_loss: 7.01223e-01\n",
            "epoch: 664, iter: 17, training_loss: 6.52610e-01\n",
            "epoch: 665, iter: 17, training_loss: 6.32182e-01\n",
            "epoch: 666, iter: 17, training_loss: 6.07309e-01\n",
            "epoch: 667, iter: 17, training_loss: 8.89608e-01\n",
            "epoch: 668, iter: 17, training_loss: 7.74802e-01\n",
            "epoch: 669, iter: 17, training_loss: 6.56874e-01\n",
            "epoch: 670, iter: 17, training_loss: 6.37448e-01\n",
            "epoch: 671, iter: 17, training_loss: 1.01896e+00\n",
            "epoch: 672, iter: 17, training_loss: 6.94924e-01\n",
            "epoch: 673, iter: 17, training_loss: 6.80219e-01\n",
            "epoch: 674, iter: 17, training_loss: 8.79059e-01\n",
            "epoch: 675, iter: 17, training_loss: 6.74853e-01\n",
            "epoch: 676, iter: 17, training_loss: 8.22146e-01\n",
            "epoch: 677, iter: 17, training_loss: 8.69898e-01\n",
            "epoch: 678, iter: 17, training_loss: 8.45545e-01\n",
            "epoch: 679, iter: 17, training_loss: 8.51180e-01\n",
            "epoch: 680, iter: 17, training_loss: 7.61203e-01\n",
            "epoch: 681, iter: 17, training_loss: 7.49108e-01\n",
            "epoch: 682, iter: 17, training_loss: 7.01668e-01\n",
            "epoch: 683, iter: 17, training_loss: 6.18128e-01\n",
            "epoch: 684, iter: 17, training_loss: 6.79637e-01\n",
            "epoch: 685, iter: 17, training_loss: 6.09715e-01\n",
            "epoch: 686, iter: 17, training_loss: 6.56218e-01\n",
            "epoch: 687, iter: 17, training_loss: 6.67600e-01\n",
            "epoch: 688, iter: 17, training_loss: 6.30521e-01\n",
            "epoch: 689, iter: 17, training_loss: 6.28936e-01\n",
            "epoch: 690, iter: 17, training_loss: 6.17144e-01\n",
            "epoch: 691, iter: 17, training_loss: 6.95755e-01\n",
            "epoch: 692, iter: 17, training_loss: 7.82826e-01\n",
            "epoch: 693, iter: 17, training_loss: 6.20422e-01\n",
            "epoch: 694, iter: 17, training_loss: 5.75650e-01\n",
            "epoch: 695, iter: 17, training_loss: 6.71474e-01\n",
            "epoch: 696, iter: 17, training_loss: 6.44843e-01\n",
            "epoch: 697, iter: 17, training_loss: 6.80156e-01\n",
            "epoch: 698, iter: 17, training_loss: 6.41276e-01\n",
            "epoch: 699, iter: 17, training_loss: 6.40270e-01\n",
            "epoch: 700, iter: 17, training_loss: 6.33179e-01\n",
            "epoch: 701, iter: 17, training_loss: 6.13065e-01\n",
            "epoch: 702, iter: 17, training_loss: 5.89499e-01\n",
            "epoch: 703, iter: 17, training_loss: 5.95122e-01\n",
            "epoch: 704, iter: 17, training_loss: 5.80464e-01\n",
            "epoch: 705, iter: 17, training_loss: 5.63865e-01\n",
            "epoch: 706, iter: 17, training_loss: 5.63696e-01\n",
            "epoch: 707, iter: 17, training_loss: 6.41634e-01\n",
            "epoch: 708, iter: 17, training_loss: 6.67580e-01\n",
            "epoch: 709, iter: 17, training_loss: 6.80972e-01\n",
            "epoch: 710, iter: 17, training_loss: 6.85227e-01\n",
            "epoch: 711, iter: 17, training_loss: 6.20531e-01\n",
            "epoch: 712, iter: 17, training_loss: 6.05354e-01\n",
            "epoch: 713, iter: 17, training_loss: 5.87744e-01\n",
            "epoch: 714, iter: 17, training_loss: 6.24068e-01\n",
            "epoch: 715, iter: 17, training_loss: 6.36120e-01\n",
            "epoch: 716, iter: 17, training_loss: 6.46577e-01\n",
            "epoch: 717, iter: 17, training_loss: 6.04740e-01\n",
            "epoch: 718, iter: 17, training_loss: 5.90053e-01\n",
            "epoch: 719, iter: 17, training_loss: 5.87900e-01\n",
            "epoch: 720, iter: 17, training_loss: 6.60419e-01\n",
            "epoch: 721, iter: 17, training_loss: 6.43430e-01\n",
            "epoch: 722, iter: 17, training_loss: 5.97205e-01\n",
            "epoch: 723, iter: 17, training_loss: 6.61103e-01\n",
            "epoch: 724, iter: 17, training_loss: 6.47981e-01\n",
            "epoch: 725, iter: 17, training_loss: 6.58985e-01\n",
            "epoch: 726, iter: 17, training_loss: 5.96439e-01\n",
            "epoch: 727, iter: 17, training_loss: 7.91554e-01\n",
            "epoch: 728, iter: 17, training_loss: 1.17269e+00\n",
            "epoch: 729, iter: 17, training_loss: 1.13203e+00\n",
            "epoch: 730, iter: 17, training_loss: 9.17414e-01\n",
            "epoch: 731, iter: 17, training_loss: 8.83644e-01\n",
            "epoch: 732, iter: 17, training_loss: 7.84023e-01\n",
            "epoch: 733, iter: 17, training_loss: 7.63309e-01\n",
            "epoch: 734, iter: 17, training_loss: 7.32241e-01\n",
            "epoch: 735, iter: 17, training_loss: 7.43795e-01\n",
            "epoch: 736, iter: 17, training_loss: 6.94669e-01\n",
            "epoch: 737, iter: 17, training_loss: 6.63136e-01\n",
            "epoch: 738, iter: 17, training_loss: 6.28200e-01\n",
            "epoch: 739, iter: 17, training_loss: 6.14828e-01\n",
            "epoch: 740, iter: 17, training_loss: 6.28110e-01\n",
            "epoch: 741, iter: 17, training_loss: 6.51051e-01\n",
            "epoch: 742, iter: 17, training_loss: 6.21339e-01\n",
            "epoch: 743, iter: 17, training_loss: 5.86835e-01\n",
            "epoch: 744, iter: 17, training_loss: 6.46230e-01\n",
            "epoch: 745, iter: 17, training_loss: 6.72148e-01\n",
            "epoch: 746, iter: 17, training_loss: 6.87727e-01\n",
            "epoch: 747, iter: 17, training_loss: 6.62157e-01\n",
            "epoch: 748, iter: 17, training_loss: 6.34751e-01\n",
            "epoch: 749, iter: 17, training_loss: 6.68064e-01\n",
            "epoch: 750, iter: 17, training_loss: 6.71506e-01\n",
            "epoch: 751, iter: 17, training_loss: 6.40735e-01\n",
            "epoch: 752, iter: 17, training_loss: 6.58635e-01\n",
            "epoch: 753, iter: 17, training_loss: 7.58322e-01\n",
            "epoch: 754, iter: 17, training_loss: 7.16401e-01\n",
            "epoch: 755, iter: 17, training_loss: 5.92040e-01\n",
            "epoch: 756, iter: 17, training_loss: 5.96091e-01\n",
            "epoch: 757, iter: 17, training_loss: 6.60805e-01\n",
            "epoch: 758, iter: 17, training_loss: 5.97965e-01\n",
            "epoch: 759, iter: 17, training_loss: 6.00295e-01\n",
            "epoch: 760, iter: 17, training_loss: 5.94646e-01\n",
            "epoch: 761, iter: 17, training_loss: 6.12285e-01\n",
            "epoch: 762, iter: 17, training_loss: 7.61391e-01\n",
            "epoch: 763, iter: 17, training_loss: 7.18424e-01\n",
            "epoch: 764, iter: 17, training_loss: 6.48470e-01\n",
            "epoch: 765, iter: 17, training_loss: 6.51045e-01\n",
            "epoch: 766, iter: 17, training_loss: 6.08327e-01\n",
            "epoch: 767, iter: 17, training_loss: 6.06135e-01\n",
            "epoch: 768, iter: 17, training_loss: 6.02403e-01\n",
            "epoch: 769, iter: 17, training_loss: 7.78471e-01\n",
            "epoch: 770, iter: 17, training_loss: 6.11219e-01\n",
            "epoch: 771, iter: 17, training_loss: 6.33425e-01\n",
            "epoch: 772, iter: 17, training_loss: 6.21123e-01\n",
            "epoch: 773, iter: 17, training_loss: 6.25992e-01\n",
            "epoch: 774, iter: 17, training_loss: 6.33544e-01\n",
            "epoch: 775, iter: 17, training_loss: 6.50339e-01\n",
            "epoch: 776, iter: 17, training_loss: 6.54063e-01\n",
            "epoch: 777, iter: 17, training_loss: 6.38535e-01\n",
            "epoch: 778, iter: 17, training_loss: 6.16968e-01\n",
            "epoch: 779, iter: 17, training_loss: 5.86393e-01\n",
            "epoch: 780, iter: 17, training_loss: 7.76293e-01\n",
            "epoch: 781, iter: 17, training_loss: 8.90733e-01\n",
            "epoch: 782, iter: 17, training_loss: 6.03243e-01\n",
            "epoch: 783, iter: 17, training_loss: 6.10748e-01\n",
            "epoch: 784, iter: 17, training_loss: 5.82001e-01\n",
            "epoch: 785, iter: 17, training_loss: 5.76443e-01\n",
            "epoch: 786, iter: 17, training_loss: 5.83907e-01\n",
            "epoch: 787, iter: 17, training_loss: 6.40191e-01\n",
            "epoch: 788, iter: 17, training_loss: 6.10722e-01\n",
            "epoch: 789, iter: 17, training_loss: 6.61709e-01\n",
            "epoch: 790, iter: 17, training_loss: 6.39823e-01\n",
            "epoch: 791, iter: 17, training_loss: 6.16726e-01\n",
            "epoch: 792, iter: 17, training_loss: 5.95486e-01\n",
            "epoch: 793, iter: 17, training_loss: 6.58658e-01\n",
            "epoch: 794, iter: 17, training_loss: 6.22175e-01\n",
            "epoch: 795, iter: 17, training_loss: 6.07431e-01\n",
            "epoch: 796, iter: 17, training_loss: 5.83348e-01\n",
            "epoch: 797, iter: 17, training_loss: 6.22410e-01\n",
            "epoch: 798, iter: 17, training_loss: 6.37782e-01\n",
            "epoch: 799, iter: 17, training_loss: 6.31691e-01\n",
            "epoch: 800, iter: 17, training_loss: 5.99042e-01\n",
            "epoch: 801, iter: 17, training_loss: 5.94448e-01\n",
            "epoch: 802, iter: 17, training_loss: 5.73031e-01\n",
            "epoch: 803, iter: 17, training_loss: 5.74589e-01\n",
            "epoch: 804, iter: 17, training_loss: 6.72597e-01\n",
            "epoch: 805, iter: 17, training_loss: 5.93785e-01\n",
            "epoch: 806, iter: 17, training_loss: 5.91168e-01\n",
            "epoch: 807, iter: 17, training_loss: 6.41296e-01\n",
            "epoch: 808, iter: 17, training_loss: 6.01930e-01\n",
            "epoch: 809, iter: 17, training_loss: 6.23849e-01\n",
            "epoch: 810, iter: 17, training_loss: 6.15417e-01\n",
            "epoch: 811, iter: 17, training_loss: 5.85973e-01\n",
            "epoch: 812, iter: 17, training_loss: 5.79351e-01\n",
            "epoch: 813, iter: 17, training_loss: 5.76811e-01\n",
            "epoch: 814, iter: 17, training_loss: 5.73615e-01\n",
            "epoch: 815, iter: 17, training_loss: 6.22624e-01\n",
            "epoch: 816, iter: 17, training_loss: 6.83820e-01\n",
            "epoch: 817, iter: 17, training_loss: 6.05593e-01\n",
            "epoch: 818, iter: 17, training_loss: 6.91112e-01\n",
            "epoch: 819, iter: 17, training_loss: 9.60786e-01\n",
            "epoch: 820, iter: 17, training_loss: 1.13981e+00\n",
            "epoch: 821, iter: 17, training_loss: 8.00015e-01\n",
            "epoch: 822, iter: 17, training_loss: 7.77394e-01\n",
            "epoch: 823, iter: 17, training_loss: 7.16745e-01\n",
            "epoch: 824, iter: 17, training_loss: 6.47600e-01\n",
            "epoch: 825, iter: 17, training_loss: 6.19351e-01\n",
            "epoch: 826, iter: 17, training_loss: 6.04173e-01\n",
            "epoch: 827, iter: 17, training_loss: 6.21591e-01\n",
            "epoch: 828, iter: 17, training_loss: 6.11981e-01\n",
            "epoch: 829, iter: 17, training_loss: 5.81338e-01\n",
            "epoch: 830, iter: 17, training_loss: 5.68950e-01\n",
            "epoch: 831, iter: 17, training_loss: 6.00773e-01\n",
            "epoch: 832, iter: 17, training_loss: 5.85955e-01\n",
            "epoch: 833, iter: 17, training_loss: 6.08822e-01\n",
            "epoch: 834, iter: 17, training_loss: 6.32982e-01\n",
            "epoch: 835, iter: 17, training_loss: 6.38845e-01\n",
            "epoch: 836, iter: 17, training_loss: 6.06473e-01\n",
            "epoch: 837, iter: 17, training_loss: 6.05461e-01\n",
            "epoch: 838, iter: 17, training_loss: 5.78650e-01\n",
            "epoch: 839, iter: 17, training_loss: 6.48043e-01\n",
            "epoch: 840, iter: 17, training_loss: 6.15024e-01\n",
            "epoch: 841, iter: 17, training_loss: 6.16949e-01\n",
            "epoch: 842, iter: 17, training_loss: 6.01684e-01\n",
            "epoch: 843, iter: 17, training_loss: 5.78142e-01\n",
            "epoch: 844, iter: 17, training_loss: 5.97466e-01\n",
            "epoch: 845, iter: 17, training_loss: 6.24287e-01\n",
            "epoch: 846, iter: 17, training_loss: 6.09856e-01\n",
            "epoch: 847, iter: 17, training_loss: 5.92602e-01\n",
            "epoch: 848, iter: 17, training_loss: 6.01760e-01\n",
            "epoch: 849, iter: 17, training_loss: 6.09188e-01\n",
            "epoch: 850, iter: 17, training_loss: 5.97854e-01\n",
            "epoch: 851, iter: 17, training_loss: 5.82394e-01\n",
            "epoch: 852, iter: 17, training_loss: 6.15559e-01\n",
            "epoch: 853, iter: 17, training_loss: 6.61911e-01\n",
            "epoch: 854, iter: 17, training_loss: 5.94697e-01\n",
            "epoch: 855, iter: 17, training_loss: 5.89936e-01\n",
            "epoch: 856, iter: 17, training_loss: 5.95023e-01\n",
            "epoch: 857, iter: 17, training_loss: 6.01175e-01\n",
            "epoch: 858, iter: 17, training_loss: 6.45733e-01\n",
            "epoch: 859, iter: 17, training_loss: 9.11327e-01\n",
            "epoch: 860, iter: 17, training_loss: 7.50643e-01\n",
            "epoch: 861, iter: 17, training_loss: 6.63186e-01\n",
            "epoch: 862, iter: 17, training_loss: 6.02892e-01\n",
            "epoch: 863, iter: 17, training_loss: 6.10605e-01\n",
            "epoch: 864, iter: 17, training_loss: 6.04095e-01\n",
            "epoch: 865, iter: 17, training_loss: 5.80105e-01\n",
            "epoch: 866, iter: 17, training_loss: 5.72608e-01\n",
            "epoch: 867, iter: 17, training_loss: 7.59021e-01\n",
            "epoch: 868, iter: 17, training_loss: 6.68698e-01\n",
            "epoch: 869, iter: 17, training_loss: 7.18240e-01\n",
            "epoch: 870, iter: 17, training_loss: 8.10976e-01\n",
            "epoch: 871, iter: 17, training_loss: 7.91386e-01\n",
            "epoch: 872, iter: 17, training_loss: 7.32763e-01\n",
            "epoch: 873, iter: 17, training_loss: 6.27528e-01\n",
            "epoch: 874, iter: 17, training_loss: 5.55814e-01\n",
            "epoch: 875, iter: 17, training_loss: 6.00727e-01\n",
            "epoch: 876, iter: 17, training_loss: 6.11330e-01\n",
            "epoch: 877, iter: 17, training_loss: 5.69140e-01\n",
            "epoch: 878, iter: 17, training_loss: 5.83865e-01\n",
            "epoch: 879, iter: 17, training_loss: 5.59376e-01\n",
            "epoch: 880, iter: 17, training_loss: 5.72178e-01\n",
            "epoch: 881, iter: 17, training_loss: 5.97995e-01\n",
            "epoch: 882, iter: 17, training_loss: 6.42780e-01\n",
            "epoch: 883, iter: 17, training_loss: 6.16856e-01\n",
            "epoch: 884, iter: 17, training_loss: 5.91187e-01\n",
            "epoch: 885, iter: 17, training_loss: 7.99856e-01\n",
            "epoch: 886, iter: 17, training_loss: 6.10414e-01\n",
            "epoch: 887, iter: 17, training_loss: 7.79754e-01\n",
            "epoch: 888, iter: 17, training_loss: 5.93904e-01\n",
            "epoch: 889, iter: 17, training_loss: 5.87962e-01\n",
            "epoch: 890, iter: 17, training_loss: 6.05038e-01\n",
            "epoch: 891, iter: 17, training_loss: 6.11434e-01\n",
            "epoch: 892, iter: 17, training_loss: 5.91473e-01\n",
            "epoch: 893, iter: 17, training_loss: 6.26667e-01\n",
            "epoch: 894, iter: 17, training_loss: 5.96222e-01\n",
            "epoch: 895, iter: 17, training_loss: 7.47171e-01\n",
            "epoch: 896, iter: 17, training_loss: 6.18478e-01\n",
            "epoch: 897, iter: 17, training_loss: 6.29260e-01\n",
            "epoch: 898, iter: 17, training_loss: 6.09610e-01\n",
            "epoch: 899, iter: 17, training_loss: 6.23991e-01\n",
            "epoch: 900, iter: 17, training_loss: 6.24098e-01\n",
            "epoch: 901, iter: 17, training_loss: 6.02716e-01\n",
            "epoch: 902, iter: 17, training_loss: 5.84255e-01\n",
            "epoch: 903, iter: 17, training_loss: 5.76109e-01\n",
            "epoch: 904, iter: 17, training_loss: 5.67936e-01\n",
            "epoch: 905, iter: 17, training_loss: 5.59728e-01\n",
            "epoch: 906, iter: 17, training_loss: 5.96599e-01\n",
            "epoch: 907, iter: 17, training_loss: 5.43383e-01\n",
            "epoch: 908, iter: 17, training_loss: 6.70071e-01\n",
            "epoch: 909, iter: 17, training_loss: 6.70235e-01\n",
            "epoch: 910, iter: 17, training_loss: 5.58434e-01\n",
            "epoch: 911, iter: 17, training_loss: 6.12689e-01\n",
            "epoch: 912, iter: 17, training_loss: 6.02675e-01\n",
            "epoch: 913, iter: 17, training_loss: 5.90561e-01\n",
            "epoch: 914, iter: 17, training_loss: 5.88390e-01\n",
            "epoch: 915, iter: 17, training_loss: 5.98229e-01\n",
            "epoch: 916, iter: 17, training_loss: 5.93469e-01\n",
            "epoch: 917, iter: 17, training_loss: 8.56046e-01\n",
            "epoch: 918, iter: 17, training_loss: 6.24505e-01\n",
            "epoch: 919, iter: 17, training_loss: 5.96455e-01\n",
            "epoch: 920, iter: 17, training_loss: 5.84597e-01\n",
            "epoch: 921, iter: 17, training_loss: 5.95617e-01\n",
            "epoch: 922, iter: 17, training_loss: 5.62108e-01\n",
            "epoch: 923, iter: 17, training_loss: 6.04349e-01\n",
            "epoch: 924, iter: 17, training_loss: 5.71005e-01\n",
            "epoch: 925, iter: 17, training_loss: 5.78160e-01\n",
            "epoch: 926, iter: 17, training_loss: 6.01988e-01\n",
            "epoch: 927, iter: 17, training_loss: 7.07417e-01\n",
            "epoch: 928, iter: 17, training_loss: 7.17954e-01\n",
            "epoch: 929, iter: 17, training_loss: 6.64522e-01\n",
            "epoch: 930, iter: 17, training_loss: 6.44748e-01\n",
            "epoch: 931, iter: 17, training_loss: 6.39709e-01\n",
            "epoch: 932, iter: 17, training_loss: 6.47983e-01\n",
            "epoch: 933, iter: 17, training_loss: 6.25177e-01\n",
            "epoch: 934, iter: 17, training_loss: 6.31351e-01\n",
            "epoch: 935, iter: 17, training_loss: 6.29026e-01\n",
            "epoch: 936, iter: 17, training_loss: 6.11752e-01\n",
            "epoch: 937, iter: 17, training_loss: 6.13048e-01\n",
            "epoch: 938, iter: 17, training_loss: 6.01552e-01\n",
            "epoch: 939, iter: 17, training_loss: 5.80520e-01\n",
            "epoch: 940, iter: 17, training_loss: 5.70832e-01\n",
            "epoch: 941, iter: 17, training_loss: 6.10514e-01\n",
            "epoch: 942, iter: 17, training_loss: 7.67122e-01\n",
            "epoch: 943, iter: 17, training_loss: 9.43886e-01\n",
            "epoch: 944, iter: 17, training_loss: 7.32690e-01\n",
            "epoch: 945, iter: 17, training_loss: 6.67706e-01\n",
            "epoch: 946, iter: 17, training_loss: 6.32501e-01\n",
            "epoch: 947, iter: 17, training_loss: 5.85874e-01\n",
            "epoch: 948, iter: 17, training_loss: 5.75154e-01\n",
            "epoch: 949, iter: 17, training_loss: 5.76114e-01\n",
            "epoch: 950, iter: 17, training_loss: 6.03526e-01\n",
            "epoch: 951, iter: 17, training_loss: 6.09786e-01\n",
            "epoch: 952, iter: 17, training_loss: 7.86990e-01\n",
            "epoch: 953, iter: 17, training_loss: 6.13121e-01\n",
            "epoch: 954, iter: 17, training_loss: 5.93043e-01\n",
            "epoch: 955, iter: 17, training_loss: 5.86267e-01\n",
            "epoch: 956, iter: 17, training_loss: 5.84580e-01\n",
            "epoch: 957, iter: 17, training_loss: 5.77587e-01\n",
            "epoch: 958, iter: 17, training_loss: 5.62433e-01\n",
            "epoch: 959, iter: 17, training_loss: 5.65201e-01\n",
            "epoch: 960, iter: 17, training_loss: 5.85524e-01\n",
            "epoch: 961, iter: 17, training_loss: 5.76642e-01\n",
            "epoch: 962, iter: 17, training_loss: 6.34561e-01\n",
            "epoch: 963, iter: 17, training_loss: 5.95126e-01\n",
            "epoch: 964, iter: 17, training_loss: 5.90834e-01\n",
            "epoch: 965, iter: 17, training_loss: 5.67425e-01\n",
            "epoch: 966, iter: 17, training_loss: 6.08098e-01\n",
            "epoch: 967, iter: 17, training_loss: 5.78447e-01\n",
            "epoch: 968, iter: 17, training_loss: 5.71428e-01\n",
            "epoch: 969, iter: 17, training_loss: 7.49471e-01\n",
            "epoch: 970, iter: 17, training_loss: 6.11219e-01\n",
            "epoch: 971, iter: 17, training_loss: 5.65754e-01\n",
            "epoch: 972, iter: 17, training_loss: 5.55406e-01\n",
            "epoch: 973, iter: 17, training_loss: 5.51395e-01\n",
            "epoch: 974, iter: 17, training_loss: 5.44697e-01\n",
            "epoch: 975, iter: 17, training_loss: 5.81726e-01\n",
            "epoch: 976, iter: 17, training_loss: 6.10597e-01\n",
            "epoch: 977, iter: 17, training_loss: 6.23585e-01\n",
            "epoch: 978, iter: 17, training_loss: 5.73415e-01\n",
            "epoch: 979, iter: 17, training_loss: 5.94546e-01\n",
            "epoch: 980, iter: 17, training_loss: 5.88674e-01\n",
            "epoch: 981, iter: 17, training_loss: 5.76497e-01\n",
            "epoch: 982, iter: 17, training_loss: 5.99621e-01\n",
            "epoch: 983, iter: 17, training_loss: 5.96801e-01\n",
            "epoch: 984, iter: 17, training_loss: 5.93374e-01\n",
            "epoch: 985, iter: 17, training_loss: 5.58931e-01\n",
            "epoch: 986, iter: 17, training_loss: 5.39149e-01\n",
            "epoch: 987, iter: 17, training_loss: 5.49439e-01\n",
            "epoch: 988, iter: 17, training_loss: 6.20337e-01\n",
            "epoch: 989, iter: 17, training_loss: 6.05217e-01\n",
            "epoch: 990, iter: 17, training_loss: 6.41791e-01\n",
            "epoch: 991, iter: 17, training_loss: 6.92805e-01\n",
            "epoch: 992, iter: 17, training_loss: 5.88999e-01\n",
            "epoch: 993, iter: 17, training_loss: 6.06153e-01\n",
            "epoch: 994, iter: 17, training_loss: 5.90305e-01\n",
            "epoch: 995, iter: 17, training_loss: 7.35694e-01\n",
            "epoch: 996, iter: 17, training_loss: 6.06393e-01\n",
            "epoch: 997, iter: 17, training_loss: 5.89036e-01\n",
            "epoch: 998, iter: 17, training_loss: 5.67677e-01\n",
            "epoch: 999, iter: 17, training_loss: 6.58989e-01\n",
            "epoch: 1000, iter: 17, training_loss: 6.18346e-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname magic --method stasy --mode sample --save_path magic_syn.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llBUvqtguDir",
        "outputId": "f1f03e99-0940-4c03-954b-60db7e25c962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No NaNs in numerical features, skipping\n",
            "Input dimension: 12\n",
            "NCSNpp(\n",
            "  (act): ELU(alpha=1.0)\n",
            "  (all_modules): ModuleList(\n",
            "    (0): GaussianFourierProjection()\n",
            "    (1): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (3): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=12, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (4): ELU(alpha=1.0)\n",
            "    (5): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=1036, out_features=2048, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=2048, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=2048, bias=True)\n",
            "    )\n",
            "    (6): ELU(alpha=1.0)\n",
            "    (7): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=3084, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (8): ELU(alpha=1.0)\n",
            "    (9): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=4108, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (10): ELU(alpha=1.0)\n",
            "    (11): Linear(in_features=5132, out_features=12, bias=True)\n",
            "  )\n",
            ")\n",
            "the number of parameters 9679580\n",
            "Loading SAVED model at from /content/tabsyn/baselines/stasy/ckpt/magic/model.pth\n",
            "Start sampling...\n",
            "(17117, 1)\n",
            "Sampling time = 20.736331701278687\n",
            "Saving sampled data to magic_syn.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname default --method stasy --mode train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ay5QX31CDrI3",
        "outputId": "fc243487-d0a4-4bce-82d7-163b32a5c73e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No NaNs in numerical features, skipping\n",
            "93\n",
            "NCSNpp(\n",
            "  (act): ELU(alpha=1.0)\n",
            "  (all_modules): ModuleList(\n",
            "    (0): GaussianFourierProjection()\n",
            "    (1): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (3): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=93, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (4): ELU(alpha=1.0)\n",
            "    (5): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=1117, out_features=2048, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=2048, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=2048, bias=True)\n",
            "    )\n",
            "    (6): ELU(alpha=1.0)\n",
            "    (7): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=3165, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (8): ELU(alpha=1.0)\n",
            "    (9): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=4189, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (10): ELU(alpha=1.0)\n",
            "    (11): Linear(in_features=5213, out_features=93, bias=True)\n",
            "  )\n",
            ")\n",
            "the number of parameters 10517606\n",
            "epoch: 0, iter: 26, training_loss: 2.52606e+00\n",
            "epoch: 1, iter: 26, training_loss: 1.32406e+00\n",
            "epoch: 2, iter: 26, training_loss: 1.26913e+00\n",
            "epoch: 3, iter: 26, training_loss: 1.29834e+00\n",
            "epoch: 4, iter: 26, training_loss: 1.31338e+00\n",
            "epoch: 5, iter: 26, training_loss: 1.27468e+00\n",
            "epoch: 6, iter: 26, training_loss: 1.27379e+00\n",
            "epoch: 7, iter: 26, training_loss: 1.19454e+00\n",
            "epoch: 8, iter: 26, training_loss: 1.24568e+00\n",
            "epoch: 9, iter: 26, training_loss: 1.15910e+00\n",
            "epoch: 10, iter: 26, training_loss: 1.17010e+00\n",
            "epoch: 11, iter: 26, training_loss: 1.10463e+00\n",
            "epoch: 12, iter: 26, training_loss: 1.08888e+00\n",
            "epoch: 13, iter: 26, training_loss: 1.11604e+00\n",
            "epoch: 14, iter: 26, training_loss: 1.05954e+00\n",
            "epoch: 15, iter: 26, training_loss: 1.09152e+00\n",
            "epoch: 16, iter: 26, training_loss: 1.02861e+00\n",
            "epoch: 17, iter: 26, training_loss: 1.07497e+00\n",
            "epoch: 18, iter: 26, training_loss: 1.06139e+00\n",
            "epoch: 19, iter: 26, training_loss: 1.10746e+00\n",
            "epoch: 20, iter: 26, training_loss: 1.12905e+00\n",
            "epoch: 21, iter: 26, training_loss: 1.09677e+00\n",
            "epoch: 22, iter: 26, training_loss: 1.04139e+00\n",
            "epoch: 23, iter: 26, training_loss: 1.08169e+00\n",
            "epoch: 24, iter: 26, training_loss: 1.06147e+00\n",
            "epoch: 25, iter: 26, training_loss: 1.07182e+00\n",
            "epoch: 26, iter: 26, training_loss: 1.13838e+00\n",
            "epoch: 27, iter: 26, training_loss: 1.10362e+00\n",
            "epoch: 28, iter: 26, training_loss: 1.04740e+00\n",
            "epoch: 29, iter: 26, training_loss: 1.05448e+00\n",
            "epoch: 30, iter: 26, training_loss: 1.04321e+00\n",
            "epoch: 31, iter: 26, training_loss: 1.07399e+00\n",
            "epoch: 32, iter: 26, training_loss: 1.13447e+00\n",
            "epoch: 33, iter: 26, training_loss: 1.10814e+00\n",
            "epoch: 34, iter: 26, training_loss: 1.15363e+00\n",
            "epoch: 35, iter: 26, training_loss: 1.16220e+00\n",
            "epoch: 36, iter: 26, training_loss: 1.18205e+00\n",
            "epoch: 37, iter: 26, training_loss: 1.28691e+00\n",
            "epoch: 38, iter: 26, training_loss: 1.17423e+00\n",
            "epoch: 39, iter: 26, training_loss: 1.26707e+00\n",
            "epoch: 40, iter: 26, training_loss: 1.20556e+00\n",
            "epoch: 41, iter: 26, training_loss: 1.22152e+00\n",
            "epoch: 42, iter: 26, training_loss: 1.25798e+00\n",
            "epoch: 43, iter: 26, training_loss: 1.24126e+00\n",
            "epoch: 44, iter: 26, training_loss: 1.26211e+00\n",
            "epoch: 45, iter: 26, training_loss: 1.41857e+00\n",
            "epoch: 46, iter: 26, training_loss: 1.43970e+00\n",
            "epoch: 47, iter: 26, training_loss: 1.43798e+00\n",
            "epoch: 48, iter: 26, training_loss: 1.54808e+00\n",
            "epoch: 49, iter: 26, training_loss: 1.34574e+00\n",
            "epoch: 50, iter: 26, training_loss: 1.60504e+00\n",
            "epoch: 51, iter: 26, training_loss: 1.37477e+00\n",
            "epoch: 52, iter: 26, training_loss: 1.45203e+00\n",
            "epoch: 53, iter: 26, training_loss: 1.62804e+00\n",
            "epoch: 54, iter: 26, training_loss: 1.49549e+00\n",
            "epoch: 55, iter: 26, training_loss: 1.44702e+00\n",
            "epoch: 56, iter: 26, training_loss: 1.45616e+00\n",
            "epoch: 57, iter: 26, training_loss: 1.64378e+00\n",
            "epoch: 58, iter: 26, training_loss: 1.53083e+00\n",
            "epoch: 59, iter: 26, training_loss: 1.52164e+00\n",
            "epoch: 60, iter: 26, training_loss: 1.53960e+00\n",
            "epoch: 61, iter: 26, training_loss: 1.70342e+00\n",
            "epoch: 62, iter: 26, training_loss: 1.59483e+00\n",
            "epoch: 63, iter: 26, training_loss: 1.73244e+00\n",
            "epoch: 64, iter: 26, training_loss: 1.67402e+00\n",
            "epoch: 65, iter: 26, training_loss: 1.53095e+00\n",
            "epoch: 66, iter: 26, training_loss: 1.62347e+00\n",
            "epoch: 67, iter: 26, training_loss: 1.54702e+00\n",
            "epoch: 68, iter: 26, training_loss: 1.66908e+00\n",
            "epoch: 69, iter: 26, training_loss: 1.60149e+00\n",
            "epoch: 70, iter: 26, training_loss: 1.83917e+00\n",
            "epoch: 71, iter: 26, training_loss: 1.74166e+00\n",
            "epoch: 72, iter: 26, training_loss: 1.59693e+00\n",
            "epoch: 73, iter: 26, training_loss: 1.64322e+00\n",
            "epoch: 74, iter: 26, training_loss: 1.85066e+00\n",
            "epoch: 75, iter: 26, training_loss: 1.80902e+00\n",
            "epoch: 76, iter: 26, training_loss: 1.65891e+00\n",
            "epoch: 77, iter: 26, training_loss: 1.75720e+00\n",
            "epoch: 78, iter: 26, training_loss: 1.84632e+00\n",
            "epoch: 79, iter: 26, training_loss: 1.90300e+00\n",
            "epoch: 80, iter: 26, training_loss: 1.81073e+00\n",
            "epoch: 81, iter: 26, training_loss: 1.73236e+00\n",
            "epoch: 82, iter: 26, training_loss: 2.01106e+00\n",
            "epoch: 83, iter: 26, training_loss: 1.73113e+00\n",
            "epoch: 84, iter: 26, training_loss: 1.91817e+00\n",
            "epoch: 85, iter: 26, training_loss: 1.87049e+00\n",
            "epoch: 86, iter: 26, training_loss: 1.94552e+00\n",
            "epoch: 87, iter: 26, training_loss: 1.82480e+00\n",
            "epoch: 88, iter: 26, training_loss: 1.73348e+00\n",
            "epoch: 89, iter: 26, training_loss: 1.76170e+00\n",
            "epoch: 90, iter: 26, training_loss: 1.84599e+00\n",
            "epoch: 91, iter: 26, training_loss: 1.78669e+00\n",
            "epoch: 92, iter: 26, training_loss: 1.86088e+00\n",
            "epoch: 93, iter: 26, training_loss: 2.03637e+00\n",
            "epoch: 94, iter: 26, training_loss: 1.96672e+00\n",
            "epoch: 95, iter: 26, training_loss: 2.12031e+00\n",
            "epoch: 96, iter: 26, training_loss: 1.86668e+00\n",
            "epoch: 97, iter: 26, training_loss: 2.14467e+00\n",
            "epoch: 98, iter: 26, training_loss: 1.94336e+00\n",
            "epoch: 99, iter: 26, training_loss: 2.05462e+00\n",
            "epoch: 100, iter: 26, training_loss: 1.96526e+00\n",
            "epoch: 101, iter: 26, training_loss: 2.17097e+00\n",
            "epoch: 102, iter: 26, training_loss: 1.99733e+00\n",
            "epoch: 103, iter: 26, training_loss: 2.68055e+00\n",
            "epoch: 104, iter: 26, training_loss: 2.01925e+00\n",
            "epoch: 105, iter: 26, training_loss: 2.26109e+00\n",
            "epoch: 106, iter: 26, training_loss: 2.53792e+00\n",
            "epoch: 107, iter: 26, training_loss: 2.46794e+00\n",
            "epoch: 108, iter: 26, training_loss: 2.32929e+00\n",
            "epoch: 109, iter: 26, training_loss: 2.27867e+00\n",
            "epoch: 110, iter: 26, training_loss: 2.42606e+00\n",
            "epoch: 111, iter: 26, training_loss: 2.52590e+00\n",
            "epoch: 112, iter: 26, training_loss: 2.38202e+00\n",
            "epoch: 113, iter: 26, training_loss: 2.47915e+00\n",
            "epoch: 114, iter: 26, training_loss: 2.73155e+00\n",
            "epoch: 115, iter: 26, training_loss: 2.63483e+00\n",
            "epoch: 116, iter: 26, training_loss: 2.64443e+00\n",
            "epoch: 117, iter: 26, training_loss: 2.48086e+00\n",
            "epoch: 118, iter: 26, training_loss: 2.79368e+00\n",
            "epoch: 119, iter: 26, training_loss: 2.80267e+00\n",
            "epoch: 120, iter: 26, training_loss: 2.56919e+00\n",
            "epoch: 121, iter: 26, training_loss: 3.02774e+00\n",
            "epoch: 122, iter: 26, training_loss: 3.20084e+00\n",
            "epoch: 123, iter: 26, training_loss: 2.93651e+00\n",
            "epoch: 124, iter: 26, training_loss: 3.04433e+00\n",
            "epoch: 125, iter: 26, training_loss: 3.07003e+00\n",
            "epoch: 126, iter: 26, training_loss: 3.03389e+00\n",
            "epoch: 127, iter: 26, training_loss: 3.14829e+00\n",
            "epoch: 128, iter: 26, training_loss: 3.11974e+00\n",
            "epoch: 129, iter: 26, training_loss: 3.31132e+00\n",
            "epoch: 130, iter: 26, training_loss: 2.92032e+00\n",
            "epoch: 131, iter: 26, training_loss: 3.30171e+00\n",
            "epoch: 132, iter: 26, training_loss: 3.44842e+00\n",
            "epoch: 133, iter: 26, training_loss: 3.60673e+00\n",
            "epoch: 134, iter: 26, training_loss: 2.91781e+00\n",
            "epoch: 135, iter: 26, training_loss: 3.65587e+00\n",
            "epoch: 136, iter: 26, training_loss: 2.94829e+00\n",
            "epoch: 137, iter: 26, training_loss: 2.72907e+00\n",
            "epoch: 138, iter: 26, training_loss: 3.76053e+00\n",
            "epoch: 139, iter: 26, training_loss: 3.46715e+00\n",
            "epoch: 140, iter: 26, training_loss: 3.76040e+00\n",
            "epoch: 141, iter: 26, training_loss: 3.53520e+00\n",
            "epoch: 142, iter: 26, training_loss: 3.54253e+00\n",
            "epoch: 143, iter: 26, training_loss: 3.30667e+00\n",
            "epoch: 144, iter: 26, training_loss: 3.58962e+00\n",
            "epoch: 145, iter: 26, training_loss: 3.45304e+00\n",
            "epoch: 146, iter: 26, training_loss: 3.15803e+00\n",
            "epoch: 147, iter: 26, training_loss: 3.05527e+00\n",
            "epoch: 148, iter: 26, training_loss: 3.57678e+00\n",
            "epoch: 149, iter: 26, training_loss: 3.22943e+00\n",
            "epoch: 150, iter: 26, training_loss: 3.11412e+00\n",
            "epoch: 151, iter: 26, training_loss: 2.85264e+00\n",
            "epoch: 152, iter: 26, training_loss: 3.32645e+00\n",
            "epoch: 153, iter: 26, training_loss: 3.70667e+00\n",
            "epoch: 154, iter: 26, training_loss: 3.09421e+00\n",
            "epoch: 155, iter: 26, training_loss: 3.40979e+00\n",
            "epoch: 156, iter: 26, training_loss: 3.65596e+00\n",
            "epoch: 157, iter: 26, training_loss: 3.13052e+00\n",
            "epoch: 158, iter: 26, training_loss: 3.35456e+00\n",
            "epoch: 159, iter: 26, training_loss: 3.38675e+00\n",
            "epoch: 160, iter: 26, training_loss: 3.33015e+00\n",
            "epoch: 161, iter: 26, training_loss: 3.38570e+00\n",
            "epoch: 162, iter: 26, training_loss: 2.97959e+00\n",
            "epoch: 163, iter: 26, training_loss: 3.03720e+00\n",
            "epoch: 164, iter: 26, training_loss: 3.07191e+00\n",
            "epoch: 165, iter: 26, training_loss: 3.16595e+00\n",
            "epoch: 166, iter: 26, training_loss: 3.42138e+00\n",
            "epoch: 167, iter: 26, training_loss: 3.29859e+00\n",
            "epoch: 168, iter: 26, training_loss: 3.91547e+00\n",
            "epoch: 169, iter: 26, training_loss: 3.05033e+00\n",
            "epoch: 170, iter: 26, training_loss: 3.06384e+00\n",
            "epoch: 171, iter: 26, training_loss: 3.13594e+00\n",
            "epoch: 172, iter: 26, training_loss: 3.20904e+00\n",
            "epoch: 173, iter: 26, training_loss: 3.37474e+00\n",
            "epoch: 174, iter: 26, training_loss: 3.18010e+00\n",
            "epoch: 175, iter: 26, training_loss: 3.29033e+00\n",
            "epoch: 176, iter: 26, training_loss: 3.17109e+00\n",
            "epoch: 177, iter: 26, training_loss: 3.76261e+00\n",
            "epoch: 178, iter: 26, training_loss: 2.76069e+00\n",
            "epoch: 179, iter: 26, training_loss: 3.13275e+00\n",
            "epoch: 180, iter: 26, training_loss: 2.92684e+00\n",
            "epoch: 181, iter: 26, training_loss: 2.93541e+00\n",
            "epoch: 182, iter: 26, training_loss: 3.90644e+00\n",
            "epoch: 183, iter: 26, training_loss: 3.46937e+00\n",
            "epoch: 184, iter: 26, training_loss: 3.10361e+00\n",
            "epoch: 185, iter: 26, training_loss: 3.03718e+00\n",
            "epoch: 186, iter: 26, training_loss: 3.05318e+00\n",
            "epoch: 187, iter: 26, training_loss: 3.02481e+00\n",
            "epoch: 188, iter: 26, training_loss: 3.43402e+00\n",
            "epoch: 189, iter: 26, training_loss: 2.92540e+00\n",
            "epoch: 190, iter: 26, training_loss: 3.18883e+00\n",
            "epoch: 191, iter: 26, training_loss: 2.79050e+00\n",
            "epoch: 192, iter: 26, training_loss: 2.95862e+00\n",
            "epoch: 193, iter: 26, training_loss: 2.98326e+00\n",
            "epoch: 194, iter: 26, training_loss: 2.77843e+00\n",
            "epoch: 195, iter: 26, training_loss: 2.48728e+00\n",
            "epoch: 196, iter: 26, training_loss: 2.57297e+00\n",
            "epoch: 197, iter: 26, training_loss: 2.74023e+00\n",
            "epoch: 198, iter: 26, training_loss: 2.45798e+00\n",
            "epoch: 199, iter: 26, training_loss: 3.42238e+00\n",
            "epoch: 200, iter: 26, training_loss: 2.75792e+00\n",
            "epoch: 201, iter: 26, training_loss: 2.93819e+00\n",
            "epoch: 202, iter: 26, training_loss: 2.39723e+00\n",
            "epoch: 203, iter: 26, training_loss: 2.60118e+00\n",
            "epoch: 204, iter: 26, training_loss: 2.47010e+00\n",
            "epoch: 205, iter: 26, training_loss: 2.49791e+00\n",
            "epoch: 206, iter: 26, training_loss: 1.89778e+00\n",
            "epoch: 207, iter: 26, training_loss: 1.92120e+00\n",
            "epoch: 208, iter: 26, training_loss: 2.33507e+00\n",
            "epoch: 209, iter: 26, training_loss: 1.80176e+00\n",
            "epoch: 210, iter: 26, training_loss: 1.96318e+00\n",
            "epoch: 211, iter: 26, training_loss: 1.87366e+00\n",
            "epoch: 212, iter: 26, training_loss: 2.16431e+00\n",
            "epoch: 213, iter: 26, training_loss: 1.49831e+00\n",
            "epoch: 214, iter: 26, training_loss: 1.47529e+00\n",
            "epoch: 215, iter: 26, training_loss: 1.86774e+00\n",
            "epoch: 216, iter: 26, training_loss: 1.96737e+00\n",
            "epoch: 217, iter: 26, training_loss: 1.40894e+00\n",
            "epoch: 218, iter: 26, training_loss: 1.23294e+00\n",
            "epoch: 219, iter: 26, training_loss: 1.29842e+00\n",
            "epoch: 220, iter: 26, training_loss: 1.15207e+00\n",
            "epoch: 221, iter: 26, training_loss: 1.14716e+00\n",
            "epoch: 222, iter: 26, training_loss: 1.00785e+00\n",
            "epoch: 223, iter: 26, training_loss: 1.11598e+00\n",
            "epoch: 224, iter: 26, training_loss: 1.23013e+00\n",
            "epoch: 225, iter: 26, training_loss: 1.25963e+00\n",
            "epoch: 226, iter: 26, training_loss: 8.69503e-01\n",
            "epoch: 227, iter: 26, training_loss: 9.41433e-01\n",
            "epoch: 228, iter: 26, training_loss: 8.34531e-01\n",
            "epoch: 229, iter: 26, training_loss: 8.85211e-01\n",
            "epoch: 230, iter: 26, training_loss: 1.18226e+00\n",
            "epoch: 231, iter: 26, training_loss: 9.26039e-01\n",
            "epoch: 232, iter: 26, training_loss: 1.14379e+00\n",
            "epoch: 233, iter: 26, training_loss: 1.01556e+00\n",
            "epoch: 234, iter: 26, training_loss: 9.56986e-01\n",
            "epoch: 235, iter: 26, training_loss: 8.61988e-01\n",
            "epoch: 236, iter: 26, training_loss: 8.25668e-01\n",
            "epoch: 237, iter: 26, training_loss: 8.90894e-01\n",
            "epoch: 238, iter: 26, training_loss: 8.46051e-01\n",
            "epoch: 239, iter: 26, training_loss: 8.45654e-01\n",
            "epoch: 240, iter: 26, training_loss: 8.06778e-01\n",
            "epoch: 241, iter: 26, training_loss: 7.51847e-01\n",
            "epoch: 242, iter: 26, training_loss: 9.57407e-01\n",
            "epoch: 243, iter: 26, training_loss: 8.50742e-01\n",
            "epoch: 244, iter: 26, training_loss: 9.89894e-01\n",
            "epoch: 245, iter: 26, training_loss: 8.79297e-01\n",
            "epoch: 246, iter: 26, training_loss: 8.50717e-01\n",
            "epoch: 247, iter: 26, training_loss: 8.72722e-01\n",
            "epoch: 248, iter: 26, training_loss: 1.00365e+00\n",
            "epoch: 249, iter: 26, training_loss: 8.20229e-01\n",
            "epoch: 250, iter: 26, training_loss: 7.06012e-01\n",
            "epoch: 251, iter: 26, training_loss: 7.90530e-01\n",
            "epoch: 252, iter: 26, training_loss: 7.64425e-01\n",
            "epoch: 253, iter: 26, training_loss: 8.76942e-01\n",
            "epoch: 254, iter: 26, training_loss: 8.70893e-01\n",
            "epoch: 255, iter: 26, training_loss: 9.64128e-01\n",
            "epoch: 256, iter: 26, training_loss: 7.09322e-01\n",
            "epoch: 257, iter: 26, training_loss: 8.51499e-01\n",
            "epoch: 258, iter: 26, training_loss: 7.62934e-01\n",
            "epoch: 259, iter: 26, training_loss: 7.30528e-01\n",
            "epoch: 260, iter: 26, training_loss: 7.34719e-01\n",
            "epoch: 261, iter: 26, training_loss: 7.90429e-01\n",
            "epoch: 262, iter: 26, training_loss: 7.60893e-01\n",
            "epoch: 263, iter: 26, training_loss: 7.47110e-01\n",
            "epoch: 264, iter: 26, training_loss: 8.94242e-01\n",
            "epoch: 265, iter: 26, training_loss: 7.46744e-01\n",
            "epoch: 266, iter: 26, training_loss: 7.44010e-01\n",
            "epoch: 267, iter: 26, training_loss: 7.68562e-01\n",
            "epoch: 268, iter: 26, training_loss: 7.89229e-01\n",
            "epoch: 269, iter: 26, training_loss: 7.86999e-01\n",
            "epoch: 270, iter: 26, training_loss: 7.38704e-01\n",
            "epoch: 271, iter: 26, training_loss: 7.70235e-01\n",
            "epoch: 272, iter: 26, training_loss: 7.45248e-01\n",
            "epoch: 273, iter: 26, training_loss: 7.14807e-01\n",
            "epoch: 274, iter: 26, training_loss: 7.46270e-01\n",
            "epoch: 275, iter: 26, training_loss: 6.84899e-01\n",
            "epoch: 276, iter: 26, training_loss: 6.81442e-01\n",
            "epoch: 277, iter: 26, training_loss: 6.69408e-01\n",
            "epoch: 278, iter: 26, training_loss: 7.04095e-01\n",
            "epoch: 279, iter: 26, training_loss: 6.55237e-01\n",
            "epoch: 280, iter: 26, training_loss: 6.79815e-01\n",
            "epoch: 281, iter: 26, training_loss: 7.02031e-01\n",
            "epoch: 282, iter: 26, training_loss: 6.42616e-01\n",
            "epoch: 283, iter: 26, training_loss: 6.55836e-01\n",
            "epoch: 284, iter: 26, training_loss: 6.84319e-01\n",
            "epoch: 285, iter: 26, training_loss: 6.45800e-01\n",
            "epoch: 286, iter: 26, training_loss: 6.18001e-01\n",
            "epoch: 287, iter: 26, training_loss: 7.01827e-01\n",
            "epoch: 288, iter: 26, training_loss: 6.73831e-01\n",
            "epoch: 289, iter: 26, training_loss: 6.43859e-01\n",
            "epoch: 290, iter: 26, training_loss: 5.28472e-01\n",
            "epoch: 291, iter: 26, training_loss: 6.22201e-01\n",
            "epoch: 292, iter: 26, training_loss: 6.30141e-01\n",
            "epoch: 293, iter: 26, training_loss: 6.48697e-01\n",
            "epoch: 294, iter: 26, training_loss: 6.95998e-01\n",
            "epoch: 295, iter: 26, training_loss: 6.40255e-01\n",
            "epoch: 296, iter: 26, training_loss: 9.68317e-01\n",
            "epoch: 297, iter: 26, training_loss: 6.55880e-01\n",
            "epoch: 298, iter: 26, training_loss: 6.10766e-01\n",
            "epoch: 299, iter: 26, training_loss: 5.91303e-01\n",
            "epoch: 300, iter: 26, training_loss: 6.02535e-01\n",
            "epoch: 301, iter: 26, training_loss: 6.64759e-01\n",
            "epoch: 302, iter: 26, training_loss: 6.35113e-01\n",
            "epoch: 303, iter: 26, training_loss: 6.09301e-01\n",
            "epoch: 304, iter: 26, training_loss: 6.10586e-01\n",
            "epoch: 305, iter: 26, training_loss: 6.34943e-01\n",
            "epoch: 306, iter: 26, training_loss: 6.13780e-01\n",
            "epoch: 307, iter: 26, training_loss: 5.87238e-01\n",
            "epoch: 308, iter: 26, training_loss: 7.58787e-01\n",
            "epoch: 309, iter: 26, training_loss: 5.12869e-01\n",
            "epoch: 310, iter: 26, training_loss: 7.18140e-01\n",
            "epoch: 311, iter: 26, training_loss: 9.43856e-01\n",
            "epoch: 312, iter: 26, training_loss: 5.09421e-01\n",
            "epoch: 313, iter: 26, training_loss: 4.54620e-01\n",
            "epoch: 314, iter: 26, training_loss: 5.19097e-01\n",
            "epoch: 315, iter: 26, training_loss: 5.10597e-01\n",
            "epoch: 316, iter: 26, training_loss: 5.31773e-01\n",
            "epoch: 317, iter: 26, training_loss: 4.83431e-01\n",
            "epoch: 318, iter: 26, training_loss: 4.37269e-01\n",
            "epoch: 319, iter: 26, training_loss: 3.85891e-01\n",
            "epoch: 320, iter: 26, training_loss: 3.77642e-01\n",
            "epoch: 321, iter: 26, training_loss: 3.70873e-01\n",
            "epoch: 322, iter: 26, training_loss: 4.17466e-01\n",
            "epoch: 323, iter: 26, training_loss: 4.50235e-01\n",
            "epoch: 324, iter: 26, training_loss: 4.48073e-01\n",
            "epoch: 325, iter: 26, training_loss: 4.02193e-01\n",
            "epoch: 326, iter: 26, training_loss: 4.01413e-01\n",
            "epoch: 327, iter: 26, training_loss: 3.97115e-01\n",
            "epoch: 328, iter: 26, training_loss: 4.02033e-01\n",
            "epoch: 329, iter: 26, training_loss: 3.75426e-01\n",
            "epoch: 330, iter: 26, training_loss: 4.41443e-01\n",
            "epoch: 331, iter: 26, training_loss: 3.85734e-01\n",
            "epoch: 332, iter: 26, training_loss: 3.98325e-01\n",
            "epoch: 333, iter: 26, training_loss: 3.63256e-01\n",
            "epoch: 334, iter: 26, training_loss: 3.76837e-01\n",
            "epoch: 335, iter: 26, training_loss: 3.89752e-01\n",
            "epoch: 336, iter: 26, training_loss: 4.10147e-01\n",
            "epoch: 337, iter: 26, training_loss: 4.09865e-01\n",
            "epoch: 338, iter: 26, training_loss: 3.57380e-01\n",
            "epoch: 339, iter: 26, training_loss: 3.50117e-01\n",
            "epoch: 340, iter: 26, training_loss: 3.41788e-01\n",
            "epoch: 341, iter: 26, training_loss: 3.41725e-01\n",
            "epoch: 342, iter: 26, training_loss: 4.29312e-01\n",
            "epoch: 343, iter: 26, training_loss: 4.40953e-01\n",
            "epoch: 344, iter: 26, training_loss: 4.06807e-01\n",
            "epoch: 345, iter: 26, training_loss: 4.41279e-01\n",
            "epoch: 346, iter: 26, training_loss: 4.48820e-01\n",
            "epoch: 347, iter: 26, training_loss: 4.23635e-01\n",
            "epoch: 348, iter: 26, training_loss: 4.71505e-01\n",
            "epoch: 349, iter: 26, training_loss: 3.77110e-01\n",
            "epoch: 350, iter: 26, training_loss: 3.48367e-01\n",
            "epoch: 351, iter: 26, training_loss: 5.31783e-01\n",
            "epoch: 352, iter: 26, training_loss: 4.53997e-01\n",
            "epoch: 353, iter: 26, training_loss: 4.12644e-01\n",
            "epoch: 354, iter: 26, training_loss: 4.71715e-01\n",
            "epoch: 355, iter: 26, training_loss: 4.64630e-01\n",
            "epoch: 356, iter: 26, training_loss: 4.04424e-01\n",
            "epoch: 357, iter: 26, training_loss: 3.43838e-01\n",
            "epoch: 358, iter: 26, training_loss: 4.14625e-01\n",
            "epoch: 359, iter: 26, training_loss: 4.60633e-01\n",
            "epoch: 360, iter: 26, training_loss: 3.65487e-01\n",
            "epoch: 361, iter: 26, training_loss: 4.91908e-01\n",
            "epoch: 362, iter: 26, training_loss: 4.30592e-01\n",
            "epoch: 363, iter: 26, training_loss: 4.04270e-01\n",
            "epoch: 364, iter: 26, training_loss: 3.93269e-01\n",
            "epoch: 365, iter: 26, training_loss: 3.98640e-01\n",
            "epoch: 366, iter: 26, training_loss: 4.49641e-01\n",
            "epoch: 367, iter: 26, training_loss: 4.03292e-01\n",
            "epoch: 368, iter: 26, training_loss: 3.56683e-01\n",
            "epoch: 369, iter: 26, training_loss: 4.60693e-01\n",
            "epoch: 370, iter: 26, training_loss: 3.98259e-01\n",
            "epoch: 371, iter: 26, training_loss: 4.42254e-01\n",
            "epoch: 372, iter: 26, training_loss: 4.37316e-01\n",
            "epoch: 373, iter: 26, training_loss: 4.29463e-01\n",
            "epoch: 374, iter: 26, training_loss: 4.18672e-01\n",
            "epoch: 375, iter: 26, training_loss: 4.25852e-01\n",
            "epoch: 376, iter: 26, training_loss: 4.23730e-01\n",
            "epoch: 377, iter: 26, training_loss: 4.50837e-01\n",
            "epoch: 378, iter: 26, training_loss: 4.65922e-01\n",
            "epoch: 379, iter: 26, training_loss: 4.18645e-01\n",
            "epoch: 380, iter: 26, training_loss: 3.38556e-01\n",
            "epoch: 381, iter: 26, training_loss: 4.55179e-01\n",
            "epoch: 382, iter: 26, training_loss: 4.31201e-01\n",
            "epoch: 383, iter: 26, training_loss: 3.92426e-01\n",
            "epoch: 384, iter: 26, training_loss: 3.98259e-01\n",
            "epoch: 385, iter: 26, training_loss: 3.89335e-01\n",
            "epoch: 386, iter: 26, training_loss: 3.71578e-01\n",
            "epoch: 387, iter: 26, training_loss: 3.57964e-01\n",
            "epoch: 388, iter: 26, training_loss: 3.70702e-01\n",
            "epoch: 389, iter: 26, training_loss: 3.77606e-01\n",
            "epoch: 390, iter: 26, training_loss: 3.32203e-01\n",
            "epoch: 391, iter: 26, training_loss: 3.48556e-01\n",
            "epoch: 392, iter: 26, training_loss: 3.88695e-01\n",
            "epoch: 393, iter: 26, training_loss: 3.78662e-01\n",
            "epoch: 394, iter: 26, training_loss: 3.46961e-01\n",
            "epoch: 395, iter: 26, training_loss: 3.37689e-01\n",
            "epoch: 396, iter: 26, training_loss: 3.63633e-01\n",
            "epoch: 397, iter: 26, training_loss: 3.41574e-01\n",
            "epoch: 398, iter: 26, training_loss: 3.44223e-01\n",
            "epoch: 399, iter: 26, training_loss: 3.19374e-01\n",
            "epoch: 400, iter: 26, training_loss: 4.20771e-01\n",
            "epoch: 401, iter: 26, training_loss: 4.10815e-01\n",
            "epoch: 402, iter: 26, training_loss: 3.63748e-01\n",
            "epoch: 403, iter: 26, training_loss: 4.02068e-01\n",
            "epoch: 404, iter: 26, training_loss: 3.94615e-01\n",
            "epoch: 405, iter: 26, training_loss: 3.37406e-01\n",
            "epoch: 406, iter: 26, training_loss: 4.29652e-01\n",
            "epoch: 407, iter: 26, training_loss: 3.70224e-01\n",
            "epoch: 408, iter: 26, training_loss: 3.47596e-01\n",
            "epoch: 409, iter: 26, training_loss: 3.91461e-01\n",
            "epoch: 410, iter: 26, training_loss: 4.13904e-01\n",
            "epoch: 411, iter: 26, training_loss: 3.68649e-01\n",
            "epoch: 412, iter: 26, training_loss: 3.42986e-01\n",
            "epoch: 413, iter: 26, training_loss: 3.21679e-01\n",
            "epoch: 414, iter: 26, training_loss: 3.39397e-01\n",
            "epoch: 415, iter: 26, training_loss: 3.99384e-01\n",
            "epoch: 416, iter: 26, training_loss: 3.42835e-01\n",
            "epoch: 417, iter: 26, training_loss: 3.38940e-01\n",
            "epoch: 418, iter: 26, training_loss: 3.18357e-01\n",
            "epoch: 419, iter: 26, training_loss: 3.15740e-01\n",
            "epoch: 420, iter: 26, training_loss: 3.21558e-01\n",
            "epoch: 421, iter: 26, training_loss: 3.76492e-01\n",
            "epoch: 422, iter: 26, training_loss: 3.31759e-01\n",
            "epoch: 423, iter: 26, training_loss: 4.46380e-01\n",
            "epoch: 424, iter: 26, training_loss: 3.68531e-01\n",
            "epoch: 425, iter: 26, training_loss: 3.43891e-01\n",
            "epoch: 426, iter: 26, training_loss: 3.58550e-01\n",
            "epoch: 427, iter: 26, training_loss: 3.73024e-01\n",
            "epoch: 428, iter: 26, training_loss: 3.46330e-01\n",
            "epoch: 429, iter: 26, training_loss: 3.21479e-01\n",
            "epoch: 430, iter: 26, training_loss: 2.96912e-01\n",
            "epoch: 431, iter: 26, training_loss: 3.05791e-01\n",
            "epoch: 432, iter: 26, training_loss: 2.97666e-01\n",
            "epoch: 433, iter: 26, training_loss: 3.09676e-01\n",
            "epoch: 434, iter: 26, training_loss: 4.02051e-01\n",
            "epoch: 435, iter: 26, training_loss: 3.40959e-01\n",
            "epoch: 436, iter: 26, training_loss: 3.18570e-01\n",
            "epoch: 437, iter: 26, training_loss: 2.95432e-01\n",
            "epoch: 438, iter: 26, training_loss: 3.00921e-01\n",
            "epoch: 439, iter: 26, training_loss: 2.94004e-01\n",
            "epoch: 440, iter: 26, training_loss: 3.45097e-01\n",
            "epoch: 441, iter: 26, training_loss: 3.28933e-01\n",
            "epoch: 442, iter: 26, training_loss: 3.28468e-01\n",
            "epoch: 443, iter: 26, training_loss: 4.44624e-01\n",
            "epoch: 444, iter: 26, training_loss: 3.35130e-01\n",
            "epoch: 445, iter: 26, training_loss: 2.99405e-01\n",
            "epoch: 446, iter: 26, training_loss: 2.86101e-01\n",
            "epoch: 447, iter: 26, training_loss: 2.81308e-01\n",
            "epoch: 448, iter: 26, training_loss: 3.10938e-01\n",
            "epoch: 449, iter: 26, training_loss: 2.96371e-01\n",
            "epoch: 450, iter: 26, training_loss: 3.02363e-01\n",
            "epoch: 451, iter: 26, training_loss: 2.90930e-01\n",
            "epoch: 452, iter: 26, training_loss: 2.85875e-01\n",
            "epoch: 453, iter: 26, training_loss: 4.03216e-01\n",
            "epoch: 454, iter: 26, training_loss: 3.20926e-01\n",
            "epoch: 455, iter: 26, training_loss: 2.96096e-01\n",
            "epoch: 456, iter: 26, training_loss: 3.27893e-01\n",
            "epoch: 457, iter: 26, training_loss: 3.27375e-01\n",
            "epoch: 458, iter: 26, training_loss: 3.27405e-01\n",
            "epoch: 459, iter: 26, training_loss: 2.83568e-01\n",
            "epoch: 460, iter: 26, training_loss: 2.91767e-01\n",
            "epoch: 461, iter: 26, training_loss: 3.90499e-01\n",
            "epoch: 462, iter: 26, training_loss: 3.29434e-01\n",
            "epoch: 463, iter: 26, training_loss: 3.14822e-01\n",
            "epoch: 464, iter: 26, training_loss: 2.92761e-01\n",
            "epoch: 465, iter: 26, training_loss: 3.80064e-01\n",
            "epoch: 466, iter: 26, training_loss: 3.29542e-01\n",
            "epoch: 467, iter: 26, training_loss: 3.18245e-01\n",
            "epoch: 468, iter: 26, training_loss: 2.89830e-01\n",
            "epoch: 469, iter: 26, training_loss: 2.95661e-01\n",
            "epoch: 470, iter: 26, training_loss: 3.27853e-01\n",
            "epoch: 471, iter: 26, training_loss: 2.93378e-01\n",
            "epoch: 472, iter: 26, training_loss: 2.86021e-01\n",
            "epoch: 473, iter: 26, training_loss: 3.26132e-01\n",
            "epoch: 474, iter: 26, training_loss: 3.39339e-01\n",
            "epoch: 475, iter: 26, training_loss: 2.94031e-01\n",
            "epoch: 476, iter: 26, training_loss: 2.87557e-01\n",
            "epoch: 477, iter: 26, training_loss: 2.79596e-01\n",
            "epoch: 478, iter: 26, training_loss: 3.18779e-01\n",
            "epoch: 479, iter: 26, training_loss: 5.03809e-01\n",
            "epoch: 480, iter: 26, training_loss: 3.64062e-01\n",
            "epoch: 481, iter: 26, training_loss: 3.73966e-01\n",
            "epoch: 482, iter: 26, training_loss: 3.21854e-01\n",
            "epoch: 483, iter: 26, training_loss: 3.12383e-01\n",
            "epoch: 484, iter: 26, training_loss: 3.11211e-01\n",
            "epoch: 485, iter: 26, training_loss: 4.15316e-01\n",
            "epoch: 486, iter: 26, training_loss: 3.30559e-01\n",
            "epoch: 487, iter: 26, training_loss: 2.88774e-01\n",
            "epoch: 488, iter: 26, training_loss: 3.43920e-01\n",
            "epoch: 489, iter: 26, training_loss: 2.97815e-01\n",
            "epoch: 490, iter: 26, training_loss: 3.62351e-01\n",
            "epoch: 491, iter: 26, training_loss: 3.31510e-01\n",
            "epoch: 492, iter: 26, training_loss: 2.79542e-01\n",
            "epoch: 493, iter: 26, training_loss: 2.83883e-01\n",
            "epoch: 494, iter: 26, training_loss: 3.32372e-01\n",
            "epoch: 495, iter: 26, training_loss: 2.72090e-01\n",
            "epoch: 496, iter: 26, training_loss: 3.75234e-01\n",
            "epoch: 497, iter: 26, training_loss: 3.67478e-01\n",
            "epoch: 498, iter: 26, training_loss: 3.88846e-01\n",
            "epoch: 499, iter: 26, training_loss: 3.23489e-01\n",
            "epoch: 500, iter: 26, training_loss: 3.04103e-01\n",
            "epoch: 501, iter: 26, training_loss: 3.15243e-01\n",
            "epoch: 502, iter: 26, training_loss: 2.95896e-01\n",
            "epoch: 503, iter: 26, training_loss: 2.69774e-01\n",
            "epoch: 504, iter: 26, training_loss: 3.14953e-01\n",
            "epoch: 505, iter: 26, training_loss: 3.51712e-01\n",
            "epoch: 506, iter: 26, training_loss: 3.17349e-01\n",
            "epoch: 507, iter: 26, training_loss: 3.15008e-01\n",
            "epoch: 508, iter: 26, training_loss: 2.95538e-01\n",
            "epoch: 509, iter: 26, training_loss: 2.71530e-01\n",
            "epoch: 510, iter: 26, training_loss: 2.69463e-01\n",
            "epoch: 511, iter: 26, training_loss: 2.66274e-01\n",
            "epoch: 512, iter: 26, training_loss: 3.49537e-01\n",
            "epoch: 513, iter: 26, training_loss: 4.15108e-01\n",
            "epoch: 514, iter: 26, training_loss: 3.82712e-01\n",
            "epoch: 515, iter: 26, training_loss: 3.33653e-01\n",
            "epoch: 516, iter: 26, training_loss: 3.27020e-01\n",
            "epoch: 517, iter: 26, training_loss: 3.77098e-01\n",
            "epoch: 518, iter: 26, training_loss: 3.66297e-01\n",
            "epoch: 519, iter: 26, training_loss: 3.10463e-01\n",
            "epoch: 520, iter: 26, training_loss: 3.14113e-01\n",
            "epoch: 521, iter: 26, training_loss: 3.04937e-01\n",
            "epoch: 522, iter: 26, training_loss: 3.16329e-01\n",
            "epoch: 523, iter: 26, training_loss: 3.73249e-01\n",
            "epoch: 524, iter: 26, training_loss: 3.33058e-01\n",
            "epoch: 525, iter: 26, training_loss: 2.84823e-01\n",
            "epoch: 526, iter: 26, training_loss: 2.65650e-01\n",
            "epoch: 527, iter: 26, training_loss: 3.43990e-01\n",
            "epoch: 528, iter: 26, training_loss: 2.99676e-01\n",
            "epoch: 529, iter: 26, training_loss: 3.16674e-01\n",
            "epoch: 530, iter: 26, training_loss: 3.19422e-01\n",
            "epoch: 531, iter: 26, training_loss: 3.22558e-01\n",
            "epoch: 532, iter: 26, training_loss: 3.45172e-01\n",
            "epoch: 533, iter: 26, training_loss: 3.37505e-01\n",
            "epoch: 534, iter: 26, training_loss: 3.74194e-01\n",
            "epoch: 535, iter: 26, training_loss: 2.92260e-01\n",
            "epoch: 536, iter: 26, training_loss: 3.40005e-01\n",
            "epoch: 537, iter: 26, training_loss: 3.37967e-01\n",
            "epoch: 538, iter: 26, training_loss: 3.01661e-01\n",
            "epoch: 539, iter: 26, training_loss: 2.61144e-01\n",
            "epoch: 540, iter: 26, training_loss: 2.50989e-01\n",
            "epoch: 541, iter: 26, training_loss: 2.48488e-01\n",
            "epoch: 542, iter: 26, training_loss: 2.42398e-01\n",
            "epoch: 543, iter: 26, training_loss: 3.53680e-01\n",
            "epoch: 544, iter: 26, training_loss: 2.89486e-01\n",
            "epoch: 545, iter: 26, training_loss: 3.11734e-01\n",
            "epoch: 546, iter: 26, training_loss: 2.81328e-01\n",
            "epoch: 547, iter: 26, training_loss: 2.57931e-01\n",
            "epoch: 548, iter: 26, training_loss: 2.44612e-01\n",
            "epoch: 549, iter: 26, training_loss: 2.81100e-01\n",
            "epoch: 550, iter: 26, training_loss: 2.70256e-01\n",
            "epoch: 551, iter: 26, training_loss: 4.09818e-01\n",
            "epoch: 552, iter: 26, training_loss: 4.04152e-01\n",
            "epoch: 553, iter: 26, training_loss: 3.32358e-01\n",
            "epoch: 554, iter: 26, training_loss: 2.78801e-01\n",
            "epoch: 555, iter: 26, training_loss: 3.10439e-01\n",
            "epoch: 556, iter: 26, training_loss: 2.94659e-01\n",
            "epoch: 557, iter: 26, training_loss: 3.23094e-01\n",
            "epoch: 558, iter: 26, training_loss: 2.67377e-01\n",
            "epoch: 559, iter: 26, training_loss: 2.71496e-01\n",
            "epoch: 560, iter: 26, training_loss: 2.76449e-01\n",
            "epoch: 561, iter: 26, training_loss: 2.62250e-01\n",
            "epoch: 562, iter: 26, training_loss: 2.66033e-01\n",
            "epoch: 563, iter: 26, training_loss: 2.53334e-01\n",
            "epoch: 564, iter: 26, training_loss: 2.88401e-01\n",
            "epoch: 565, iter: 26, training_loss: 3.26745e-01\n",
            "epoch: 566, iter: 26, training_loss: 3.18783e-01\n",
            "epoch: 567, iter: 26, training_loss: 3.23569e-01\n",
            "epoch: 568, iter: 26, training_loss: 2.92836e-01\n",
            "epoch: 569, iter: 26, training_loss: 3.47443e-01\n",
            "epoch: 570, iter: 26, training_loss: 3.54987e-01\n",
            "epoch: 571, iter: 26, training_loss: 2.97482e-01\n",
            "epoch: 572, iter: 26, training_loss: 2.58891e-01\n",
            "epoch: 573, iter: 26, training_loss: 2.77243e-01\n",
            "epoch: 574, iter: 26, training_loss: 2.91000e-01\n",
            "epoch: 575, iter: 26, training_loss: 2.76759e-01\n",
            "epoch: 576, iter: 26, training_loss: 2.57470e-01\n",
            "epoch: 577, iter: 26, training_loss: 2.66886e-01\n",
            "epoch: 578, iter: 26, training_loss: 2.56329e-01\n",
            "epoch: 579, iter: 26, training_loss: 3.22928e-01\n",
            "epoch: 580, iter: 26, training_loss: 3.12549e-01\n",
            "epoch: 581, iter: 26, training_loss: 3.07680e-01\n",
            "epoch: 582, iter: 26, training_loss: 2.58391e-01\n",
            "epoch: 583, iter: 26, training_loss: 3.15567e-01\n",
            "epoch: 584, iter: 26, training_loss: 3.35918e-01\n",
            "epoch: 585, iter: 26, training_loss: 2.98846e-01\n",
            "epoch: 586, iter: 26, training_loss: 3.05632e-01\n",
            "epoch: 587, iter: 26, training_loss: 2.77809e-01\n",
            "epoch: 588, iter: 26, training_loss: 2.50051e-01\n",
            "epoch: 589, iter: 26, training_loss: 2.58731e-01\n",
            "epoch: 590, iter: 26, training_loss: 2.64316e-01\n",
            "epoch: 591, iter: 26, training_loss: 2.98884e-01\n",
            "epoch: 592, iter: 26, training_loss: 2.81312e-01\n",
            "epoch: 593, iter: 26, training_loss: 2.43965e-01\n",
            "epoch: 594, iter: 26, training_loss: 2.85399e-01\n",
            "epoch: 595, iter: 26, training_loss: 2.82921e-01\n",
            "epoch: 596, iter: 26, training_loss: 2.51456e-01\n",
            "epoch: 597, iter: 26, training_loss: 2.99307e-01\n",
            "epoch: 598, iter: 26, training_loss: 2.97439e-01\n",
            "epoch: 599, iter: 26, training_loss: 2.74708e-01\n",
            "epoch: 600, iter: 26, training_loss: 2.47963e-01\n",
            "epoch: 601, iter: 26, training_loss: 2.33347e-01\n",
            "epoch: 602, iter: 26, training_loss: 2.97089e-01\n",
            "epoch: 603, iter: 26, training_loss: 3.71612e-01\n",
            "epoch: 604, iter: 26, training_loss: 3.12753e-01\n",
            "epoch: 605, iter: 26, training_loss: 2.86198e-01\n",
            "epoch: 606, iter: 26, training_loss: 2.45350e-01\n",
            "epoch: 607, iter: 26, training_loss: 2.45963e-01\n",
            "epoch: 608, iter: 26, training_loss: 2.98682e-01\n",
            "epoch: 609, iter: 26, training_loss: 3.21576e-01\n",
            "epoch: 610, iter: 26, training_loss: 2.89356e-01\n",
            "epoch: 611, iter: 26, training_loss: 2.49013e-01\n",
            "epoch: 612, iter: 26, training_loss: 2.28757e-01\n",
            "epoch: 613, iter: 26, training_loss: 3.01055e-01\n",
            "epoch: 614, iter: 26, training_loss: 2.92378e-01\n",
            "epoch: 615, iter: 26, training_loss: 2.73228e-01\n",
            "epoch: 616, iter: 26, training_loss: 3.14552e-01\n",
            "epoch: 617, iter: 26, training_loss: 2.92552e-01\n",
            "epoch: 618, iter: 26, training_loss: 2.93085e-01\n",
            "epoch: 619, iter: 26, training_loss: 2.88978e-01\n",
            "epoch: 620, iter: 26, training_loss: 2.67883e-01\n",
            "epoch: 621, iter: 26, training_loss: 2.60422e-01\n",
            "epoch: 622, iter: 26, training_loss: 2.81955e-01\n",
            "epoch: 623, iter: 26, training_loss: 2.53027e-01\n",
            "epoch: 624, iter: 26, training_loss: 2.83068e-01\n",
            "epoch: 625, iter: 26, training_loss: 3.38161e-01\n",
            "epoch: 626, iter: 26, training_loss: 3.11658e-01\n",
            "epoch: 627, iter: 26, training_loss: 2.64860e-01\n",
            "epoch: 628, iter: 26, training_loss: 2.36510e-01\n",
            "epoch: 629, iter: 26, training_loss: 3.05740e-01\n",
            "epoch: 630, iter: 26, training_loss: 2.83854e-01\n",
            "epoch: 631, iter: 26, training_loss: 2.75950e-01\n",
            "epoch: 632, iter: 26, training_loss: 2.58363e-01\n",
            "epoch: 633, iter: 26, training_loss: 2.37373e-01\n",
            "epoch: 634, iter: 26, training_loss: 2.55854e-01\n",
            "epoch: 635, iter: 26, training_loss: 2.61662e-01\n",
            "epoch: 636, iter: 26, training_loss: 2.40165e-01\n",
            "epoch: 637, iter: 26, training_loss: 2.35876e-01\n",
            "epoch: 638, iter: 26, training_loss: 2.20641e-01\n",
            "epoch: 639, iter: 26, training_loss: 2.17692e-01\n",
            "epoch: 640, iter: 26, training_loss: 3.22159e-01\n",
            "epoch: 641, iter: 26, training_loss: 2.88690e-01\n",
            "epoch: 642, iter: 26, training_loss: 2.39831e-01\n",
            "epoch: 643, iter: 26, training_loss: 2.44103e-01\n",
            "epoch: 644, iter: 26, training_loss: 2.77825e-01\n",
            "epoch: 645, iter: 26, training_loss: 2.87896e-01\n",
            "epoch: 646, iter: 26, training_loss: 2.64665e-01\n",
            "epoch: 647, iter: 26, training_loss: 2.61412e-01\n",
            "epoch: 648, iter: 26, training_loss: 2.45574e-01\n",
            "epoch: 649, iter: 26, training_loss: 2.65414e-01\n",
            "epoch: 650, iter: 26, training_loss: 2.65708e-01\n",
            "epoch: 651, iter: 26, training_loss: 2.57895e-01\n",
            "epoch: 652, iter: 26, training_loss: 2.33584e-01\n",
            "epoch: 653, iter: 26, training_loss: 2.29761e-01\n",
            "epoch: 654, iter: 26, training_loss: 2.37187e-01\n",
            "epoch: 655, iter: 26, training_loss: 2.18078e-01\n",
            "epoch: 656, iter: 26, training_loss: 2.15868e-01\n",
            "epoch: 657, iter: 26, training_loss: 2.24786e-01\n",
            "epoch: 658, iter: 26, training_loss: 2.20834e-01\n",
            "epoch: 659, iter: 26, training_loss: 2.48957e-01\n",
            "epoch: 660, iter: 26, training_loss: 3.30908e-01\n",
            "epoch: 661, iter: 26, training_loss: 2.71890e-01\n",
            "epoch: 662, iter: 26, training_loss: 2.31278e-01\n",
            "epoch: 663, iter: 26, training_loss: 2.27069e-01\n",
            "epoch: 664, iter: 26, training_loss: 2.24301e-01\n",
            "epoch: 665, iter: 26, training_loss: 2.25058e-01\n",
            "epoch: 666, iter: 26, training_loss: 2.43193e-01\n",
            "epoch: 667, iter: 26, training_loss: 2.56678e-01\n",
            "epoch: 668, iter: 26, training_loss: 2.28369e-01\n",
            "epoch: 669, iter: 26, training_loss: 2.12537e-01\n",
            "epoch: 670, iter: 26, training_loss: 2.36945e-01\n",
            "epoch: 671, iter: 26, training_loss: 2.52356e-01\n",
            "epoch: 672, iter: 26, training_loss: 2.71004e-01\n",
            "epoch: 673, iter: 26, training_loss: 2.52940e-01\n",
            "epoch: 674, iter: 26, training_loss: 2.26334e-01\n",
            "epoch: 675, iter: 26, training_loss: 2.25993e-01\n",
            "epoch: 676, iter: 26, training_loss: 2.49860e-01\n",
            "epoch: 677, iter: 26, training_loss: 2.64851e-01\n",
            "epoch: 678, iter: 26, training_loss: 2.50887e-01\n",
            "epoch: 679, iter: 26, training_loss: 2.46282e-01\n",
            "epoch: 680, iter: 26, training_loss: 2.45084e-01\n",
            "epoch: 681, iter: 26, training_loss: 2.12651e-01\n",
            "epoch: 682, iter: 26, training_loss: 2.46163e-01\n",
            "epoch: 683, iter: 26, training_loss: 3.51627e-01\n",
            "epoch: 684, iter: 26, training_loss: 2.43794e-01\n",
            "epoch: 685, iter: 26, training_loss: 2.37464e-01\n",
            "epoch: 686, iter: 26, training_loss: 2.65615e-01\n",
            "epoch: 687, iter: 26, training_loss: 2.57494e-01\n",
            "epoch: 688, iter: 26, training_loss: 2.11555e-01\n",
            "epoch: 689, iter: 26, training_loss: 2.31654e-01\n",
            "epoch: 690, iter: 26, training_loss: 2.59076e-01\n",
            "epoch: 691, iter: 26, training_loss: 2.89517e-01\n",
            "epoch: 692, iter: 26, training_loss: 3.42331e-01\n",
            "epoch: 693, iter: 26, training_loss: 3.11775e-01\n",
            "epoch: 694, iter: 26, training_loss: 2.84326e-01\n",
            "epoch: 695, iter: 26, training_loss: 2.85757e-01\n",
            "epoch: 696, iter: 26, training_loss: 2.50025e-01\n",
            "epoch: 697, iter: 26, training_loss: 2.30689e-01\n",
            "epoch: 698, iter: 26, training_loss: 2.33289e-01\n",
            "epoch: 699, iter: 26, training_loss: 2.19598e-01\n",
            "epoch: 700, iter: 26, training_loss: 2.09295e-01\n",
            "epoch: 701, iter: 26, training_loss: 2.93254e-01\n",
            "epoch: 702, iter: 26, training_loss: 2.76882e-01\n",
            "epoch: 703, iter: 26, training_loss: 2.27663e-01\n",
            "epoch: 704, iter: 26, training_loss: 2.76074e-01\n",
            "epoch: 705, iter: 26, training_loss: 2.88386e-01\n",
            "epoch: 706, iter: 26, training_loss: 2.32292e-01\n",
            "epoch: 707, iter: 26, training_loss: 2.18515e-01\n",
            "epoch: 708, iter: 26, training_loss: 2.15324e-01\n",
            "epoch: 709, iter: 26, training_loss: 2.72928e-01\n",
            "epoch: 710, iter: 26, training_loss: 3.00179e-01\n",
            "epoch: 711, iter: 26, training_loss: 2.51520e-01\n",
            "epoch: 712, iter: 26, training_loss: 2.46635e-01\n",
            "epoch: 713, iter: 26, training_loss: 2.49968e-01\n",
            "epoch: 714, iter: 26, training_loss: 2.52433e-01\n",
            "epoch: 715, iter: 26, training_loss: 2.19345e-01\n",
            "epoch: 716, iter: 26, training_loss: 3.16093e-01\n",
            "epoch: 717, iter: 26, training_loss: 2.53570e-01\n",
            "epoch: 718, iter: 26, training_loss: 2.56302e-01\n",
            "epoch: 719, iter: 26, training_loss: 2.46380e-01\n",
            "epoch: 720, iter: 26, training_loss: 2.63205e-01\n",
            "epoch: 721, iter: 26, training_loss: 2.42167e-01\n",
            "epoch: 722, iter: 26, training_loss: 2.16526e-01\n",
            "epoch: 723, iter: 26, training_loss: 2.13991e-01\n",
            "epoch: 724, iter: 26, training_loss: 2.29740e-01\n",
            "epoch: 725, iter: 26, training_loss: 2.34950e-01\n",
            "epoch: 726, iter: 26, training_loss: 2.54227e-01\n",
            "epoch: 727, iter: 26, training_loss: 2.34046e-01\n",
            "epoch: 728, iter: 26, training_loss: 2.22648e-01\n",
            "epoch: 729, iter: 26, training_loss: 2.04037e-01\n",
            "epoch: 730, iter: 26, training_loss: 2.35182e-01\n",
            "epoch: 731, iter: 26, training_loss: 2.41927e-01\n",
            "epoch: 732, iter: 26, training_loss: 2.47199e-01\n",
            "epoch: 733, iter: 26, training_loss: 2.23594e-01\n",
            "epoch: 734, iter: 26, training_loss: 2.01285e-01\n",
            "epoch: 735, iter: 26, training_loss: 2.08938e-01\n",
            "epoch: 736, iter: 26, training_loss: 3.45507e-01\n",
            "epoch: 737, iter: 26, training_loss: 2.66542e-01\n",
            "epoch: 738, iter: 26, training_loss: 2.55107e-01\n",
            "epoch: 739, iter: 26, training_loss: 2.44525e-01\n",
            "epoch: 740, iter: 26, training_loss: 2.71876e-01\n",
            "epoch: 741, iter: 26, training_loss: 2.27905e-01\n",
            "epoch: 742, iter: 26, training_loss: 2.53887e-01\n",
            "epoch: 743, iter: 26, training_loss: 2.59472e-01\n",
            "epoch: 744, iter: 26, training_loss: 3.23825e-01\n",
            "epoch: 745, iter: 26, training_loss: 2.40004e-01\n",
            "epoch: 746, iter: 26, training_loss: 2.74114e-01\n",
            "epoch: 747, iter: 26, training_loss: 2.40266e-01\n",
            "epoch: 748, iter: 26, training_loss: 2.22101e-01\n",
            "epoch: 749, iter: 26, training_loss: 2.18277e-01\n",
            "epoch: 750, iter: 26, training_loss: 2.18057e-01\n",
            "epoch: 751, iter: 26, training_loss: 2.63386e-01\n",
            "epoch: 752, iter: 26, training_loss: 2.66775e-01\n",
            "epoch: 753, iter: 26, training_loss: 2.93244e-01\n",
            "epoch: 754, iter: 26, training_loss: 2.31576e-01\n",
            "epoch: 755, iter: 26, training_loss: 2.54961e-01\n",
            "epoch: 756, iter: 26, training_loss: 2.19884e-01\n",
            "epoch: 757, iter: 26, training_loss: 2.01933e-01\n",
            "epoch: 758, iter: 26, training_loss: 2.16932e-01\n",
            "epoch: 759, iter: 26, training_loss: 2.07814e-01\n",
            "epoch: 760, iter: 26, training_loss: 2.24284e-01\n",
            "epoch: 761, iter: 26, training_loss: 2.76824e-01\n",
            "epoch: 762, iter: 26, training_loss: 2.28192e-01\n",
            "epoch: 763, iter: 26, training_loss: 2.15155e-01\n",
            "epoch: 764, iter: 26, training_loss: 2.39902e-01\n",
            "epoch: 765, iter: 26, training_loss: 2.27049e-01\n",
            "epoch: 766, iter: 26, training_loss: 2.60909e-01\n",
            "epoch: 767, iter: 26, training_loss: 2.44599e-01\n",
            "epoch: 768, iter: 26, training_loss: 2.61527e-01\n",
            "epoch: 769, iter: 26, training_loss: 2.26531e-01\n",
            "epoch: 770, iter: 26, training_loss: 2.04857e-01\n",
            "epoch: 771, iter: 26, training_loss: 2.61559e-01\n",
            "epoch: 772, iter: 26, training_loss: 2.42297e-01\n",
            "epoch: 773, iter: 26, training_loss: 2.10400e-01\n",
            "epoch: 774, iter: 26, training_loss: 2.35365e-01\n",
            "epoch: 775, iter: 26, training_loss: 2.60321e-01\n",
            "epoch: 776, iter: 26, training_loss: 2.11688e-01\n",
            "epoch: 777, iter: 26, training_loss: 2.04128e-01\n",
            "epoch: 778, iter: 26, training_loss: 2.11370e-01\n",
            "epoch: 779, iter: 26, training_loss: 2.28910e-01\n",
            "epoch: 780, iter: 26, training_loss: 2.64187e-01\n",
            "epoch: 781, iter: 26, training_loss: 2.56220e-01\n",
            "epoch: 782, iter: 26, training_loss: 2.11533e-01\n",
            "epoch: 783, iter: 26, training_loss: 1.99806e-01\n",
            "epoch: 784, iter: 26, training_loss: 2.14533e-01\n",
            "epoch: 785, iter: 26, training_loss: 2.24412e-01\n",
            "epoch: 786, iter: 26, training_loss: 2.54136e-01\n",
            "epoch: 787, iter: 26, training_loss: 2.28023e-01\n",
            "epoch: 788, iter: 26, training_loss: 2.11128e-01\n",
            "epoch: 789, iter: 26, training_loss: 2.01857e-01\n",
            "epoch: 790, iter: 26, training_loss: 2.01530e-01\n",
            "epoch: 791, iter: 26, training_loss: 2.46282e-01\n",
            "epoch: 792, iter: 26, training_loss: 2.27783e-01\n",
            "epoch: 793, iter: 26, training_loss: 2.87679e-01\n",
            "epoch: 794, iter: 26, training_loss: 2.80015e-01\n",
            "epoch: 795, iter: 26, training_loss: 2.26580e-01\n",
            "epoch: 796, iter: 26, training_loss: 2.07779e-01\n",
            "epoch: 797, iter: 26, training_loss: 2.03179e-01\n",
            "epoch: 798, iter: 26, training_loss: 2.26854e-01\n",
            "epoch: 799, iter: 26, training_loss: 2.43548e-01\n",
            "epoch: 800, iter: 26, training_loss: 2.29823e-01\n",
            "epoch: 801, iter: 26, training_loss: 2.13665e-01\n",
            "epoch: 802, iter: 26, training_loss: 2.37453e-01\n",
            "epoch: 803, iter: 26, training_loss: 2.39713e-01\n",
            "epoch: 804, iter: 26, training_loss: 2.51082e-01\n",
            "epoch: 805, iter: 26, training_loss: 2.45001e-01\n",
            "epoch: 806, iter: 26, training_loss: 2.30655e-01\n",
            "epoch: 807, iter: 26, training_loss: 2.27679e-01\n",
            "epoch: 808, iter: 26, training_loss: 2.15458e-01\n",
            "epoch: 809, iter: 26, training_loss: 2.93428e-01\n",
            "epoch: 810, iter: 26, training_loss: 2.46070e-01\n",
            "epoch: 811, iter: 26, training_loss: 2.16813e-01\n",
            "epoch: 812, iter: 26, training_loss: 2.21293e-01\n",
            "epoch: 813, iter: 26, training_loss: 2.05491e-01\n",
            "epoch: 814, iter: 26, training_loss: 2.67440e-01\n",
            "epoch: 815, iter: 26, training_loss: 2.76053e-01\n",
            "epoch: 816, iter: 26, training_loss: 2.23562e-01\n",
            "epoch: 817, iter: 26, training_loss: 1.98739e-01\n",
            "epoch: 818, iter: 26, training_loss: 1.98151e-01\n",
            "epoch: 819, iter: 26, training_loss: 2.74657e-01\n",
            "epoch: 820, iter: 26, training_loss: 2.11209e-01\n",
            "epoch: 821, iter: 26, training_loss: 2.00091e-01\n",
            "epoch: 822, iter: 26, training_loss: 1.98381e-01\n",
            "epoch: 823, iter: 26, training_loss: 2.34734e-01\n",
            "epoch: 824, iter: 26, training_loss: 2.30669e-01\n",
            "epoch: 825, iter: 26, training_loss: 2.37882e-01\n",
            "epoch: 826, iter: 26, training_loss: 2.12682e-01\n",
            "epoch: 827, iter: 26, training_loss: 2.31238e-01\n",
            "epoch: 828, iter: 26, training_loss: 2.32068e-01\n",
            "epoch: 829, iter: 26, training_loss: 2.44711e-01\n",
            "epoch: 830, iter: 26, training_loss: 2.02551e-01\n",
            "epoch: 831, iter: 26, training_loss: 2.50925e-01\n",
            "epoch: 832, iter: 26, training_loss: 2.10304e-01\n",
            "epoch: 833, iter: 26, training_loss: 1.97343e-01\n",
            "epoch: 834, iter: 26, training_loss: 1.88600e-01\n",
            "epoch: 835, iter: 26, training_loss: 2.29543e-01\n",
            "epoch: 836, iter: 26, training_loss: 2.12716e-01\n",
            "epoch: 837, iter: 26, training_loss: 1.93403e-01\n",
            "epoch: 838, iter: 26, training_loss: 2.09382e-01\n",
            "epoch: 839, iter: 26, training_loss: 2.61809e-01\n",
            "epoch: 840, iter: 26, training_loss: 2.23213e-01\n",
            "epoch: 841, iter: 26, training_loss: 1.87502e-01\n",
            "epoch: 842, iter: 26, training_loss: 2.16529e-01\n",
            "epoch: 843, iter: 26, training_loss: 1.92031e-01\n",
            "epoch: 844, iter: 26, training_loss: 1.85979e-01\n",
            "epoch: 845, iter: 26, training_loss: 2.19002e-01\n",
            "epoch: 846, iter: 26, training_loss: 3.16622e-01\n",
            "epoch: 847, iter: 26, training_loss: 2.69891e-01\n",
            "epoch: 848, iter: 26, training_loss: 2.06548e-01\n",
            "epoch: 849, iter: 26, training_loss: 1.93722e-01\n",
            "epoch: 850, iter: 26, training_loss: 2.11009e-01\n",
            "epoch: 851, iter: 26, training_loss: 2.05263e-01\n",
            "epoch: 852, iter: 26, training_loss: 2.38168e-01\n",
            "epoch: 853, iter: 26, training_loss: 2.65793e-01\n",
            "epoch: 854, iter: 26, training_loss: 2.13006e-01\n",
            "epoch: 855, iter: 26, training_loss: 1.91836e-01\n",
            "epoch: 856, iter: 26, training_loss: 2.07753e-01\n",
            "epoch: 857, iter: 26, training_loss: 2.28754e-01\n",
            "epoch: 858, iter: 26, training_loss: 2.00298e-01\n",
            "epoch: 859, iter: 26, training_loss: 2.12944e-01\n",
            "epoch: 860, iter: 26, training_loss: 2.22259e-01\n",
            "epoch: 861, iter: 26, training_loss: 1.95445e-01\n",
            "epoch: 862, iter: 26, training_loss: 1.90404e-01\n",
            "epoch: 863, iter: 26, training_loss: 1.84231e-01\n",
            "epoch: 864, iter: 26, training_loss: 2.23221e-01\n",
            "epoch: 865, iter: 26, training_loss: 2.04287e-01\n",
            "epoch: 866, iter: 26, training_loss: 2.25619e-01\n",
            "epoch: 867, iter: 26, training_loss: 2.09716e-01\n",
            "epoch: 868, iter: 26, training_loss: 2.14694e-01\n",
            "epoch: 869, iter: 26, training_loss: 2.01153e-01\n",
            "epoch: 870, iter: 26, training_loss: 2.02507e-01\n",
            "epoch: 871, iter: 26, training_loss: 2.27952e-01\n",
            "epoch: 872, iter: 26, training_loss: 2.14255e-01\n",
            "epoch: 873, iter: 26, training_loss: 2.35131e-01\n",
            "epoch: 874, iter: 26, training_loss: 1.97091e-01\n",
            "epoch: 875, iter: 26, training_loss: 1.93145e-01\n",
            "epoch: 876, iter: 26, training_loss: 2.30664e-01\n",
            "epoch: 877, iter: 26, training_loss: 2.16001e-01\n",
            "epoch: 878, iter: 26, training_loss: 2.19004e-01\n",
            "epoch: 879, iter: 26, training_loss: 2.09690e-01\n",
            "epoch: 880, iter: 26, training_loss: 2.50679e-01\n",
            "epoch: 881, iter: 26, training_loss: 2.18050e-01\n",
            "epoch: 882, iter: 26, training_loss: 1.95844e-01\n",
            "epoch: 883, iter: 26, training_loss: 1.93383e-01\n",
            "epoch: 884, iter: 26, training_loss: 2.21437e-01\n",
            "epoch: 885, iter: 26, training_loss: 2.01292e-01\n",
            "epoch: 886, iter: 26, training_loss: 1.91614e-01\n",
            "epoch: 887, iter: 26, training_loss: 2.37322e-01\n",
            "epoch: 888, iter: 26, training_loss: 2.16255e-01\n",
            "epoch: 889, iter: 26, training_loss: 1.96533e-01\n",
            "epoch: 890, iter: 26, training_loss: 2.21382e-01\n",
            "epoch: 891, iter: 26, training_loss: 2.53694e-01\n",
            "epoch: 892, iter: 26, training_loss: 2.07129e-01\n",
            "epoch: 893, iter: 26, training_loss: 2.21435e-01\n",
            "epoch: 894, iter: 26, training_loss: 1.84203e-01\n",
            "epoch: 895, iter: 26, training_loss: 2.04124e-01\n",
            "epoch: 896, iter: 26, training_loss: 1.98882e-01\n",
            "epoch: 897, iter: 26, training_loss: 1.80971e-01\n",
            "epoch: 898, iter: 26, training_loss: 1.82677e-01\n",
            "epoch: 899, iter: 26, training_loss: 2.12854e-01\n",
            "epoch: 900, iter: 26, training_loss: 2.18491e-01\n",
            "epoch: 901, iter: 26, training_loss: 1.97661e-01\n",
            "epoch: 902, iter: 26, training_loss: 1.83765e-01\n",
            "epoch: 903, iter: 26, training_loss: 2.18923e-01\n",
            "epoch: 904, iter: 26, training_loss: 2.03698e-01\n",
            "epoch: 905, iter: 26, training_loss: 1.78910e-01\n",
            "epoch: 906, iter: 26, training_loss: 2.25388e-01\n",
            "epoch: 907, iter: 26, training_loss: 2.28066e-01\n",
            "epoch: 908, iter: 26, training_loss: 2.12445e-01\n",
            "epoch: 909, iter: 26, training_loss: 2.47154e-01\n",
            "epoch: 910, iter: 26, training_loss: 2.05174e-01\n",
            "epoch: 911, iter: 26, training_loss: 1.84185e-01\n",
            "epoch: 912, iter: 26, training_loss: 2.35793e-01\n",
            "epoch: 913, iter: 26, training_loss: 2.80769e-01\n",
            "epoch: 914, iter: 26, training_loss: 2.14752e-01\n",
            "epoch: 915, iter: 26, training_loss: 2.20634e-01\n",
            "epoch: 916, iter: 26, training_loss: 2.59424e-01\n",
            "epoch: 917, iter: 26, training_loss: 1.99863e-01\n",
            "epoch: 918, iter: 26, training_loss: 2.14921e-01\n",
            "epoch: 919, iter: 26, training_loss: 2.16196e-01\n",
            "epoch: 920, iter: 26, training_loss: 2.08450e-01\n",
            "epoch: 921, iter: 26, training_loss: 2.09961e-01\n",
            "epoch: 922, iter: 26, training_loss: 2.01769e-01\n",
            "epoch: 923, iter: 26, training_loss: 2.03665e-01\n",
            "epoch: 924, iter: 26, training_loss: 1.99987e-01\n",
            "epoch: 925, iter: 26, training_loss: 2.05037e-01\n",
            "epoch: 926, iter: 26, training_loss: 1.89804e-01\n",
            "epoch: 927, iter: 26, training_loss: 1.87756e-01\n",
            "epoch: 928, iter: 26, training_loss: 1.96898e-01\n",
            "epoch: 929, iter: 26, training_loss: 2.38685e-01\n",
            "epoch: 930, iter: 26, training_loss: 1.93197e-01\n",
            "epoch: 931, iter: 26, training_loss: 1.81263e-01\n",
            "epoch: 932, iter: 26, training_loss: 2.06209e-01\n",
            "epoch: 933, iter: 26, training_loss: 2.22027e-01\n",
            "epoch: 934, iter: 26, training_loss: 2.02150e-01\n",
            "epoch: 935, iter: 26, training_loss: 2.14364e-01\n",
            "epoch: 936, iter: 26, training_loss: 2.09179e-01\n",
            "epoch: 937, iter: 26, training_loss: 2.09094e-01\n",
            "epoch: 938, iter: 26, training_loss: 1.85730e-01\n",
            "epoch: 939, iter: 26, training_loss: 2.00757e-01\n",
            "epoch: 940, iter: 26, training_loss: 2.83216e-01\n",
            "epoch: 941, iter: 26, training_loss: 2.11078e-01\n",
            "epoch: 942, iter: 26, training_loss: 2.18455e-01\n",
            "epoch: 943, iter: 26, training_loss: 2.35693e-01\n",
            "epoch: 944, iter: 26, training_loss: 1.97917e-01\n",
            "epoch: 945, iter: 26, training_loss: 2.32866e-01\n",
            "epoch: 946, iter: 26, training_loss: 2.05726e-01\n",
            "epoch: 947, iter: 26, training_loss: 2.99217e-01\n",
            "epoch: 948, iter: 26, training_loss: 2.10927e-01\n",
            "epoch: 949, iter: 26, training_loss: 1.92945e-01\n",
            "epoch: 950, iter: 26, training_loss: 2.26621e-01\n",
            "epoch: 951, iter: 26, training_loss: 1.95243e-01\n",
            "epoch: 952, iter: 26, training_loss: 1.78047e-01\n",
            "epoch: 953, iter: 26, training_loss: 2.16823e-01\n",
            "epoch: 954, iter: 26, training_loss: 2.24107e-01\n",
            "epoch: 955, iter: 26, training_loss: 2.04209e-01\n",
            "epoch: 956, iter: 26, training_loss: 2.00510e-01\n",
            "epoch: 957, iter: 26, training_loss: 1.76929e-01\n",
            "epoch: 958, iter: 26, training_loss: 1.74190e-01\n",
            "epoch: 959, iter: 26, training_loss: 1.85261e-01\n",
            "epoch: 960, iter: 26, training_loss: 2.63479e-01\n",
            "epoch: 961, iter: 26, training_loss: 2.05904e-01\n",
            "epoch: 962, iter: 26, training_loss: 2.16299e-01\n",
            "epoch: 963, iter: 26, training_loss: 2.30207e-01\n",
            "epoch: 964, iter: 26, training_loss: 2.01427e-01\n",
            "epoch: 965, iter: 26, training_loss: 2.04233e-01\n",
            "epoch: 966, iter: 26, training_loss: 1.81247e-01\n",
            "epoch: 967, iter: 26, training_loss: 1.82392e-01\n",
            "epoch: 968, iter: 26, training_loss: 1.72346e-01\n",
            "epoch: 969, iter: 26, training_loss: 2.00874e-01\n",
            "epoch: 970, iter: 26, training_loss: 2.00711e-01\n",
            "epoch: 971, iter: 26, training_loss: 1.77541e-01\n",
            "epoch: 972, iter: 26, training_loss: 1.84533e-01\n",
            "epoch: 973, iter: 26, training_loss: 2.16464e-01\n",
            "epoch: 974, iter: 26, training_loss: 1.79730e-01\n",
            "epoch: 975, iter: 26, training_loss: 1.71739e-01\n",
            "epoch: 976, iter: 26, training_loss: 2.21302e-01\n",
            "epoch: 977, iter: 26, training_loss: 2.11720e-01\n",
            "epoch: 978, iter: 26, training_loss: 1.89290e-01\n",
            "epoch: 979, iter: 26, training_loss: 1.90046e-01\n",
            "epoch: 980, iter: 26, training_loss: 1.89063e-01\n",
            "epoch: 981, iter: 26, training_loss: 1.97890e-01\n",
            "epoch: 982, iter: 26, training_loss: 1.72912e-01\n",
            "epoch: 983, iter: 26, training_loss: 2.50450e-01\n",
            "epoch: 984, iter: 26, training_loss: 2.41798e-01\n",
            "epoch: 985, iter: 26, training_loss: 2.00137e-01\n",
            "epoch: 986, iter: 26, training_loss: 1.71488e-01\n",
            "epoch: 987, iter: 26, training_loss: 2.01380e-01\n",
            "epoch: 988, iter: 26, training_loss: 1.76132e-01\n",
            "epoch: 989, iter: 26, training_loss: 2.37646e-01\n",
            "epoch: 990, iter: 26, training_loss: 1.91287e-01\n",
            "epoch: 991, iter: 26, training_loss: 1.73314e-01\n",
            "epoch: 992, iter: 26, training_loss: 1.75304e-01\n",
            "epoch: 993, iter: 26, training_loss: 1.85013e-01\n",
            "epoch: 994, iter: 26, training_loss: 1.90253e-01\n",
            "epoch: 995, iter: 26, training_loss: 1.82550e-01\n",
            "epoch: 996, iter: 26, training_loss: 1.91160e-01\n",
            "epoch: 997, iter: 26, training_loss: 2.01808e-01\n",
            "epoch: 998, iter: 26, training_loss: 2.18387e-01\n",
            "epoch: 999, iter: 26, training_loss: 2.27417e-01\n",
            "epoch: 1000, iter: 26, training_loss: 2.03223e-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname default --method stasy --mode sample --save_path default_syn.csv"
      ],
      "metadata": {
        "id": "Iq6bmOW1uzvq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6107f3b9-f9b8-40c8-a232-3b5e5d74a42d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No NaNs in numerical features, skipping\n",
            "Input dimension: 93\n",
            "NCSNpp(\n",
            "  (act): ELU(alpha=1.0)\n",
            "  (all_modules): ModuleList(\n",
            "    (0): GaussianFourierProjection()\n",
            "    (1): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (3): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=93, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (4): ELU(alpha=1.0)\n",
            "    (5): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=1117, out_features=2048, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=2048, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=2048, bias=True)\n",
            "    )\n",
            "    (6): ELU(alpha=1.0)\n",
            "    (7): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=3165, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (8): ELU(alpha=1.0)\n",
            "    (9): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=4189, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (10): ELU(alpha=1.0)\n",
            "    (11): Linear(in_features=5213, out_features=93, bias=True)\n",
            "  )\n",
            ")\n",
            "the number of parameters 10517606\n",
            "Loading SAVED model at from /content/tabsyn/baselines/stasy/ckpt/default/model.pth\n",
            "Start sampling...\n",
            "(27000, 10)\n",
            "Sampling time = 43.4890022277832\n",
            "Saving sampled data to default_syn.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname shoppers --method stasy --mode train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIV5D1YmDu2C",
        "outputId": "396fcc80-d1e0-4592-a0d4-7d9e16194df6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No NaNs in numerical features, skipping\n",
            "77\n",
            "NCSNpp(\n",
            "  (act): ELU(alpha=1.0)\n",
            "  (all_modules): ModuleList(\n",
            "    (0): GaussianFourierProjection()\n",
            "    (1): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (3): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=77, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (4): ELU(alpha=1.0)\n",
            "    (5): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=1101, out_features=2048, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=2048, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=2048, bias=True)\n",
            "    )\n",
            "    (6): ELU(alpha=1.0)\n",
            "    (7): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=3149, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (8): ELU(alpha=1.0)\n",
            "    (9): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=4173, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (10): ELU(alpha=1.0)\n",
            "    (11): Linear(in_features=5197, out_features=77, bias=True)\n",
            "  )\n",
            ")\n",
            "the number of parameters 10351030\n",
            "epoch: 0, iter: 11, training_loss: 3.65814e+00\n",
            "epoch: 1, iter: 11, training_loss: 2.09271e+00\n",
            "epoch: 2, iter: 11, training_loss: 1.31195e+00\n",
            "epoch: 3, iter: 11, training_loss: 1.35203e+00\n",
            "epoch: 4, iter: 11, training_loss: 1.26142e+00\n",
            "epoch: 5, iter: 11, training_loss: 1.34207e+00\n",
            "epoch: 6, iter: 11, training_loss: 1.23606e+00\n",
            "epoch: 7, iter: 11, training_loss: 1.28056e+00\n",
            "epoch: 8, iter: 11, training_loss: 1.22472e+00\n",
            "epoch: 9, iter: 11, training_loss: 1.23089e+00\n",
            "epoch: 10, iter: 11, training_loss: 1.28502e+00\n",
            "epoch: 11, iter: 11, training_loss: 1.25668e+00\n",
            "epoch: 12, iter: 11, training_loss: 1.22448e+00\n",
            "epoch: 13, iter: 11, training_loss: 1.28053e+00\n",
            "epoch: 14, iter: 11, training_loss: 1.22222e+00\n",
            "epoch: 15, iter: 11, training_loss: 1.22799e+00\n",
            "epoch: 16, iter: 11, training_loss: 1.19519e+00\n",
            "epoch: 17, iter: 11, training_loss: 1.17584e+00\n",
            "epoch: 18, iter: 11, training_loss: 1.20252e+00\n",
            "epoch: 19, iter: 11, training_loss: 1.12785e+00\n",
            "epoch: 20, iter: 11, training_loss: 1.17803e+00\n",
            "epoch: 21, iter: 11, training_loss: 1.21321e+00\n",
            "epoch: 22, iter: 11, training_loss: 1.09396e+00\n",
            "epoch: 23, iter: 11, training_loss: 1.16327e+00\n",
            "epoch: 24, iter: 11, training_loss: 1.15639e+00\n",
            "epoch: 25, iter: 11, training_loss: 1.12393e+00\n",
            "epoch: 26, iter: 11, training_loss: 1.07974e+00\n",
            "epoch: 27, iter: 11, training_loss: 1.05793e+00\n",
            "epoch: 28, iter: 11, training_loss: 1.14771e+00\n",
            "epoch: 29, iter: 11, training_loss: 1.10671e+00\n",
            "epoch: 30, iter: 11, training_loss: 1.07732e+00\n",
            "epoch: 31, iter: 11, training_loss: 1.08982e+00\n",
            "epoch: 32, iter: 11, training_loss: 1.06787e+00\n",
            "epoch: 33, iter: 11, training_loss: 1.07827e+00\n",
            "epoch: 34, iter: 11, training_loss: 1.09529e+00\n",
            "epoch: 35, iter: 11, training_loss: 1.01651e+00\n",
            "epoch: 36, iter: 11, training_loss: 1.08694e+00\n",
            "epoch: 37, iter: 11, training_loss: 1.03045e+00\n",
            "epoch: 38, iter: 11, training_loss: 1.04469e+00\n",
            "epoch: 39, iter: 11, training_loss: 1.03063e+00\n",
            "epoch: 40, iter: 11, training_loss: 1.06508e+00\n",
            "epoch: 41, iter: 11, training_loss: 1.13441e+00\n",
            "epoch: 42, iter: 11, training_loss: 1.03559e+00\n",
            "epoch: 43, iter: 11, training_loss: 1.10073e+00\n",
            "epoch: 44, iter: 11, training_loss: 1.10620e+00\n",
            "epoch: 45, iter: 11, training_loss: 1.07500e+00\n",
            "epoch: 46, iter: 11, training_loss: 1.02989e+00\n",
            "epoch: 47, iter: 11, training_loss: 1.01156e+00\n",
            "epoch: 48, iter: 11, training_loss: 1.05098e+00\n",
            "epoch: 49, iter: 11, training_loss: 1.02204e+00\n",
            "epoch: 50, iter: 11, training_loss: 1.02754e+00\n",
            "epoch: 51, iter: 11, training_loss: 1.08200e+00\n",
            "epoch: 52, iter: 11, training_loss: 1.11008e+00\n",
            "epoch: 53, iter: 11, training_loss: 1.04296e+00\n",
            "epoch: 54, iter: 11, training_loss: 1.10004e+00\n",
            "epoch: 55, iter: 11, training_loss: 1.13749e+00\n",
            "epoch: 56, iter: 11, training_loss: 1.12610e+00\n",
            "epoch: 57, iter: 11, training_loss: 1.10429e+00\n",
            "epoch: 58, iter: 11, training_loss: 1.05664e+00\n",
            "epoch: 59, iter: 11, training_loss: 1.18699e+00\n",
            "epoch: 60, iter: 11, training_loss: 1.08605e+00\n",
            "epoch: 61, iter: 11, training_loss: 1.22728e+00\n",
            "epoch: 62, iter: 11, training_loss: 1.18712e+00\n",
            "epoch: 63, iter: 11, training_loss: 1.06694e+00\n",
            "epoch: 64, iter: 11, training_loss: 1.12555e+00\n",
            "epoch: 65, iter: 11, training_loss: 1.08488e+00\n",
            "epoch: 66, iter: 11, training_loss: 1.06126e+00\n",
            "epoch: 67, iter: 11, training_loss: 1.13009e+00\n",
            "epoch: 68, iter: 11, training_loss: 1.10389e+00\n",
            "epoch: 69, iter: 11, training_loss: 1.15925e+00\n",
            "epoch: 70, iter: 11, training_loss: 1.08907e+00\n",
            "epoch: 71, iter: 11, training_loss: 1.07443e+00\n",
            "epoch: 72, iter: 11, training_loss: 1.13227e+00\n",
            "epoch: 73, iter: 11, training_loss: 1.12326e+00\n",
            "epoch: 74, iter: 11, training_loss: 1.15404e+00\n",
            "epoch: 75, iter: 11, training_loss: 1.12425e+00\n",
            "epoch: 76, iter: 11, training_loss: 1.43228e+00\n",
            "epoch: 77, iter: 11, training_loss: 1.50306e+00\n",
            "epoch: 78, iter: 11, training_loss: 1.22481e+00\n",
            "epoch: 79, iter: 11, training_loss: 1.06139e+00\n",
            "epoch: 80, iter: 11, training_loss: 1.27451e+00\n",
            "epoch: 81, iter: 11, training_loss: 1.14629e+00\n",
            "epoch: 82, iter: 11, training_loss: 1.13785e+00\n",
            "epoch: 83, iter: 11, training_loss: 1.22838e+00\n",
            "epoch: 84, iter: 11, training_loss: 1.08111e+00\n",
            "epoch: 85, iter: 11, training_loss: 1.05906e+00\n",
            "epoch: 86, iter: 11, training_loss: 1.43509e+00\n",
            "epoch: 87, iter: 11, training_loss: 1.15461e+00\n",
            "epoch: 88, iter: 11, training_loss: 1.20143e+00\n",
            "epoch: 89, iter: 11, training_loss: 1.28992e+00\n",
            "epoch: 90, iter: 11, training_loss: 1.33124e+00\n",
            "epoch: 91, iter: 11, training_loss: 1.23999e+00\n",
            "epoch: 92, iter: 11, training_loss: 1.41208e+00\n",
            "epoch: 93, iter: 11, training_loss: 1.45213e+00\n",
            "epoch: 94, iter: 11, training_loss: 1.37209e+00\n",
            "epoch: 95, iter: 11, training_loss: 1.32224e+00\n",
            "epoch: 96, iter: 11, training_loss: 1.30676e+00\n",
            "epoch: 97, iter: 11, training_loss: 1.31341e+00\n",
            "epoch: 98, iter: 11, training_loss: 1.66485e+00\n",
            "epoch: 99, iter: 11, training_loss: 1.53746e+00\n",
            "epoch: 100, iter: 11, training_loss: 1.26792e+00\n",
            "epoch: 101, iter: 11, training_loss: 1.18036e+00\n",
            "epoch: 102, iter: 11, training_loss: 1.36773e+00\n",
            "epoch: 103, iter: 11, training_loss: 1.29297e+00\n",
            "epoch: 104, iter: 11, training_loss: 1.25867e+00\n",
            "epoch: 105, iter: 11, training_loss: 1.37804e+00\n",
            "epoch: 106, iter: 11, training_loss: 1.20066e+00\n",
            "epoch: 107, iter: 11, training_loss: 1.35945e+00\n",
            "epoch: 108, iter: 11, training_loss: 1.44600e+00\n",
            "epoch: 109, iter: 11, training_loss: 1.56326e+00\n",
            "epoch: 110, iter: 11, training_loss: 1.48644e+00\n",
            "epoch: 111, iter: 11, training_loss: 1.45197e+00\n",
            "epoch: 112, iter: 11, training_loss: 1.39998e+00\n",
            "epoch: 113, iter: 11, training_loss: 1.33521e+00\n",
            "epoch: 114, iter: 11, training_loss: 1.27813e+00\n",
            "epoch: 115, iter: 11, training_loss: 1.29836e+00\n",
            "epoch: 116, iter: 11, training_loss: 1.22664e+00\n",
            "epoch: 117, iter: 11, training_loss: 1.70967e+00\n",
            "epoch: 118, iter: 11, training_loss: 1.41796e+00\n",
            "epoch: 119, iter: 11, training_loss: 1.40683e+00\n",
            "epoch: 120, iter: 11, training_loss: 1.25730e+00\n",
            "epoch: 121, iter: 11, training_loss: 1.58799e+00\n",
            "epoch: 122, iter: 11, training_loss: 1.49549e+00\n",
            "epoch: 123, iter: 11, training_loss: 1.64911e+00\n",
            "epoch: 124, iter: 11, training_loss: 1.40653e+00\n",
            "epoch: 125, iter: 11, training_loss: 1.61358e+00\n",
            "epoch: 126, iter: 11, training_loss: 1.37082e+00\n",
            "epoch: 127, iter: 11, training_loss: 1.71186e+00\n",
            "epoch: 128, iter: 11, training_loss: 1.49458e+00\n",
            "epoch: 129, iter: 11, training_loss: 1.73153e+00\n",
            "epoch: 130, iter: 11, training_loss: 1.75619e+00\n",
            "epoch: 131, iter: 11, training_loss: 1.59971e+00\n",
            "epoch: 132, iter: 11, training_loss: 1.59986e+00\n",
            "epoch: 133, iter: 11, training_loss: 1.76413e+00\n",
            "epoch: 134, iter: 11, training_loss: 1.85898e+00\n",
            "epoch: 135, iter: 11, training_loss: 1.53162e+00\n",
            "epoch: 136, iter: 11, training_loss: 1.49543e+00\n",
            "epoch: 137, iter: 11, training_loss: 1.60850e+00\n",
            "epoch: 138, iter: 11, training_loss: 1.52588e+00\n",
            "epoch: 139, iter: 11, training_loss: 1.68891e+00\n",
            "epoch: 140, iter: 11, training_loss: 1.66725e+00\n",
            "epoch: 141, iter: 11, training_loss: 1.57242e+00\n",
            "epoch: 142, iter: 11, training_loss: 1.73686e+00\n",
            "epoch: 143, iter: 11, training_loss: 1.35795e+00\n",
            "epoch: 144, iter: 11, training_loss: 1.57321e+00\n",
            "epoch: 145, iter: 11, training_loss: 1.54999e+00\n",
            "epoch: 146, iter: 11, training_loss: 1.71192e+00\n",
            "epoch: 147, iter: 11, training_loss: 1.61527e+00\n",
            "epoch: 148, iter: 11, training_loss: 2.31803e+00\n",
            "epoch: 149, iter: 11, training_loss: 1.59617e+00\n",
            "epoch: 150, iter: 11, training_loss: 1.43820e+00\n",
            "epoch: 151, iter: 11, training_loss: 1.69761e+00\n",
            "epoch: 152, iter: 11, training_loss: 1.80420e+00\n",
            "epoch: 153, iter: 11, training_loss: 1.70100e+00\n",
            "epoch: 154, iter: 11, training_loss: 1.75766e+00\n",
            "epoch: 155, iter: 11, training_loss: 1.92442e+00\n",
            "epoch: 156, iter: 11, training_loss: 1.71555e+00\n",
            "epoch: 157, iter: 11, training_loss: 1.92230e+00\n",
            "epoch: 158, iter: 11, training_loss: 1.68559e+00\n",
            "epoch: 159, iter: 11, training_loss: 1.75440e+00\n",
            "epoch: 160, iter: 11, training_loss: 1.49030e+00\n",
            "epoch: 161, iter: 11, training_loss: 1.55319e+00\n",
            "epoch: 162, iter: 11, training_loss: 1.56559e+00\n",
            "epoch: 163, iter: 11, training_loss: 1.45104e+00\n",
            "epoch: 164, iter: 11, training_loss: 1.66568e+00\n",
            "epoch: 165, iter: 11, training_loss: 1.65877e+00\n",
            "epoch: 166, iter: 11, training_loss: 1.61159e+00\n",
            "epoch: 167, iter: 11, training_loss: 1.78649e+00\n",
            "epoch: 168, iter: 11, training_loss: 2.14577e+00\n",
            "epoch: 169, iter: 11, training_loss: 2.18761e+00\n",
            "epoch: 170, iter: 11, training_loss: 1.90858e+00\n",
            "epoch: 171, iter: 11, training_loss: 2.56344e+00\n",
            "epoch: 172, iter: 11, training_loss: 2.00240e+00\n",
            "epoch: 173, iter: 11, training_loss: 1.93915e+00\n",
            "epoch: 174, iter: 11, training_loss: 1.91124e+00\n",
            "epoch: 175, iter: 11, training_loss: 1.96605e+00\n",
            "epoch: 176, iter: 11, training_loss: 2.34849e+00\n",
            "epoch: 177, iter: 11, training_loss: 1.92328e+00\n",
            "epoch: 178, iter: 11, training_loss: 1.96332e+00\n",
            "epoch: 179, iter: 11, training_loss: 1.74406e+00\n",
            "epoch: 180, iter: 11, training_loss: 3.15547e+00\n",
            "epoch: 181, iter: 11, training_loss: 2.36975e+00\n",
            "epoch: 182, iter: 11, training_loss: 2.04665e+00\n",
            "epoch: 183, iter: 11, training_loss: 2.30974e+00\n",
            "epoch: 184, iter: 11, training_loss: 2.18653e+00\n",
            "epoch: 185, iter: 11, training_loss: 2.49917e+00\n",
            "epoch: 186, iter: 11, training_loss: 2.18545e+00\n",
            "epoch: 187, iter: 11, training_loss: 2.54785e+00\n",
            "epoch: 188, iter: 11, training_loss: 2.71400e+00\n",
            "epoch: 189, iter: 11, training_loss: 2.23145e+00\n",
            "epoch: 190, iter: 11, training_loss: 2.69460e+00\n",
            "epoch: 191, iter: 11, training_loss: 2.23835e+00\n",
            "epoch: 192, iter: 11, training_loss: 2.04732e+00\n",
            "epoch: 193, iter: 11, training_loss: 2.46668e+00\n",
            "epoch: 194, iter: 11, training_loss: 2.04639e+00\n",
            "epoch: 195, iter: 11, training_loss: 1.85010e+00\n",
            "epoch: 196, iter: 11, training_loss: 2.23924e+00\n",
            "epoch: 197, iter: 11, training_loss: 1.81702e+00\n",
            "epoch: 198, iter: 11, training_loss: 2.31345e+00\n",
            "epoch: 199, iter: 11, training_loss: 2.00049e+00\n",
            "epoch: 200, iter: 11, training_loss: 1.88177e+00\n",
            "epoch: 201, iter: 11, training_loss: 2.33865e+00\n",
            "epoch: 202, iter: 11, training_loss: 2.82856e+00\n",
            "epoch: 203, iter: 11, training_loss: 1.92003e+00\n",
            "epoch: 204, iter: 11, training_loss: 1.86856e+00\n",
            "epoch: 205, iter: 11, training_loss: 1.95892e+00\n",
            "epoch: 206, iter: 11, training_loss: 1.73868e+00\n",
            "epoch: 207, iter: 11, training_loss: 2.05667e+00\n",
            "epoch: 208, iter: 11, training_loss: 2.13846e+00\n",
            "epoch: 209, iter: 11, training_loss: 2.24547e+00\n",
            "epoch: 210, iter: 11, training_loss: 1.71778e+00\n",
            "epoch: 211, iter: 11, training_loss: 1.87264e+00\n",
            "epoch: 212, iter: 11, training_loss: 1.85573e+00\n",
            "epoch: 213, iter: 11, training_loss: 1.78958e+00\n",
            "epoch: 214, iter: 11, training_loss: 1.88296e+00\n",
            "epoch: 215, iter: 11, training_loss: 1.78622e+00\n",
            "epoch: 216, iter: 11, training_loss: 2.26283e+00\n",
            "epoch: 217, iter: 11, training_loss: 2.16915e+00\n",
            "epoch: 218, iter: 11, training_loss: 2.49653e+00\n",
            "epoch: 219, iter: 11, training_loss: 2.23970e+00\n",
            "epoch: 220, iter: 11, training_loss: 2.88990e+00\n",
            "epoch: 221, iter: 11, training_loss: 2.10597e+00\n",
            "epoch: 222, iter: 11, training_loss: 2.03859e+00\n",
            "epoch: 223, iter: 11, training_loss: 1.74769e+00\n",
            "epoch: 224, iter: 11, training_loss: 2.25698e+00\n",
            "epoch: 225, iter: 11, training_loss: 2.44872e+00\n",
            "epoch: 226, iter: 11, training_loss: 2.73475e+00\n",
            "epoch: 227, iter: 11, training_loss: 2.63125e+00\n",
            "epoch: 228, iter: 11, training_loss: 2.26198e+00\n",
            "epoch: 229, iter: 11, training_loss: 2.07724e+00\n",
            "epoch: 230, iter: 11, training_loss: 2.45303e+00\n",
            "epoch: 231, iter: 11, training_loss: 2.66015e+00\n",
            "epoch: 232, iter: 11, training_loss: 2.53297e+00\n",
            "epoch: 233, iter: 11, training_loss: 2.13938e+00\n",
            "epoch: 234, iter: 11, training_loss: 1.84634e+00\n",
            "epoch: 235, iter: 11, training_loss: 2.75600e+00\n",
            "epoch: 236, iter: 11, training_loss: 2.17212e+00\n",
            "epoch: 237, iter: 11, training_loss: 2.78202e+00\n",
            "epoch: 238, iter: 11, training_loss: 2.35663e+00\n",
            "epoch: 239, iter: 11, training_loss: 2.54635e+00\n",
            "epoch: 240, iter: 11, training_loss: 2.17241e+00\n",
            "epoch: 241, iter: 11, training_loss: 2.19703e+00\n",
            "epoch: 242, iter: 11, training_loss: 2.19159e+00\n",
            "epoch: 243, iter: 11, training_loss: 1.99112e+00\n",
            "epoch: 244, iter: 11, training_loss: 1.99801e+00\n",
            "epoch: 245, iter: 11, training_loss: 2.55437e+00\n",
            "epoch: 246, iter: 11, training_loss: 2.03483e+00\n",
            "epoch: 247, iter: 11, training_loss: 2.02906e+00\n",
            "epoch: 248, iter: 11, training_loss: 2.08193e+00\n",
            "epoch: 249, iter: 11, training_loss: 2.34998e+00\n",
            "epoch: 250, iter: 11, training_loss: 2.06663e+00\n",
            "epoch: 251, iter: 11, training_loss: 2.29922e+00\n",
            "epoch: 252, iter: 11, training_loss: 2.40044e+00\n",
            "epoch: 253, iter: 11, training_loss: 3.02007e+00\n",
            "epoch: 254, iter: 11, training_loss: 2.96560e+00\n",
            "epoch: 255, iter: 11, training_loss: 2.55740e+00\n",
            "epoch: 256, iter: 11, training_loss: 2.66942e+00\n",
            "epoch: 257, iter: 11, training_loss: 2.40735e+00\n",
            "epoch: 258, iter: 11, training_loss: 2.39086e+00\n",
            "epoch: 259, iter: 11, training_loss: 2.80587e+00\n",
            "epoch: 260, iter: 11, training_loss: 2.33291e+00\n",
            "epoch: 261, iter: 11, training_loss: 2.82438e+00\n",
            "epoch: 262, iter: 11, training_loss: 2.65762e+00\n",
            "epoch: 263, iter: 11, training_loss: 2.23805e+00\n",
            "epoch: 264, iter: 11, training_loss: 2.78382e+00\n",
            "epoch: 265, iter: 11, training_loss: 2.55600e+00\n",
            "epoch: 266, iter: 11, training_loss: 2.48240e+00\n",
            "epoch: 267, iter: 11, training_loss: 2.85236e+00\n",
            "epoch: 268, iter: 11, training_loss: 3.20245e+00\n",
            "epoch: 269, iter: 11, training_loss: 2.81384e+00\n",
            "epoch: 270, iter: 11, training_loss: 2.59804e+00\n",
            "epoch: 271, iter: 11, training_loss: 2.75100e+00\n",
            "epoch: 272, iter: 11, training_loss: 2.63902e+00\n",
            "epoch: 273, iter: 11, training_loss: 2.94302e+00\n",
            "epoch: 274, iter: 11, training_loss: 2.66262e+00\n",
            "epoch: 275, iter: 11, training_loss: 3.32724e+00\n",
            "epoch: 276, iter: 11, training_loss: 2.35318e+00\n",
            "epoch: 277, iter: 11, training_loss: 2.81531e+00\n",
            "epoch: 278, iter: 11, training_loss: 2.85983e+00\n",
            "epoch: 279, iter: 11, training_loss: 3.02566e+00\n",
            "epoch: 280, iter: 11, training_loss: 2.61064e+00\n",
            "epoch: 281, iter: 11, training_loss: 3.01715e+00\n",
            "epoch: 282, iter: 11, training_loss: 3.46794e+00\n",
            "epoch: 283, iter: 11, training_loss: 3.58511e+00\n",
            "epoch: 284, iter: 11, training_loss: 2.99193e+00\n",
            "epoch: 285, iter: 11, training_loss: 3.70266e+00\n",
            "epoch: 286, iter: 11, training_loss: 2.31654e+00\n",
            "epoch: 287, iter: 11, training_loss: 2.65496e+00\n",
            "epoch: 288, iter: 11, training_loss: 2.34321e+00\n",
            "epoch: 289, iter: 11, training_loss: 2.50444e+00\n",
            "epoch: 290, iter: 11, training_loss: 2.41457e+00\n",
            "epoch: 291, iter: 11, training_loss: 2.81262e+00\n",
            "epoch: 292, iter: 11, training_loss: 3.56964e+00\n",
            "epoch: 293, iter: 11, training_loss: 2.80619e+00\n",
            "epoch: 294, iter: 11, training_loss: 2.95714e+00\n",
            "epoch: 295, iter: 11, training_loss: 2.65542e+00\n",
            "epoch: 296, iter: 11, training_loss: 2.82060e+00\n",
            "epoch: 297, iter: 11, training_loss: 3.20341e+00\n",
            "epoch: 298, iter: 11, training_loss: 2.67465e+00\n",
            "epoch: 299, iter: 11, training_loss: 3.11046e+00\n",
            "epoch: 300, iter: 11, training_loss: 3.03924e+00\n",
            "epoch: 301, iter: 11, training_loss: 2.44309e+00\n",
            "epoch: 302, iter: 11, training_loss: 2.50066e+00\n",
            "epoch: 303, iter: 11, training_loss: 3.06513e+00\n",
            "epoch: 304, iter: 11, training_loss: 2.84823e+00\n",
            "epoch: 305, iter: 11, training_loss: 2.73305e+00\n",
            "epoch: 306, iter: 11, training_loss: 2.71165e+00\n",
            "epoch: 307, iter: 11, training_loss: 3.59593e+00\n",
            "epoch: 308, iter: 11, training_loss: 3.17516e+00\n",
            "epoch: 309, iter: 11, training_loss: 2.79639e+00\n",
            "epoch: 310, iter: 11, training_loss: 2.66502e+00\n",
            "epoch: 311, iter: 11, training_loss: 2.68473e+00\n",
            "epoch: 312, iter: 11, training_loss: 2.36770e+00\n",
            "epoch: 313, iter: 11, training_loss: 2.49626e+00\n",
            "epoch: 314, iter: 11, training_loss: 2.75944e+00\n",
            "epoch: 315, iter: 11, training_loss: 2.76092e+00\n",
            "epoch: 316, iter: 11, training_loss: 2.66365e+00\n",
            "epoch: 317, iter: 11, training_loss: 2.69574e+00\n",
            "epoch: 318, iter: 11, training_loss: 2.60239e+00\n",
            "epoch: 319, iter: 11, training_loss: 3.20569e+00\n",
            "epoch: 320, iter: 11, training_loss: 2.87551e+00\n",
            "epoch: 321, iter: 11, training_loss: 2.63800e+00\n",
            "epoch: 322, iter: 11, training_loss: 2.75049e+00\n",
            "epoch: 323, iter: 11, training_loss: 3.01606e+00\n",
            "epoch: 324, iter: 11, training_loss: 2.47607e+00\n",
            "epoch: 325, iter: 11, training_loss: 2.58786e+00\n",
            "epoch: 326, iter: 11, training_loss: 2.45760e+00\n",
            "epoch: 327, iter: 11, training_loss: 3.23203e+00\n",
            "epoch: 328, iter: 11, training_loss: 2.38346e+00\n",
            "epoch: 329, iter: 11, training_loss: 3.25665e+00\n",
            "epoch: 330, iter: 11, training_loss: 2.17297e+00\n",
            "epoch: 331, iter: 11, training_loss: 2.68888e+00\n",
            "epoch: 332, iter: 11, training_loss: 2.75067e+00\n",
            "epoch: 333, iter: 11, training_loss: 3.21336e+00\n",
            "epoch: 334, iter: 11, training_loss: 2.51969e+00\n",
            "epoch: 335, iter: 11, training_loss: 2.58350e+00\n",
            "epoch: 336, iter: 11, training_loss: 2.65318e+00\n",
            "epoch: 337, iter: 11, training_loss: 2.84095e+00\n",
            "epoch: 338, iter: 11, training_loss: 2.86505e+00\n",
            "epoch: 339, iter: 11, training_loss: 2.87507e+00\n",
            "epoch: 340, iter: 11, training_loss: 3.09328e+00\n",
            "epoch: 341, iter: 11, training_loss: 2.91140e+00\n",
            "epoch: 342, iter: 11, training_loss: 2.29496e+00\n",
            "epoch: 343, iter: 11, training_loss: 2.90133e+00\n",
            "epoch: 344, iter: 11, training_loss: 3.24310e+00\n",
            "epoch: 345, iter: 11, training_loss: 2.83445e+00\n",
            "epoch: 346, iter: 11, training_loss: 2.93464e+00\n",
            "epoch: 347, iter: 11, training_loss: 3.54619e+00\n",
            "epoch: 348, iter: 11, training_loss: 2.98108e+00\n",
            "epoch: 349, iter: 11, training_loss: 2.64304e+00\n",
            "epoch: 350, iter: 11, training_loss: 2.36258e+00\n",
            "epoch: 351, iter: 11, training_loss: 2.40084e+00\n",
            "epoch: 352, iter: 11, training_loss: 2.70420e+00\n",
            "epoch: 353, iter: 11, training_loss: 3.02834e+00\n",
            "epoch: 354, iter: 11, training_loss: 3.68667e+00\n",
            "epoch: 355, iter: 11, training_loss: 2.85796e+00\n",
            "epoch: 356, iter: 11, training_loss: 3.07416e+00\n",
            "epoch: 357, iter: 11, training_loss: 2.93739e+00\n",
            "epoch: 358, iter: 11, training_loss: 3.17391e+00\n",
            "epoch: 359, iter: 11, training_loss: 2.74206e+00\n",
            "epoch: 360, iter: 11, training_loss: 3.16043e+00\n",
            "epoch: 361, iter: 11, training_loss: 2.82041e+00\n",
            "epoch: 362, iter: 11, training_loss: 2.74349e+00\n",
            "epoch: 363, iter: 11, training_loss: 3.52303e+00\n",
            "epoch: 364, iter: 11, training_loss: 4.13345e+00\n",
            "epoch: 365, iter: 11, training_loss: 4.17726e+00\n",
            "epoch: 366, iter: 11, training_loss: 2.96716e+00\n",
            "epoch: 367, iter: 11, training_loss: 2.73550e+00\n",
            "epoch: 368, iter: 11, training_loss: 3.30630e+00\n",
            "epoch: 369, iter: 11, training_loss: 3.11225e+00\n",
            "epoch: 370, iter: 11, training_loss: 3.33431e+00\n",
            "epoch: 371, iter: 11, training_loss: 2.52004e+00\n",
            "epoch: 372, iter: 11, training_loss: 2.51482e+00\n",
            "epoch: 373, iter: 11, training_loss: 2.59520e+00\n",
            "epoch: 374, iter: 11, training_loss: 2.92826e+00\n",
            "epoch: 375, iter: 11, training_loss: 2.68527e+00\n",
            "epoch: 376, iter: 11, training_loss: 2.50689e+00\n",
            "epoch: 377, iter: 11, training_loss: 2.36553e+00\n",
            "epoch: 378, iter: 11, training_loss: 2.80476e+00\n",
            "epoch: 379, iter: 11, training_loss: 2.68802e+00\n",
            "epoch: 380, iter: 11, training_loss: 3.06928e+00\n",
            "epoch: 381, iter: 11, training_loss: 3.14398e+00\n",
            "epoch: 382, iter: 11, training_loss: 2.77005e+00\n",
            "epoch: 383, iter: 11, training_loss: 2.31450e+00\n",
            "epoch: 384, iter: 11, training_loss: 2.86915e+00\n",
            "epoch: 385, iter: 11, training_loss: 3.35320e+00\n",
            "epoch: 386, iter: 11, training_loss: 2.70986e+00\n",
            "epoch: 387, iter: 11, training_loss: 2.37970e+00\n",
            "epoch: 388, iter: 11, training_loss: 2.66031e+00\n",
            "epoch: 389, iter: 11, training_loss: 3.33958e+00\n",
            "epoch: 390, iter: 11, training_loss: 2.92589e+00\n",
            "epoch: 391, iter: 11, training_loss: 3.82159e+00\n",
            "epoch: 392, iter: 11, training_loss: 2.74220e+00\n",
            "epoch: 393, iter: 11, training_loss: 2.72730e+00\n",
            "epoch: 394, iter: 11, training_loss: 3.48193e+00\n",
            "epoch: 395, iter: 11, training_loss: 3.18260e+00\n",
            "epoch: 396, iter: 11, training_loss: 3.32221e+00\n",
            "epoch: 397, iter: 11, training_loss: 2.88290e+00\n",
            "epoch: 398, iter: 11, training_loss: 3.06374e+00\n",
            "epoch: 399, iter: 11, training_loss: 2.59113e+00\n",
            "epoch: 400, iter: 11, training_loss: 2.86091e+00\n",
            "epoch: 401, iter: 11, training_loss: 3.30355e+00\n",
            "epoch: 402, iter: 11, training_loss: 2.74874e+00\n",
            "epoch: 403, iter: 11, training_loss: 3.30170e+00\n",
            "epoch: 404, iter: 11, training_loss: 3.41239e+00\n",
            "epoch: 405, iter: 11, training_loss: 4.26082e+00\n",
            "epoch: 406, iter: 11, training_loss: 3.20417e+00\n",
            "epoch: 407, iter: 11, training_loss: 3.17842e+00\n",
            "epoch: 408, iter: 11, training_loss: 4.08457e+00\n",
            "epoch: 409, iter: 11, training_loss: 2.48010e+00\n",
            "epoch: 410, iter: 11, training_loss: 3.17121e+00\n",
            "epoch: 411, iter: 11, training_loss: 2.83836e+00\n",
            "epoch: 412, iter: 11, training_loss: 2.37152e+00\n",
            "epoch: 413, iter: 11, training_loss: 2.83609e+00\n",
            "epoch: 414, iter: 11, training_loss: 2.22377e+00\n",
            "epoch: 415, iter: 11, training_loss: 2.09555e+00\n",
            "epoch: 416, iter: 11, training_loss: 2.49733e+00\n",
            "epoch: 417, iter: 11, training_loss: 2.38018e+00\n",
            "epoch: 418, iter: 11, training_loss: 2.46323e+00\n",
            "epoch: 419, iter: 11, training_loss: 3.39540e+00\n",
            "epoch: 420, iter: 11, training_loss: 2.70464e+00\n",
            "epoch: 421, iter: 11, training_loss: 2.30227e+00\n",
            "epoch: 422, iter: 11, training_loss: 3.05165e+00\n",
            "epoch: 423, iter: 11, training_loss: 2.22694e+00\n",
            "epoch: 424, iter: 11, training_loss: 2.84983e+00\n",
            "epoch: 425, iter: 11, training_loss: 2.76943e+00\n",
            "epoch: 426, iter: 11, training_loss: 2.94246e+00\n",
            "epoch: 427, iter: 11, training_loss: 2.90288e+00\n",
            "epoch: 428, iter: 11, training_loss: 2.88033e+00\n",
            "epoch: 429, iter: 11, training_loss: 2.74751e+00\n",
            "epoch: 430, iter: 11, training_loss: 2.85721e+00\n",
            "epoch: 431, iter: 11, training_loss: 3.15954e+00\n",
            "epoch: 432, iter: 11, training_loss: 2.92967e+00\n",
            "epoch: 433, iter: 11, training_loss: 2.81386e+00\n",
            "epoch: 434, iter: 11, training_loss: 2.52743e+00\n",
            "epoch: 435, iter: 11, training_loss: 2.61181e+00\n",
            "epoch: 436, iter: 11, training_loss: 2.69685e+00\n",
            "epoch: 437, iter: 11, training_loss: 2.30574e+00\n",
            "epoch: 438, iter: 11, training_loss: 2.01467e+00\n",
            "epoch: 439, iter: 11, training_loss: 2.40289e+00\n",
            "epoch: 440, iter: 11, training_loss: 2.33072e+00\n",
            "epoch: 441, iter: 11, training_loss: 2.99514e+00\n",
            "epoch: 442, iter: 11, training_loss: 3.32620e+00\n",
            "epoch: 443, iter: 11, training_loss: 2.61411e+00\n",
            "epoch: 444, iter: 11, training_loss: 2.33606e+00\n",
            "epoch: 445, iter: 11, training_loss: 1.96676e+00\n",
            "epoch: 446, iter: 11, training_loss: 2.60205e+00\n",
            "epoch: 447, iter: 11, training_loss: 2.73062e+00\n",
            "epoch: 448, iter: 11, training_loss: 2.75042e+00\n",
            "epoch: 449, iter: 11, training_loss: 2.26926e+00\n",
            "epoch: 450, iter: 11, training_loss: 2.17750e+00\n",
            "epoch: 451, iter: 11, training_loss: 2.03187e+00\n",
            "epoch: 452, iter: 11, training_loss: 2.17386e+00\n",
            "epoch: 453, iter: 11, training_loss: 2.88102e+00\n",
            "epoch: 454, iter: 11, training_loss: 2.09476e+00\n",
            "epoch: 455, iter: 11, training_loss: 1.93065e+00\n",
            "epoch: 456, iter: 11, training_loss: 2.32616e+00\n",
            "epoch: 457, iter: 11, training_loss: 2.61731e+00\n",
            "epoch: 458, iter: 11, training_loss: 1.85228e+00\n",
            "epoch: 459, iter: 11, training_loss: 2.17018e+00\n",
            "epoch: 460, iter: 11, training_loss: 1.83169e+00\n",
            "epoch: 461, iter: 11, training_loss: 1.66203e+00\n",
            "epoch: 462, iter: 11, training_loss: 1.96962e+00\n",
            "epoch: 463, iter: 11, training_loss: 2.22030e+00\n",
            "epoch: 464, iter: 11, training_loss: 2.16951e+00\n",
            "epoch: 465, iter: 11, training_loss: 2.56398e+00\n",
            "epoch: 466, iter: 11, training_loss: 2.12107e+00\n",
            "epoch: 467, iter: 11, training_loss: 2.07438e+00\n",
            "epoch: 468, iter: 11, training_loss: 1.72604e+00\n",
            "epoch: 469, iter: 11, training_loss: 1.82535e+00\n",
            "epoch: 470, iter: 11, training_loss: 2.17347e+00\n",
            "epoch: 471, iter: 11, training_loss: 2.87115e+00\n",
            "epoch: 472, iter: 11, training_loss: 1.94695e+00\n",
            "epoch: 473, iter: 11, training_loss: 1.90677e+00\n",
            "epoch: 474, iter: 11, training_loss: 1.54539e+00\n",
            "epoch: 475, iter: 11, training_loss: 1.57101e+00\n",
            "epoch: 476, iter: 11, training_loss: 1.62213e+00\n",
            "epoch: 477, iter: 11, training_loss: 1.53169e+00\n",
            "epoch: 478, iter: 11, training_loss: 1.62544e+00\n",
            "epoch: 479, iter: 11, training_loss: 1.63952e+00\n",
            "epoch: 480, iter: 11, training_loss: 1.55111e+00\n",
            "epoch: 481, iter: 11, training_loss: 1.63936e+00\n",
            "epoch: 482, iter: 11, training_loss: 1.82621e+00\n",
            "epoch: 483, iter: 11, training_loss: 1.94370e+00\n",
            "epoch: 484, iter: 11, training_loss: 2.29421e+00\n",
            "epoch: 485, iter: 11, training_loss: 1.92093e+00\n",
            "epoch: 486, iter: 11, training_loss: 1.64810e+00\n",
            "epoch: 487, iter: 11, training_loss: 1.55439e+00\n",
            "epoch: 488, iter: 11, training_loss: 1.41290e+00\n",
            "epoch: 489, iter: 11, training_loss: 1.52927e+00\n",
            "epoch: 490, iter: 11, training_loss: 1.43576e+00\n",
            "epoch: 491, iter: 11, training_loss: 1.27955e+00\n",
            "epoch: 492, iter: 11, training_loss: 1.57743e+00\n",
            "epoch: 493, iter: 11, training_loss: 1.41683e+00\n",
            "epoch: 494, iter: 11, training_loss: 1.32201e+00\n",
            "epoch: 495, iter: 11, training_loss: 1.29992e+00\n",
            "epoch: 496, iter: 11, training_loss: 1.80468e+00\n",
            "epoch: 497, iter: 11, training_loss: 1.65134e+00\n",
            "epoch: 498, iter: 11, training_loss: 1.40787e+00\n",
            "epoch: 499, iter: 11, training_loss: 1.28405e+00\n",
            "epoch: 500, iter: 11, training_loss: 1.10216e+00\n",
            "epoch: 501, iter: 11, training_loss: 1.32328e+00\n",
            "epoch: 502, iter: 11, training_loss: 1.48537e+00\n",
            "epoch: 503, iter: 11, training_loss: 1.18926e+00\n",
            "epoch: 504, iter: 11, training_loss: 1.43731e+00\n",
            "epoch: 505, iter: 11, training_loss: 1.30842e+00\n",
            "epoch: 506, iter: 11, training_loss: 1.01341e+00\n",
            "epoch: 507, iter: 11, training_loss: 9.98216e-01\n",
            "epoch: 508, iter: 11, training_loss: 1.13208e+00\n",
            "epoch: 509, iter: 11, training_loss: 2.08612e+00\n",
            "epoch: 510, iter: 11, training_loss: 1.42111e+00\n",
            "epoch: 511, iter: 11, training_loss: 1.16467e+00\n",
            "epoch: 512, iter: 11, training_loss: 9.94969e-01\n",
            "epoch: 513, iter: 11, training_loss: 1.04490e+00\n",
            "epoch: 514, iter: 11, training_loss: 9.21271e-01\n",
            "epoch: 515, iter: 11, training_loss: 1.03735e+00\n",
            "epoch: 516, iter: 11, training_loss: 1.01061e+00\n",
            "epoch: 517, iter: 11, training_loss: 9.15973e-01\n",
            "epoch: 518, iter: 11, training_loss: 9.81277e-01\n",
            "epoch: 519, iter: 11, training_loss: 1.00308e+00\n",
            "epoch: 520, iter: 11, training_loss: 9.86141e-01\n",
            "epoch: 521, iter: 11, training_loss: 9.96060e-01\n",
            "epoch: 522, iter: 11, training_loss: 1.20905e+00\n",
            "epoch: 523, iter: 11, training_loss: 1.02397e+00\n",
            "epoch: 524, iter: 11, training_loss: 9.29873e-01\n",
            "epoch: 525, iter: 11, training_loss: 9.69819e-01\n",
            "epoch: 526, iter: 11, training_loss: 8.75835e-01\n",
            "epoch: 527, iter: 11, training_loss: 1.17429e+00\n",
            "epoch: 528, iter: 11, training_loss: 1.00709e+00\n",
            "epoch: 529, iter: 11, training_loss: 8.84024e-01\n",
            "epoch: 530, iter: 11, training_loss: 8.71616e-01\n",
            "epoch: 531, iter: 11, training_loss: 1.10830e+00\n",
            "epoch: 532, iter: 11, training_loss: 1.06998e+00\n",
            "epoch: 533, iter: 11, training_loss: 8.65819e-01\n",
            "epoch: 534, iter: 11, training_loss: 8.78049e-01\n",
            "epoch: 535, iter: 11, training_loss: 8.99104e-01\n",
            "epoch: 536, iter: 11, training_loss: 1.04481e+00\n",
            "epoch: 537, iter: 11, training_loss: 1.05741e+00\n",
            "epoch: 538, iter: 11, training_loss: 1.09812e+00\n",
            "epoch: 539, iter: 11, training_loss: 1.23793e+00\n",
            "epoch: 540, iter: 11, training_loss: 9.71044e-01\n",
            "epoch: 541, iter: 11, training_loss: 8.67250e-01\n",
            "epoch: 542, iter: 11, training_loss: 8.30916e-01\n",
            "epoch: 543, iter: 11, training_loss: 8.69173e-01\n",
            "epoch: 544, iter: 11, training_loss: 8.91928e-01\n",
            "epoch: 545, iter: 11, training_loss: 9.01201e-01\n",
            "epoch: 546, iter: 11, training_loss: 8.74392e-01\n",
            "epoch: 547, iter: 11, training_loss: 1.08643e+00\n",
            "epoch: 548, iter: 11, training_loss: 1.11683e+00\n",
            "epoch: 549, iter: 11, training_loss: 8.12119e-01\n",
            "epoch: 550, iter: 11, training_loss: 7.83414e-01\n",
            "epoch: 551, iter: 11, training_loss: 8.81313e-01\n",
            "epoch: 552, iter: 11, training_loss: 8.53796e-01\n",
            "epoch: 553, iter: 11, training_loss: 1.28327e+00\n",
            "epoch: 554, iter: 11, training_loss: 1.29094e+00\n",
            "epoch: 555, iter: 11, training_loss: 1.16525e+00\n",
            "epoch: 556, iter: 11, training_loss: 9.43796e-01\n",
            "epoch: 557, iter: 11, training_loss: 8.91425e-01\n",
            "epoch: 558, iter: 11, training_loss: 8.01585e-01\n",
            "epoch: 559, iter: 11, training_loss: 7.74574e-01\n",
            "epoch: 560, iter: 11, training_loss: 8.50193e-01\n",
            "epoch: 561, iter: 11, training_loss: 8.26014e-01\n",
            "epoch: 562, iter: 11, training_loss: 8.66336e-01\n",
            "epoch: 563, iter: 11, training_loss: 8.05381e-01\n",
            "epoch: 564, iter: 11, training_loss: 9.45719e-01\n",
            "epoch: 565, iter: 11, training_loss: 1.15035e+00\n",
            "epoch: 566, iter: 11, training_loss: 9.88809e-01\n",
            "epoch: 567, iter: 11, training_loss: 8.21109e-01\n",
            "epoch: 568, iter: 11, training_loss: 8.54201e-01\n",
            "epoch: 569, iter: 11, training_loss: 7.82656e-01\n",
            "epoch: 570, iter: 11, training_loss: 8.48553e-01\n",
            "epoch: 571, iter: 11, training_loss: 7.52196e-01\n",
            "epoch: 572, iter: 11, training_loss: 9.03914e-01\n",
            "epoch: 573, iter: 11, training_loss: 8.71387e-01\n",
            "epoch: 574, iter: 11, training_loss: 7.50307e-01\n",
            "epoch: 575, iter: 11, training_loss: 9.32293e-01\n",
            "epoch: 576, iter: 11, training_loss: 7.23203e-01\n",
            "epoch: 577, iter: 11, training_loss: 7.73833e-01\n",
            "epoch: 578, iter: 11, training_loss: 8.26291e-01\n",
            "epoch: 579, iter: 11, training_loss: 8.06424e-01\n",
            "epoch: 580, iter: 11, training_loss: 1.08944e+00\n",
            "epoch: 581, iter: 11, training_loss: 8.29994e-01\n",
            "epoch: 582, iter: 11, training_loss: 8.04754e-01\n",
            "epoch: 583, iter: 11, training_loss: 8.02121e-01\n",
            "epoch: 584, iter: 11, training_loss: 1.13652e+00\n",
            "epoch: 585, iter: 11, training_loss: 1.20601e+00\n",
            "epoch: 586, iter: 11, training_loss: 9.10769e-01\n",
            "epoch: 587, iter: 11, training_loss: 8.20997e-01\n",
            "epoch: 588, iter: 11, training_loss: 7.59785e-01\n",
            "epoch: 589, iter: 11, training_loss: 7.85836e-01\n",
            "epoch: 590, iter: 11, training_loss: 8.33192e-01\n",
            "epoch: 591, iter: 11, training_loss: 7.07205e-01\n",
            "epoch: 592, iter: 11, training_loss: 1.17986e+00\n",
            "epoch: 593, iter: 11, training_loss: 1.17876e+00\n",
            "epoch: 594, iter: 11, training_loss: 8.73501e-01\n",
            "epoch: 595, iter: 11, training_loss: 7.23562e-01\n",
            "epoch: 596, iter: 11, training_loss: 7.21640e-01\n",
            "epoch: 597, iter: 11, training_loss: 6.97231e-01\n",
            "epoch: 598, iter: 11, training_loss: 7.41551e-01\n",
            "epoch: 599, iter: 11, training_loss: 8.13346e-01\n",
            "epoch: 600, iter: 11, training_loss: 7.22696e-01\n",
            "epoch: 601, iter: 11, training_loss: 6.83732e-01\n",
            "epoch: 602, iter: 11, training_loss: 7.85938e-01\n",
            "epoch: 603, iter: 11, training_loss: 7.28769e-01\n",
            "epoch: 604, iter: 11, training_loss: 7.58544e-01\n",
            "epoch: 605, iter: 11, training_loss: 6.22497e-01\n",
            "epoch: 606, iter: 11, training_loss: 6.76405e-01\n",
            "epoch: 607, iter: 11, training_loss: 8.63092e-01\n",
            "epoch: 608, iter: 11, training_loss: 7.81277e-01\n",
            "epoch: 609, iter: 11, training_loss: 7.82945e-01\n",
            "epoch: 610, iter: 11, training_loss: 7.70237e-01\n",
            "epoch: 611, iter: 11, training_loss: 7.74976e-01\n",
            "epoch: 612, iter: 11, training_loss: 7.22584e-01\n",
            "epoch: 613, iter: 11, training_loss: 6.65162e-01\n",
            "epoch: 614, iter: 11, training_loss: 7.24485e-01\n",
            "epoch: 615, iter: 11, training_loss: 7.30583e-01\n",
            "epoch: 616, iter: 11, training_loss: 6.85015e-01\n",
            "epoch: 617, iter: 11, training_loss: 7.52200e-01\n",
            "epoch: 618, iter: 11, training_loss: 9.59575e-01\n",
            "epoch: 619, iter: 11, training_loss: 8.63466e-01\n",
            "epoch: 620, iter: 11, training_loss: 7.94663e-01\n",
            "epoch: 621, iter: 11, training_loss: 8.11953e-01\n",
            "epoch: 622, iter: 11, training_loss: 1.12238e+00\n",
            "epoch: 623, iter: 11, training_loss: 8.72146e-01\n",
            "epoch: 624, iter: 11, training_loss: 8.86397e-01\n",
            "epoch: 625, iter: 11, training_loss: 7.57067e-01\n",
            "epoch: 626, iter: 11, training_loss: 7.92154e-01\n",
            "epoch: 627, iter: 11, training_loss: 8.24500e-01\n",
            "epoch: 628, iter: 11, training_loss: 9.68425e-01\n",
            "epoch: 629, iter: 11, training_loss: 9.42565e-01\n",
            "epoch: 630, iter: 11, training_loss: 1.13288e+00\n",
            "epoch: 631, iter: 11, training_loss: 7.66757e-01\n",
            "epoch: 632, iter: 11, training_loss: 7.12794e-01\n",
            "epoch: 633, iter: 11, training_loss: 6.79654e-01\n",
            "epoch: 634, iter: 11, training_loss: 7.49334e-01\n",
            "epoch: 635, iter: 11, training_loss: 6.85789e-01\n",
            "epoch: 636, iter: 11, training_loss: 6.98109e-01\n",
            "epoch: 637, iter: 11, training_loss: 7.68153e-01\n",
            "epoch: 638, iter: 11, training_loss: 7.67573e-01\n",
            "epoch: 639, iter: 11, training_loss: 8.07947e-01\n",
            "epoch: 640, iter: 11, training_loss: 6.95818e-01\n",
            "epoch: 641, iter: 11, training_loss: 7.33193e-01\n",
            "epoch: 642, iter: 11, training_loss: 7.61186e-01\n",
            "epoch: 643, iter: 11, training_loss: 8.45845e-01\n",
            "epoch: 644, iter: 11, training_loss: 1.27397e+00\n",
            "epoch: 645, iter: 11, training_loss: 9.28319e-01\n",
            "epoch: 646, iter: 11, training_loss: 7.63829e-01\n",
            "epoch: 647, iter: 11, training_loss: 7.13679e-01\n",
            "epoch: 648, iter: 11, training_loss: 7.92073e-01\n",
            "epoch: 649, iter: 11, training_loss: 7.24117e-01\n",
            "epoch: 650, iter: 11, training_loss: 6.70013e-01\n",
            "epoch: 651, iter: 11, training_loss: 7.19896e-01\n",
            "epoch: 652, iter: 11, training_loss: 6.57672e-01\n",
            "epoch: 653, iter: 11, training_loss: 7.58897e-01\n",
            "epoch: 654, iter: 11, training_loss: 9.35729e-01\n",
            "epoch: 655, iter: 11, training_loss: 6.33529e-01\n",
            "epoch: 656, iter: 11, training_loss: 7.53101e-01\n",
            "epoch: 657, iter: 11, training_loss: 6.58275e-01\n",
            "epoch: 658, iter: 11, training_loss: 7.19517e-01\n",
            "epoch: 659, iter: 11, training_loss: 6.98182e-01\n",
            "epoch: 660, iter: 11, training_loss: 6.80868e-01\n",
            "epoch: 661, iter: 11, training_loss: 5.62199e-01\n",
            "epoch: 662, iter: 11, training_loss: 6.98010e-01\n",
            "epoch: 663, iter: 11, training_loss: 7.13928e-01\n",
            "epoch: 664, iter: 11, training_loss: 6.91783e-01\n",
            "epoch: 665, iter: 11, training_loss: 6.80812e-01\n",
            "epoch: 666, iter: 11, training_loss: 6.95180e-01\n",
            "epoch: 667, iter: 11, training_loss: 6.64152e-01\n",
            "epoch: 668, iter: 11, training_loss: 6.91426e-01\n",
            "epoch: 669, iter: 11, training_loss: 6.63096e-01\n",
            "epoch: 670, iter: 11, training_loss: 6.03187e-01\n",
            "epoch: 671, iter: 11, training_loss: 7.49419e-01\n",
            "epoch: 672, iter: 11, training_loss: 8.43864e-01\n",
            "epoch: 673, iter: 11, training_loss: 6.52750e-01\n",
            "epoch: 674, iter: 11, training_loss: 6.70959e-01\n",
            "epoch: 675, iter: 11, training_loss: 6.57225e-01\n",
            "epoch: 676, iter: 11, training_loss: 6.21013e-01\n",
            "epoch: 677, iter: 11, training_loss: 6.60863e-01\n",
            "epoch: 678, iter: 11, training_loss: 5.70950e-01\n",
            "epoch: 679, iter: 11, training_loss: 5.87890e-01\n",
            "epoch: 680, iter: 11, training_loss: 6.38088e-01\n",
            "epoch: 681, iter: 11, training_loss: 6.12286e-01\n",
            "epoch: 682, iter: 11, training_loss: 6.51504e-01\n",
            "epoch: 683, iter: 11, training_loss: 6.45418e-01\n",
            "epoch: 684, iter: 11, training_loss: 6.11649e-01\n",
            "epoch: 685, iter: 11, training_loss: 6.91080e-01\n",
            "epoch: 686, iter: 11, training_loss: 5.44405e-01\n",
            "epoch: 687, iter: 11, training_loss: 5.55352e-01\n",
            "epoch: 688, iter: 11, training_loss: 6.13759e-01\n",
            "epoch: 689, iter: 11, training_loss: 6.44826e-01\n",
            "epoch: 690, iter: 11, training_loss: 6.10212e-01\n",
            "epoch: 691, iter: 11, training_loss: 6.15592e-01\n",
            "epoch: 692, iter: 11, training_loss: 5.79595e-01\n",
            "epoch: 693, iter: 11, training_loss: 5.08754e-01\n",
            "epoch: 694, iter: 11, training_loss: 6.02769e-01\n",
            "epoch: 695, iter: 11, training_loss: 5.99357e-01\n",
            "epoch: 696, iter: 11, training_loss: 6.55327e-01\n",
            "epoch: 697, iter: 11, training_loss: 5.96428e-01\n",
            "epoch: 698, iter: 11, training_loss: 5.45152e-01\n",
            "epoch: 699, iter: 11, training_loss: 5.99496e-01\n",
            "epoch: 700, iter: 11, training_loss: 5.42551e-01\n",
            "epoch: 701, iter: 11, training_loss: 5.37756e-01\n",
            "epoch: 702, iter: 11, training_loss: 4.74768e-01\n",
            "epoch: 703, iter: 11, training_loss: 5.24559e-01\n",
            "epoch: 704, iter: 11, training_loss: 5.36117e-01\n",
            "epoch: 705, iter: 11, training_loss: 5.72201e-01\n",
            "epoch: 706, iter: 11, training_loss: 6.31119e-01\n",
            "epoch: 707, iter: 11, training_loss: 5.26575e-01\n",
            "epoch: 708, iter: 11, training_loss: 4.90999e-01\n",
            "epoch: 709, iter: 11, training_loss: 5.71628e-01\n",
            "epoch: 710, iter: 11, training_loss: 5.96708e-01\n",
            "epoch: 711, iter: 11, training_loss: 4.51684e-01\n",
            "epoch: 712, iter: 11, training_loss: 4.82590e-01\n",
            "epoch: 713, iter: 11, training_loss: 5.76154e-01\n",
            "epoch: 714, iter: 11, training_loss: 4.64352e-01\n",
            "epoch: 715, iter: 11, training_loss: 5.13592e-01\n",
            "epoch: 716, iter: 11, training_loss: 5.18893e-01\n",
            "epoch: 717, iter: 11, training_loss: 5.60301e-01\n",
            "epoch: 718, iter: 11, training_loss: 5.79232e-01\n",
            "epoch: 719, iter: 11, training_loss: 5.25764e-01\n",
            "epoch: 720, iter: 11, training_loss: 4.56642e-01\n",
            "epoch: 721, iter: 11, training_loss: 5.66049e-01\n",
            "epoch: 722, iter: 11, training_loss: 5.74802e-01\n",
            "epoch: 723, iter: 11, training_loss: 5.71998e-01\n",
            "epoch: 724, iter: 11, training_loss: 5.00125e-01\n",
            "epoch: 725, iter: 11, training_loss: 5.14486e-01\n",
            "epoch: 726, iter: 11, training_loss: 4.39990e-01\n",
            "epoch: 727, iter: 11, training_loss: 4.87082e-01\n",
            "epoch: 728, iter: 11, training_loss: 4.93015e-01\n",
            "epoch: 729, iter: 11, training_loss: 5.59159e-01\n",
            "epoch: 730, iter: 11, training_loss: 5.41414e-01\n",
            "epoch: 731, iter: 11, training_loss: 4.87793e-01\n",
            "epoch: 732, iter: 11, training_loss: 4.29707e-01\n",
            "epoch: 733, iter: 11, training_loss: 4.71434e-01\n",
            "epoch: 734, iter: 11, training_loss: 4.77684e-01\n",
            "epoch: 735, iter: 11, training_loss: 5.07969e-01\n",
            "epoch: 736, iter: 11, training_loss: 5.16839e-01\n",
            "epoch: 737, iter: 11, training_loss: 4.56709e-01\n",
            "epoch: 738, iter: 11, training_loss: 4.56600e-01\n",
            "epoch: 739, iter: 11, training_loss: 4.52889e-01\n",
            "epoch: 740, iter: 11, training_loss: 4.30509e-01\n",
            "epoch: 741, iter: 11, training_loss: 4.38688e-01\n",
            "epoch: 742, iter: 11, training_loss: 4.33811e-01\n",
            "epoch: 743, iter: 11, training_loss: 4.22872e-01\n",
            "epoch: 744, iter: 11, training_loss: 5.13657e-01\n",
            "epoch: 745, iter: 11, training_loss: 5.10493e-01\n",
            "epoch: 746, iter: 11, training_loss: 4.47850e-01\n",
            "epoch: 747, iter: 11, training_loss: 5.05151e-01\n",
            "epoch: 748, iter: 11, training_loss: 4.81132e-01\n",
            "epoch: 749, iter: 11, training_loss: 4.71544e-01\n",
            "epoch: 750, iter: 11, training_loss: 4.81931e-01\n",
            "epoch: 751, iter: 11, training_loss: 5.15365e-01\n",
            "epoch: 752, iter: 11, training_loss: 4.50993e-01\n",
            "epoch: 753, iter: 11, training_loss: 5.21212e-01\n",
            "epoch: 754, iter: 11, training_loss: 5.03738e-01\n",
            "epoch: 755, iter: 11, training_loss: 5.18469e-01\n",
            "epoch: 756, iter: 11, training_loss: 4.93628e-01\n",
            "epoch: 757, iter: 11, training_loss: 4.97100e-01\n",
            "epoch: 758, iter: 11, training_loss: 4.62255e-01\n",
            "epoch: 759, iter: 11, training_loss: 4.46766e-01\n",
            "epoch: 760, iter: 11, training_loss: 3.92366e-01\n",
            "epoch: 761, iter: 11, training_loss: 3.89985e-01\n",
            "epoch: 762, iter: 11, training_loss: 4.53003e-01\n",
            "epoch: 763, iter: 11, training_loss: 4.59408e-01\n",
            "epoch: 764, iter: 11, training_loss: 4.36681e-01\n",
            "epoch: 765, iter: 11, training_loss: 4.22110e-01\n",
            "epoch: 766, iter: 11, training_loss: 4.14532e-01\n",
            "epoch: 767, iter: 11, training_loss: 4.39505e-01\n",
            "epoch: 768, iter: 11, training_loss: 4.83667e-01\n",
            "epoch: 769, iter: 11, training_loss: 4.23450e-01\n",
            "epoch: 770, iter: 11, training_loss: 3.79428e-01\n",
            "epoch: 771, iter: 11, training_loss: 5.03183e-01\n",
            "epoch: 772, iter: 11, training_loss: 4.88989e-01\n",
            "epoch: 773, iter: 11, training_loss: 5.75605e-01\n",
            "epoch: 774, iter: 11, training_loss: 4.88420e-01\n",
            "epoch: 775, iter: 11, training_loss: 5.64803e-01\n",
            "epoch: 776, iter: 11, training_loss: 3.91204e-01\n",
            "epoch: 777, iter: 11, training_loss: 3.86046e-01\n",
            "epoch: 778, iter: 11, training_loss: 3.52900e-01\n",
            "epoch: 779, iter: 11, training_loss: 3.53120e-01\n",
            "epoch: 780, iter: 11, training_loss: 4.02897e-01\n",
            "epoch: 781, iter: 11, training_loss: 4.61529e-01\n",
            "epoch: 782, iter: 11, training_loss: 3.79504e-01\n",
            "epoch: 783, iter: 11, training_loss: 4.24144e-01\n",
            "epoch: 784, iter: 11, training_loss: 4.46155e-01\n",
            "epoch: 785, iter: 11, training_loss: 4.63763e-01\n",
            "epoch: 786, iter: 11, training_loss: 4.20937e-01\n",
            "epoch: 787, iter: 11, training_loss: 4.15678e-01\n",
            "epoch: 788, iter: 11, training_loss: 4.58741e-01\n",
            "epoch: 789, iter: 11, training_loss: 4.13674e-01\n",
            "epoch: 790, iter: 11, training_loss: 3.98060e-01\n",
            "epoch: 791, iter: 11, training_loss: 3.89143e-01\n",
            "epoch: 792, iter: 11, training_loss: 3.80413e-01\n",
            "epoch: 793, iter: 11, training_loss: 4.59986e-01\n",
            "epoch: 794, iter: 11, training_loss: 4.08904e-01\n",
            "epoch: 795, iter: 11, training_loss: 4.38296e-01\n",
            "epoch: 796, iter: 11, training_loss: 4.49852e-01\n",
            "epoch: 797, iter: 11, training_loss: 4.81543e-01\n",
            "epoch: 798, iter: 11, training_loss: 4.18479e-01\n",
            "epoch: 799, iter: 11, training_loss: 4.14218e-01\n",
            "epoch: 800, iter: 11, training_loss: 5.10969e-01\n",
            "epoch: 801, iter: 11, training_loss: 4.81506e-01\n",
            "epoch: 802, iter: 11, training_loss: 4.70629e-01\n",
            "epoch: 803, iter: 11, training_loss: 4.26614e-01\n",
            "epoch: 804, iter: 11, training_loss: 4.70146e-01\n",
            "epoch: 805, iter: 11, training_loss: 4.64515e-01\n",
            "epoch: 806, iter: 11, training_loss: 4.95545e-01\n",
            "epoch: 807, iter: 11, training_loss: 4.65078e-01\n",
            "epoch: 808, iter: 11, training_loss: 4.01191e-01\n",
            "epoch: 809, iter: 11, training_loss: 4.34822e-01\n",
            "epoch: 810, iter: 11, training_loss: 4.34019e-01\n",
            "epoch: 811, iter: 11, training_loss: 4.32809e-01\n",
            "epoch: 812, iter: 11, training_loss: 4.15660e-01\n",
            "epoch: 813, iter: 11, training_loss: 3.71367e-01\n",
            "epoch: 814, iter: 11, training_loss: 3.40627e-01\n",
            "epoch: 815, iter: 11, training_loss: 4.85719e-01\n",
            "epoch: 816, iter: 11, training_loss: 5.64953e-01\n",
            "epoch: 817, iter: 11, training_loss: 5.00791e-01\n",
            "epoch: 818, iter: 11, training_loss: 4.32038e-01\n",
            "epoch: 819, iter: 11, training_loss: 4.50757e-01\n",
            "epoch: 820, iter: 11, training_loss: 4.19599e-01\n",
            "epoch: 821, iter: 11, training_loss: 4.00793e-01\n",
            "epoch: 822, iter: 11, training_loss: 3.81093e-01\n",
            "epoch: 823, iter: 11, training_loss: 3.90073e-01\n",
            "epoch: 824, iter: 11, training_loss: 4.77965e-01\n",
            "epoch: 825, iter: 11, training_loss: 4.04193e-01\n",
            "epoch: 826, iter: 11, training_loss: 4.02337e-01\n",
            "epoch: 827, iter: 11, training_loss: 3.88506e-01\n",
            "epoch: 828, iter: 11, training_loss: 4.91455e-01\n",
            "epoch: 829, iter: 11, training_loss: 4.95756e-01\n",
            "epoch: 830, iter: 11, training_loss: 5.68037e-01\n",
            "epoch: 831, iter: 11, training_loss: 4.34954e-01\n",
            "epoch: 832, iter: 11, training_loss: 4.26142e-01\n",
            "epoch: 833, iter: 11, training_loss: 4.51543e-01\n",
            "epoch: 834, iter: 11, training_loss: 4.19386e-01\n",
            "epoch: 835, iter: 11, training_loss: 4.94041e-01\n",
            "epoch: 836, iter: 11, training_loss: 4.39511e-01\n",
            "epoch: 837, iter: 11, training_loss: 3.99926e-01\n",
            "epoch: 838, iter: 11, training_loss: 4.71590e-01\n",
            "epoch: 839, iter: 11, training_loss: 3.72037e-01\n",
            "epoch: 840, iter: 11, training_loss: 3.66510e-01\n",
            "epoch: 841, iter: 11, training_loss: 4.25785e-01\n",
            "epoch: 842, iter: 11, training_loss: 5.37577e-01\n",
            "epoch: 843, iter: 11, training_loss: 4.64135e-01\n",
            "epoch: 844, iter: 11, training_loss: 5.05726e-01\n",
            "epoch: 845, iter: 11, training_loss: 4.54669e-01\n",
            "epoch: 846, iter: 11, training_loss: 4.22745e-01\n",
            "epoch: 847, iter: 11, training_loss: 4.13784e-01\n",
            "epoch: 848, iter: 11, training_loss: 3.85532e-01\n",
            "epoch: 849, iter: 11, training_loss: 4.12412e-01\n",
            "epoch: 850, iter: 11, training_loss: 4.11734e-01\n",
            "epoch: 851, iter: 11, training_loss: 3.60055e-01\n",
            "epoch: 852, iter: 11, training_loss: 4.53685e-01\n",
            "epoch: 853, iter: 11, training_loss: 4.50352e-01\n",
            "epoch: 854, iter: 11, training_loss: 4.28519e-01\n",
            "epoch: 855, iter: 11, training_loss: 4.26827e-01\n",
            "epoch: 856, iter: 11, training_loss: 3.63763e-01\n",
            "epoch: 857, iter: 11, training_loss: 3.73132e-01\n",
            "epoch: 858, iter: 11, training_loss: 4.49806e-01\n",
            "epoch: 859, iter: 11, training_loss: 4.48842e-01\n",
            "epoch: 860, iter: 11, training_loss: 3.91964e-01\n",
            "epoch: 861, iter: 11, training_loss: 4.57217e-01\n",
            "epoch: 862, iter: 11, training_loss: 4.10131e-01\n",
            "epoch: 863, iter: 11, training_loss: 4.06745e-01\n",
            "epoch: 864, iter: 11, training_loss: 4.20162e-01\n",
            "epoch: 865, iter: 11, training_loss: 3.55789e-01\n",
            "epoch: 866, iter: 11, training_loss: 4.16727e-01\n",
            "epoch: 867, iter: 11, training_loss: 4.30187e-01\n",
            "epoch: 868, iter: 11, training_loss: 3.90317e-01\n",
            "epoch: 869, iter: 11, training_loss: 4.30874e-01\n",
            "epoch: 870, iter: 11, training_loss: 4.30666e-01\n",
            "epoch: 871, iter: 11, training_loss: 4.53186e-01\n",
            "epoch: 872, iter: 11, training_loss: 3.71745e-01\n",
            "epoch: 873, iter: 11, training_loss: 4.20673e-01\n",
            "epoch: 874, iter: 11, training_loss: 4.16643e-01\n",
            "epoch: 875, iter: 11, training_loss: 4.10253e-01\n",
            "epoch: 876, iter: 11, training_loss: 3.51002e-01\n",
            "epoch: 877, iter: 11, training_loss: 3.83331e-01\n",
            "epoch: 878, iter: 11, training_loss: 3.91408e-01\n",
            "epoch: 879, iter: 11, training_loss: 3.42873e-01\n",
            "epoch: 880, iter: 11, training_loss: 4.00301e-01\n",
            "epoch: 881, iter: 11, training_loss: 3.84291e-01\n",
            "epoch: 882, iter: 11, training_loss: 4.42700e-01\n",
            "epoch: 883, iter: 11, training_loss: 3.85385e-01\n",
            "epoch: 884, iter: 11, training_loss: 4.00094e-01\n",
            "epoch: 885, iter: 11, training_loss: 4.73060e-01\n",
            "epoch: 886, iter: 11, training_loss: 3.83112e-01\n",
            "epoch: 887, iter: 11, training_loss: 4.25512e-01\n",
            "epoch: 888, iter: 11, training_loss: 3.70063e-01\n",
            "epoch: 889, iter: 11, training_loss: 3.56924e-01\n",
            "epoch: 890, iter: 11, training_loss: 3.49394e-01\n",
            "epoch: 891, iter: 11, training_loss: 4.72103e-01\n",
            "epoch: 892, iter: 11, training_loss: 3.75627e-01\n",
            "epoch: 893, iter: 11, training_loss: 3.80062e-01\n",
            "epoch: 894, iter: 11, training_loss: 4.69307e-01\n",
            "epoch: 895, iter: 11, training_loss: 4.12923e-01\n",
            "epoch: 896, iter: 11, training_loss: 4.10397e-01\n",
            "epoch: 897, iter: 11, training_loss: 4.86575e-01\n",
            "epoch: 898, iter: 11, training_loss: 4.17983e-01\n",
            "epoch: 899, iter: 11, training_loss: 4.51291e-01\n",
            "epoch: 900, iter: 11, training_loss: 3.84057e-01\n",
            "epoch: 901, iter: 11, training_loss: 4.23648e-01\n",
            "epoch: 902, iter: 11, training_loss: 3.41037e-01\n",
            "epoch: 903, iter: 11, training_loss: 3.98184e-01\n",
            "epoch: 904, iter: 11, training_loss: 4.19046e-01\n",
            "epoch: 905, iter: 11, training_loss: 4.04924e-01\n",
            "epoch: 906, iter: 11, training_loss: 4.40936e-01\n",
            "epoch: 907, iter: 11, training_loss: 4.22970e-01\n",
            "epoch: 908, iter: 11, training_loss: 4.79434e-01\n",
            "epoch: 909, iter: 11, training_loss: 3.49847e-01\n",
            "epoch: 910, iter: 11, training_loss: 3.40357e-01\n",
            "epoch: 911, iter: 11, training_loss: 4.11220e-01\n",
            "epoch: 912, iter: 11, training_loss: 4.19871e-01\n",
            "epoch: 913, iter: 11, training_loss: 3.83605e-01\n",
            "epoch: 914, iter: 11, training_loss: 3.39338e-01\n",
            "epoch: 915, iter: 11, training_loss: 3.62327e-01\n",
            "epoch: 916, iter: 11, training_loss: 3.59526e-01\n",
            "epoch: 917, iter: 11, training_loss: 4.03356e-01\n",
            "epoch: 918, iter: 11, training_loss: 4.70630e-01\n",
            "epoch: 919, iter: 11, training_loss: 4.40630e-01\n",
            "epoch: 920, iter: 11, training_loss: 4.44719e-01\n",
            "epoch: 921, iter: 11, training_loss: 3.90108e-01\n",
            "epoch: 922, iter: 11, training_loss: 4.32009e-01\n",
            "epoch: 923, iter: 11, training_loss: 4.65368e-01\n",
            "epoch: 924, iter: 11, training_loss: 4.84180e-01\n",
            "epoch: 925, iter: 11, training_loss: 4.42663e-01\n",
            "epoch: 926, iter: 11, training_loss: 4.06546e-01\n",
            "epoch: 927, iter: 11, training_loss: 3.54616e-01\n",
            "epoch: 928, iter: 11, training_loss: 3.50159e-01\n",
            "epoch: 929, iter: 11, training_loss: 5.02987e-01\n",
            "epoch: 930, iter: 11, training_loss: 4.77459e-01\n",
            "epoch: 931, iter: 11, training_loss: 4.20747e-01\n",
            "epoch: 932, iter: 11, training_loss: 3.86404e-01\n",
            "epoch: 933, iter: 11, training_loss: 4.25795e-01\n",
            "epoch: 934, iter: 11, training_loss: 4.15092e-01\n",
            "epoch: 935, iter: 11, training_loss: 3.78148e-01\n",
            "epoch: 936, iter: 11, training_loss: 3.30646e-01\n",
            "epoch: 937, iter: 11, training_loss: 3.65583e-01\n",
            "epoch: 938, iter: 11, training_loss: 3.76695e-01\n",
            "epoch: 939, iter: 11, training_loss: 3.54442e-01\n",
            "epoch: 940, iter: 11, training_loss: 3.75495e-01\n",
            "epoch: 941, iter: 11, training_loss: 4.14581e-01\n",
            "epoch: 942, iter: 11, training_loss: 3.58387e-01\n",
            "epoch: 943, iter: 11, training_loss: 3.61849e-01\n",
            "epoch: 944, iter: 11, training_loss: 3.88883e-01\n",
            "epoch: 945, iter: 11, training_loss: 3.68202e-01\n",
            "epoch: 946, iter: 11, training_loss: 4.07022e-01\n",
            "epoch: 947, iter: 11, training_loss: 3.91994e-01\n",
            "epoch: 948, iter: 11, training_loss: 3.74972e-01\n",
            "epoch: 949, iter: 11, training_loss: 3.56508e-01\n",
            "epoch: 950, iter: 11, training_loss: 3.46373e-01\n",
            "epoch: 951, iter: 11, training_loss: 3.47318e-01\n",
            "epoch: 952, iter: 11, training_loss: 3.67875e-01\n",
            "epoch: 953, iter: 11, training_loss: 3.60326e-01\n",
            "epoch: 954, iter: 11, training_loss: 3.56836e-01\n",
            "epoch: 955, iter: 11, training_loss: 3.05835e-01\n",
            "epoch: 956, iter: 11, training_loss: 3.26513e-01\n",
            "epoch: 957, iter: 11, training_loss: 4.21251e-01\n",
            "epoch: 958, iter: 11, training_loss: 3.61901e-01\n",
            "epoch: 959, iter: 11, training_loss: 3.98910e-01\n",
            "epoch: 960, iter: 11, training_loss: 4.40024e-01\n",
            "epoch: 961, iter: 11, training_loss: 3.95825e-01\n",
            "epoch: 962, iter: 11, training_loss: 3.52671e-01\n",
            "epoch: 963, iter: 11, training_loss: 4.65285e-01\n",
            "epoch: 964, iter: 11, training_loss: 4.46005e-01\n",
            "epoch: 965, iter: 11, training_loss: 3.64440e-01\n",
            "epoch: 966, iter: 11, training_loss: 4.14073e-01\n",
            "epoch: 967, iter: 11, training_loss: 3.49099e-01\n",
            "epoch: 968, iter: 11, training_loss: 3.50775e-01\n",
            "epoch: 969, iter: 11, training_loss: 4.35366e-01\n",
            "epoch: 970, iter: 11, training_loss: 4.20760e-01\n",
            "epoch: 971, iter: 11, training_loss: 3.95429e-01\n",
            "epoch: 972, iter: 11, training_loss: 3.40025e-01\n",
            "epoch: 973, iter: 11, training_loss: 3.07329e-01\n",
            "epoch: 974, iter: 11, training_loss: 4.09689e-01\n",
            "epoch: 975, iter: 11, training_loss: 4.84691e-01\n",
            "epoch: 976, iter: 11, training_loss: 3.97423e-01\n",
            "epoch: 977, iter: 11, training_loss: 4.06539e-01\n",
            "epoch: 978, iter: 11, training_loss: 3.84784e-01\n",
            "epoch: 979, iter: 11, training_loss: 3.63948e-01\n",
            "epoch: 980, iter: 11, training_loss: 3.59685e-01\n",
            "epoch: 981, iter: 11, training_loss: 3.72917e-01\n",
            "epoch: 982, iter: 11, training_loss: 3.17195e-01\n",
            "epoch: 983, iter: 11, training_loss: 3.30444e-01\n",
            "epoch: 984, iter: 11, training_loss: 4.13942e-01\n",
            "epoch: 985, iter: 11, training_loss: 4.14339e-01\n",
            "epoch: 986, iter: 11, training_loss: 3.70646e-01\n",
            "epoch: 987, iter: 11, training_loss: 3.73161e-01\n",
            "epoch: 988, iter: 11, training_loss: 3.64452e-01\n",
            "epoch: 989, iter: 11, training_loss: 3.43423e-01\n",
            "epoch: 990, iter: 11, training_loss: 3.79829e-01\n",
            "epoch: 991, iter: 11, training_loss: 4.21481e-01\n",
            "epoch: 992, iter: 11, training_loss: 3.49530e-01\n",
            "epoch: 993, iter: 11, training_loss: 3.94368e-01\n",
            "epoch: 994, iter: 11, training_loss: 3.27461e-01\n",
            "epoch: 995, iter: 11, training_loss: 4.22906e-01\n",
            "epoch: 996, iter: 11, training_loss: 3.59509e-01\n",
            "epoch: 997, iter: 11, training_loss: 3.94821e-01\n",
            "epoch: 998, iter: 11, training_loss: 3.52785e-01\n",
            "epoch: 999, iter: 11, training_loss: 3.59541e-01\n",
            "epoch: 1000, iter: 11, training_loss: 3.08519e-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname shoppers --method stasy --mode sample --save_path shoppers_syn.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3k-BWz1i1de",
        "outputId": "4579a37c-6702-4e58-bf3c-19de18af1f90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No NaNs in numerical features, skipping\n",
            "Input dimension: 77\n",
            "NCSNpp(\n",
            "  (act): ELU(alpha=1.0)\n",
            "  (all_modules): ModuleList(\n",
            "    (0): GaussianFourierProjection()\n",
            "    (1): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (3): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=77, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (4): ELU(alpha=1.0)\n",
            "    (5): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=1101, out_features=2048, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=2048, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=2048, bias=True)\n",
            "    )\n",
            "    (6): ELU(alpha=1.0)\n",
            "    (7): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=3149, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (8): ELU(alpha=1.0)\n",
            "    (9): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=4173, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (10): ELU(alpha=1.0)\n",
            "    (11): Linear(in_features=5197, out_features=77, bias=True)\n",
            "  )\n",
            ")\n",
            "the number of parameters 10351030\n",
            "Loading SAVED model at from /content/tabsyn/baselines/stasy/ckpt/shoppers/model.pth\n",
            "Start sampling...\n",
            "(11097, 8)\n",
            "Sampling time = 24.874069929122925\n",
            "Saving sampled data to shoppers_syn.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname beijing --method stasy --mode sample --save_path beijing_syn.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGnppkwU4g5n",
        "outputId": "899322f0-8dda-4957-da51-22916718c256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No NaNs in numerical features, skipping\n",
            "Input dimension: 83\n",
            "NCSNpp(\n",
            "  (act): ELU(alpha=1.0)\n",
            "  (all_modules): ModuleList(\n",
            "    (0): GaussianFourierProjection()\n",
            "    (1): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (3): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=83, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (4): ELU(alpha=1.0)\n",
            "    (5): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=1107, out_features=2048, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=2048, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=2048, bias=True)\n",
            "    )\n",
            "    (6): ELU(alpha=1.0)\n",
            "    (7): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=3155, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (8): ELU(alpha=1.0)\n",
            "    (9): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=4179, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (10): ELU(alpha=1.0)\n",
            "    (11): Linear(in_features=5203, out_features=83, bias=True)\n",
            "  )\n",
            ")\n",
            "the number of parameters 10413436\n",
            "Loading SAVED model at from /content/tabsyn/baselines/stasy/ckpt/beijing/model.pth\n",
            "Start sampling...\n",
            "Sampling time = 73.09838771820068\n",
            "Saving sampled data to beijing_syn.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6Kvt6Utk62X",
        "outputId": "394eb329-0247-41d0-8dd6-a3657fac0330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 132\n",
            "drwxr-xr-x 11 root root  4096 May 11 16:01 .\n",
            "drwxr-xr-x  1 root root  4096 May 11 15:51 ..\n",
            "drwxr-xr-x  8 root root  4096 May 11 15:51 baselines\n",
            "-rw-r--r--  1 root root   309 May 11 15:51 CODE_OF_CONDUCT.md\n",
            "-rw-r--r--  1 root root  3160 May 11 15:51 CONTRIBUTING.md\n",
            "drwxr-xr-x  9 root root  4096 May 11 15:51 data\n",
            "-rw-r--r--  1 root root  1470 May 11 15:51 download_dataset.py\n",
            "drwxr-xr-x  3 root root  4096 May 11 15:51 eval\n",
            "-rw-r--r--  1 root root  1213 May 11 15:51 eval_impute.py\n",
            "drwxr-xr-x  8 root root  4096 May 11 15:51 .git\n",
            "drwxr-xr-x  2 root root  4096 May 11 15:51 images\n",
            "-rw-r--r--  1 root root  7943 May 11 15:51 impute.py\n",
            "-rw-r--r--  1 root root 10142 May 11 15:51 LICENSE\n",
            "-rw-r--r--  1 root root   394 May 11 15:51 main.py\n",
            "-rw-r--r--  1 root root    67 May 11 15:51 NOTICE\n",
            "-rw-r--r--  1 root root 10416 May 11 15:51 process_dataset.py\n",
            "drwxr-xr-x  2 root root  4096 May 11 16:05 __pycache__\n",
            "-rw-r--r--  1 root root 10289 May 11 15:51 README.md\n",
            "-rw-r--r--  1 root root   193 May 11 15:51 requirements.txt\n",
            "drwxr-xr-x  3 root root  4096 May 11 16:03 src\n",
            "drwxr-xr-x  8 root root  4096 May 11 15:52 synthetic\n",
            "drwxr-xr-x  3 root root  4096 May 11 15:51 tabsyn\n",
            "-rw-r--r--  1 root root  7570 May 11 15:51 utils.py\n",
            "-rw-r--r--  1 root root  4708 May 11 15:51 utils_train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('gen_syn/adult_syn.csv')"
      ],
      "metadata": {
        "id": "XR-m4LQT5DLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "X5HrP_pT5JfQ",
        "outputId": "742d2be3-307b-47aa-cf55-b881e6471917",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             age          workclass      fnlwgt      education  education.num  \\\n",
              "0      21.268696            Private  122065.220        HS-grad            9.0   \n",
              "1      28.000000          Local-gov   35365.266           12th            8.0   \n",
              "2      28.000000            Private   21078.660           12th            8.0   \n",
              "3      32.463060            Private  105450.450        HS-grad            9.0   \n",
              "4      33.000000            Private   99170.750      Assoc-voc           11.0   \n",
              "...          ...                ...         ...            ...            ...   \n",
              "32556  28.000000            Private   32059.720   Some-college           10.0   \n",
              "32557  51.000000                  ?   37364.330    Prof-school           15.0   \n",
              "32558  19.000000            Private  196683.030   Some-college           10.0   \n",
              "32559  17.000000            Private  147142.170        HS-grad            9.0   \n",
              "32560  52.000000   Self-emp-not-inc   94072.195   Some-college           10.0   \n",
              "\n",
              "            marital.status          occupation    relationship    race  \\\n",
              "0            Never-married               Sales   Not-in-family   White   \n",
              "1            Never-married               Sales   Not-in-family   White   \n",
              "2            Never-married       Other-service       Unmarried   White   \n",
              "3            Never-married   Handlers-cleaners   Not-in-family   White   \n",
              "4       Married-civ-spouse        Craft-repair         Husband   Black   \n",
              "...                    ...                 ...             ...     ...   \n",
              "32556        Never-married   Handlers-cleaners       Own-child   White   \n",
              "32557   Married-civ-spouse                   ?         Husband   White   \n",
              "32558        Never-married   Handlers-cleaners       Own-child   White   \n",
              "32559        Never-married   Handlers-cleaners       Own-child   White   \n",
              "32560   Married-civ-spouse        Tech-support         Husband   White   \n",
              "\n",
              "           sex  capital.gain  capital.loss  hours.per.week  native.country  \\\n",
              "0       Female         0.000        0.0000            50.0   United-States   \n",
              "1         Male         0.000        0.0000            40.0   United-States   \n",
              "2       Female         0.000        0.0000            35.0   United-States   \n",
              "3         Male         0.000     2248.0703            40.0   United-States   \n",
              "4         Male         0.000        0.0000            40.0   United-States   \n",
              "...        ...           ...           ...             ...             ...   \n",
              "32556     Male         0.000        0.0000            40.0   United-States   \n",
              "32557     Male      5175.879        0.0000             8.0   United-States   \n",
              "32558     Male         0.000        0.0000            40.0   United-States   \n",
              "32559     Male         0.000        0.0000            10.0   United-States   \n",
              "32560     Male         0.000     2414.5137             6.0   United-States   \n",
              "\n",
              "       income  \n",
              "0       <=50K  \n",
              "1       <=50K  \n",
              "2       <=50K  \n",
              "3       <=50K  \n",
              "4       <=50K  \n",
              "...       ...  \n",
              "32556   <=50K  \n",
              "32557    >50K  \n",
              "32558   <=50K  \n",
              "32559   <=50K  \n",
              "32560   <=50K  \n",
              "\n",
              "[32561 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f56927ff-963f-41b6-8ed5-9af5b320d656\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education.num</th>\n",
              "      <th>marital.status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital.gain</th>\n",
              "      <th>capital.loss</th>\n",
              "      <th>hours.per.week</th>\n",
              "      <th>native.country</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21.268696</td>\n",
              "      <td>Private</td>\n",
              "      <td>122065.220</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Sales</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>50.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28.000000</td>\n",
              "      <td>Local-gov</td>\n",
              "      <td>35365.266</td>\n",
              "      <td>12th</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Sales</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28.000000</td>\n",
              "      <td>Private</td>\n",
              "      <td>21078.660</td>\n",
              "      <td>12th</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Other-service</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>35.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>32.463060</td>\n",
              "      <td>Private</td>\n",
              "      <td>105450.450</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2248.0703</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33.000000</td>\n",
              "      <td>Private</td>\n",
              "      <td>99170.750</td>\n",
              "      <td>Assoc-voc</td>\n",
              "      <td>11.0</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32556</th>\n",
              "      <td>28.000000</td>\n",
              "      <td>Private</td>\n",
              "      <td>32059.720</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32557</th>\n",
              "      <td>51.000000</td>\n",
              "      <td>?</td>\n",
              "      <td>37364.330</td>\n",
              "      <td>Prof-school</td>\n",
              "      <td>15.0</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>?</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>5175.879</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32558</th>\n",
              "      <td>19.000000</td>\n",
              "      <td>Private</td>\n",
              "      <td>196683.030</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32559</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>Private</td>\n",
              "      <td>147142.170</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>10.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32560</th>\n",
              "      <td>52.000000</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>94072.195</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Tech-support</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2414.5137</td>\n",
              "      <td>6.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32561 rows  15 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f56927ff-963f-41b6-8ed5-9af5b320d656')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f56927ff-963f-41b6-8ed5-9af5b320d656 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f56927ff-963f-41b6-8ed5-9af5b320d656');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c1ff2185-8bc4-4ad3-92e5-90ef07e1a1fc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c1ff2185-8bc4-4ad3-92e5-90ef07e1a1fc')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c1ff2185-8bc4-4ad3-92e5-90ef07e1a1fc button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 32561,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.171284508499477,\n        \"min\": 17.0,\n        \"max\": 90.0,\n        \"num_unique_values\": 2090,\n        \"samples\": [\n          58.92868,\n          81.84867,\n          32.61907\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"workclass\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \" Without-pay\",\n          \" Local-gov\",\n          \" ?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fnlwgt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 88958.81621040749,\n        \"min\": 12285.886,\n        \"max\": 1483849.6,\n        \"num_unique_values\": 32544,\n        \"samples\": [\n          65496.652,\n          176857.3,\n          118802.36\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \" HS-grad\",\n          \" 12th\",\n          \" 7th-8th\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education.num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.5871884657555637,\n        \"min\": 1.0,\n        \"max\": 16.0,\n        \"num_unique_values\": 70,\n        \"samples\": [\n          2.0567443,\n          9.0,\n          5.6808934\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"marital.status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \" Never-married\",\n          \" Married-civ-spouse\",\n          \" Widowed\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"occupation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \" Tech-support\",\n          \" ?\",\n          \" Sales\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relationship\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \" Not-in-family\",\n          \" Unmarried\",\n          \" Wife\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"race\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \" Black\",\n          \" Amer-Indian-Eskimo\",\n          \" Asian-Pac-Islander\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \" Male\",\n          \" Female\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"capital.gain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8013.391488646674,\n        \"min\": 0.0,\n        \"max\": 99999.0,\n        \"num_unique_values\": 1888,\n        \"samples\": [\n          2015.94,\n          14179.636\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"capital.loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 794.2468843149129,\n        \"min\": 0.0,\n        \"max\": 4356.0,\n        \"num_unique_values\": 3895,\n        \"samples\": [\n          2249.4666,\n          1850.8204\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hours.per.week\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.886663179821529,\n        \"min\": 1.0,\n        \"max\": 99.0,\n        \"num_unique_values\": 2475,\n        \"samples\": [\n          44.734653,\n          87.94593\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"native.country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 41,\n        \"samples\": [\n          \" Guatemala\",\n          \" Iran\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"income\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \" >50K\",\n          \" <=50K\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CODI"
      ],
      "metadata": {
        "id": "ls-Q9w9dU0Hk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### adult"
      ],
      "metadata": {
        "id": "KcPjq270U80L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname adult --method codi --mode train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDT5VPSdUzHn",
        "outputId": "7674290e-9a57-4998-cb2f-3e98469c422d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m        (5000).\u001b[0m\n",
            "Epoch:532, step = 4263, Total continuous loss: 0.498, discrete loss: 0.375\n",
            "Time taken: 0.510\n",
            "Time taken: 0.421\n",
            "Time taken: 0.423\n",
            "Time taken: 0.422\n",
            "Time taken: 0.424\n",
            "Time taken: 0.423\n",
            "Time taken: 0.425\n",
            "Time taken: 0.422\n",
            "Epoch:533, step = 4271, diffusion continuous loss: 0.293, discrete loss: 0.215\n",
            "Epoch:533, step = 4271, CL continuous loss: 0.889, discrete loss: 0.780\n",
            "Epoch:533, step = 4271, Total continuous loss: 0.471, discrete loss: 0.371\n",
            "Time taken: 0.412\n",
            "Time taken: 0.429\n",
            "Time taken: 0.451\n",
            "Time taken: 0.446\n",
            "Time taken: 0.442\n",
            "Time taken: 0.448\n",
            "Time taken: 0.446\n",
            "Time taken: 0.420\n",
            "Epoch:534, step = 4279, diffusion continuous loss: 0.331, discrete loss: 0.217\n",
            "Epoch:534, step = 4279, CL continuous loss: 0.919, discrete loss: 0.790\n",
            "Epoch:534, step = 4279, Total continuous loss: 0.515, discrete loss: 0.375\n",
            "Time taken: 0.416\n",
            "Time taken: 0.423\n",
            "Time taken: 0.426\n",
            "Time taken: 0.418\n",
            "Time taken: 0.422\n",
            "Time taken: 0.426\n",
            "Time taken: 0.420\n",
            "Time taken: 0.426\n",
            "Epoch:535, step = 4287, diffusion continuous loss: 0.293, discrete loss: 0.222\n",
            "Epoch:535, step = 4287, CL continuous loss: 0.910, discrete loss: 0.798\n",
            "Epoch:535, step = 4287, Total continuous loss: 0.475, discrete loss: 0.382\n",
            "Time taken: 0.412\n",
            "Time taken: 0.425\n",
            "Time taken: 0.423\n",
            "Time taken: 0.420\n",
            "Time taken: 0.422\n",
            "Time taken: 0.424\n",
            "Time taken: 0.426\n",
            "Time taken: 0.451\n",
            "Epoch:536, step = 4295, diffusion continuous loss: 0.281, discrete loss: 0.217\n",
            "Epoch:536, step = 4295, CL continuous loss: 0.882, discrete loss: 0.785\n",
            "Epoch:536, step = 4295, Total continuous loss: 0.457, discrete loss: 0.374\n",
            "Time taken: 0.412\n",
            "Time taken: 0.421\n",
            "Time taken: 0.423\n",
            "Time taken: 0.421\n",
            "Time taken: 0.422\n",
            "Time taken: 0.423\n",
            "Time taken: 0.433\n",
            "Time taken: 0.572\n",
            "Epoch:537, step = 4303, diffusion continuous loss: 0.338, discrete loss: 0.217\n",
            "Epoch:537, step = 4303, CL continuous loss: 0.911, discrete loss: 0.778\n",
            "Epoch:537, step = 4303, Total continuous loss: 0.520, discrete loss: 0.373\n",
            "Time taken: 0.433\n",
            "Time taken: 0.461\n",
            "Time taken: 0.450\n",
            "Time taken: 0.437\n",
            "Time taken: 0.423\n",
            "Time taken: 0.423\n",
            "Time taken: 0.421\n",
            "Time taken: 0.421\n",
            "Epoch:538, step = 4311, diffusion continuous loss: 0.291, discrete loss: 0.214\n",
            "Epoch:538, step = 4311, CL continuous loss: 0.897, discrete loss: 0.792\n",
            "Epoch:538, step = 4311, Total continuous loss: 0.471, discrete loss: 0.372\n",
            "Time taken: 0.413\n",
            "Time taken: 0.424\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.422\n",
            "Time taken: 0.424\n",
            "Time taken: 0.420\n",
            "Time taken: 0.420\n",
            "Epoch:539, step = 4319, diffusion continuous loss: 0.281, discrete loss: 0.209\n",
            "Epoch:539, step = 4319, CL continuous loss: 0.875, discrete loss: 0.780\n",
            "Epoch:539, step = 4319, Total continuous loss: 0.456, discrete loss: 0.365\n",
            "Time taken: 0.414\n",
            "Time taken: 0.419\n",
            "Time taken: 0.426\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.421\n",
            "Epoch:540, step = 4327, diffusion continuous loss: 0.277, discrete loss: 0.207\n",
            "Epoch:540, step = 4327, CL continuous loss: 0.871, discrete loss: 0.777\n",
            "Epoch:540, step = 4327, Total continuous loss: 0.452, discrete loss: 0.363\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.422\n",
            "Time taken: 0.452\n",
            "Time taken: 0.444\n",
            "Time taken: 0.446\n",
            "Time taken: 0.454\n",
            "Time taken: 0.454\n",
            "Epoch:541, step = 4335, diffusion continuous loss: 0.271, discrete loss: 0.208\n",
            "Epoch:541, step = 4335, CL continuous loss: 0.886, discrete loss: 0.779\n",
            "Epoch:541, step = 4335, Total continuous loss: 0.448, discrete loss: 0.364\n",
            "Time taken: 0.414\n",
            "Time taken: 0.425\n",
            "Time taken: 0.417\n",
            "Time taken: 0.432\n",
            "Time taken: 0.420\n",
            "Time taken: 0.527\n",
            "Time taken: 0.423\n",
            "Time taken: 0.423\n",
            "Epoch:542, step = 4343, diffusion continuous loss: 0.287, discrete loss: 0.228\n",
            "Epoch:542, step = 4343, CL continuous loss: 0.869, discrete loss: 0.782\n",
            "Epoch:542, step = 4343, Total continuous loss: 0.461, discrete loss: 0.384\n",
            "Time taken: 0.413\n",
            "Time taken: 0.422\n",
            "Time taken: 0.422\n",
            "Time taken: 0.423\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.429\n",
            "Epoch:543, step = 4351, diffusion continuous loss: 0.297, discrete loss: 0.219\n",
            "Epoch:543, step = 4351, CL continuous loss: 0.893, discrete loss: 0.782\n",
            "Epoch:543, step = 4351, Total continuous loss: 0.475, discrete loss: 0.375\n",
            "Time taken: 0.413\n",
            "Time taken: 0.425\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.422\n",
            "Time taken: 0.428\n",
            "Epoch:544, step = 4359, diffusion continuous loss: 0.307, discrete loss: 0.219\n",
            "Epoch:544, step = 4359, CL continuous loss: 0.912, discrete loss: 0.779\n",
            "Epoch:544, step = 4359, Total continuous loss: 0.489, discrete loss: 0.374\n",
            "Time taken: 0.443\n",
            "Time taken: 0.449\n",
            "Time taken: 0.441\n",
            "Time taken: 0.447\n",
            "Time taken: 0.448\n",
            "Time taken: 0.437\n",
            "Time taken: 0.420\n",
            "Time taken: 0.424\n",
            "Epoch:545, step = 4367, diffusion continuous loss: 0.294, discrete loss: 0.213\n",
            "Epoch:545, step = 4367, CL continuous loss: 0.894, discrete loss: 0.777\n",
            "Epoch:545, step = 4367, Total continuous loss: 0.473, discrete loss: 0.368\n",
            "Time taken: 0.421\n",
            "Time taken: 0.419\n",
            "Time taken: 0.423\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.426\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Epoch:546, step = 4375, diffusion continuous loss: 0.277, discrete loss: 0.214\n",
            "Epoch:546, step = 4375, CL continuous loss: 0.881, discrete loss: 0.787\n",
            "Epoch:546, step = 4375, Total continuous loss: 0.454, discrete loss: 0.372\n",
            "Time taken: 0.410\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.422\n",
            "Time taken: 0.530\n",
            "Time taken: 0.420\n",
            "Time taken: 0.425\n",
            "Time taken: 0.418\n",
            "Epoch:547, step = 4383, diffusion continuous loss: 0.267, discrete loss: 0.215\n",
            "Epoch:547, step = 4383, CL continuous loss: 0.885, discrete loss: 0.802\n",
            "Epoch:547, step = 4383, Total continuous loss: 0.444, discrete loss: 0.376\n",
            "Time taken: 0.410\n",
            "Time taken: 0.435\n",
            "Time taken: 0.419\n",
            "Time taken: 0.429\n",
            "Time taken: 0.452\n",
            "Time taken: 0.444\n",
            "Time taken: 0.445\n",
            "Time taken: 0.445\n",
            "Epoch:548, step = 4391, diffusion continuous loss: 0.347, discrete loss: 0.211\n",
            "Epoch:548, step = 4391, CL continuous loss: 0.880, discrete loss: 0.791\n",
            "Epoch:548, step = 4391, Total continuous loss: 0.523, discrete loss: 0.369\n",
            "Time taken: 0.454\n",
            "Time taken: 0.427\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.422\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Epoch:549, step = 4399, diffusion continuous loss: 0.343, discrete loss: 0.224\n",
            "Epoch:549, step = 4399, CL continuous loss: 0.881, discrete loss: 0.795\n",
            "Epoch:549, step = 4399, Total continuous loss: 0.519, discrete loss: 0.383\n",
            "Time taken: 0.417\n",
            "Time taken: 0.428\n",
            "Time taken: 0.431\n",
            "Time taken: 0.419\n",
            "Time taken: 0.423\n",
            "Time taken: 0.422\n",
            "Time taken: 0.417\n",
            "Time taken: 0.422\n",
            "Epoch:550, step = 4407, diffusion continuous loss: 0.278, discrete loss: 0.218\n",
            "Epoch:550, step = 4407, CL continuous loss: 0.882, discrete loss: 0.786\n",
            "Epoch:550, step = 4407, Total continuous loss: 0.455, discrete loss: 0.375\n",
            "Time taken: 0.414\n",
            "Time taken: 0.421\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.420\n",
            "Time taken: 0.423\n",
            "Time taken: 0.417\n",
            "Time taken: 0.422\n",
            "Epoch:551, step = 4415, diffusion continuous loss: 0.283, discrete loss: 0.222\n",
            "Epoch:551, step = 4415, CL continuous loss: 0.888, discrete loss: 0.784\n",
            "Epoch:551, step = 4415, Total continuous loss: 0.460, discrete loss: 0.379\n",
            "Time taken: 0.417\n",
            "Time taken: 0.448\n",
            "Time taken: 0.574\n",
            "Time taken: 0.439\n",
            "Time taken: 0.452\n",
            "Time taken: 0.453\n",
            "Time taken: 0.422\n",
            "Time taken: 0.423\n",
            "Epoch:552, step = 4423, diffusion continuous loss: 0.279, discrete loss: 0.224\n",
            "Epoch:552, step = 4423, CL continuous loss: 0.873, discrete loss: 0.790\n",
            "Epoch:552, step = 4423, Total continuous loss: 0.454, discrete loss: 0.382\n",
            "Time taken: 0.410\n",
            "Time taken: 0.423\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.422\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.429\n",
            "Epoch:553, step = 4431, diffusion continuous loss: 0.268, discrete loss: 0.222\n",
            "Epoch:553, step = 4431, CL continuous loss: 0.867, discrete loss: 0.790\n",
            "Epoch:553, step = 4431, Total continuous loss: 0.441, discrete loss: 0.380\n",
            "Time taken: 0.413\n",
            "Time taken: 0.424\n",
            "Time taken: 0.418\n",
            "Time taken: 0.423\n",
            "Time taken: 0.426\n",
            "Time taken: 0.423\n",
            "Time taken: 0.426\n",
            "Time taken: 0.425\n",
            "Epoch:554, step = 4439, diffusion continuous loss: 0.298, discrete loss: 0.228\n",
            "Epoch:554, step = 4439, CL continuous loss: 0.871, discrete loss: 0.816\n",
            "Epoch:554, step = 4439, Total continuous loss: 0.473, discrete loss: 0.391\n",
            "Time taken: 0.411\n",
            "Time taken: 0.418\n",
            "Time taken: 0.424\n",
            "Time taken: 0.427\n",
            "Time taken: 0.425\n",
            "Time taken: 0.429\n",
            "Time taken: 0.444\n",
            "Time taken: 0.444\n",
            "Epoch:555, step = 4447, diffusion continuous loss: 0.286, discrete loss: 0.278\n",
            "Epoch:555, step = 4447, CL continuous loss: 0.892, discrete loss: 0.886\n",
            "Epoch:555, step = 4447, Total continuous loss: 0.465, discrete loss: 0.455\n",
            "Time taken: 0.433\n",
            "Time taken: 0.442\n",
            "Time taken: 0.446\n",
            "Time taken: 0.418\n",
            "Time taken: 0.425\n",
            "Time taken: 0.428\n",
            "Time taken: 0.421\n",
            "Time taken: 0.426\n",
            "Epoch:556, step = 4455, diffusion continuous loss: 0.282, discrete loss: 0.334\n",
            "Epoch:556, step = 4455, CL continuous loss: 0.878, discrete loss: 0.905\n",
            "Epoch:556, step = 4455, Total continuous loss: 0.457, discrete loss: 0.516\n",
            "Time taken: 0.415\n",
            "Time taken: 0.530\n",
            "Time taken: 0.424\n",
            "Time taken: 0.424\n",
            "Time taken: 0.426\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.422\n",
            "Epoch:557, step = 4463, diffusion continuous loss: 0.286, discrete loss: 0.304\n",
            "Epoch:557, step = 4463, CL continuous loss: 0.878, discrete loss: 0.863\n",
            "Epoch:557, step = 4463, Total continuous loss: 0.462, discrete loss: 0.477\n",
            "Time taken: 0.417\n",
            "Time taken: 0.427\n",
            "Time taken: 0.421\n",
            "Time taken: 0.427\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.424\n",
            "Time taken: 0.424\n",
            "Epoch:558, step = 4471, diffusion continuous loss: 0.297, discrete loss: 0.244\n",
            "Epoch:558, step = 4471, CL continuous loss: 0.900, discrete loss: 0.861\n",
            "Epoch:558, step = 4471, Total continuous loss: 0.477, discrete loss: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.422\n",
            "Time taken: 0.447\n",
            "Time taken: 0.440\n",
            "Time taken: 0.435\n",
            "Time taken: 0.453\n",
            "Time taken: 0.454\n",
            "Time taken: 0.419\n",
            "Epoch:559, step = 4479, diffusion continuous loss: 0.286, discrete loss: 0.244\n",
            "Epoch:559, step = 4479, CL continuous loss: 0.894, discrete loss: 0.840\n",
            "Epoch:559, step = 4479, Total continuous loss: 0.464, discrete loss: 0.412\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.433\n",
            "Time taken: 0.420\n",
            "Time taken: 0.423\n",
            "Time taken: 0.422\n",
            "Time taken: 0.424\n",
            "Time taken: 0.425\n",
            "Epoch:560, step = 4487, diffusion continuous loss: 0.265, discrete loss: 0.220\n",
            "Epoch:560, step = 4487, CL continuous loss: 0.880, discrete loss: 0.817\n",
            "Epoch:560, step = 4487, Total continuous loss: 0.441, discrete loss: 0.383\n",
            "Time taken: 0.415\n",
            "Time taken: 0.426\n",
            "Time taken: 0.426\n",
            "Time taken: 0.420\n",
            "Time taken: 0.420\n",
            "Time taken: 0.420\n",
            "Time taken: 0.424\n",
            "Time taken: 0.517\n",
            "Epoch:561, step = 4495, diffusion continuous loss: 0.277, discrete loss: 0.219\n",
            "Epoch:561, step = 4495, CL continuous loss: 0.871, discrete loss: 0.818\n",
            "Epoch:561, step = 4495, Total continuous loss: 0.451, discrete loss: 0.383\n",
            "Time taken: 0.417\n",
            "Time taken: 0.427\n",
            "Time taken: 0.421\n",
            "Time taken: 0.423\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.426\n",
            "Time taken: 0.450\n",
            "Epoch:562, step = 4503, diffusion continuous loss: 0.358, discrete loss: 0.226\n",
            "Epoch:562, step = 4503, CL continuous loss: 0.860, discrete loss: 0.808\n",
            "Epoch:562, step = 4503, Total continuous loss: 0.530, discrete loss: 0.388\n",
            "Time taken: 0.434\n",
            "Time taken: 0.437\n",
            "Time taken: 0.456\n",
            "Time taken: 0.452\n",
            "Time taken: 0.419\n",
            "Time taken: 0.424\n",
            "Time taken: 0.418\n",
            "Time taken: 0.433\n",
            "Epoch:563, step = 4511, diffusion continuous loss: 0.301, discrete loss: 0.212\n",
            "Epoch:563, step = 4511, CL continuous loss: 0.929, discrete loss: 0.805\n",
            "Epoch:563, step = 4511, Total continuous loss: 0.487, discrete loss: 0.373\n",
            "Time taken: 0.410\n",
            "Time taken: 0.427\n",
            "Time taken: 0.424\n",
            "Time taken: 0.423\n",
            "Time taken: 0.423\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.421\n",
            "Epoch:564, step = 4519, diffusion continuous loss: 0.297, discrete loss: 0.217\n",
            "Epoch:564, step = 4519, CL continuous loss: 0.896, discrete loss: 0.799\n",
            "Epoch:564, step = 4519, Total continuous loss: 0.476, discrete loss: 0.376\n",
            "Time taken: 0.413\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Time taken: 0.423\n",
            "Time taken: 0.424\n",
            "Time taken: 0.423\n",
            "Epoch:565, step = 4527, diffusion continuous loss: 0.269, discrete loss: 0.224\n",
            "Epoch:565, step = 4527, CL continuous loss: 0.878, discrete loss: 0.806\n",
            "Epoch:565, step = 4527, Total continuous loss: 0.444, discrete loss: 0.385\n",
            "Time taken: 0.419\n",
            "Time taken: 0.422\n",
            "Time taken: 0.419\n",
            "Time taken: 0.424\n",
            "Time taken: 0.448\n",
            "Time taken: 0.445\n",
            "Time taken: 0.566\n",
            "Time taken: 0.457\n",
            "Epoch:566, step = 4535, diffusion continuous loss: 0.274, discrete loss: 0.220\n",
            "Epoch:566, step = 4535, CL continuous loss: 0.880, discrete loss: 0.812\n",
            "Epoch:566, step = 4535, Total continuous loss: 0.450, discrete loss: 0.383\n",
            "Time taken: 0.431\n",
            "Time taken: 0.417\n",
            "Time taken: 0.422\n",
            "Time taken: 0.420\n",
            "Time taken: 0.430\n",
            "Time taken: 0.419\n",
            "Time taken: 0.423\n",
            "Time taken: 0.420\n",
            "Epoch:567, step = 4543, diffusion continuous loss: 0.277, discrete loss: 0.222\n",
            "Epoch:567, step = 4543, CL continuous loss: 0.869, discrete loss: 0.788\n",
            "Epoch:567, step = 4543, Total continuous loss: 0.451, discrete loss: 0.379\n",
            "Time taken: 0.414\n",
            "Time taken: 0.420\n",
            "Time taken: 0.424\n",
            "Time taken: 0.427\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Time taken: 0.419\n",
            "Time taken: 0.422\n",
            "Epoch:568, step = 4551, diffusion continuous loss: 0.288, discrete loss: 0.217\n",
            "Epoch:568, step = 4551, CL continuous loss: 0.916, discrete loss: 0.789\n",
            "Epoch:568, step = 4551, Total continuous loss: 0.471, discrete loss: 0.374\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Time taken: 0.420\n",
            "Time taken: 0.424\n",
            "Time taken: 0.419\n",
            "Time taken: 0.428\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Epoch:569, step = 4559, diffusion continuous loss: 0.284, discrete loss: 0.228\n",
            "Epoch:569, step = 4559, CL continuous loss: 0.873, discrete loss: 0.796\n",
            "Epoch:569, step = 4559, Total continuous loss: 0.458, discrete loss: 0.387\n",
            "Time taken: 0.441\n",
            "Time taken: 0.445\n",
            "Time taken: 0.442\n",
            "Time taken: 0.451\n",
            "Time taken: 0.456\n",
            "Time taken: 0.431\n",
            "Time taken: 0.423\n",
            "Time taken: 0.419\n",
            "Epoch:570, step = 4567, diffusion continuous loss: 0.316, discrete loss: 0.222\n",
            "Epoch:570, step = 4567, CL continuous loss: 0.910, discrete loss: 0.799\n",
            "Epoch:570, step = 4567, Total continuous loss: 0.498, discrete loss: 0.381\n",
            "Time taken: 0.414\n",
            "Time taken: 0.422\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.516\n",
            "Time taken: 0.420\n",
            "Time taken: 0.430\n",
            "Time taken: 0.426\n",
            "Epoch:571, step = 4575, diffusion continuous loss: 0.340, discrete loss: 0.223\n",
            "Epoch:571, step = 4575, CL continuous loss: 0.850, discrete loss: 0.792\n",
            "Epoch:571, step = 4575, Total continuous loss: 0.510, discrete loss: 0.381\n",
            "Time taken: 0.421\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.424\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Epoch:572, step = 4583, diffusion continuous loss: 0.389, discrete loss: 0.224\n",
            "Epoch:572, step = 4583, CL continuous loss: 0.882, discrete loss: 0.798\n",
            "Epoch:572, step = 4583, Total continuous loss: 0.565, discrete loss: 0.383\n",
            "Time taken: 0.412\n",
            "Time taken: 0.423\n",
            "Time taken: 0.424\n",
            "Time taken: 0.423\n",
            "Time taken: 0.421\n",
            "Time taken: 0.445\n",
            "Time taken: 0.447\n",
            "Time taken: 0.460\n",
            "Epoch:573, step = 4591, diffusion continuous loss: 0.330, discrete loss: 0.201\n",
            "Epoch:573, step = 4591, CL continuous loss: 0.926, discrete loss: 0.796\n",
            "Epoch:573, step = 4591, Total continuous loss: 0.515, discrete loss: 0.360\n",
            "Time taken: 0.440\n",
            "Time taken: 0.471\n",
            "Time taken: 0.448\n",
            "Time taken: 0.463\n",
            "Time taken: 0.466\n",
            "Time taken: 0.465\n",
            "Time taken: 0.430\n",
            "Time taken: 0.429\n",
            "Epoch:574, step = 4599, diffusion continuous loss: 0.305, discrete loss: 0.213\n",
            "Epoch:574, step = 4599, CL continuous loss: 0.902, discrete loss: 0.784\n",
            "Epoch:574, step = 4599, Total continuous loss: 0.485, discrete loss: 0.370\n",
            "Time taken: 0.415\n",
            "Time taken: 0.422\n",
            "Time taken: 0.421\n",
            "Time taken: 0.427\n",
            "Time taken: 0.420\n",
            "Time taken: 0.424\n",
            "Time taken: 0.429\n",
            "Time taken: 0.422\n",
            "Epoch:575, step = 4607, diffusion continuous loss: 0.299, discrete loss: 0.219\n",
            "Epoch:575, step = 4607, CL continuous loss: 0.875, discrete loss: 0.785\n",
            "Epoch:575, step = 4607, Total continuous loss: 0.474, discrete loss: 0.376\n",
            "Time taken: 0.412\n",
            "Time taken: 0.420\n",
            "Time taken: 0.427\n",
            "Time taken: 0.521\n",
            "Time taken: 0.423\n",
            "Time taken: 0.425\n",
            "Time taken: 0.421\n",
            "Time taken: 0.422\n",
            "Epoch:576, step = 4615, diffusion continuous loss: 0.284, discrete loss: 0.209\n",
            "Epoch:576, step = 4615, CL continuous loss: 0.872, discrete loss: 0.791\n",
            "Epoch:576, step = 4615, Total continuous loss: 0.458, discrete loss: 0.367\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.423\n",
            "Time taken: 0.419\n",
            "Time taken: 0.434\n",
            "Time taken: 0.446\n",
            "Time taken: 0.448\n",
            "Time taken: 0.442\n",
            "Epoch:577, step = 4623, diffusion continuous loss: 0.349, discrete loss: 0.234\n",
            "Epoch:577, step = 4623, CL continuous loss: 0.891, discrete loss: 0.794\n",
            "Epoch:577, step = 4623, Total continuous loss: 0.527, discrete loss: 0.393\n",
            "Time taken: 0.437\n",
            "Time taken: 0.452\n",
            "Time taken: 0.421\n",
            "Time taken: 0.424\n",
            "Time taken: 0.418\n",
            "Time taken: 0.425\n",
            "Time taken: 0.418\n",
            "Time taken: 0.422\n",
            "Epoch:578, step = 4631, diffusion continuous loss: 0.312, discrete loss: 0.220\n",
            "Epoch:578, step = 4631, CL continuous loss: 0.906, discrete loss: 0.786\n",
            "Epoch:578, step = 4631, Total continuous loss: 0.493, discrete loss: 0.377\n",
            "Time taken: 0.417\n",
            "Time taken: 0.422\n",
            "Time taken: 0.421\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.436\n",
            "Time taken: 0.418\n",
            "Time taken: 0.425\n",
            "Epoch:579, step = 4639, diffusion continuous loss: 0.370, discrete loss: 0.216\n",
            "Epoch:579, step = 4639, CL continuous loss: 0.913, discrete loss: 0.795\n",
            "Epoch:579, step = 4639, Total continuous loss: 0.553, discrete loss: 0.375\n",
            "Time taken: 0.411\n",
            "Time taken: 0.419\n",
            "Time taken: 0.422\n",
            "Time taken: 0.421\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Time taken: 0.425\n",
            "Time taken: 0.420\n",
            "Epoch:580, step = 4647, diffusion continuous loss: 0.298, discrete loss: 0.222\n",
            "Epoch:580, step = 4647, CL continuous loss: 0.891, discrete loss: 0.798\n",
            "Epoch:580, step = 4647, Total continuous loss: 0.476, discrete loss: 0.381\n",
            "Time taken: 0.413\n",
            "Time taken: 0.543\n",
            "Time taken: 0.443\n",
            "Time taken: 0.450\n",
            "Time taken: 0.441\n",
            "Time taken: 0.448\n",
            "Time taken: 0.438\n",
            "Time taken: 0.418\n",
            "Epoch:581, step = 4655, diffusion continuous loss: 0.325, discrete loss: 0.212\n",
            "Epoch:581, step = 4655, CL continuous loss: 0.869, discrete loss: 0.797\n",
            "Epoch:581, step = 4655, Total continuous loss: 0.499, discrete loss: 0.371\n",
            "Time taken: 0.418\n",
            "Time taken: 0.423\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.422\n",
            "Time taken: 0.424\n",
            "Time taken: 0.423\n",
            "Time taken: 0.421\n",
            "Epoch:582, step = 4663, diffusion continuous loss: 0.292, discrete loss: 0.215\n",
            "Epoch:582, step = 4663, CL continuous loss: 0.898, discrete loss: 0.794\n",
            "Epoch:582, step = 4663, Total continuous loss: 0.471, discrete loss: 0.374\n",
            "Time taken: 0.413\n",
            "Time taken: 0.421\n",
            "Time taken: 0.423\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.423\n",
            "Time taken: 0.421\n",
            "Time taken: 0.430\n",
            "Epoch:583, step = 4671, diffusion continuous loss: 0.291, discrete loss: 0.212\n",
            "Epoch:583, step = 4671, CL continuous loss: 0.891, discrete loss: 0.778\n",
            "Epoch:583, step = 4671, Total continuous loss: 0.469, discrete loss: 0.368\n",
            "Time taken: 0.415\n",
            "Time taken: 0.425\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.424\n",
            "Time taken: 0.425\n",
            "Time taken: 0.451\n",
            "Time taken: 0.442\n",
            "Epoch:584, step = 4679, diffusion continuous loss: 0.285, discrete loss: 0.216\n",
            "Epoch:584, step = 4679, CL continuous loss: 0.892, discrete loss: 0.787\n",
            "Epoch:584, step = 4679, Total continuous loss: 0.463, discrete loss: 0.374\n",
            "Time taken: 0.430\n",
            "Time taken: 0.441\n",
            "Time taken: 0.449\n",
            "Time taken: 0.432\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.420\n",
            "Time taken: 0.421\n",
            "Epoch:585, step = 4687, diffusion continuous loss: 0.292, discrete loss: 0.248\n",
            "Epoch:585, step = 4687, CL continuous loss: 0.879, discrete loss: 0.842\n",
            "Epoch:585, step = 4687, Total continuous loss: 0.468, discrete loss: 0.417\n",
            "Time taken: 0.514\n",
            "Time taken: 0.416\n",
            "Time taken: 0.425\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.422\n",
            "Time taken: 0.418\n",
            "Time taken: 0.427\n",
            "Epoch:586, step = 4695, diffusion continuous loss: 0.344, discrete loss: 0.229\n",
            "Epoch:586, step = 4695, CL continuous loss: 0.878, discrete loss: 0.829\n",
            "Epoch:586, step = 4695, Total continuous loss: 0.519, discrete loss: 0.395\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Time taken: 0.419\n",
            "Time taken: 0.424\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.420\n",
            "Epoch:587, step = 4703, diffusion continuous loss: 0.311, discrete loss: 0.231\n",
            "Epoch:587, step = 4703, CL continuous loss: 0.920, discrete loss: 0.825\n",
            "Epoch:587, step = 4703, Total continuous loss: 0.495, discrete loss: 0.396\n",
            "Time taken: 0.414\n",
            "Time taken: 0.429\n",
            "Time taken: 0.421\n",
            "Time taken: 0.441\n",
            "Time taken: 0.442\n",
            "Time taken: 0.441\n",
            "Time taken: 0.449\n",
            "Time taken: 0.448\n",
            "Epoch:588, step = 4711, diffusion continuous loss: 0.275, discrete loss: 0.233\n",
            "Epoch:588, step = 4711, CL continuous loss: 0.905, discrete loss: 0.817\n",
            "Epoch:588, step = 4711, Total continuous loss: 0.456, discrete loss: 0.396\n",
            "Time taken: 0.412\n",
            "Time taken: 0.417\n",
            "Time taken: 0.422\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.424\n",
            "Time taken: 0.422\n",
            "Time taken: 0.422\n",
            "Epoch:589, step = 4719, diffusion continuous loss: 0.283, discrete loss: 0.223\n",
            "Epoch:589, step = 4719, CL continuous loss: 0.889, discrete loss: 0.814\n",
            "Epoch:589, step = 4719, Total continuous loss: 0.461, discrete loss: 0.386\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Time taken: 0.424\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.518\n",
            "Time taken: 0.419\n",
            "Epoch:590, step = 4727, diffusion continuous loss: 0.286, discrete loss: 0.225\n",
            "Epoch:590, step = 4727, CL continuous loss: 0.908, discrete loss: 0.805\n",
            "Epoch:590, step = 4727, Total continuous loss: 0.467, discrete loss: 0.386\n",
            "Time taken: 0.411\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.422\n",
            "Time taken: 0.422\n",
            "Time taken: 0.424\n",
            "Time taken: 0.422\n",
            "Epoch:591, step = 4735, diffusion continuous loss: 0.284, discrete loss: 0.244\n",
            "Epoch:591, step = 4735, CL continuous loss: 0.898, discrete loss: 0.827\n",
            "Epoch:591, step = 4735, Total continuous loss: 0.464, discrete loss: 0.409\n",
            "Time taken: 0.435\n",
            "Time taken: 0.449\n",
            "Time taken: 0.441\n",
            "Time taken: 0.461\n",
            "Time taken: 0.445\n",
            "Time taken: 0.419\n",
            "Time taken: 0.422\n",
            "Time taken: 0.421\n",
            "Epoch:592, step = 4743, diffusion continuous loss: 0.285, discrete loss: 0.222\n",
            "Epoch:592, step = 4743, CL continuous loss: 0.875, discrete loss: 0.819\n",
            "Epoch:592, step = 4743, Total continuous loss: 0.460, discrete loss: 0.386\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.422\n",
            "Time taken: 0.422\n",
            "Time taken: 0.421\n",
            "Epoch:593, step = 4751, diffusion continuous loss: 0.283, discrete loss: 0.232\n",
            "Epoch:593, step = 4751, CL continuous loss: 0.880, discrete loss: 0.786\n",
            "Epoch:593, step = 4751, Total continuous loss: 0.459, discrete loss: 0.390\n",
            "Time taken: 0.410\n",
            "Time taken: 0.425\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.423\n",
            "Time taken: 0.421\n",
            "Time taken: 0.419\n",
            "Epoch:594, step = 4759, diffusion continuous loss: 0.274, discrete loss: 0.224\n",
            "Epoch:594, step = 4759, CL continuous loss: 0.870, discrete loss: 0.814\n",
            "Epoch:594, step = 4759, Total continuous loss: 0.448, discrete loss: 0.387\n",
            "Time taken: 0.408\n",
            "Time taken: 0.424\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.431\n",
            "Time taken: 0.570\n",
            "Time taken: 0.440\n",
            "Time taken: 0.441\n",
            "Epoch:595, step = 4767, diffusion continuous loss: 0.283, discrete loss: 0.227\n",
            "Epoch:595, step = 4767, CL continuous loss: 0.880, discrete loss: 0.804\n",
            "Epoch:595, step = 4767, Total continuous loss: 0.459, discrete loss: 0.388\n",
            "Time taken: 0.446\n",
            "Time taken: 0.438\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Time taken: 0.421\n",
            "Epoch:596, step = 4775, diffusion continuous loss: 0.289, discrete loss: 0.221\n",
            "Epoch:596, step = 4775, CL continuous loss: 0.870, discrete loss: 0.805\n",
            "Epoch:596, step = 4775, Total continuous loss: 0.463, discrete loss: 0.382\n",
            "Time taken: 0.409\n",
            "Time taken: 0.423\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.424\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Epoch:597, step = 4783, diffusion continuous loss: 0.274, discrete loss: 0.218\n",
            "Epoch:597, step = 4783, CL continuous loss: 0.882, discrete loss: 0.804\n",
            "Epoch:597, step = 4783, Total continuous loss: 0.451, discrete loss: 0.379\n",
            "Time taken: 0.413\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.426\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.426\n",
            "Time taken: 0.422\n",
            "Epoch:598, step = 4791, diffusion continuous loss: 0.355, discrete loss: 0.214\n",
            "Epoch:598, step = 4791, CL continuous loss: 0.903, discrete loss: 0.807\n",
            "Epoch:598, step = 4791, Total continuous loss: 0.536, discrete loss: 0.375\n",
            "Time taken: 0.417\n",
            "Time taken: 0.430\n",
            "Time taken: 0.438\n",
            "Time taken: 0.447\n",
            "Time taken: 0.443\n",
            "Time taken: 0.447\n",
            "Time taken: 0.426\n",
            "Time taken: 0.419\n",
            "Epoch:599, step = 4799, diffusion continuous loss: 0.332, discrete loss: 0.219\n",
            "Epoch:599, step = 4799, CL continuous loss: 0.892, discrete loss: 0.799\n",
            "Epoch:599, step = 4799, Total continuous loss: 0.510, discrete loss: 0.379\n",
            "Time taken: 0.555\n",
            "Time taken: 0.446\n",
            "Time taken: 0.418\n",
            "Time taken: 0.423\n",
            "Time taken: 0.523\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Epoch:600, step = 4807, diffusion continuous loss: 0.301, discrete loss: 0.214\n",
            "Epoch:600, step = 4807, CL continuous loss: 0.883, discrete loss: 0.779\n",
            "Epoch:600, step = 4807, Total continuous loss: 0.478, discrete loss: 0.370\n",
            "Time taken: 0.414\n",
            "Time taken: 0.433\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.428\n",
            "Time taken: 0.419\n",
            "Epoch:601, step = 4815, diffusion continuous loss: 0.288, discrete loss: 0.231\n",
            "Epoch:601, step = 4815, CL continuous loss: 0.896, discrete loss: 0.802\n",
            "Epoch:601, step = 4815, Total continuous loss: 0.467, discrete loss: 0.391\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.426\n",
            "Time taken: 0.437\n",
            "Time taken: 0.440\n",
            "Epoch:602, step = 4823, diffusion continuous loss: 0.304, discrete loss: 0.231\n",
            "Epoch:602, step = 4823, CL continuous loss: 0.893, discrete loss: 0.803\n",
            "Epoch:602, step = 4823, Total continuous loss: 0.482, discrete loss: 0.392\n",
            "Time taken: 0.427\n",
            "Time taken: 0.443\n",
            "Time taken: 0.443\n",
            "Time taken: 0.415\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Epoch:603, step = 4831, diffusion continuous loss: 0.307, discrete loss: 0.224\n",
            "Epoch:603, step = 4831, CL continuous loss: 0.869, discrete loss: 0.797\n",
            "Epoch:603, step = 4831, Total continuous loss: 0.480, discrete loss: 0.384\n",
            "Time taken: 0.410\n",
            "Time taken: 0.423\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Time taken: 0.429\n",
            "Time taken: 0.420\n",
            "Time taken: 0.429\n",
            "Time taken: 0.421\n",
            "Epoch:604, step = 4839, diffusion continuous loss: 0.277, discrete loss: 0.210\n",
            "Epoch:604, step = 4839, CL continuous loss: 0.867, discrete loss: 0.797\n",
            "Epoch:604, step = 4839, Total continuous loss: 0.451, discrete loss: 0.369\n",
            "Time taken: 0.411\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.519\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Epoch:605, step = 4847, diffusion continuous loss: 0.313, discrete loss: 0.213\n",
            "Epoch:605, step = 4847, CL continuous loss: 0.903, discrete loss: 0.791\n",
            "Epoch:605, step = 4847, Total continuous loss: 0.493, discrete loss: 0.372\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.444\n",
            "Time taken: 0.433\n",
            "Time taken: 0.435\n",
            "Time taken: 0.449\n",
            "Time taken: 0.449\n",
            "Time taken: 0.425\n",
            "Epoch:606, step = 4855, diffusion continuous loss: 0.294, discrete loss: 0.208\n",
            "Epoch:606, step = 4855, CL continuous loss: 0.874, discrete loss: 0.796\n",
            "Epoch:606, step = 4855, Total continuous loss: 0.469, discrete loss: 0.368\n",
            "Time taken: 0.412\n",
            "Time taken: 0.422\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.425\n",
            "Time taken: 0.423\n",
            "Time taken: 0.420\n",
            "Epoch:607, step = 4863, diffusion continuous loss: 0.290, discrete loss: 0.222\n",
            "Epoch:607, step = 4863, CL continuous loss: 0.924, discrete loss: 0.796\n",
            "Epoch:607, step = 4863, Total continuous loss: 0.474, discrete loss: 0.381\n",
            "Time taken: 0.410\n",
            "Time taken: 0.424\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Epoch:608, step = 4871, diffusion continuous loss: 0.279, discrete loss: 0.228\n",
            "Epoch:608, step = 4871, CL continuous loss: 0.894, discrete loss: 0.810\n",
            "Epoch:608, step = 4871, Total continuous loss: 0.458, discrete loss: 0.390\n",
            "Time taken: 0.419\n",
            "Time taken: 0.414\n",
            "Time taken: 0.422\n",
            "Time taken: 0.424\n",
            "Time taken: 0.423\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.448\n",
            "Epoch:609, step = 4879, diffusion continuous loss: 0.298, discrete loss: 0.214\n",
            "Epoch:609, step = 4879, CL continuous loss: 0.897, discrete loss: 0.799\n",
            "Epoch:609, step = 4879, Total continuous loss: 0.477, discrete loss: 0.374\n",
            "Time taken: 0.439\n",
            "Time taken: 0.436\n",
            "Time taken: 0.452\n",
            "Time taken: 0.447\n",
            "Time taken: 0.517\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.425\n",
            "Epoch:610, step = 4887, diffusion continuous loss: 0.322, discrete loss: 0.217\n",
            "Epoch:610, step = 4887, CL continuous loss: 0.894, discrete loss: 0.799\n",
            "Epoch:610, step = 4887, Total continuous loss: 0.500, discrete loss: 0.376\n",
            "Time taken: 0.405\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.431\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Epoch:611, step = 4895, diffusion continuous loss: 0.297, discrete loss: 0.220\n",
            "Epoch:611, step = 4895, CL continuous loss: 0.892, discrete loss: 0.794\n",
            "Epoch:611, step = 4895, Total continuous loss: 0.475, discrete loss: 0.379\n",
            "Time taken: 0.411\n",
            "Time taken: 0.418\n",
            "Time taken: 0.422\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.411\n",
            "Time taken: 0.422\n",
            "Epoch:612, step = 4903, diffusion continuous loss: 0.294, discrete loss: 0.219\n",
            "Epoch:612, step = 4903, CL continuous loss: 0.887, discrete loss: 0.800\n",
            "Epoch:612, step = 4903, Total continuous loss: 0.471, discrete loss: 0.379\n",
            "Time taken: 0.412\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.442\n",
            "Time taken: 0.439\n",
            "Time taken: 0.439\n",
            "Time taken: 0.441\n",
            "Epoch:613, step = 4911, diffusion continuous loss: 0.275, discrete loss: 0.231\n",
            "Epoch:613, step = 4911, CL continuous loss: 0.885, discrete loss: 0.803\n",
            "Epoch:613, step = 4911, Total continuous loss: 0.452, discrete loss: 0.392\n",
            "Time taken: 0.441\n",
            "Time taken: 0.418\n",
            "Time taken: 0.422\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Time taken: 0.428\n",
            "Epoch:614, step = 4919, diffusion continuous loss: 0.275, discrete loss: 0.215\n",
            "Epoch:614, step = 4919, CL continuous loss: 0.888, discrete loss: 0.797\n",
            "Epoch:614, step = 4919, Total continuous loss: 0.452, discrete loss: 0.375\n",
            "Time taken: 0.411\n",
            "Time taken: 0.418\n",
            "Time taken: 0.523\n",
            "Time taken: 0.422\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Epoch:615, step = 4927, diffusion continuous loss: 0.310, discrete loss: 0.217\n",
            "Epoch:615, step = 4927, CL continuous loss: 0.853, discrete loss: 0.778\n",
            "Epoch:615, step = 4927, Total continuous loss: 0.481, discrete loss: 0.373\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.419\n",
            "Time taken: 0.422\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Epoch:616, step = 4935, diffusion continuous loss: 0.305, discrete loss: 0.216\n",
            "Epoch:616, step = 4935, CL continuous loss: 0.895, discrete loss: 0.796\n",
            "Epoch:616, step = 4935, Total continuous loss: 0.484, discrete loss: 0.375\n",
            "Time taken: 0.419\n",
            "Time taken: 0.456\n",
            "Time taken: 0.439\n",
            "Time taken: 0.434\n",
            "Time taken: 0.448\n",
            "Time taken: 0.460\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Epoch:617, step = 4943, diffusion continuous loss: 0.294, discrete loss: 0.212\n",
            "Epoch:617, step = 4943, CL continuous loss: 0.889, discrete loss: 0.803\n",
            "Epoch:617, step = 4943, Total continuous loss: 0.472, discrete loss: 0.373\n",
            "Time taken: 0.410\n",
            "Time taken: 0.415\n",
            "Time taken: 0.421\n",
            "Time taken: 0.422\n",
            "Time taken: 0.422\n",
            "Time taken: 0.418\n",
            "Time taken: 0.426\n",
            "Time taken: 0.416\n",
            "Epoch:618, step = 4951, diffusion continuous loss: 0.294, discrete loss: 0.218\n",
            "Epoch:618, step = 4951, CL continuous loss: 0.880, discrete loss: 0.801\n",
            "Epoch:618, step = 4951, Total continuous loss: 0.470, discrete loss: 0.378\n",
            "Time taken: 0.407\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.413\n",
            "Time taken: 0.423\n",
            "Time taken: 0.422\n",
            "Time taken: 0.421\n",
            "Epoch:619, step = 4959, diffusion continuous loss: 0.324, discrete loss: 0.222\n",
            "Epoch:619, step = 4959, CL continuous loss: 0.906, discrete loss: 0.785\n",
            "Epoch:619, step = 4959, Total continuous loss: 0.505, discrete loss: 0.379\n",
            "Time taken: 0.425\n",
            "Time taken: 0.515\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.426\n",
            "Time taken: 0.441\n",
            "Time taken: 0.441\n",
            "Epoch:620, step = 4967, diffusion continuous loss: 0.309, discrete loss: 0.223\n",
            "Epoch:620, step = 4967, CL continuous loss: 0.880, discrete loss: 0.794\n",
            "Epoch:620, step = 4967, Total continuous loss: 0.485, discrete loss: 0.382\n",
            "Time taken: 0.432\n",
            "Time taken: 0.441\n",
            "Time taken: 0.450\n",
            "Time taken: 0.413\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.432\n",
            "Epoch:621, step = 4975, diffusion continuous loss: 0.284, discrete loss: 0.218\n",
            "Epoch:621, step = 4975, CL continuous loss: 0.892, discrete loss: 0.799\n",
            "Epoch:621, step = 4975, Total continuous loss: 0.462, discrete loss: 0.378\n",
            "Time taken: 0.412\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.424\n",
            "Time taken: 0.425\n",
            "Time taken: 0.423\n",
            "Epoch:622, step = 4983, diffusion continuous loss: 0.405, discrete loss: 0.216\n",
            "Epoch:622, step = 4983, CL continuous loss: 0.892, discrete loss: 0.791\n",
            "Epoch:622, step = 4983, Total continuous loss: 0.583, discrete loss: 0.374\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.422\n",
            "Time taken: 0.423\n",
            "Time taken: 0.416\n",
            "Epoch:623, step = 4991, diffusion continuous loss: 0.384, discrete loss: 0.215\n",
            "Epoch:623, step = 4991, CL continuous loss: 0.879, discrete loss: 0.784\n",
            "Epoch:623, step = 4991, Total continuous loss: 0.560, discrete loss: 0.372\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.427\n",
            "Time taken: 0.438\n",
            "Time taken: 0.437\n",
            "Time taken: 0.447\n",
            "Time taken: 0.447\n",
            "Time taken: 0.584\n",
            "Epoch:624, step = 4999, diffusion continuous loss: 0.322, discrete loss: 0.222\n",
            "Epoch:624, step = 4999, CL continuous loss: 0.885, discrete loss: 0.788\n",
            "Epoch:624, step = 4999, Total continuous loss: 0.499, discrete loss: 0.380\n",
            "Time taken: 0.413\n",
            "Time taken: 0.422\n",
            "Time taken: 0.422\n",
            "Time taken: 0.422\n",
            "Time taken: 0.425\n",
            "Time taken: 0.425\n",
            "Time taken: 0.422\n",
            "Time taken: 0.417\n",
            "Epoch:625, step = 5007, diffusion continuous loss: 0.312, discrete loss: 0.207\n",
            "Epoch:625, step = 5007, CL continuous loss: 0.893, discrete loss: 0.786\n",
            "Epoch:625, step = 5007, Total continuous loss: 0.491, discrete loss: 0.365\n",
            "Time taken: 0.415\n",
            "Time taken: 0.424\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Time taken: 0.421\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Epoch:626, step = 5015, diffusion continuous loss: 0.287, discrete loss: 0.209\n",
            "Epoch:626, step = 5015, CL continuous loss: 0.888, discrete loss: 0.797\n",
            "Epoch:626, step = 5015, Total continuous loss: 0.465, discrete loss: 0.368\n",
            "Time taken: 0.413\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.413\n",
            "Time taken: 0.420\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.447\n",
            "Epoch:627, step = 5023, diffusion continuous loss: 0.314, discrete loss: 0.229\n",
            "Epoch:627, step = 5023, CL continuous loss: 0.890, discrete loss: 0.788\n",
            "Epoch:627, step = 5023, Total continuous loss: 0.492, discrete loss: 0.387\n",
            "Time taken: 0.428\n",
            "Time taken: 0.437\n",
            "Time taken: 0.442\n",
            "Time taken: 0.453\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.429\n",
            "Time taken: 0.427\n",
            "Epoch:628, step = 5031, diffusion continuous loss: 0.284, discrete loss: 0.219\n",
            "Epoch:628, step = 5031, CL continuous loss: 0.901, discrete loss: 0.792\n",
            "Epoch:628, step = 5031, Total continuous loss: 0.464, discrete loss: 0.378\n",
            "Time taken: 0.415\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.518\n",
            "Time taken: 0.420\n",
            "Epoch:629, step = 5039, diffusion continuous loss: 0.281, discrete loss: 0.208\n",
            "Epoch:629, step = 5039, CL continuous loss: 0.880, discrete loss: 0.789\n",
            "Epoch:629, step = 5039, Total continuous loss: 0.457, discrete loss: 0.365\n",
            "Time taken: 0.414\n",
            "Time taken: 0.421\n",
            "Time taken: 0.421\n",
            "Time taken: 0.426\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Epoch:630, step = 5047, diffusion continuous loss: 0.305, discrete loss: 0.225\n",
            "Epoch:630, step = 5047, CL continuous loss: 0.865, discrete loss: 0.796\n",
            "Epoch:630, step = 5047, Total continuous loss: 0.478, discrete loss: 0.384\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.425\n",
            "Time taken: 0.423\n",
            "Time taken: 0.440\n",
            "Time taken: 0.436\n",
            "Time taken: 0.438\n",
            "Time taken: 0.451\n",
            "Epoch:631, step = 5055, diffusion continuous loss: 0.285, discrete loss: 0.217\n",
            "Epoch:631, step = 5055, CL continuous loss: 0.886, discrete loss: 0.788\n",
            "Epoch:631, step = 5055, Total continuous loss: 0.462, discrete loss: 0.375\n",
            "Time taken: 0.443\n",
            "Time taken: 0.421\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.423\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Epoch:632, step = 5063, diffusion continuous loss: 0.273, discrete loss: 0.220\n",
            "Epoch:632, step = 5063, CL continuous loss: 0.877, discrete loss: 0.785\n",
            "Epoch:632, step = 5063, Total continuous loss: 0.449, discrete loss: 0.378\n",
            "Time taken: 0.413\n",
            "Time taken: 0.428\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.423\n",
            "Time taken: 0.419\n",
            "Epoch:633, step = 5071, diffusion continuous loss: 0.378, discrete loss: 0.215\n",
            "Epoch:633, step = 5071, CL continuous loss: 0.929, discrete loss: 0.783\n",
            "Epoch:633, step = 5071, Total continuous loss: 0.564, discrete loss: 0.372\n",
            "Time taken: 0.412\n",
            "Time taken: 0.419\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Time taken: 0.513\n",
            "Time taken: 0.420\n",
            "Time taken: 0.424\n",
            "Time taken: 0.424\n",
            "Epoch:634, step = 5079, diffusion continuous loss: 0.339, discrete loss: 0.218\n",
            "Epoch:634, step = 5079, CL continuous loss: 0.923, discrete loss: 0.798\n",
            "Epoch:634, step = 5079, Total continuous loss: 0.524, discrete loss: 0.378\n",
            "Time taken: 0.412\n",
            "Time taken: 0.447\n",
            "Time taken: 0.445\n",
            "Time taken: 0.434\n",
            "Time taken: 0.444\n",
            "Time taken: 0.452\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Epoch:635, step = 5087, diffusion continuous loss: 0.296, discrete loss: 0.212\n",
            "Epoch:635, step = 5087, CL continuous loss: 0.901, discrete loss: 0.823\n",
            "Epoch:635, step = 5087, Total continuous loss: 0.476, discrete loss: 0.377\n",
            "Time taken: 0.413\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.414\n",
            "Epoch:636, step = 5095, diffusion continuous loss: 0.289, discrete loss: 0.221\n",
            "Epoch:636, step = 5095, CL continuous loss: 0.882, discrete loss: 0.798\n",
            "Epoch:636, step = 5095, Total continuous loss: 0.466, discrete loss: 0.380\n",
            "Time taken: 0.413\n",
            "Time taken: 0.418\n",
            "Time taken: 0.423\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.414\n",
            "Epoch:637, step = 5103, diffusion continuous loss: 0.291, discrete loss: 0.209\n",
            "Epoch:637, step = 5103, CL continuous loss: 0.871, discrete loss: 0.787\n",
            "Epoch:637, step = 5103, Total continuous loss: 0.465, discrete loss: 0.366\n",
            "Time taken: 0.413\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.436\n",
            "Time taken: 0.435\n",
            "Epoch:638, step = 5111, diffusion continuous loss: 0.269, discrete loss: 0.215\n",
            "Epoch:638, step = 5111, CL continuous loss: 0.887, discrete loss: 0.787\n",
            "Epoch:638, step = 5111, Total continuous loss: 0.446, discrete loss: 0.373\n",
            "Time taken: 0.430\n",
            "Time taken: 0.443\n",
            "Time taken: 0.451\n",
            "Time taken: 0.509\n",
            "Time taken: 0.425\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Epoch:639, step = 5119, diffusion continuous loss: 0.318, discrete loss: 0.212\n",
            "Epoch:639, step = 5119, CL continuous loss: 0.908, discrete loss: 0.782\n",
            "Epoch:639, step = 5119, Total continuous loss: 0.499, discrete loss: 0.369\n",
            "Time taken: 0.413\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.424\n",
            "Epoch:640, step = 5127, diffusion continuous loss: 0.341, discrete loss: 0.217\n",
            "Epoch:640, step = 5127, CL continuous loss: 0.917, discrete loss: 0.790\n",
            "Epoch:640, step = 5127, Total continuous loss: 0.525, discrete loss: 0.375\n",
            "Time taken: 0.411\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.430\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Epoch:641, step = 5135, diffusion continuous loss: 0.353, discrete loss: 0.211\n",
            "Epoch:641, step = 5135, CL continuous loss: 0.903, discrete loss: 0.789\n",
            "Epoch:641, step = 5135, Total continuous loss: 0.533, discrete loss: 0.369\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.421\n",
            "Time taken: 0.440\n",
            "Time taken: 0.442\n",
            "Time taken: 0.440\n",
            "Time taken: 0.451\n",
            "Time taken: 0.456\n",
            "Epoch:642, step = 5143, diffusion continuous loss: 0.296, discrete loss: 0.211\n",
            "Epoch:642, step = 5143, CL continuous loss: 0.905, discrete loss: 0.795\n",
            "Epoch:642, step = 5143, Total continuous loss: 0.477, discrete loss: 0.370\n",
            "Time taken: 0.409\n",
            "Time taken: 0.427\n",
            "Time taken: 0.420\n",
            "Time taken: 0.421\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Epoch:643, step = 5151, diffusion continuous loss: 0.304, discrete loss: 0.215\n",
            "Epoch:643, step = 5151, CL continuous loss: 0.886, discrete loss: 0.784\n",
            "Epoch:643, step = 5151, Total continuous loss: 0.481, discrete loss: 0.372\n",
            "Time taken: 0.411\n",
            "Time taken: 0.529\n",
            "Time taken: 0.417\n",
            "Time taken: 0.425\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Epoch:644, step = 5159, diffusion continuous loss: 0.287, discrete loss: 0.222\n",
            "Epoch:644, step = 5159, CL continuous loss: 0.874, discrete loss: 0.777\n",
            "Epoch:644, step = 5159, Total continuous loss: 0.462, discrete loss: 0.377\n",
            "Time taken: 0.412\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Time taken: 0.409\n",
            "Time taken: 0.417\n",
            "Time taken: 0.428\n",
            "Time taken: 0.417\n",
            "Time taken: 0.428\n",
            "Epoch:645, step = 5167, diffusion continuous loss: 0.283, discrete loss: 0.223\n",
            "Epoch:645, step = 5167, CL continuous loss: 0.893, discrete loss: 0.791\n",
            "Epoch:645, step = 5167, Total continuous loss: 0.461, discrete loss: 0.381\n",
            "Time taken: 0.440\n",
            "Time taken: 0.440\n",
            "Time taken: 0.453\n",
            "Time taken: 0.448\n",
            "Time taken: 0.455\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.423\n",
            "Epoch:646, step = 5175, diffusion continuous loss: 0.269, discrete loss: 0.214\n",
            "Epoch:646, step = 5175, CL continuous loss: 0.887, discrete loss: 0.790\n",
            "Epoch:646, step = 5175, Total continuous loss: 0.446, discrete loss: 0.372\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Epoch:647, step = 5183, diffusion continuous loss: 0.270, discrete loss: 0.228\n",
            "Epoch:647, step = 5183, CL continuous loss: 0.873, discrete loss: 0.797\n",
            "Epoch:647, step = 5183, Total continuous loss: 0.445, discrete loss: 0.387\n",
            "Time taken: 0.411\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.422\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Epoch:648, step = 5191, diffusion continuous loss: 0.287, discrete loss: 0.214\n",
            "Epoch:648, step = 5191, CL continuous loss: 0.872, discrete loss: 0.795\n",
            "Epoch:648, step = 5191, Total continuous loss: 0.461, discrete loss: 0.373\n",
            "Time taken: 0.517\n",
            "Time taken: 0.415\n",
            "Time taken: 0.427\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Time taken: 0.442\n",
            "Time taken: 0.442\n",
            "Time taken: 0.442\n",
            "Epoch:649, step = 5199, diffusion continuous loss: 0.275, discrete loss: 0.214\n",
            "Epoch:649, step = 5199, CL continuous loss: 0.875, discrete loss: 0.789\n",
            "Epoch:649, step = 5199, Total continuous loss: 0.450, discrete loss: 0.371\n",
            "Time taken: 0.432\n",
            "Time taken: 0.452\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.413\n",
            "Time taken: 0.423\n",
            "Time taken: 0.419\n",
            "Epoch:650, step = 5207, diffusion continuous loss: 0.292, discrete loss: 0.215\n",
            "Epoch:650, step = 5207, CL continuous loss: 0.874, discrete loss: 0.789\n",
            "Epoch:650, step = 5207, Total continuous loss: 0.467, discrete loss: 0.372\n",
            "Time taken: 0.410\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Time taken: 0.413\n",
            "Time taken: 0.422\n",
            "Time taken: 0.415\n",
            "Epoch:651, step = 5215, diffusion continuous loss: 0.364, discrete loss: 0.225\n",
            "Epoch:651, step = 5215, CL continuous loss: 0.919, discrete loss: 0.793\n",
            "Epoch:651, step = 5215, Total continuous loss: 0.548, discrete loss: 0.383\n",
            "Time taken: 0.409\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Epoch:652, step = 5223, diffusion continuous loss: 0.303, discrete loss: 0.228\n",
            "Epoch:652, step = 5223, CL continuous loss: 0.900, discrete loss: 0.789\n",
            "Epoch:652, step = 5223, Total continuous loss: 0.483, discrete loss: 0.385\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.446\n",
            "Time taken: 0.444\n",
            "Time taken: 0.437\n",
            "Time taken: 0.449\n",
            "Time taken: 0.580\n",
            "Time taken: 0.427\n",
            "Epoch:653, step = 5231, diffusion continuous loss: 0.289, discrete loss: 0.214\n",
            "Epoch:653, step = 5231, CL continuous loss: 0.895, discrete loss: 0.791\n",
            "Epoch:653, step = 5231, Total continuous loss: 0.468, discrete loss: 0.372\n",
            "Time taken: 0.409\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.422\n",
            "Time taken: 0.422\n",
            "Epoch:654, step = 5239, diffusion continuous loss: 0.293, discrete loss: 0.217\n",
            "Epoch:654, step = 5239, CL continuous loss: 0.883, discrete loss: 0.800\n",
            "Epoch:654, step = 5239, Total continuous loss: 0.470, discrete loss: 0.377\n",
            "Time taken: 0.409\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.423\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Epoch:655, step = 5247, diffusion continuous loss: 0.308, discrete loss: 0.220\n",
            "Epoch:655, step = 5247, CL continuous loss: 0.899, discrete loss: 0.789\n",
            "Epoch:655, step = 5247, Total continuous loss: 0.488, discrete loss: 0.377\n",
            "Time taken: 0.414\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.427\n",
            "Time taken: 0.440\n",
            "Epoch:656, step = 5255, diffusion continuous loss: 0.294, discrete loss: 0.218\n",
            "Epoch:656, step = 5255, CL continuous loss: 0.883, discrete loss: 0.778\n",
            "Epoch:656, step = 5255, Total continuous loss: 0.471, discrete loss: 0.374\n",
            "Time taken: 0.428\n",
            "Time taken: 0.437\n",
            "Time taken: 0.453\n",
            "Time taken: 0.438\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.429\n",
            "Epoch:657, step = 5263, diffusion continuous loss: 0.296, discrete loss: 0.215\n",
            "Epoch:657, step = 5263, CL continuous loss: 0.863, discrete loss: 0.788\n",
            "Epoch:657, step = 5263, Total continuous loss: 0.469, discrete loss: 0.373\n",
            "Time taken: 0.406\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.525\n",
            "Time taken: 0.420\n",
            "Time taken: 0.415\n",
            "Epoch:658, step = 5271, diffusion continuous loss: 0.272, discrete loss: 0.214\n",
            "Epoch:658, step = 5271, CL continuous loss: 0.871, discrete loss: 0.793\n",
            "Epoch:658, step = 5271, Total continuous loss: 0.446, discrete loss: 0.373\n",
            "Time taken: 0.413\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.422\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.413\n",
            "Time taken: 0.426\n",
            "Epoch:659, step = 5279, diffusion continuous loss: 0.273, discrete loss: 0.222\n",
            "Epoch:659, step = 5279, CL continuous loss: 0.891, discrete loss: 0.782\n",
            "Epoch:659, step = 5279, Total continuous loss: 0.451, discrete loss: 0.378\n",
            "Time taken: 0.429\n",
            "Time taken: 0.436\n",
            "Time taken: 0.438\n",
            "Time taken: 0.467\n",
            "Time taken: 0.460\n",
            "Time taken: 0.498\n",
            "Time taken: 0.435\n",
            "Time taken: 0.446\n",
            "Epoch:660, step = 5287, diffusion continuous loss: 0.301, discrete loss: 0.224\n",
            "Epoch:660, step = 5287, CL continuous loss: 0.879, discrete loss: 0.795\n",
            "Epoch:660, step = 5287, Total continuous loss: 0.477, discrete loss: 0.383\n",
            "Time taken: 0.441\n",
            "Time taken: 0.418\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Time taken: 0.423\n",
            "Time taken: 0.420\n",
            "Epoch:661, step = 5295, diffusion continuous loss: 0.289, discrete loss: 0.216\n",
            "Epoch:661, step = 5295, CL continuous loss: 0.862, discrete loss: 0.788\n",
            "Epoch:661, step = 5295, Total continuous loss: 0.462, discrete loss: 0.374\n",
            "Time taken: 0.402\n",
            "Time taken: 0.422\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Epoch:662, step = 5303, diffusion continuous loss: 0.347, discrete loss: 0.223\n",
            "Epoch:662, step = 5303, CL continuous loss: 0.903, discrete loss: 0.793\n",
            "Epoch:662, step = 5303, Total continuous loss: 0.528, discrete loss: 0.381\n",
            "Time taken: 0.406\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.526\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Epoch:663, step = 5311, diffusion continuous loss: 0.273, discrete loss: 0.210\n",
            "Epoch:663, step = 5311, CL continuous loss: 0.904, discrete loss: 0.795\n",
            "Epoch:663, step = 5311, Total continuous loss: 0.454, discrete loss: 0.369\n",
            "Time taken: 0.406\n",
            "Time taken: 0.447\n",
            "Time taken: 0.442\n",
            "Time taken: 0.433\n",
            "Time taken: 0.453\n",
            "Time taken: 0.444\n",
            "Time taken: 0.417\n",
            "Time taken: 0.428\n",
            "Epoch:664, step = 5319, diffusion continuous loss: 0.304, discrete loss: 0.228\n",
            "Epoch:664, step = 5319, CL continuous loss: 0.875, discrete loss: 0.820\n",
            "Epoch:664, step = 5319, Total continuous loss: 0.479, discrete loss: 0.392\n",
            "Time taken: 0.412\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.412\n",
            "Time taken: 0.429\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.415\n",
            "Epoch:665, step = 5327, diffusion continuous loss: 0.304, discrete loss: 0.211\n",
            "Epoch:665, step = 5327, CL continuous loss: 0.860, discrete loss: 0.797\n",
            "Epoch:665, step = 5327, Total continuous loss: 0.477, discrete loss: 0.370\n",
            "Time taken: 0.409\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.422\n",
            "Time taken: 0.415\n",
            "Time taken: 0.414\n",
            "Time taken: 0.411\n",
            "Time taken: 0.418\n",
            "Epoch:666, step = 5335, diffusion continuous loss: 0.294, discrete loss: 0.215\n",
            "Epoch:666, step = 5335, CL continuous loss: 0.879, discrete loss: 0.804\n",
            "Epoch:666, step = 5335, Total continuous loss: 0.470, discrete loss: 0.375\n",
            "Time taken: 0.411\n",
            "Time taken: 0.417\n",
            "Time taken: 0.413\n",
            "Time taken: 0.418\n",
            "Time taken: 0.413\n",
            "Time taken: 0.422\n",
            "Time taken: 0.446\n",
            "Time taken: 0.443\n",
            "Epoch:667, step = 5343, diffusion continuous loss: 0.281, discrete loss: 0.215\n",
            "Epoch:667, step = 5343, CL continuous loss: 0.879, discrete loss: 0.804\n",
            "Epoch:667, step = 5343, Total continuous loss: 0.456, discrete loss: 0.376\n",
            "Time taken: 0.423\n",
            "Time taken: 0.448\n",
            "Time taken: 0.593\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Epoch:668, step = 5351, diffusion continuous loss: 0.311, discrete loss: 0.220\n",
            "Epoch:668, step = 5351, CL continuous loss: 0.900, discrete loss: 0.794\n",
            "Epoch:668, step = 5351, Total continuous loss: 0.491, discrete loss: 0.379\n",
            "Time taken: 0.412\n",
            "Time taken: 0.424\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Epoch:669, step = 5359, diffusion continuous loss: 0.291, discrete loss: 0.209\n",
            "Epoch:669, step = 5359, CL continuous loss: 0.889, discrete loss: 0.783\n",
            "Epoch:669, step = 5359, Total continuous loss: 0.469, discrete loss: 0.366\n",
            "Time taken: 0.413\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.414\n",
            "Time taken: 0.423\n",
            "Time taken: 0.424\n",
            "Time taken: 0.419\n",
            "Epoch:670, step = 5367, diffusion continuous loss: 0.276, discrete loss: 0.214\n",
            "Epoch:670, step = 5367, CL continuous loss: 0.884, discrete loss: 0.787\n",
            "Epoch:670, step = 5367, Total continuous loss: 0.453, discrete loss: 0.371\n",
            "Time taken: 0.409\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.435\n",
            "Time taken: 0.437\n",
            "Time taken: 0.442\n",
            "Time taken: 0.438\n",
            "Time taken: 0.445\n",
            "Epoch:671, step = 5375, diffusion continuous loss: 0.266, discrete loss: 0.213\n",
            "Epoch:671, step = 5375, CL continuous loss: 0.877, discrete loss: 0.784\n",
            "Epoch:671, step = 5375, Total continuous loss: 0.441, discrete loss: 0.370\n",
            "Time taken: 0.409\n",
            "Time taken: 0.413\n",
            "Time taken: 0.422\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.628\n",
            "Epoch:672, step = 5383, diffusion continuous loss: 0.297, discrete loss: 0.220\n",
            "Epoch:672, step = 5383, CL continuous loss: 0.874, discrete loss: 0.782\n",
            "Epoch:672, step = 5383, Total continuous loss: 0.472, discrete loss: 0.376\n",
            "Time taken: 0.510\n",
            "Time taken: 0.415\n",
            "Time taken: 0.424\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.425\n",
            "Time taken: 0.421\n",
            "Epoch:673, step = 5391, diffusion continuous loss: 0.275, discrete loss: 0.217\n",
            "Epoch:673, step = 5391, CL continuous loss: 0.881, discrete loss: 0.779\n",
            "Epoch:673, step = 5391, Total continuous loss: 0.451, discrete loss: 0.373\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Time taken: 0.439\n",
            "Epoch:674, step = 5399, diffusion continuous loss: 0.277, discrete loss: 0.236\n",
            "Epoch:674, step = 5399, CL continuous loss: 0.892, discrete loss: 0.809\n",
            "Epoch:674, step = 5399, Total continuous loss: 0.455, discrete loss: 0.397\n",
            "Time taken: 0.430\n",
            "Time taken: 0.435\n",
            "Time taken: 0.456\n",
            "Time taken: 0.443\n",
            "Time taken: 0.422\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Epoch:675, step = 5407, diffusion continuous loss: 0.303, discrete loss: 0.243\n",
            "Epoch:675, step = 5407, CL continuous loss: 0.918, discrete loss: 0.827\n",
            "Epoch:675, step = 5407, Total continuous loss: 0.486, discrete loss: 0.409\n",
            "Time taken: 0.408\n",
            "Time taken: 0.419\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Epoch:676, step = 5415, diffusion continuous loss: 0.289, discrete loss: 0.238\n",
            "Epoch:676, step = 5415, CL continuous loss: 0.906, discrete loss: 0.825\n",
            "Epoch:676, step = 5415, Total continuous loss: 0.470, discrete loss: 0.403\n",
            "Time taken: 0.406\n",
            "Time taken: 0.412\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.523\n",
            "Epoch:677, step = 5423, diffusion continuous loss: 0.279, discrete loss: 0.231\n",
            "Epoch:677, step = 5423, CL continuous loss: 0.894, discrete loss: 0.830\n",
            "Epoch:677, step = 5423, Total continuous loss: 0.458, discrete loss: 0.397\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.448\n",
            "Time taken: 0.440\n",
            "Time taken: 0.439\n",
            "Time taken: 0.456\n",
            "Epoch:678, step = 5431, diffusion continuous loss: 0.322, discrete loss: 0.270\n",
            "Epoch:678, step = 5431, CL continuous loss: 0.907, discrete loss: 0.851\n",
            "Epoch:678, step = 5431, Total continuous loss: 0.504, discrete loss: 0.440\n",
            "Time taken: 0.448\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.414\n",
            "Time taken: 0.419\n",
            "Epoch:679, step = 5439, diffusion continuous loss: 0.281, discrete loss: 0.249\n",
            "Epoch:679, step = 5439, CL continuous loss: 0.872, discrete loss: 0.856\n",
            "Epoch:679, step = 5439, Total continuous loss: 0.456, discrete loss: 0.420\n",
            "Time taken: 0.409\n",
            "Time taken: 0.424\n",
            "Time taken: 0.412\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Epoch:680, step = 5447, diffusion continuous loss: 0.287, discrete loss: 0.237\n",
            "Epoch:680, step = 5447, CL continuous loss: 0.872, discrete loss: 0.835\n",
            "Epoch:680, step = 5447, Total continuous loss: 0.461, discrete loss: 0.404\n",
            "Time taken: 0.411\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Epoch:681, step = 5455, diffusion continuous loss: 0.275, discrete loss: 0.237\n",
            "Epoch:681, step = 5455, CL continuous loss: 0.867, discrete loss: 0.833\n",
            "Epoch:681, step = 5455, Total continuous loss: 0.449, discrete loss: 0.404\n",
            "Time taken: 0.408\n",
            "Time taken: 0.445\n",
            "Time taken: 0.437\n",
            "Time taken: 0.434\n",
            "Time taken: 0.440\n",
            "Time taken: 0.594\n",
            "Time taken: 0.420\n",
            "Time taken: 0.424\n",
            "Epoch:682, step = 5463, diffusion continuous loss: 0.279, discrete loss: 0.221\n",
            "Epoch:682, step = 5463, CL continuous loss: 0.866, discrete loss: 0.821\n",
            "Epoch:682, step = 5463, Total continuous loss: 0.452, discrete loss: 0.386\n",
            "Time taken: 0.407\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.423\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.415\n",
            "Epoch:683, step = 5471, diffusion continuous loss: 0.280, discrete loss: 0.221\n",
            "Epoch:683, step = 5471, CL continuous loss: 0.877, discrete loss: 0.827\n",
            "Epoch:683, step = 5471, Total continuous loss: 0.456, discrete loss: 0.387\n",
            "Time taken: 0.410\n",
            "Time taken: 0.430\n",
            "Time taken: 0.414\n",
            "Time taken: 0.430\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Epoch:684, step = 5479, diffusion continuous loss: 0.291, discrete loss: 0.214\n",
            "Epoch:684, step = 5479, CL continuous loss: 0.887, discrete loss: 0.842\n",
            "Epoch:684, step = 5479, Total continuous loss: 0.468, discrete loss: 0.383\n",
            "Time taken: 0.410\n",
            "Time taken: 0.421\n",
            "Time taken: 0.425\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Time taken: 0.441\n",
            "Time taken: 0.436\n",
            "Epoch:685, step = 5487, diffusion continuous loss: 0.296, discrete loss: 0.225\n",
            "Epoch:685, step = 5487, CL continuous loss: 0.878, discrete loss: 0.818\n",
            "Epoch:685, step = 5487, Total continuous loss: 0.472, discrete loss: 0.389\n",
            "Time taken: 0.431\n",
            "Time taken: 0.444\n",
            "Time taken: 0.455\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.436\n",
            "Epoch:686, step = 5495, diffusion continuous loss: 0.304, discrete loss: 0.246\n",
            "Epoch:686, step = 5495, CL continuous loss: 0.897, discrete loss: 0.823\n",
            "Epoch:686, step = 5495, Total continuous loss: 0.483, discrete loss: 0.411\n",
            "Time taken: 0.405\n",
            "Time taken: 0.424\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.513\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Epoch:687, step = 5503, diffusion continuous loss: 0.307, discrete loss: 0.211\n",
            "Epoch:687, step = 5503, CL continuous loss: 0.895, discrete loss: 0.829\n",
            "Epoch:687, step = 5503, Total continuous loss: 0.486, discrete loss: 0.376\n",
            "Time taken: 0.411\n",
            "Time taken: 0.420\n",
            "Time taken: 0.421\n",
            "Time taken: 0.422\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Epoch:688, step = 5511, diffusion continuous loss: 0.296, discrete loss: 0.221\n",
            "Epoch:688, step = 5511, CL continuous loss: 0.883, discrete loss: 0.811\n",
            "Epoch:688, step = 5511, Total continuous loss: 0.473, discrete loss: 0.383\n",
            "Time taken: 0.422\n",
            "Time taken: 0.419\n",
            "Time taken: 0.439\n",
            "Time taken: 0.446\n",
            "Time taken: 0.440\n",
            "Time taken: 0.438\n",
            "Time taken: 0.446\n",
            "Time taken: 0.458\n",
            "Epoch:689, step = 5519, diffusion continuous loss: 0.279, discrete loss: 0.214\n",
            "Epoch:689, step = 5519, CL continuous loss: 0.882, discrete loss: 0.828\n",
            "Epoch:689, step = 5519, Total continuous loss: 0.456, discrete loss: 0.380\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.414\n",
            "Epoch:690, step = 5527, diffusion continuous loss: 0.267, discrete loss: 0.220\n",
            "Epoch:690, step = 5527, CL continuous loss: 0.900, discrete loss: 0.805\n",
            "Epoch:690, step = 5527, Total continuous loss: 0.447, discrete loss: 0.381\n",
            "Time taken: 0.413\n",
            "Time taken: 0.422\n",
            "Time taken: 0.423\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.424\n",
            "Time taken: 0.419\n",
            "Epoch:691, step = 5535, diffusion continuous loss: 0.274, discrete loss: 0.224\n",
            "Epoch:691, step = 5535, CL continuous loss: 0.869, discrete loss: 0.823\n",
            "Epoch:691, step = 5535, Total continuous loss: 0.448, discrete loss: 0.389\n",
            "Time taken: 0.410\n",
            "Time taken: 0.418\n",
            "Time taken: 0.526\n",
            "Time taken: 0.422\n",
            "Time taken: 0.424\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Time taken: 0.423\n",
            "Epoch:692, step = 5543, diffusion continuous loss: 0.302, discrete loss: 0.222\n",
            "Epoch:692, step = 5543, CL continuous loss: 0.878, discrete loss: 0.802\n",
            "Epoch:692, step = 5543, Total continuous loss: 0.477, discrete loss: 0.382\n",
            "Time taken: 0.438\n",
            "Time taken: 0.442\n",
            "Time taken: 0.442\n",
            "Time taken: 0.449\n",
            "Time taken: 0.440\n",
            "Time taken: 0.415\n",
            "Time taken: 0.422\n",
            "Time taken: 0.428\n",
            "Epoch:693, step = 5551, diffusion continuous loss: 0.292, discrete loss: 0.209\n",
            "Epoch:693, step = 5551, CL continuous loss: 0.877, discrete loss: 0.807\n",
            "Epoch:693, step = 5551, Total continuous loss: 0.467, discrete loss: 0.370\n",
            "Time taken: 0.410\n",
            "Time taken: 0.421\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Epoch:694, step = 5559, diffusion continuous loss: 0.287, discrete loss: 0.228\n",
            "Epoch:694, step = 5559, CL continuous loss: 0.901, discrete loss: 0.806\n",
            "Epoch:694, step = 5559, Total continuous loss: 0.467, discrete loss: 0.389\n",
            "Time taken: 0.406\n",
            "Time taken: 0.418\n",
            "Time taken: 0.424\n",
            "Time taken: 0.421\n",
            "Time taken: 0.423\n",
            "Time taken: 0.424\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Epoch:695, step = 5567, diffusion continuous loss: 0.303, discrete loss: 0.217\n",
            "Epoch:695, step = 5567, CL continuous loss: 0.903, discrete loss: 0.794\n",
            "Epoch:695, step = 5567, Total continuous loss: 0.483, discrete loss: 0.375\n",
            "Time taken: 0.412\n",
            "Time taken: 0.419\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Time taken: 0.427\n",
            "Time taken: 0.445\n",
            "Time taken: 0.440\n",
            "Time taken: 0.439\n",
            "Epoch:696, step = 5575, diffusion continuous loss: 0.342, discrete loss: 0.219\n",
            "Epoch:696, step = 5575, CL continuous loss: 0.895, discrete loss: 0.801\n",
            "Epoch:696, step = 5575, Total continuous loss: 0.521, discrete loss: 0.379\n",
            "Time taken: 0.437\n",
            "Time taken: 0.580\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Epoch:697, step = 5583, diffusion continuous loss: 0.311, discrete loss: 0.207\n",
            "Epoch:697, step = 5583, CL continuous loss: 0.914, discrete loss: 0.791\n",
            "Epoch:697, step = 5583, Total continuous loss: 0.494, discrete loss: 0.365\n",
            "Time taken: 0.403\n",
            "Time taken: 0.424\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.426\n",
            "Time taken: 0.418\n",
            "Epoch:698, step = 5591, diffusion continuous loss: 0.311, discrete loss: 0.222\n",
            "Epoch:698, step = 5591, CL continuous loss: 0.889, discrete loss: 0.796\n",
            "Epoch:698, step = 5591, Total continuous loss: 0.489, discrete loss: 0.381\n",
            "Time taken: 0.407\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.427\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Epoch:699, step = 5599, diffusion continuous loss: 0.278, discrete loss: 0.227\n",
            "Epoch:699, step = 5599, CL continuous loss: 0.891, discrete loss: 0.786\n",
            "Epoch:699, step = 5599, Total continuous loss: 0.456, discrete loss: 0.384\n",
            "Time taken: 0.585\n",
            "Time taken: 0.481\n",
            "Time taken: 0.438\n",
            "Time taken: 0.437\n",
            "Time taken: 0.453\n",
            "Time taken: 0.447\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Epoch:700, step = 5607, diffusion continuous loss: 0.323, discrete loss: 0.207\n",
            "Epoch:700, step = 5607, CL continuous loss: 0.912, discrete loss: 0.781\n",
            "Epoch:700, step = 5607, Total continuous loss: 0.506, discrete loss: 0.363\n",
            "Time taken: 0.411\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Epoch:701, step = 5615, diffusion continuous loss: 0.291, discrete loss: 0.215\n",
            "Epoch:701, step = 5615, CL continuous loss: 0.890, discrete loss: 0.789\n",
            "Epoch:701, step = 5615, Total continuous loss: 0.469, discrete loss: 0.373\n",
            "Time taken: 0.505\n",
            "Time taken: 0.415\n",
            "Time taken: 0.423\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.423\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Epoch:702, step = 5623, diffusion continuous loss: 0.384, discrete loss: 0.218\n",
            "Epoch:702, step = 5623, CL continuous loss: 0.889, discrete loss: 0.804\n",
            "Epoch:702, step = 5623, Total continuous loss: 0.562, discrete loss: 0.378\n",
            "Time taken: 0.406\n",
            "Time taken: 0.423\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.443\n",
            "Time taken: 0.445\n",
            "Epoch:703, step = 5631, diffusion continuous loss: 0.279, discrete loss: 0.217\n",
            "Epoch:703, step = 5631, CL continuous loss: 0.866, discrete loss: 0.797\n",
            "Epoch:703, step = 5631, Total continuous loss: 0.452, discrete loss: 0.376\n",
            "Time taken: 0.424\n",
            "Time taken: 0.446\n",
            "Time taken: 0.446\n",
            "Time taken: 0.419\n",
            "Time taken: 0.429\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Epoch:704, step = 5639, diffusion continuous loss: 0.301, discrete loss: 0.223\n",
            "Epoch:704, step = 5639, CL continuous loss: 0.882, discrete loss: 0.788\n",
            "Epoch:704, step = 5639, Total continuous loss: 0.477, discrete loss: 0.381\n",
            "Time taken: 0.410\n",
            "Time taken: 0.422\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.422\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Epoch:705, step = 5647, diffusion continuous loss: 0.273, discrete loss: 0.211\n",
            "Epoch:705, step = 5647, CL continuous loss: 0.876, discrete loss: 0.799\n",
            "Epoch:705, step = 5647, Total continuous loss: 0.448, discrete loss: 0.371\n",
            "Time taken: 0.413\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.413\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Epoch:706, step = 5655, diffusion continuous loss: 0.290, discrete loss: 0.222\n",
            "Epoch:706, step = 5655, CL continuous loss: 0.877, discrete loss: 0.791\n",
            "Epoch:706, step = 5655, Total continuous loss: 0.465, discrete loss: 0.380\n",
            "Time taken: 0.509\n",
            "Time taken: 0.422\n",
            "Time taken: 0.432\n",
            "Time taken: 0.440\n",
            "Time taken: 0.441\n",
            "Time taken: 0.437\n",
            "Time taken: 0.447\n",
            "Time taken: 0.447\n",
            "Epoch:707, step = 5663, diffusion continuous loss: 0.279, discrete loss: 0.213\n",
            "Epoch:707, step = 5663, CL continuous loss: 0.887, discrete loss: 0.780\n",
            "Epoch:707, step = 5663, Total continuous loss: 0.457, discrete loss: 0.369\n",
            "Time taken: 0.407\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.422\n",
            "Time taken: 0.417\n",
            "Epoch:708, step = 5671, diffusion continuous loss: 0.271, discrete loss: 0.221\n",
            "Epoch:708, step = 5671, CL continuous loss: 0.884, discrete loss: 0.785\n",
            "Epoch:708, step = 5671, Total continuous loss: 0.448, discrete loss: 0.378\n",
            "Time taken: 0.410\n",
            "Time taken: 0.410\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Epoch:709, step = 5679, diffusion continuous loss: 0.284, discrete loss: 0.212\n",
            "Epoch:709, step = 5679, CL continuous loss: 0.878, discrete loss: 0.791\n",
            "Epoch:709, step = 5679, Total continuous loss: 0.459, discrete loss: 0.370\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.426\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Epoch:710, step = 5687, diffusion continuous loss: 0.261, discrete loss: 0.209\n",
            "Epoch:710, step = 5687, CL continuous loss: 0.867, discrete loss: 0.786\n",
            "Epoch:710, step = 5687, Total continuous loss: 0.434, discrete loss: 0.366\n",
            "Time taken: 0.755\n",
            "Time taken: 0.455\n",
            "Time taken: 0.441\n",
            "Time taken: 0.448\n",
            "Time taken: 0.435\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.516\n",
            "Epoch:711, step = 5695, diffusion continuous loss: 0.282, discrete loss: 0.203\n",
            "Epoch:711, step = 5695, CL continuous loss: 0.877, discrete loss: 0.799\n",
            "Epoch:711, step = 5695, Total continuous loss: 0.458, discrete loss: 0.363\n",
            "Time taken: 0.413\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.422\n",
            "Time taken: 0.419\n",
            "Time taken: 0.425\n",
            "Epoch:712, step = 5703, diffusion continuous loss: 0.274, discrete loss: 0.219\n",
            "Epoch:712, step = 5703, CL continuous loss: 0.889, discrete loss: 0.784\n",
            "Epoch:712, step = 5703, Total continuous loss: 0.452, discrete loss: 0.376\n",
            "Time taken: 0.404\n",
            "Time taken: 0.414\n",
            "Time taken: 0.428\n",
            "Time taken: 0.416\n",
            "Time taken: 0.412\n",
            "Time taken: 0.419\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Epoch:713, step = 5711, diffusion continuous loss: 0.287, discrete loss: 0.222\n",
            "Epoch:713, step = 5711, CL continuous loss: 0.893, discrete loss: 0.783\n",
            "Epoch:713, step = 5711, Total continuous loss: 0.466, discrete loss: 0.378\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.415\n",
            "Time taken: 0.451\n",
            "Time taken: 0.437\n",
            "Time taken: 0.436\n",
            "Time taken: 0.438\n",
            "Epoch:714, step = 5719, diffusion continuous loss: 0.277, discrete loss: 0.221\n",
            "Epoch:714, step = 5719, CL continuous loss: 0.865, discrete loss: 0.785\n",
            "Epoch:714, step = 5719, Total continuous loss: 0.450, discrete loss: 0.378\n",
            "Time taken: 0.440\n",
            "Time taken: 0.445\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.414\n",
            "Time taken: 0.416\n",
            "Time taken: 0.430\n",
            "Time taken: 0.416\n",
            "Epoch:715, step = 5727, diffusion continuous loss: 0.274, discrete loss: 0.220\n",
            "Epoch:715, step = 5727, CL continuous loss: 0.861, discrete loss: 0.795\n",
            "Epoch:715, step = 5727, Total continuous loss: 0.447, discrete loss: 0.379\n",
            "Time taken: 0.409\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.427\n",
            "Time taken: 0.417\n",
            "Time taken: 0.423\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Epoch:716, step = 5735, diffusion continuous loss: 0.266, discrete loss: 0.227\n",
            "Epoch:716, step = 5735, CL continuous loss: 0.853, discrete loss: 0.796\n",
            "Epoch:716, step = 5735, Total continuous loss: 0.437, discrete loss: 0.386\n",
            "Time taken: 0.509\n",
            "Time taken: 0.415\n",
            "Time taken: 0.623\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Epoch:717, step = 5743, diffusion continuous loss: 0.267, discrete loss: 0.227\n",
            "Epoch:717, step = 5743, CL continuous loss: 0.871, discrete loss: 0.784\n",
            "Epoch:717, step = 5743, Total continuous loss: 0.442, discrete loss: 0.384\n",
            "Time taken: 0.413\n",
            "Time taken: 0.444\n",
            "Time taken: 0.441\n",
            "Time taken: 0.434\n",
            "Time taken: 0.444\n",
            "Time taken: 0.446\n",
            "Time taken: 0.428\n",
            "Time taken: 0.416\n",
            "Epoch:718, step = 5751, diffusion continuous loss: 0.271, discrete loss: 0.215\n",
            "Epoch:718, step = 5751, CL continuous loss: 0.859, discrete loss: 0.790\n",
            "Epoch:718, step = 5751, Total continuous loss: 0.443, discrete loss: 0.373\n",
            "Time taken: 0.414\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.414\n",
            "Time taken: 0.415\n",
            "Epoch:719, step = 5759, diffusion continuous loss: 0.264, discrete loss: 0.223\n",
            "Epoch:719, step = 5759, CL continuous loss: 0.872, discrete loss: 0.784\n",
            "Epoch:719, step = 5759, Total continuous loss: 0.438, discrete loss: 0.380\n",
            "Time taken: 0.408\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Epoch:720, step = 5767, diffusion continuous loss: 0.279, discrete loss: 0.219\n",
            "Epoch:720, step = 5767, CL continuous loss: 0.861, discrete loss: 0.788\n",
            "Epoch:720, step = 5767, Total continuous loss: 0.451, discrete loss: 0.377\n",
            "Time taken: 0.403\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.441\n",
            "Time taken: 0.439\n",
            "Epoch:721, step = 5775, diffusion continuous loss: 0.282, discrete loss: 0.224\n",
            "Epoch:721, step = 5775, CL continuous loss: 0.882, discrete loss: 0.785\n",
            "Epoch:721, step = 5775, Total continuous loss: 0.458, discrete loss: 0.382\n",
            "Time taken: 0.558\n",
            "Time taken: 0.449\n",
            "Time taken: 0.444\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.412\n",
            "Time taken: 0.419\n",
            "Epoch:722, step = 5783, diffusion continuous loss: 0.279, discrete loss: 0.215\n",
            "Epoch:722, step = 5783, CL continuous loss: 0.868, discrete loss: 0.789\n",
            "Epoch:722, step = 5783, Total continuous loss: 0.453, discrete loss: 0.373\n",
            "Time taken: 0.406\n",
            "Time taken: 0.412\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Epoch:723, step = 5791, diffusion continuous loss: 0.293, discrete loss: 0.218\n",
            "Epoch:723, step = 5791, CL continuous loss: 0.892, discrete loss: 0.798\n",
            "Epoch:723, step = 5791, Total continuous loss: 0.471, discrete loss: 0.377\n",
            "Time taken: 0.407\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.412\n",
            "Time taken: 0.423\n",
            "Epoch:724, step = 5799, diffusion continuous loss: 0.305, discrete loss: 0.217\n",
            "Epoch:724, step = 5799, CL continuous loss: 0.893, discrete loss: 0.786\n",
            "Epoch:724, step = 5799, Total continuous loss: 0.484, discrete loss: 0.374\n",
            "Time taken: 0.406\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.438\n",
            "Time taken: 0.438\n",
            "Time taken: 0.439\n",
            "Time taken: 0.455\n",
            "Time taken: 0.444\n",
            "Epoch:725, step = 5807, diffusion continuous loss: 0.288, discrete loss: 0.224\n",
            "Epoch:725, step = 5807, CL continuous loss: 0.911, discrete loss: 0.781\n",
            "Epoch:725, step = 5807, Total continuous loss: 0.470, discrete loss: 0.380\n",
            "Time taken: 0.407\n",
            "Time taken: 0.431\n",
            "Time taken: 0.413\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.414\n",
            "Epoch:726, step = 5815, diffusion continuous loss: 0.388, discrete loss: 0.213\n",
            "Epoch:726, step = 5815, CL continuous loss: 0.933, discrete loss: 0.780\n",
            "Epoch:726, step = 5815, Total continuous loss: 0.574, discrete loss: 0.369\n",
            "Time taken: 0.414\n",
            "Time taken: 0.518\n",
            "Time taken: 0.420\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Epoch:727, step = 5823, diffusion continuous loss: 0.316, discrete loss: 0.219\n",
            "Epoch:727, step = 5823, CL continuous loss: 0.901, discrete loss: 0.795\n",
            "Epoch:727, step = 5823, Total continuous loss: 0.496, discrete loss: 0.378\n",
            "Time taken: 0.412\n",
            "Time taken: 0.414\n",
            "Time taken: 0.423\n",
            "Time taken: 0.421\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.430\n",
            "Epoch:728, step = 5831, diffusion continuous loss: 0.300, discrete loss: 0.214\n",
            "Epoch:728, step = 5831, CL continuous loss: 0.883, discrete loss: 0.798\n",
            "Epoch:728, step = 5831, Total continuous loss: 0.477, discrete loss: 0.373\n",
            "Time taken: 0.428\n",
            "Time taken: 0.440\n",
            "Time taken: 0.446\n",
            "Time taken: 0.444\n",
            "Time taken: 0.448\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Epoch:729, step = 5839, diffusion continuous loss: 0.292, discrete loss: 0.212\n",
            "Epoch:729, step = 5839, CL continuous loss: 0.881, discrete loss: 0.781\n",
            "Epoch:729, step = 5839, Total continuous loss: 0.468, discrete loss: 0.368\n",
            "Time taken: 0.402\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Epoch:730, step = 5847, diffusion continuous loss: 0.295, discrete loss: 0.217\n",
            "Epoch:730, step = 5847, CL continuous loss: 0.895, discrete loss: 0.783\n",
            "Epoch:730, step = 5847, Total continuous loss: 0.474, discrete loss: 0.373\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Epoch:731, step = 5855, diffusion continuous loss: 0.307, discrete loss: 0.215\n",
            "Epoch:731, step = 5855, CL continuous loss: 0.893, discrete loss: 0.780\n",
            "Epoch:731, step = 5855, Total continuous loss: 0.485, discrete loss: 0.371\n",
            "Time taken: 0.413\n",
            "Time taken: 0.511\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.426\n",
            "Time taken: 0.443\n",
            "Time taken: 0.436\n",
            "Time taken: 0.437\n",
            "Epoch:732, step = 5863, diffusion continuous loss: 0.291, discrete loss: 0.224\n",
            "Epoch:732, step = 5863, CL continuous loss: 0.906, discrete loss: 0.784\n",
            "Epoch:732, step = 5863, Total continuous loss: 0.472, discrete loss: 0.381\n",
            "Time taken: 0.436\n",
            "Time taken: 0.455\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.413\n",
            "Time taken: 0.424\n",
            "Time taken: 0.416\n",
            "Epoch:733, step = 5871, diffusion continuous loss: 0.284, discrete loss: 0.229\n",
            "Epoch:733, step = 5871, CL continuous loss: 0.868, discrete loss: 0.783\n",
            "Epoch:733, step = 5871, Total continuous loss: 0.458, discrete loss: 0.386\n",
            "Time taken: 0.413\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.424\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Epoch:734, step = 5879, diffusion continuous loss: 0.372, discrete loss: 0.203\n",
            "Epoch:734, step = 5879, CL continuous loss: 0.900, discrete loss: 0.774\n",
            "Epoch:734, step = 5879, Total continuous loss: 0.552, discrete loss: 0.357\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Epoch:735, step = 5887, diffusion continuous loss: 0.360, discrete loss: 0.217\n",
            "Epoch:735, step = 5887, CL continuous loss: 0.875, discrete loss: 0.780\n",
            "Epoch:735, step = 5887, Total continuous loss: 0.535, discrete loss: 0.374\n",
            "Time taken: 0.411\n",
            "Time taken: 0.420\n",
            "Time taken: 0.456\n",
            "Time taken: 0.438\n",
            "Time taken: 0.434\n",
            "Time taken: 0.454\n",
            "Time taken: 0.448\n",
            "Time taken: 0.518\n",
            "Epoch:736, step = 5895, diffusion continuous loss: 0.300, discrete loss: 0.212\n",
            "Epoch:736, step = 5895, CL continuous loss: 0.904, discrete loss: 0.780\n",
            "Epoch:736, step = 5895, Total continuous loss: 0.480, discrete loss: 0.368\n",
            "Time taken: 0.408\n",
            "Time taken: 0.423\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Epoch:737, step = 5903, diffusion continuous loss: 0.294, discrete loss: 0.215\n",
            "Epoch:737, step = 5903, CL continuous loss: 0.897, discrete loss: 0.789\n",
            "Epoch:737, step = 5903, Total continuous loss: 0.474, discrete loss: 0.373\n",
            "Time taken: 0.411\n",
            "Time taken: 0.433\n",
            "Time taken: 0.417\n",
            "Time taken: 0.422\n",
            "Time taken: 0.421\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Epoch:738, step = 5911, diffusion continuous loss: 0.276, discrete loss: 0.213\n",
            "Epoch:738, step = 5911, CL continuous loss: 0.879, discrete loss: 0.785\n",
            "Epoch:738, step = 5911, Total continuous loss: 0.452, discrete loss: 0.370\n",
            "Time taken: 0.413\n",
            "Time taken: 0.420\n",
            "Time taken: 0.423\n",
            "Time taken: 0.415\n",
            "Time taken: 0.422\n",
            "Time taken: 0.422\n",
            "Time taken: 0.423\n",
            "Time taken: 0.440\n",
            "Epoch:739, step = 5919, diffusion continuous loss: 0.278, discrete loss: 0.210\n",
            "Epoch:739, step = 5919, CL continuous loss: 0.877, discrete loss: 0.779\n",
            "Epoch:739, step = 5919, Total continuous loss: 0.453, discrete loss: 0.365\n",
            "Time taken: 0.426\n",
            "Time taken: 0.442\n",
            "Time taken: 0.470\n",
            "Time taken: 0.448\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Epoch:740, step = 5927, diffusion continuous loss: 0.292, discrete loss: 0.204\n",
            "Epoch:740, step = 5927, CL continuous loss: 0.864, discrete loss: 0.782\n",
            "Epoch:740, step = 5927, Total continuous loss: 0.465, discrete loss: 0.360\n",
            "Time taken: 0.412\n",
            "Time taken: 0.428\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.415\n",
            "Time taken: 0.523\n",
            "Time taken: 0.419\n",
            "Epoch:741, step = 5935, diffusion continuous loss: 0.281, discrete loss: 0.220\n",
            "Epoch:741, step = 5935, CL continuous loss: 0.879, discrete loss: 0.776\n",
            "Epoch:741, step = 5935, Total continuous loss: 0.457, discrete loss: 0.375\n",
            "Time taken: 0.406\n",
            "Time taken: 0.419\n",
            "Time taken: 0.415\n",
            "Time taken: 0.424\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Epoch:742, step = 5943, diffusion continuous loss: 0.289, discrete loss: 0.219\n",
            "Epoch:742, step = 5943, CL continuous loss: 0.889, discrete loss: 0.779\n",
            "Epoch:742, step = 5943, Total continuous loss: 0.466, discrete loss: 0.375\n",
            "Time taken: 0.414\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.437\n",
            "Time taken: 0.438\n",
            "Time taken: 0.433\n",
            "Time taken: 0.438\n",
            "Epoch:743, step = 5951, diffusion continuous loss: 0.287, discrete loss: 0.213\n",
            "Epoch:743, step = 5951, CL continuous loss: 0.888, discrete loss: 0.781\n",
            "Epoch:743, step = 5951, Total continuous loss: 0.464, discrete loss: 0.370\n",
            "Time taken: 0.448\n",
            "Time taken: 0.414\n",
            "Time taken: 0.421\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Epoch:744, step = 5959, diffusion continuous loss: 0.287, discrete loss: 0.219\n",
            "Epoch:744, step = 5959, CL continuous loss: 0.876, discrete loss: 0.780\n",
            "Epoch:744, step = 5959, Total continuous loss: 0.462, discrete loss: 0.375\n",
            "Time taken: 0.411\n",
            "Time taken: 0.425\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.414\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.423\n",
            "Epoch:745, step = 5967, diffusion continuous loss: 0.287, discrete loss: 0.216\n",
            "Epoch:745, step = 5967, CL continuous loss: 0.872, discrete loss: 0.788\n",
            "Epoch:745, step = 5967, Total continuous loss: 0.461, discrete loss: 0.374\n",
            "Time taken: 0.430\n",
            "Time taken: 0.445\n",
            "Time taken: 0.436\n",
            "Time taken: 0.460\n",
            "Time taken: 0.588\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Epoch:746, step = 5975, diffusion continuous loss: 0.306, discrete loss: 0.218\n",
            "Epoch:746, step = 5975, CL continuous loss: 0.912, discrete loss: 0.794\n",
            "Epoch:746, step = 5975, Total continuous loss: 0.488, discrete loss: 0.377\n",
            "Time taken: 0.434\n",
            "Time taken: 0.438\n",
            "Time taken: 0.442\n",
            "Time taken: 0.453\n",
            "Time taken: 0.458\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Epoch:747, step = 5983, diffusion continuous loss: 0.282, discrete loss: 0.215\n",
            "Epoch:747, step = 5983, CL continuous loss: 0.893, discrete loss: 0.791\n",
            "Epoch:747, step = 5983, Total continuous loss: 0.460, discrete loss: 0.373\n",
            "Time taken: 0.411\n",
            "Time taken: 0.422\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.425\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Epoch:748, step = 5991, diffusion continuous loss: 0.275, discrete loss: 0.218\n",
            "Epoch:748, step = 5991, CL continuous loss: 0.866, discrete loss: 0.804\n",
            "Epoch:748, step = 5991, Total continuous loss: 0.448, discrete loss: 0.378\n",
            "Time taken: 0.410\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Epoch:749, step = 5999, diffusion continuous loss: 0.296, discrete loss: 0.214\n",
            "Epoch:749, step = 5999, CL continuous loss: 0.861, discrete loss: 0.786\n",
            "Epoch:749, step = 5999, Total continuous loss: 0.469, discrete loss: 0.371\n",
            "Time taken: 0.412\n",
            "Time taken: 0.414\n",
            "Time taken: 0.423\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.446\n",
            "Time taken: 0.441\n",
            "Time taken: 0.434\n",
            "Epoch:750, step = 6007, diffusion continuous loss: 0.294, discrete loss: 0.228\n",
            "Epoch:750, step = 6007, CL continuous loss: 0.878, discrete loss: 0.776\n",
            "Epoch:750, step = 6007, Total continuous loss: 0.470, discrete loss: 0.383\n",
            "Time taken: 0.439\n",
            "Time taken: 0.451\n",
            "Time taken: 0.429\n",
            "Time taken: 0.514\n",
            "Time taken: 0.419\n",
            "Time taken: 0.413\n",
            "Time taken: 0.422\n",
            "Time taken: 0.416\n",
            "Epoch:751, step = 6015, diffusion continuous loss: 0.281, discrete loss: 0.228\n",
            "Epoch:751, step = 6015, CL continuous loss: 0.863, discrete loss: 0.777\n",
            "Epoch:751, step = 6015, Total continuous loss: 0.453, discrete loss: 0.383\n",
            "Time taken: 0.410\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.414\n",
            "Epoch:752, step = 6023, diffusion continuous loss: 0.281, discrete loss: 0.214\n",
            "Epoch:752, step = 6023, CL continuous loss: 0.857, discrete loss: 0.788\n",
            "Epoch:752, step = 6023, Total continuous loss: 0.452, discrete loss: 0.371\n",
            "Time taken: 0.407\n",
            "Time taken: 0.419\n",
            "Time taken: 0.413\n",
            "Time taken: 0.416\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Time taken: 0.414\n",
            "Time taken: 0.419\n",
            "Epoch:753, step = 6031, diffusion continuous loss: 0.285, discrete loss: 0.237\n",
            "Epoch:753, step = 6031, CL continuous loss: 0.879, discrete loss: 0.786\n",
            "Epoch:753, step = 6031, Total continuous loss: 0.461, discrete loss: 0.394\n",
            "Time taken: 0.406\n",
            "Time taken: 0.416\n",
            "Time taken: 0.456\n",
            "Time taken: 0.437\n",
            "Time taken: 0.434\n",
            "Time taken: 0.459\n",
            "Time taken: 0.449\n",
            "Time taken: 0.420\n",
            "Epoch:754, step = 6039, diffusion continuous loss: 0.274, discrete loss: 0.218\n",
            "Epoch:754, step = 6039, CL continuous loss: 0.859, discrete loss: 0.789\n",
            "Epoch:754, step = 6039, Total continuous loss: 0.445, discrete loss: 0.376\n",
            "Time taken: 0.411\n",
            "Time taken: 0.422\n",
            "Time taken: 0.420\n",
            "Time taken: 0.420\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Epoch:755, step = 6047, diffusion continuous loss: 0.268, discrete loss: 0.200\n",
            "Epoch:755, step = 6047, CL continuous loss: 0.890, discrete loss: 0.784\n",
            "Epoch:755, step = 6047, Total continuous loss: 0.446, discrete loss: 0.357\n",
            "Time taken: 0.410\n",
            "Time taken: 0.520\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.427\n",
            "Time taken: 0.414\n",
            "Epoch:756, step = 6055, diffusion continuous loss: 0.271, discrete loss: 0.200\n",
            "Epoch:756, step = 6055, CL continuous loss: 0.858, discrete loss: 0.781\n",
            "Epoch:756, step = 6055, Total continuous loss: 0.442, discrete loss: 0.356\n",
            "Time taken: 0.624\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Time taken: 0.430\n",
            "Time taken: 0.441\n",
            "Epoch:757, step = 6063, diffusion continuous loss: 0.281, discrete loss: 0.213\n",
            "Epoch:757, step = 6063, CL continuous loss: 0.851, discrete loss: 0.798\n",
            "Epoch:757, step = 6063, Total continuous loss: 0.451, discrete loss: 0.373\n",
            "Time taken: 0.426\n",
            "Time taken: 0.453\n",
            "Time taken: 0.449\n",
            "Time taken: 0.441\n",
            "Time taken: 0.422\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.411\n",
            "Epoch:758, step = 6071, diffusion continuous loss: 0.276, discrete loss: 0.222\n",
            "Epoch:758, step = 6071, CL continuous loss: 0.907, discrete loss: 0.773\n",
            "Epoch:758, step = 6071, Total continuous loss: 0.457, discrete loss: 0.376\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Epoch:759, step = 6079, diffusion continuous loss: 0.290, discrete loss: 0.227\n",
            "Epoch:759, step = 6079, CL continuous loss: 0.892, discrete loss: 0.783\n",
            "Epoch:759, step = 6079, Total continuous loss: 0.469, discrete loss: 0.384\n",
            "Time taken: 0.406\n",
            "Time taken: 0.416\n",
            "Time taken: 0.423\n",
            "Time taken: 0.422\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.511\n",
            "Epoch:760, step = 6087, diffusion continuous loss: 0.285, discrete loss: 0.213\n",
            "Epoch:760, step = 6087, CL continuous loss: 0.903, discrete loss: 0.791\n",
            "Epoch:760, step = 6087, Total continuous loss: 0.466, discrete loss: 0.371\n",
            "Time taken: 0.410\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.424\n",
            "Time taken: 0.437\n",
            "Time taken: 0.435\n",
            "Time taken: 0.441\n",
            "Time taken: 0.455\n",
            "Epoch:761, step = 6095, diffusion continuous loss: 0.276, discrete loss: 0.213\n",
            "Epoch:761, step = 6095, CL continuous loss: 0.876, discrete loss: 0.780\n",
            "Epoch:761, step = 6095, Total continuous loss: 0.451, discrete loss: 0.369\n",
            "Time taken: 0.437\n",
            "Time taken: 0.414\n",
            "Time taken: 0.414\n",
            "Time taken: 0.414\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Epoch:762, step = 6103, diffusion continuous loss: 0.276, discrete loss: 0.216\n",
            "Epoch:762, step = 6103, CL continuous loss: 0.873, discrete loss: 0.771\n",
            "Epoch:762, step = 6103, Total continuous loss: 0.450, discrete loss: 0.370\n",
            "Time taken: 0.407\n",
            "Time taken: 0.422\n",
            "Time taken: 0.424\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.412\n",
            "Time taken: 0.425\n",
            "Time taken: 0.416\n",
            "Epoch:763, step = 6111, diffusion continuous loss: 0.271, discrete loss: 0.218\n",
            "Epoch:763, step = 6111, CL continuous loss: 0.873, discrete loss: 0.786\n",
            "Epoch:763, step = 6111, Total continuous loss: 0.446, discrete loss: 0.375\n",
            "Time taken: 0.407\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Time taken: 0.422\n",
            "Time taken: 0.414\n",
            "Time taken: 0.422\n",
            "Time taken: 0.419\n",
            "Time taken: 0.412\n",
            "Epoch:764, step = 6119, diffusion continuous loss: 0.269, discrete loss: 0.217\n",
            "Epoch:764, step = 6119, CL continuous loss: 0.872, discrete loss: 0.774\n",
            "Epoch:764, step = 6119, Total continuous loss: 0.443, discrete loss: 0.372\n",
            "Time taken: 0.417\n",
            "Time taken: 0.438\n",
            "Time taken: 0.437\n",
            "Time taken: 0.433\n",
            "Time taken: 0.448\n",
            "Time taken: 0.447\n",
            "Time taken: 0.414\n",
            "Time taken: 0.422\n",
            "Epoch:765, step = 6127, diffusion continuous loss: 0.282, discrete loss: 0.221\n",
            "Epoch:765, step = 6127, CL continuous loss: 0.859, discrete loss: 0.769\n",
            "Epoch:765, step = 6127, Total continuous loss: 0.453, discrete loss: 0.375\n",
            "Time taken: 0.505\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.426\n",
            "Time taken: 0.419\n",
            "Epoch:766, step = 6135, diffusion continuous loss: 0.266, discrete loss: 0.216\n",
            "Epoch:766, step = 6135, CL continuous loss: 0.873, discrete loss: 0.796\n",
            "Epoch:766, step = 6135, Total continuous loss: 0.440, discrete loss: 0.375\n",
            "Time taken: 0.402\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Epoch:767, step = 6143, diffusion continuous loss: 0.272, discrete loss: 0.212\n",
            "Epoch:767, step = 6143, CL continuous loss: 0.862, discrete loss: 0.790\n",
            "Epoch:767, step = 6143, Total continuous loss: 0.444, discrete loss: 0.370\n",
            "Time taken: 0.412\n",
            "Time taken: 0.414\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.428\n",
            "Time taken: 0.437\n",
            "Time taken: 0.443\n",
            "Epoch:768, step = 6151, diffusion continuous loss: 0.283, discrete loss: 0.214\n",
            "Epoch:768, step = 6151, CL continuous loss: 0.865, discrete loss: 0.783\n",
            "Epoch:768, step = 6151, Total continuous loss: 0.456, discrete loss: 0.370\n",
            "Time taken: 0.431\n",
            "Time taken: 0.445\n",
            "Time taken: 0.461\n",
            "Time taken: 0.632\n",
            "Time taken: 0.425\n",
            "Time taken: 0.413\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Epoch:769, step = 6159, diffusion continuous loss: 0.289, discrete loss: 0.210\n",
            "Epoch:769, step = 6159, CL continuous loss: 0.857, discrete loss: 0.769\n",
            "Epoch:769, step = 6159, Total continuous loss: 0.460, discrete loss: 0.364\n",
            "Time taken: 0.409\n",
            "Time taken: 0.424\n",
            "Time taken: 0.415\n",
            "Time taken: 0.423\n",
            "Time taken: 0.420\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.414\n",
            "Epoch:770, step = 6167, diffusion continuous loss: 0.293, discrete loss: 0.232\n",
            "Epoch:770, step = 6167, CL continuous loss: 0.884, discrete loss: 0.800\n",
            "Epoch:770, step = 6167, Total continuous loss: 0.470, discrete loss: 0.392\n",
            "Time taken: 0.508\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.411\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Epoch:771, step = 6175, diffusion continuous loss: 0.288, discrete loss: 0.214\n",
            "Epoch:771, step = 6175, CL continuous loss: 0.865, discrete loss: 0.790\n",
            "Epoch:771, step = 6175, Total continuous loss: 0.461, discrete loss: 0.372\n",
            "Time taken: 0.406\n",
            "Time taken: 0.417\n",
            "Time taken: 0.450\n",
            "Time taken: 0.441\n",
            "Time taken: 0.438\n",
            "Time taken: 0.442\n",
            "Time taken: 0.450\n",
            "Time taken: 0.438\n",
            "Epoch:772, step = 6183, diffusion continuous loss: 0.359, discrete loss: 0.225\n",
            "Epoch:772, step = 6183, CL continuous loss: 0.943, discrete loss: 0.771\n",
            "Epoch:772, step = 6183, Total continuous loss: 0.547, discrete loss: 0.379\n",
            "Time taken: 0.406\n",
            "Time taken: 0.424\n",
            "Time taken: 0.415\n",
            "Time taken: 0.414\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Epoch:773, step = 6191, diffusion continuous loss: 0.303, discrete loss: 0.215\n",
            "Epoch:773, step = 6191, CL continuous loss: 0.888, discrete loss: 0.778\n",
            "Epoch:773, step = 6191, Total continuous loss: 0.481, discrete loss: 0.370\n",
            "Time taken: 0.409\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Epoch:774, step = 6199, diffusion continuous loss: 0.294, discrete loss: 0.206\n",
            "Epoch:774, step = 6199, CL continuous loss: 0.916, discrete loss: 0.783\n",
            "Epoch:774, step = 6199, Total continuous loss: 0.478, discrete loss: 0.362\n",
            "Time taken: 0.417\n",
            "Time taken: 0.423\n",
            "Time taken: 0.424\n",
            "Time taken: 0.420\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.422\n",
            "Time taken: 0.445\n",
            "Epoch:775, step = 6207, diffusion continuous loss: 0.306, discrete loss: 0.224\n",
            "Epoch:775, step = 6207, CL continuous loss: 0.887, discrete loss: 0.783\n",
            "Epoch:775, step = 6207, Total continuous loss: 0.483, discrete loss: 0.381\n",
            "Time taken: 0.432\n",
            "Time taken: 0.581\n",
            "Time taken: 0.445\n",
            "Time taken: 0.459\n",
            "Time taken: 0.442\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Epoch:776, step = 6215, diffusion continuous loss: 0.284, discrete loss: 0.216\n",
            "Epoch:776, step = 6215, CL continuous loss: 0.873, discrete loss: 0.783\n",
            "Epoch:776, step = 6215, Total continuous loss: 0.459, discrete loss: 0.373\n",
            "Time taken: 0.413\n",
            "Time taken: 0.429\n",
            "Time taken: 0.414\n",
            "Time taken: 0.425\n",
            "Time taken: 0.418\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.414\n",
            "Epoch:777, step = 6223, diffusion continuous loss: 0.264, discrete loss: 0.214\n",
            "Epoch:777, step = 6223, CL continuous loss: 0.851, discrete loss: 0.785\n",
            "Epoch:777, step = 6223, Total continuous loss: 0.434, discrete loss: 0.371\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Epoch:778, step = 6231, diffusion continuous loss: 0.280, discrete loss: 0.222\n",
            "Epoch:778, step = 6231, CL continuous loss: 0.887, discrete loss: 0.792\n",
            "Epoch:778, step = 6231, Total continuous loss: 0.457, discrete loss: 0.381\n",
            "Time taken: 0.410\n",
            "Time taken: 0.411\n",
            "Time taken: 0.424\n",
            "Time taken: 0.418\n",
            "Time taken: 0.431\n",
            "Time taken: 0.439\n",
            "Time taken: 0.436\n",
            "Time taken: 0.454\n",
            "Epoch:779, step = 6239, diffusion continuous loss: 0.283, discrete loss: 0.215\n",
            "Epoch:779, step = 6239, CL continuous loss: 0.869, discrete loss: 0.791\n",
            "Epoch:779, step = 6239, Total continuous loss: 0.457, discrete loss: 0.373\n",
            "Time taken: 0.440\n",
            "Time taken: 0.445\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.422\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Epoch:780, step = 6247, diffusion continuous loss: 0.277, discrete loss: 0.211\n",
            "Epoch:780, step = 6247, CL continuous loss: 0.874, discrete loss: 0.777\n",
            "Epoch:780, step = 6247, Total continuous loss: 0.452, discrete loss: 0.367\n",
            "Time taken: 0.409\n",
            "Time taken: 0.528\n",
            "Time taken: 0.423\n",
            "Time taken: 0.422\n",
            "Time taken: 0.422\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Time taken: 0.421\n",
            "Epoch:781, step = 6255, diffusion continuous loss: 0.295, discrete loss: 0.215\n",
            "Epoch:781, step = 6255, CL continuous loss: 0.873, discrete loss: 0.778\n",
            "Epoch:781, step = 6255, Total continuous loss: 0.469, discrete loss: 0.371\n",
            "Time taken: 0.414\n",
            "Time taken: 0.424\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.413\n",
            "Time taken: 0.418\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Epoch:782, step = 6263, diffusion continuous loss: 0.319, discrete loss: 0.211\n",
            "Epoch:782, step = 6263, CL continuous loss: 0.919, discrete loss: 0.767\n",
            "Epoch:782, step = 6263, Total continuous loss: 0.503, discrete loss: 0.365\n",
            "Time taken: 0.410\n",
            "Time taken: 0.443\n",
            "Time taken: 0.451\n",
            "Time taken: 0.438\n",
            "Time taken: 0.449\n",
            "Time taken: 0.447\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Epoch:783, step = 6271, diffusion continuous loss: 0.288, discrete loss: 0.217\n",
            "Epoch:783, step = 6271, CL continuous loss: 0.917, discrete loss: 0.790\n",
            "Epoch:783, step = 6271, Total continuous loss: 0.472, discrete loss: 0.375\n",
            "Time taken: 0.409\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.422\n",
            "Time taken: 0.419\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.413\n",
            "Epoch:784, step = 6279, diffusion continuous loss: 0.283, discrete loss: 0.216\n",
            "Epoch:784, step = 6279, CL continuous loss: 0.900, discrete loss: 0.789\n",
            "Epoch:784, step = 6279, Total continuous loss: 0.463, discrete loss: 0.373\n",
            "Time taken: 0.411\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.422\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Time taken: 0.515\n",
            "Epoch:785, step = 6287, diffusion continuous loss: 0.287, discrete loss: 0.221\n",
            "Epoch:785, step = 6287, CL continuous loss: 0.858, discrete loss: 0.787\n",
            "Epoch:785, step = 6287, Total continuous loss: 0.459, discrete loss: 0.378\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.423\n",
            "Time taken: 0.456\n",
            "Time taken: 0.446\n",
            "Epoch:786, step = 6295, diffusion continuous loss: 0.282, discrete loss: 0.218\n",
            "Epoch:786, step = 6295, CL continuous loss: 0.886, discrete loss: 0.777\n",
            "Epoch:786, step = 6295, Total continuous loss: 0.460, discrete loss: 0.373\n",
            "Time taken: 0.432\n",
            "Time taken: 0.466\n",
            "Time taken: 0.469\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.413\n",
            "Time taken: 0.419\n",
            "Epoch:787, step = 6303, diffusion continuous loss: 0.312, discrete loss: 0.213\n",
            "Epoch:787, step = 6303, CL continuous loss: 0.878, discrete loss: 0.780\n",
            "Epoch:787, step = 6303, Total continuous loss: 0.487, discrete loss: 0.369\n",
            "Time taken: 0.412\n",
            "Time taken: 0.425\n",
            "Time taken: 0.419\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.422\n",
            "Time taken: 0.424\n",
            "Time taken: 0.416\n",
            "Epoch:788, step = 6311, diffusion continuous loss: 0.307, discrete loss: 0.218\n",
            "Epoch:788, step = 6311, CL continuous loss: 0.886, discrete loss: 0.773\n",
            "Epoch:788, step = 6311, Total continuous loss: 0.484, discrete loss: 0.372\n",
            "Time taken: 0.413\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.412\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Epoch:789, step = 6319, diffusion continuous loss: 0.296, discrete loss: 0.213\n",
            "Epoch:789, step = 6319, CL continuous loss: 0.869, discrete loss: 0.780\n",
            "Epoch:789, step = 6319, Total continuous loss: 0.470, discrete loss: 0.369\n",
            "Time taken: 0.411\n",
            "Time taken: 0.414\n",
            "Time taken: 0.422\n",
            "Time taken: 0.445\n",
            "Time taken: 0.433\n",
            "Time taken: 0.444\n",
            "Time taken: 0.586\n",
            "Time taken: 0.452\n",
            "Epoch:790, step = 6327, diffusion continuous loss: 0.299, discrete loss: 0.202\n",
            "Epoch:790, step = 6327, CL continuous loss: 0.858, discrete loss: 0.769\n",
            "Epoch:790, step = 6327, Total continuous loss: 0.470, discrete loss: 0.356\n",
            "Time taken: 0.411\n",
            "Time taken: 0.421\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.413\n",
            "Epoch:791, step = 6335, diffusion continuous loss: 0.285, discrete loss: 0.222\n",
            "Epoch:791, step = 6335, CL continuous loss: 0.862, discrete loss: 0.795\n",
            "Epoch:791, step = 6335, Total continuous loss: 0.457, discrete loss: 0.381\n",
            "Time taken: 0.413\n",
            "Time taken: 0.414\n",
            "Time taken: 0.415\n",
            "Time taken: 0.423\n",
            "Time taken: 0.415\n",
            "Time taken: 0.414\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Epoch:792, step = 6343, diffusion continuous loss: 0.294, discrete loss: 0.220\n",
            "Epoch:792, step = 6343, CL continuous loss: 0.883, discrete loss: 0.783\n",
            "Epoch:792, step = 6343, Total continuous loss: 0.470, discrete loss: 0.376\n",
            "Time taken: 0.407\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.414\n",
            "Time taken: 0.419\n",
            "Time taken: 0.433\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Epoch:793, step = 6351, diffusion continuous loss: 0.291, discrete loss: 0.222\n",
            "Epoch:793, step = 6351, CL continuous loss: 0.874, discrete loss: 0.769\n",
            "Epoch:793, step = 6351, Total continuous loss: 0.466, discrete loss: 0.375\n",
            "Time taken: 0.442\n",
            "Time taken: 0.447\n",
            "Time taken: 0.454\n",
            "Time taken: 0.443\n",
            "Time taken: 0.450\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Epoch:794, step = 6359, diffusion continuous loss: 0.282, discrete loss: 0.215\n",
            "Epoch:794, step = 6359, CL continuous loss: 0.892, discrete loss: 0.781\n",
            "Epoch:794, step = 6359, Total continuous loss: 0.460, discrete loss: 0.372\n",
            "Time taken: 0.407\n",
            "Time taken: 0.423\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.515\n",
            "Time taken: 0.417\n",
            "Time taken: 0.425\n",
            "Time taken: 0.414\n",
            "Epoch:795, step = 6367, diffusion continuous loss: 0.305, discrete loss: 0.226\n",
            "Epoch:795, step = 6367, CL continuous loss: 0.878, discrete loss: 0.799\n",
            "Epoch:795, step = 6367, Total continuous loss: 0.481, discrete loss: 0.386\n",
            "Time taken: 0.408\n",
            "Time taken: 0.414\n",
            "Time taken: 0.414\n",
            "Time taken: 0.430\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.411\n",
            "Time taken: 0.418\n",
            "Epoch:796, step = 6375, diffusion continuous loss: 0.278, discrete loss: 0.223\n",
            "Epoch:796, step = 6375, CL continuous loss: 0.872, discrete loss: 0.790\n",
            "Epoch:796, step = 6375, Total continuous loss: 0.452, discrete loss: 0.381\n",
            "Time taken: 0.408\n",
            "Time taken: 0.415\n",
            "Time taken: 0.422\n",
            "Time taken: 0.416\n",
            "Time taken: 0.410\n",
            "Time taken: 0.439\n",
            "Time taken: 0.443\n",
            "Time taken: 0.443\n",
            "Epoch:797, step = 6383, diffusion continuous loss: 0.330, discrete loss: 0.210\n",
            "Epoch:797, step = 6383, CL continuous loss: 0.876, discrete loss: 0.789\n",
            "Epoch:797, step = 6383, Total continuous loss: 0.506, discrete loss: 0.368\n",
            "Time taken: 0.438\n",
            "Time taken: 0.448\n",
            "Time taken: 0.420\n",
            "Time taken: 0.414\n",
            "Time taken: 0.429\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Epoch:798, step = 6391, diffusion continuous loss: 0.314, discrete loss: 0.219\n",
            "Epoch:798, step = 6391, CL continuous loss: 0.876, discrete loss: 0.784\n",
            "Epoch:798, step = 6391, Total continuous loss: 0.489, discrete loss: 0.375\n",
            "Time taken: 0.407\n",
            "Time taken: 0.421\n",
            "Time taken: 0.415\n",
            "Time taken: 0.428\n",
            "Time taken: 0.417\n",
            "Time taken: 0.422\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Epoch:799, step = 6399, diffusion continuous loss: 0.299, discrete loss: 0.215\n",
            "Epoch:799, step = 6399, CL continuous loss: 0.899, discrete loss: 0.791\n",
            "Epoch:799, step = 6399, Total continuous loss: 0.479, discrete loss: 0.373\n",
            "Time taken: 0.540\n",
            "Time taken: 0.445\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.515\n",
            "Time taken: 0.427\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Epoch:800, step = 6407, diffusion continuous loss: 0.290, discrete loss: 0.218\n",
            "Epoch:800, step = 6407, CL continuous loss: 0.878, discrete loss: 0.774\n",
            "Epoch:800, step = 6407, Total continuous loss: 0.466, discrete loss: 0.373\n",
            "Time taken: 0.411\n",
            "Time taken: 0.424\n",
            "Time taken: 0.444\n",
            "Time taken: 0.444\n",
            "Time taken: 0.444\n",
            "Time taken: 0.453\n",
            "Time taken: 0.452\n",
            "Time taken: 0.418\n",
            "Epoch:801, step = 6415, diffusion continuous loss: 0.270, discrete loss: 0.216\n",
            "Epoch:801, step = 6415, CL continuous loss: 0.881, discrete loss: 0.773\n",
            "Epoch:801, step = 6415, Total continuous loss: 0.446, discrete loss: 0.371\n",
            "Time taken: 0.403\n",
            "Time taken: 0.420\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Time taken: 0.412\n",
            "Time taken: 0.421\n",
            "Time taken: 0.415\n",
            "Epoch:802, step = 6423, diffusion continuous loss: 0.277, discrete loss: 0.215\n",
            "Epoch:802, step = 6423, CL continuous loss: 0.879, discrete loss: 0.789\n",
            "Epoch:802, step = 6423, Total continuous loss: 0.453, discrete loss: 0.372\n",
            "Time taken: 0.409\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.413\n",
            "Time taken: 0.421\n",
            "Time taken: 0.409\n",
            "Time taken: 0.413\n",
            "Epoch:803, step = 6431, diffusion continuous loss: 0.282, discrete loss: 0.220\n",
            "Epoch:803, step = 6431, CL continuous loss: 0.865, discrete loss: 0.792\n",
            "Epoch:803, step = 6431, Total continuous loss: 0.455, discrete loss: 0.378\n",
            "Time taken: 0.412\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.425\n",
            "Time taken: 0.419\n",
            "Time taken: 0.440\n",
            "Epoch:804, step = 6439, diffusion continuous loss: 0.267, discrete loss: 0.216\n",
            "Epoch:804, step = 6439, CL continuous loss: 0.857, discrete loss: 0.788\n",
            "Epoch:804, step = 6439, Total continuous loss: 0.438, discrete loss: 0.374\n",
            "Time taken: 0.439\n",
            "Time taken: 0.438\n",
            "Time taken: 0.471\n",
            "Time taken: 0.592\n",
            "Time taken: 0.430\n",
            "Time taken: 0.414\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Epoch:805, step = 6447, diffusion continuous loss: 0.320, discrete loss: 0.214\n",
            "Epoch:805, step = 6447, CL continuous loss: 0.867, discrete loss: 0.775\n",
            "Epoch:805, step = 6447, Total continuous loss: 0.493, discrete loss: 0.369\n",
            "Time taken: 0.409\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.412\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Epoch:806, step = 6455, diffusion continuous loss: 0.300, discrete loss: 0.214\n",
            "Epoch:806, step = 6455, CL continuous loss: 0.903, discrete loss: 0.788\n",
            "Epoch:806, step = 6455, Total continuous loss: 0.481, discrete loss: 0.371\n",
            "Time taken: 0.409\n",
            "Time taken: 0.413\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.414\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Epoch:807, step = 6463, diffusion continuous loss: 0.280, discrete loss: 0.224\n",
            "Epoch:807, step = 6463, CL continuous loss: 0.867, discrete loss: 0.782\n",
            "Epoch:807, step = 6463, Total continuous loss: 0.453, discrete loss: 0.380\n",
            "Time taken: 0.406\n",
            "Time taken: 0.410\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.442\n",
            "Time taken: 0.456\n",
            "Time taken: 0.439\n",
            "Time taken: 0.442\n",
            "Epoch:808, step = 6471, diffusion continuous loss: 0.284, discrete loss: 0.218\n",
            "Epoch:808, step = 6471, CL continuous loss: 0.858, discrete loss: 0.781\n",
            "Epoch:808, step = 6471, Total continuous loss: 0.456, discrete loss: 0.374\n",
            "Time taken: 0.442\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.410\n",
            "Time taken: 0.419\n",
            "Epoch:809, step = 6479, diffusion continuous loss: 0.281, discrete loss: 0.216\n",
            "Epoch:809, step = 6479, CL continuous loss: 0.875, discrete loss: 0.773\n",
            "Epoch:809, step = 6479, Total continuous loss: 0.456, discrete loss: 0.371\n",
            "Time taken: 0.405\n",
            "Time taken: 0.417\n",
            "Time taken: 0.414\n",
            "Time taken: 0.515\n",
            "Time taken: 0.426\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.414\n",
            "Epoch:810, step = 6487, diffusion continuous loss: 0.300, discrete loss: 0.219\n",
            "Epoch:810, step = 6487, CL continuous loss: 0.857, discrete loss: 0.781\n",
            "Epoch:810, step = 6487, Total continuous loss: 0.472, discrete loss: 0.376\n",
            "Time taken: 0.404\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.414\n",
            "Time taken: 0.419\n",
            "Epoch:811, step = 6495, diffusion continuous loss: 0.270, discrete loss: 0.221\n",
            "Epoch:811, step = 6495, CL continuous loss: 0.896, discrete loss: 0.786\n",
            "Epoch:811, step = 6495, Total continuous loss: 0.450, discrete loss: 0.379\n",
            "Time taken: 0.410\n",
            "Time taken: 0.441\n",
            "Time taken: 0.438\n",
            "Time taken: 0.437\n",
            "Time taken: 0.453\n",
            "Time taken: 0.449\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Epoch:812, step = 6503, diffusion continuous loss: 0.268, discrete loss: 0.211\n",
            "Epoch:812, step = 6503, CL continuous loss: 0.862, discrete loss: 0.787\n",
            "Epoch:812, step = 6503, Total continuous loss: 0.440, discrete loss: 0.368\n",
            "Time taken: 0.402\n",
            "Time taken: 0.418\n",
            "Time taken: 0.414\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Time taken: 0.412\n",
            "Time taken: 0.418\n",
            "Epoch:813, step = 6511, diffusion continuous loss: 0.291, discrete loss: 0.226\n",
            "Epoch:813, step = 6511, CL continuous loss: 0.913, discrete loss: 0.789\n",
            "Epoch:813, step = 6511, Total continuous loss: 0.474, discrete loss: 0.384\n",
            "Time taken: 0.403\n",
            "Time taken: 0.421\n",
            "Time taken: 0.414\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Time taken: 0.412\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Epoch:814, step = 6519, diffusion continuous loss: 0.279, discrete loss: 0.214\n",
            "Epoch:814, step = 6519, CL continuous loss: 0.874, discrete loss: 0.778\n",
            "Epoch:814, step = 6519, Total continuous loss: 0.454, discrete loss: 0.369\n",
            "Time taken: 0.411\n",
            "Time taken: 0.415\n",
            "Time taken: 0.517\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.445\n",
            "Time taken: 0.437\n",
            "Epoch:815, step = 6527, diffusion continuous loss: 0.290, discrete loss: 0.214\n",
            "Epoch:815, step = 6527, CL continuous loss: 0.865, discrete loss: 0.783\n",
            "Epoch:815, step = 6527, Total continuous loss: 0.463, discrete loss: 0.370\n",
            "Time taken: 0.425\n",
            "Time taken: 0.445\n",
            "Time taken: 0.459\n",
            "Time taken: 0.416\n",
            "Time taken: 0.422\n",
            "Time taken: 0.414\n",
            "Time taken: 0.419\n",
            "Time taken: 0.426\n",
            "Epoch:816, step = 6535, diffusion continuous loss: 0.279, discrete loss: 0.217\n",
            "Epoch:816, step = 6535, CL continuous loss: 0.848, discrete loss: 0.775\n",
            "Epoch:816, step = 6535, Total continuous loss: 0.448, discrete loss: 0.372\n",
            "Time taken: 0.404\n",
            "Time taken: 0.419\n",
            "Time taken: 0.415\n",
            "Time taken: 0.412\n",
            "Time taken: 0.428\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.414\n",
            "Epoch:817, step = 6543, diffusion continuous loss: 0.318, discrete loss: 0.216\n",
            "Epoch:817, step = 6543, CL continuous loss: 0.856, discrete loss: 0.776\n",
            "Epoch:817, step = 6543, Total continuous loss: 0.489, discrete loss: 0.372\n",
            "Time taken: 0.403\n",
            "Time taken: 0.423\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Time taken: 0.414\n",
            "Time taken: 0.416\n",
            "Epoch:818, step = 6551, diffusion continuous loss: 0.285, discrete loss: 0.231\n",
            "Epoch:818, step = 6551, CL continuous loss: 0.902, discrete loss: 0.781\n",
            "Epoch:818, step = 6551, Total continuous loss: 0.465, discrete loss: 0.387\n",
            "Time taken: 0.411\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.452\n",
            "Time taken: 0.447\n",
            "Time taken: 0.444\n",
            "Time taken: 0.441\n",
            "Time taken: 0.445\n",
            "Epoch:819, step = 6559, diffusion continuous loss: 0.262, discrete loss: 0.213\n",
            "Epoch:819, step = 6559, CL continuous loss: 0.864, discrete loss: 0.792\n",
            "Epoch:819, step = 6559, Total continuous loss: 0.434, discrete loss: 0.372\n",
            "Time taken: 0.551\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.413\n",
            "Time taken: 0.418\n",
            "Time taken: 0.413\n",
            "Time taken: 0.417\n",
            "Time taken: 0.414\n",
            "Epoch:820, step = 6567, diffusion continuous loss: 0.287, discrete loss: 0.213\n",
            "Epoch:820, step = 6567, CL continuous loss: 0.871, discrete loss: 0.779\n",
            "Epoch:820, step = 6567, Total continuous loss: 0.461, discrete loss: 0.369\n",
            "Time taken: 0.412\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.412\n",
            "Time taken: 0.418\n",
            "Time taken: 0.411\n",
            "Time taken: 0.418\n",
            "Time taken: 0.412\n",
            "Epoch:821, step = 6575, diffusion continuous loss: 0.273, discrete loss: 0.218\n",
            "Epoch:821, step = 6575, CL continuous loss: 0.878, discrete loss: 0.789\n",
            "Epoch:821, step = 6575, Total continuous loss: 0.449, discrete loss: 0.376\n",
            "Time taken: 0.411\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Time taken: 0.422\n",
            "Time taken: 0.418\n",
            "Time taken: 0.424\n",
            "Time taken: 0.417\n",
            "Time taken: 0.414\n",
            "Epoch:822, step = 6583, diffusion continuous loss: 0.297, discrete loss: 0.210\n",
            "Epoch:822, step = 6583, CL continuous loss: 0.874, discrete loss: 0.778\n",
            "Epoch:822, step = 6583, Total continuous loss: 0.472, discrete loss: 0.366\n",
            "Time taken: 0.437\n",
            "Time taken: 0.438\n",
            "Time taken: 0.444\n",
            "Time taken: 0.433\n",
            "Time taken: 0.445\n",
            "Time taken: 0.445\n",
            "Time taken: 0.411\n",
            "Time taken: 0.417\n",
            "Epoch:823, step = 6591, diffusion continuous loss: 0.269, discrete loss: 0.218\n",
            "Epoch:823, step = 6591, CL continuous loss: 0.866, discrete loss: 0.794\n",
            "Epoch:823, step = 6591, Total continuous loss: 0.442, discrete loss: 0.377\n",
            "Time taken: 0.409\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.414\n",
            "Time taken: 0.422\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.507\n",
            "Epoch:824, step = 6599, diffusion continuous loss: 0.276, discrete loss: 0.216\n",
            "Epoch:824, step = 6599, CL continuous loss: 0.859, discrete loss: 0.777\n",
            "Epoch:824, step = 6599, Total continuous loss: 0.448, discrete loss: 0.372\n",
            "Time taken: 0.408\n",
            "Time taken: 0.423\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.422\n",
            "Time taken: 0.417\n",
            "Epoch:825, step = 6607, diffusion continuous loss: 0.330, discrete loss: 0.209\n",
            "Epoch:825, step = 6607, CL continuous loss: 0.905, discrete loss: 0.784\n",
            "Epoch:825, step = 6607, Total continuous loss: 0.511, discrete loss: 0.366\n",
            "Time taken: 0.408\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Time taken: 0.412\n",
            "Time taken: 0.442\n",
            "Time taken: 0.448\n",
            "Time taken: 0.438\n",
            "Epoch:826, step = 6615, diffusion continuous loss: 0.296, discrete loss: 0.219\n",
            "Epoch:826, step = 6615, CL continuous loss: 0.877, discrete loss: 0.790\n",
            "Epoch:826, step = 6615, Total continuous loss: 0.471, discrete loss: 0.377\n",
            "Time taken: 0.447\n",
            "Time taken: 0.442\n",
            "Time taken: 0.443\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Time taken: 0.414\n",
            "Time taken: 0.414\n",
            "Time taken: 0.422\n",
            "Epoch:827, step = 6623, diffusion continuous loss: 0.301, discrete loss: 0.221\n",
            "Epoch:827, step = 6623, CL continuous loss: 0.896, discrete loss: 0.784\n",
            "Epoch:827, step = 6623, Total continuous loss: 0.480, discrete loss: 0.378\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.422\n",
            "Time taken: 0.419\n",
            "Time taken: 0.414\n",
            "Time taken: 0.416\n",
            "Epoch:828, step = 6631, diffusion continuous loss: 0.280, discrete loss: 0.211\n",
            "Epoch:828, step = 6631, CL continuous loss: 0.874, discrete loss: 0.783\n",
            "Epoch:828, step = 6631, Total continuous loss: 0.455, discrete loss: 0.368\n",
            "Time taken: 0.401\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Time taken: 0.515\n",
            "Time taken: 0.426\n",
            "Time taken: 0.422\n",
            "Epoch:829, step = 6639, diffusion continuous loss: 0.271, discrete loss: 0.215\n",
            "Epoch:829, step = 6639, CL continuous loss: 0.879, discrete loss: 0.791\n",
            "Epoch:829, step = 6639, Total continuous loss: 0.447, discrete loss: 0.373\n",
            "Time taken: 0.407\n",
            "Time taken: 0.420\n",
            "Time taken: 0.449\n",
            "Time taken: 0.446\n",
            "Time taken: 0.436\n",
            "Time taken: 0.443\n",
            "Time taken: 0.448\n",
            "Time taken: 0.438\n",
            "Epoch:830, step = 6647, diffusion continuous loss: 0.266, discrete loss: 0.217\n",
            "Epoch:830, step = 6647, CL continuous loss: 0.874, discrete loss: 0.788\n",
            "Epoch:830, step = 6647, Total continuous loss: 0.441, discrete loss: 0.375\n",
            "Time taken: 0.411\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.412\n",
            "Time taken: 0.421\n",
            "Time taken: 0.422\n",
            "Time taken: 0.413\n",
            "Time taken: 0.421\n",
            "Epoch:831, step = 6655, diffusion continuous loss: 0.267, discrete loss: 0.222\n",
            "Epoch:831, step = 6655, CL continuous loss: 0.861, discrete loss: 0.785\n",
            "Epoch:831, step = 6655, Total continuous loss: 0.439, discrete loss: 0.379\n",
            "Time taken: 0.408\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Epoch:832, step = 6663, diffusion continuous loss: 0.300, discrete loss: 0.204\n",
            "Epoch:832, step = 6663, CL continuous loss: 0.871, discrete loss: 0.781\n",
            "Epoch:832, step = 6663, Total continuous loss: 0.475, discrete loss: 0.360\n",
            "Time taken: 0.425\n",
            "Time taken: 0.444\n",
            "Time taken: 0.437\n",
            "Time taken: 0.437\n",
            "Time taken: 0.441\n",
            "Time taken: 0.451\n",
            "Time taken: 0.419\n",
            "Time taken: 0.445\n",
            "Epoch:833, step = 6671, diffusion continuous loss: 0.286, discrete loss: 0.210\n",
            "Epoch:833, step = 6671, CL continuous loss: 0.873, discrete loss: 0.788\n",
            "Epoch:833, step = 6671, Total continuous loss: 0.460, discrete loss: 0.368\n",
            "Time taken: 0.434\n",
            "Time taken: 0.442\n",
            "Time taken: 0.443\n",
            "Time taken: 0.448\n",
            "Time taken: 0.533\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.421\n",
            "Epoch:834, step = 6679, diffusion continuous loss: 0.280, discrete loss: 0.218\n",
            "Epoch:834, step = 6679, CL continuous loss: 0.874, discrete loss: 0.772\n",
            "Epoch:834, step = 6679, Total continuous loss: 0.454, discrete loss: 0.373\n",
            "Time taken: 0.409\n",
            "Time taken: 0.414\n",
            "Time taken: 0.416\n",
            "Time taken: 0.414\n",
            "Time taken: 0.419\n",
            "Time taken: 0.410\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Epoch:835, step = 6687, diffusion continuous loss: 0.285, discrete loss: 0.212\n",
            "Epoch:835, step = 6687, CL continuous loss: 0.878, discrete loss: 0.768\n",
            "Epoch:835, step = 6687, Total continuous loss: 0.460, discrete loss: 0.366\n",
            "Time taken: 0.410\n",
            "Time taken: 0.421\n",
            "Time taken: 0.413\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.419\n",
            "Epoch:836, step = 6695, diffusion continuous loss: 0.279, discrete loss: 0.226\n",
            "Epoch:836, step = 6695, CL continuous loss: 0.878, discrete loss: 0.780\n",
            "Epoch:836, step = 6695, Total continuous loss: 0.455, discrete loss: 0.382\n",
            "Time taken: 0.410\n",
            "Time taken: 0.421\n",
            "Time taken: 0.413\n",
            "Time taken: 0.419\n",
            "Time taken: 0.448\n",
            "Time taken: 0.437\n",
            "Time taken: 0.440\n",
            "Time taken: 0.440\n",
            "Epoch:837, step = 6703, diffusion continuous loss: 0.274, discrete loss: 0.214\n",
            "Epoch:837, step = 6703, CL continuous loss: 0.867, discrete loss: 0.779\n",
            "Epoch:837, step = 6703, Total continuous loss: 0.448, discrete loss: 0.370\n",
            "Time taken: 0.456\n",
            "Time taken: 0.434\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Time taken: 0.429\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Epoch:838, step = 6711, diffusion continuous loss: 0.334, discrete loss: 0.207\n",
            "Epoch:838, step = 6711, CL continuous loss: 0.893, discrete loss: 0.783\n",
            "Epoch:838, step = 6711, Total continuous loss: 0.513, discrete loss: 0.363\n",
            "Time taken: 0.407\n",
            "Time taken: 0.419\n",
            "Time taken: 0.511\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.414\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Epoch:839, step = 6719, diffusion continuous loss: 0.276, discrete loss: 0.227\n",
            "Epoch:839, step = 6719, CL continuous loss: 0.899, discrete loss: 0.785\n",
            "Epoch:839, step = 6719, Total continuous loss: 0.455, discrete loss: 0.384\n",
            "Time taken: 0.405\n",
            "Time taken: 0.419\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.412\n",
            "Time taken: 0.423\n",
            "Time taken: 0.419\n",
            "Time taken: 0.415\n",
            "Epoch:840, step = 6727, diffusion continuous loss: 0.274, discrete loss: 0.224\n",
            "Epoch:840, step = 6727, CL continuous loss: 0.870, discrete loss: 0.791\n",
            "Epoch:840, step = 6727, Total continuous loss: 0.448, discrete loss: 0.382\n",
            "Time taken: 0.413\n",
            "Time taken: 0.447\n",
            "Time taken: 0.440\n",
            "Time taken: 0.436\n",
            "Time taken: 0.444\n",
            "Time taken: 0.455\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Epoch:841, step = 6735, diffusion continuous loss: 0.266, discrete loss: 0.233\n",
            "Epoch:841, step = 6735, CL continuous loss: 0.858, discrete loss: 0.805\n",
            "Epoch:841, step = 6735, Total continuous loss: 0.438, discrete loss: 0.394\n",
            "Time taken: 0.410\n",
            "Time taken: 0.415\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.412\n",
            "Time taken: 0.417\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Epoch:842, step = 6743, diffusion continuous loss: 0.309, discrete loss: 0.227\n",
            "Epoch:842, step = 6743, CL continuous loss: 0.892, discrete loss: 0.794\n",
            "Epoch:842, step = 6743, Total continuous loss: 0.488, discrete loss: 0.386\n",
            "Time taken: 0.406\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.412\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Epoch:843, step = 6751, diffusion continuous loss: 0.352, discrete loss: 0.207\n",
            "Epoch:843, step = 6751, CL continuous loss: 0.916, discrete loss: 0.804\n",
            "Epoch:843, step = 6751, Total continuous loss: 0.535, discrete loss: 0.368\n",
            "Time taken: 0.416\n",
            "Time taken: 0.534\n",
            "Time taken: 0.424\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Time taken: 0.448\n",
            "Time taken: 0.443\n",
            "Epoch:844, step = 6759, diffusion continuous loss: 0.308, discrete loss: 0.212\n",
            "Epoch:844, step = 6759, CL continuous loss: 0.887, discrete loss: 0.802\n",
            "Epoch:844, step = 6759, Total continuous loss: 0.486, discrete loss: 0.372\n",
            "Time taken: 0.433\n",
            "Time taken: 0.447\n",
            "Time taken: 0.451\n",
            "Time taken: 0.435\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.413\n",
            "Time taken: 0.416\n",
            "Epoch:845, step = 6767, diffusion continuous loss: 0.305, discrete loss: 0.277\n",
            "Epoch:845, step = 6767, CL continuous loss: 0.896, discrete loss: 0.834\n",
            "Epoch:845, step = 6767, Total continuous loss: 0.484, discrete loss: 0.443\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.422\n",
            "Epoch:846, step = 6775, diffusion continuous loss: 0.308, discrete loss: 0.285\n",
            "Epoch:846, step = 6775, CL continuous loss: 0.863, discrete loss: 0.873\n",
            "Epoch:846, step = 6775, Total continuous loss: 0.480, discrete loss: 0.460\n",
            "Time taken: 0.406\n",
            "Time taken: 0.424\n",
            "Time taken: 0.415\n",
            "Time taken: 0.422\n",
            "Time taken: 0.428\n",
            "Time taken: 0.418\n",
            "Time taken: 0.423\n",
            "Time taken: 0.418\n",
            "Epoch:847, step = 6783, diffusion continuous loss: 0.305, discrete loss: 0.284\n",
            "Epoch:847, step = 6783, CL continuous loss: 0.856, discrete loss: 0.924\n",
            "Epoch:847, step = 6783, Total continuous loss: 0.476, discrete loss: 0.469\n",
            "Time taken: 0.440\n",
            "Time taken: 0.429\n",
            "Time taken: 0.425\n",
            "Time taken: 0.463\n",
            "Time taken: 0.463\n",
            "Time taken: 0.446\n",
            "Time taken: 0.433\n",
            "Time taken: 0.582\n",
            "Epoch:848, step = 6791, diffusion continuous loss: 0.285, discrete loss: 0.287\n",
            "Epoch:848, step = 6791, CL continuous loss: 0.886, discrete loss: 0.927\n",
            "Epoch:848, step = 6791, Total continuous loss: 0.462, discrete loss: 0.473\n",
            "Time taken: 0.429\n",
            "Time taken: 0.425\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.414\n",
            "Time taken: 0.423\n",
            "Time taken: 0.422\n",
            "Time taken: 0.422\n",
            "Epoch:849, step = 6799, diffusion continuous loss: 0.326, discrete loss: 0.279\n",
            "Epoch:849, step = 6799, CL continuous loss: 0.866, discrete loss: 0.926\n",
            "Epoch:849, step = 6799, Total continuous loss: 0.500, discrete loss: 0.464\n",
            "Time taken: 0.406\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.412\n",
            "Epoch:850, step = 6807, diffusion continuous loss: 0.289, discrete loss: 0.270\n",
            "Epoch:850, step = 6807, CL continuous loss: 0.902, discrete loss: 0.929\n",
            "Epoch:850, step = 6807, Total continuous loss: 0.469, discrete loss: 0.455\n",
            "Time taken: 0.413\n",
            "Time taken: 0.422\n",
            "Time taken: 0.420\n",
            "Time taken: 0.421\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.423\n",
            "Time taken: 0.419\n",
            "Epoch:851, step = 6815, diffusion continuous loss: 0.321, discrete loss: 0.248\n",
            "Epoch:851, step = 6815, CL continuous loss: 0.938, discrete loss: 0.898\n",
            "Epoch:851, step = 6815, Total continuous loss: 0.508, discrete loss: 0.428\n",
            "Time taken: 0.423\n",
            "Time taken: 0.441\n",
            "Time taken: 0.446\n",
            "Time taken: 0.447\n",
            "Time taken: 0.456\n",
            "Time taken: 0.457\n",
            "Time taken: 0.414\n",
            "Time taken: 0.420\n",
            "Epoch:852, step = 6823, diffusion continuous loss: 0.287, discrete loss: 0.257\n",
            "Epoch:852, step = 6823, CL continuous loss: 0.899, discrete loss: 0.889\n",
            "Epoch:852, step = 6823, Total continuous loss: 0.467, discrete loss: 0.435\n",
            "Time taken: 0.407\n",
            "Time taken: 0.413\n",
            "Time taken: 0.424\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.511\n",
            "Time taken: 0.421\n",
            "Epoch:853, step = 6831, diffusion continuous loss: 0.274, discrete loss: 0.240\n",
            "Epoch:853, step = 6831, CL continuous loss: 0.873, discrete loss: 0.860\n",
            "Epoch:853, step = 6831, Total continuous loss: 0.448, discrete loss: 0.412\n",
            "Time taken: 0.412\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Epoch:854, step = 6839, diffusion continuous loss: 0.281, discrete loss: 0.230\n",
            "Epoch:854, step = 6839, CL continuous loss: 0.854, discrete loss: 0.847\n",
            "Epoch:854, step = 6839, Total continuous loss: 0.452, discrete loss: 0.399\n",
            "Time taken: 0.408\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.423\n",
            "Time taken: 0.420\n",
            "Time taken: 0.426\n",
            "Time taken: 0.447\n",
            "Time taken: 0.441\n",
            "Epoch:855, step = 6847, diffusion continuous loss: 0.268, discrete loss: 0.221\n",
            "Epoch:855, step = 6847, CL continuous loss: 0.852, discrete loss: 0.851\n",
            "Epoch:855, step = 6847, Total continuous loss: 0.438, discrete loss: 0.392\n",
            "Time taken: 0.433\n",
            "Time taken: 0.446\n",
            "Time taken: 0.460\n",
            "Time taken: 0.423\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Epoch:856, step = 6855, diffusion continuous loss: 0.282, discrete loss: 0.228\n",
            "Epoch:856, step = 6855, CL continuous loss: 0.900, discrete loss: 0.831\n",
            "Epoch:856, step = 6855, Total continuous loss: 0.462, discrete loss: 0.394\n",
            "Time taken: 0.412\n",
            "Time taken: 0.420\n",
            "Time taken: 0.422\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.423\n",
            "Epoch:857, step = 6863, diffusion continuous loss: 0.288, discrete loss: 0.221\n",
            "Epoch:857, step = 6863, CL continuous loss: 0.878, discrete loss: 0.824\n",
            "Epoch:857, step = 6863, Total continuous loss: 0.464, discrete loss: 0.386\n",
            "Time taken: 0.407\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.538\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.413\n",
            "Epoch:858, step = 6871, diffusion continuous loss: 0.274, discrete loss: 0.230\n",
            "Epoch:858, step = 6871, CL continuous loss: 0.886, discrete loss: 0.819\n",
            "Epoch:858, step = 6871, Total continuous loss: 0.451, discrete loss: 0.394\n",
            "Time taken: 0.412\n",
            "Time taken: 0.421\n",
            "Time taken: 0.423\n",
            "Time taken: 0.443\n",
            "Time taken: 0.441\n",
            "Time taken: 0.437\n",
            "Time taken: 0.453\n",
            "Time taken: 0.460\n",
            "Epoch:859, step = 6879, diffusion continuous loss: 0.260, discrete loss: 0.220\n",
            "Epoch:859, step = 6879, CL continuous loss: 0.877, discrete loss: 0.809\n",
            "Epoch:859, step = 6879, Total continuous loss: 0.436, discrete loss: 0.381\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.426\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.422\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Epoch:860, step = 6887, diffusion continuous loss: 0.263, discrete loss: 0.236\n",
            "Epoch:860, step = 6887, CL continuous loss: 0.865, discrete loss: 0.812\n",
            "Epoch:860, step = 6887, Total continuous loss: 0.436, discrete loss: 0.399\n",
            "Time taken: 0.405\n",
            "Time taken: 0.422\n",
            "Time taken: 0.424\n",
            "Time taken: 0.420\n",
            "Time taken: 0.421\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.435\n",
            "Epoch:861, step = 6895, diffusion continuous loss: 0.287, discrete loss: 0.235\n",
            "Epoch:861, step = 6895, CL continuous loss: 0.891, discrete loss: 0.812\n",
            "Epoch:861, step = 6895, Total continuous loss: 0.465, discrete loss: 0.397\n",
            "Time taken: 0.413\n",
            "Time taken: 0.422\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.432\n",
            "Time taken: 0.421\n",
            "Epoch:862, step = 6903, diffusion continuous loss: 0.326, discrete loss: 0.226\n",
            "Epoch:862, step = 6903, CL continuous loss: 0.875, discrete loss: 0.801\n",
            "Epoch:862, step = 6903, Total continuous loss: 0.501, discrete loss: 0.386\n",
            "Time taken: 0.446\n",
            "Time taken: 0.439\n",
            "Time taken: 0.442\n",
            "Time taken: 0.608\n",
            "Time taken: 0.452\n",
            "Time taken: 0.431\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Epoch:863, step = 6911, diffusion continuous loss: 0.330, discrete loss: 0.215\n",
            "Epoch:863, step = 6911, CL continuous loss: 0.894, discrete loss: 0.807\n",
            "Epoch:863, step = 6911, Total continuous loss: 0.509, discrete loss: 0.376\n",
            "Time taken: 0.408\n",
            "Time taken: 0.418\n",
            "Time taken: 0.423\n",
            "Time taken: 0.420\n",
            "Time taken: 0.427\n",
            "Time taken: 0.421\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Epoch:864, step = 6919, diffusion continuous loss: 0.302, discrete loss: 0.216\n",
            "Epoch:864, step = 6919, CL continuous loss: 0.875, discrete loss: 0.796\n",
            "Epoch:864, step = 6919, Total continuous loss: 0.477, discrete loss: 0.376\n",
            "Time taken: 0.412\n",
            "Time taken: 0.419\n",
            "Time taken: 0.423\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Epoch:865, step = 6927, diffusion continuous loss: 0.286, discrete loss: 0.216\n",
            "Epoch:865, step = 6927, CL continuous loss: 0.876, discrete loss: 0.801\n",
            "Epoch:865, step = 6927, Total continuous loss: 0.461, discrete loss: 0.376\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.443\n",
            "Time taken: 0.447\n",
            "Time taken: 0.435\n",
            "Epoch:866, step = 6935, diffusion continuous loss: 0.278, discrete loss: 0.228\n",
            "Epoch:866, step = 6935, CL continuous loss: 0.861, discrete loss: 0.794\n",
            "Epoch:866, step = 6935, Total continuous loss: 0.451, discrete loss: 0.387\n",
            "Time taken: 0.445\n",
            "Time taken: 0.451\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Time taken: 0.415\n",
            "Time taken: 0.425\n",
            "Time taken: 0.418\n",
            "Time taken: 0.413\n",
            "Epoch:867, step = 6943, diffusion continuous loss: 0.295, discrete loss: 0.217\n",
            "Epoch:867, step = 6943, CL continuous loss: 0.886, discrete loss: 0.797\n",
            "Epoch:867, step = 6943, Total continuous loss: 0.472, discrete loss: 0.377\n",
            "Time taken: 0.411\n",
            "Time taken: 0.517\n",
            "Time taken: 0.421\n",
            "Time taken: 0.421\n",
            "Time taken: 0.411\n",
            "Time taken: 0.414\n",
            "Time taken: 0.419\n",
            "Time taken: 0.424\n",
            "Epoch:868, step = 6951, diffusion continuous loss: 0.304, discrete loss: 0.213\n",
            "Epoch:868, step = 6951, CL continuous loss: 0.879, discrete loss: 0.805\n",
            "Epoch:868, step = 6951, Total continuous loss: 0.479, discrete loss: 0.374\n",
            "Time taken: 0.407\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.427\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Epoch:869, step = 6959, diffusion continuous loss: 0.282, discrete loss: 0.221\n",
            "Epoch:869, step = 6959, CL continuous loss: 0.874, discrete loss: 0.801\n",
            "Epoch:869, step = 6959, Total continuous loss: 0.456, discrete loss: 0.381\n",
            "Time taken: 0.402\n",
            "Time taken: 0.431\n",
            "Time taken: 0.447\n",
            "Time taken: 0.440\n",
            "Time taken: 0.437\n",
            "Time taken: 0.449\n",
            "Time taken: 0.446\n",
            "Time taken: 0.415\n",
            "Epoch:870, step = 6967, diffusion continuous loss: 0.282, discrete loss: 0.223\n",
            "Epoch:870, step = 6967, CL continuous loss: 0.865, discrete loss: 0.798\n",
            "Epoch:870, step = 6967, Total continuous loss: 0.455, discrete loss: 0.383\n",
            "Time taken: 0.412\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Time taken: 0.412\n",
            "Time taken: 0.416\n",
            "Time taken: 0.414\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Epoch:871, step = 6975, diffusion continuous loss: 0.277, discrete loss: 0.210\n",
            "Epoch:871, step = 6975, CL continuous loss: 0.867, discrete loss: 0.795\n",
            "Epoch:871, step = 6975, Total continuous loss: 0.450, discrete loss: 0.369\n",
            "Time taken: 0.410\n",
            "Time taken: 0.416\n",
            "Time taken: 0.422\n",
            "Time taken: 0.415\n",
            "Time taken: 0.422\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Epoch:872, step = 6983, diffusion continuous loss: 0.295, discrete loss: 0.222\n",
            "Epoch:872, step = 6983, CL continuous loss: 0.882, discrete loss: 0.794\n",
            "Epoch:872, step = 6983, Total continuous loss: 0.471, discrete loss: 0.381\n",
            "Time taken: 0.505\n",
            "Time taken: 0.422\n",
            "Time taken: 0.422\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.447\n",
            "Epoch:873, step = 6991, diffusion continuous loss: 0.306, discrete loss: 0.222\n",
            "Epoch:873, step = 6991, CL continuous loss: 0.920, discrete loss: 0.794\n",
            "Epoch:873, step = 6991, Total continuous loss: 0.490, discrete loss: 0.381\n",
            "Time taken: 0.426\n",
            "Time taken: 0.438\n",
            "Time taken: 0.453\n",
            "Time taken: 0.458\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Epoch:874, step = 6999, diffusion continuous loss: 0.296, discrete loss: 0.226\n",
            "Epoch:874, step = 6999, CL continuous loss: 0.876, discrete loss: 0.794\n",
            "Epoch:874, step = 6999, Total continuous loss: 0.472, discrete loss: 0.385\n",
            "Time taken: 0.413\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.423\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Epoch:875, step = 7007, diffusion continuous loss: 0.278, discrete loss: 0.222\n",
            "Epoch:875, step = 7007, CL continuous loss: 0.881, discrete loss: 0.799\n",
            "Epoch:875, step = 7007, Total continuous loss: 0.454, discrete loss: 0.382\n",
            "Time taken: 0.413\n",
            "Time taken: 0.420\n",
            "Time taken: 0.426\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.423\n",
            "Epoch:876, step = 7015, diffusion continuous loss: 0.298, discrete loss: 0.218\n",
            "Epoch:876, step = 7015, CL continuous loss: 0.864, discrete loss: 0.789\n",
            "Epoch:876, step = 7015, Total continuous loss: 0.471, discrete loss: 0.375\n",
            "Time taken: 0.411\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.444\n",
            "Time taken: 0.435\n",
            "Time taken: 0.594\n",
            "Time taken: 0.444\n",
            "Epoch:877, step = 7023, diffusion continuous loss: 0.268, discrete loss: 0.210\n",
            "Epoch:877, step = 7023, CL continuous loss: 0.862, discrete loss: 0.778\n",
            "Epoch:877, step = 7023, Total continuous loss: 0.440, discrete loss: 0.365\n",
            "Time taken: 0.447\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.423\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Epoch:878, step = 7031, diffusion continuous loss: 0.268, discrete loss: 0.220\n",
            "Epoch:878, step = 7031, CL continuous loss: 0.869, discrete loss: 0.780\n",
            "Epoch:878, step = 7031, Total continuous loss: 0.441, discrete loss: 0.376\n",
            "Time taken: 0.409\n",
            "Time taken: 0.411\n",
            "Time taken: 0.421\n",
            "Time taken: 0.412\n",
            "Time taken: 0.422\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Epoch:879, step = 7039, diffusion continuous loss: 0.296, discrete loss: 0.223\n",
            "Epoch:879, step = 7039, CL continuous loss: 0.870, discrete loss: 0.783\n",
            "Epoch:879, step = 7039, Total continuous loss: 0.470, discrete loss: 0.379\n",
            "Time taken: 0.406\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Epoch:880, step = 7047, diffusion continuous loss: 0.314, discrete loss: 0.215\n",
            "Epoch:880, step = 7047, CL continuous loss: 0.880, discrete loss: 0.784\n",
            "Epoch:880, step = 7047, Total continuous loss: 0.490, discrete loss: 0.372\n",
            "Time taken: 0.408\n",
            "Time taken: 0.437\n",
            "Time taken: 0.445\n",
            "Time taken: 0.456\n",
            "Time taken: 0.446\n",
            "Time taken: 0.448\n",
            "Time taken: 0.422\n",
            "Time taken: 0.419\n",
            "Epoch:881, step = 7055, diffusion continuous loss: 0.295, discrete loss: 0.207\n",
            "Epoch:881, step = 7055, CL continuous loss: 0.894, discrete loss: 0.788\n",
            "Epoch:881, step = 7055, Total continuous loss: 0.474, discrete loss: 0.365\n",
            "Time taken: 0.407\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.425\n",
            "Time taken: 0.418\n",
            "Time taken: 0.531\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Epoch:882, step = 7063, diffusion continuous loss: 0.275, discrete loss: 0.217\n",
            "Epoch:882, step = 7063, CL continuous loss: 0.876, discrete loss: 0.788\n",
            "Epoch:882, step = 7063, Total continuous loss: 0.450, discrete loss: 0.375\n",
            "Time taken: 0.410\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.413\n",
            "Time taken: 0.417\n",
            "Time taken: 0.414\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Epoch:883, step = 7071, diffusion continuous loss: 0.266, discrete loss: 0.226\n",
            "Epoch:883, step = 7071, CL continuous loss: 0.865, discrete loss: 0.789\n",
            "Epoch:883, step = 7071, Total continuous loss: 0.439, discrete loss: 0.384\n",
            "Time taken: 0.411\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.423\n",
            "Time taken: 0.418\n",
            "Time taken: 0.435\n",
            "Time taken: 0.436\n",
            "Epoch:884, step = 7079, diffusion continuous loss: 0.276, discrete loss: 0.206\n",
            "Epoch:884, step = 7079, CL continuous loss: 0.856, discrete loss: 0.779\n",
            "Epoch:884, step = 7079, Total continuous loss: 0.447, discrete loss: 0.361\n",
            "Time taken: 0.429\n",
            "Time taken: 0.453\n",
            "Time taken: 0.447\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.421\n",
            "Time taken: 0.412\n",
            "Time taken: 0.416\n",
            "Epoch:885, step = 7087, diffusion continuous loss: 0.282, discrete loss: 0.225\n",
            "Epoch:885, step = 7087, CL continuous loss: 0.859, discrete loss: 0.777\n",
            "Epoch:885, step = 7087, Total continuous loss: 0.454, discrete loss: 0.380\n",
            "Time taken: 0.409\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.412\n",
            "Time taken: 0.418\n",
            "Epoch:886, step = 7095, diffusion continuous loss: 0.264, discrete loss: 0.213\n",
            "Epoch:886, step = 7095, CL continuous loss: 0.867, discrete loss: 0.784\n",
            "Epoch:886, step = 7095, Total continuous loss: 0.437, discrete loss: 0.370\n",
            "Time taken: 0.406\n",
            "Time taken: 0.415\n",
            "Time taken: 0.421\n",
            "Time taken: 0.513\n",
            "Time taken: 0.415\n",
            "Time taken: 0.423\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Epoch:887, step = 7103, diffusion continuous loss: 0.270, discrete loss: 0.217\n",
            "Epoch:887, step = 7103, CL continuous loss: 0.899, discrete loss: 0.787\n",
            "Epoch:887, step = 7103, Total continuous loss: 0.450, discrete loss: 0.375\n",
            "Time taken: 0.411\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Time taken: 0.450\n",
            "Time taken: 0.440\n",
            "Time taken: 0.439\n",
            "Time taken: 0.461\n",
            "Time taken: 0.447\n",
            "Epoch:888, step = 7111, diffusion continuous loss: 0.282, discrete loss: 0.216\n",
            "Epoch:888, step = 7111, CL continuous loss: 0.897, discrete loss: 0.778\n",
            "Epoch:888, step = 7111, Total continuous loss: 0.461, discrete loss: 0.371\n",
            "Time taken: 0.405\n",
            "Time taken: 0.428\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.412\n",
            "Time taken: 0.419\n",
            "Epoch:889, step = 7119, diffusion continuous loss: 0.271, discrete loss: 0.211\n",
            "Epoch:889, step = 7119, CL continuous loss: 0.858, discrete loss: 0.788\n",
            "Epoch:889, step = 7119, Total continuous loss: 0.442, discrete loss: 0.369\n",
            "Time taken: 0.407\n",
            "Time taken: 0.418\n",
            "Time taken: 0.423\n",
            "Time taken: 0.416\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Epoch:890, step = 7127, diffusion continuous loss: 0.277, discrete loss: 0.228\n",
            "Epoch:890, step = 7127, CL continuous loss: 0.863, discrete loss: 0.783\n",
            "Epoch:890, step = 7127, Total continuous loss: 0.449, discrete loss: 0.384\n",
            "Time taken: 0.410\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.413\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Epoch:891, step = 7135, diffusion continuous loss: 0.274, discrete loss: 0.218\n",
            "Epoch:891, step = 7135, CL continuous loss: 0.886, discrete loss: 0.798\n",
            "Epoch:891, step = 7135, Total continuous loss: 0.451, discrete loss: 0.378\n",
            "Time taken: 0.437\n",
            "Time taken: 0.437\n",
            "Time taken: 0.572\n",
            "Time taken: 0.447\n",
            "Time taken: 0.456\n",
            "Time taken: 0.416\n",
            "Time taken: 0.422\n",
            "Time taken: 0.421\n",
            "Epoch:892, step = 7143, diffusion continuous loss: 0.314, discrete loss: 0.216\n",
            "Epoch:892, step = 7143, CL continuous loss: 0.888, discrete loss: 0.785\n",
            "Epoch:892, step = 7143, Total continuous loss: 0.492, discrete loss: 0.373\n",
            "Time taken: 0.406\n",
            "Time taken: 0.420\n",
            "Time taken: 0.411\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Epoch:893, step = 7151, diffusion continuous loss: 0.320, discrete loss: 0.214\n",
            "Epoch:893, step = 7151, CL continuous loss: 0.870, discrete loss: 0.802\n",
            "Epoch:893, step = 7151, Total continuous loss: 0.494, discrete loss: 0.375\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.427\n",
            "Time taken: 0.411\n",
            "Time taken: 0.419\n",
            "Epoch:894, step = 7159, diffusion continuous loss: 0.280, discrete loss: 0.225\n",
            "Epoch:894, step = 7159, CL continuous loss: 0.875, discrete loss: 0.783\n",
            "Epoch:894, step = 7159, Total continuous loss: 0.455, discrete loss: 0.381\n",
            "Time taken: 0.409\n",
            "Time taken: 0.419\n",
            "Time taken: 0.422\n",
            "Time taken: 0.421\n",
            "Time taken: 0.424\n",
            "Time taken: 0.445\n",
            "Time taken: 0.443\n",
            "Time taken: 0.437\n",
            "Epoch:895, step = 7167, diffusion continuous loss: 0.307, discrete loss: 0.215\n",
            "Epoch:895, step = 7167, CL continuous loss: 0.863, discrete loss: 0.775\n",
            "Epoch:895, step = 7167, Total continuous loss: 0.480, discrete loss: 0.370\n",
            "Time taken: 0.432\n",
            "Time taken: 0.450\n",
            "Time taken: 0.434\n",
            "Time taken: 0.415\n",
            "Time taken: 0.414\n",
            "Time taken: 0.414\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Epoch:896, step = 7175, diffusion continuous loss: 0.280, discrete loss: 0.225\n",
            "Epoch:896, step = 7175, CL continuous loss: 0.884, discrete loss: 0.788\n",
            "Epoch:896, step = 7175, Total continuous loss: 0.456, discrete loss: 0.383\n",
            "Time taken: 0.505\n",
            "Time taken: 0.412\n",
            "Time taken: 0.418\n",
            "Time taken: 0.429\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.415\n",
            "Epoch:897, step = 7183, diffusion continuous loss: 0.294, discrete loss: 0.217\n",
            "Epoch:897, step = 7183, CL continuous loss: 0.869, discrete loss: 0.785\n",
            "Epoch:897, step = 7183, Total continuous loss: 0.468, discrete loss: 0.374\n",
            "Time taken: 0.414\n",
            "Time taken: 0.413\n",
            "Time taken: 0.417\n",
            "Time taken: 0.412\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Epoch:898, step = 7191, diffusion continuous loss: 0.331, discrete loss: 0.225\n",
            "Epoch:898, step = 7191, CL continuous loss: 0.883, discrete loss: 0.788\n",
            "Epoch:898, step = 7191, Total continuous loss: 0.508, discrete loss: 0.382\n",
            "Time taken: 0.409\n",
            "Time taken: 0.422\n",
            "Time taken: 0.454\n",
            "Time taken: 0.435\n",
            "Time taken: 0.447\n",
            "Time taken: 0.442\n",
            "Time taken: 0.453\n",
            "Time taken: 0.433\n",
            "Epoch:899, step = 7199, diffusion continuous loss: 0.275, discrete loss: 0.206\n",
            "Epoch:899, step = 7199, CL continuous loss: 0.895, discrete loss: 0.789\n",
            "Epoch:899, step = 7199, Total continuous loss: 0.454, discrete loss: 0.364\n",
            "Time taken: 0.555\n",
            "Time taken: 0.461\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.412\n",
            "Time taken: 0.417\n",
            "Time taken: 0.413\n",
            "Time taken: 0.418\n",
            "Epoch:900, step = 7207, diffusion continuous loss: 0.285, discrete loss: 0.212\n",
            "Epoch:900, step = 7207, CL continuous loss: 0.856, discrete loss: 0.788\n",
            "Epoch:900, step = 7207, Total continuous loss: 0.456, discrete loss: 0.370\n",
            "Time taken: 0.409\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.422\n",
            "Time taken: 0.426\n",
            "Time taken: 0.414\n",
            "Epoch:901, step = 7215, diffusion continuous loss: 0.280, discrete loss: 0.221\n",
            "Epoch:901, step = 7215, CL continuous loss: 0.866, discrete loss: 0.779\n",
            "Epoch:901, step = 7215, Total continuous loss: 0.453, discrete loss: 0.377\n",
            "Time taken: 0.509\n",
            "Time taken: 0.420\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Time taken: 0.424\n",
            "Time taken: 0.437\n",
            "Epoch:902, step = 7223, diffusion continuous loss: 0.267, discrete loss: 0.212\n",
            "Epoch:902, step = 7223, CL continuous loss: 0.866, discrete loss: 0.781\n",
            "Epoch:902, step = 7223, Total continuous loss: 0.440, discrete loss: 0.368\n",
            "Time taken: 0.431\n",
            "Time taken: 0.436\n",
            "Time taken: 0.448\n",
            "Time taken: 0.446\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Time taken: 0.423\n",
            "Time taken: 0.415\n",
            "Epoch:903, step = 7231, diffusion continuous loss: 0.271, discrete loss: 0.215\n",
            "Epoch:903, step = 7231, CL continuous loss: 0.857, discrete loss: 0.781\n",
            "Epoch:903, step = 7231, Total continuous loss: 0.442, discrete loss: 0.371\n",
            "Time taken: 0.410\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Time taken: 0.412\n",
            "Epoch:904, step = 7239, diffusion continuous loss: 0.274, discrete loss: 0.213\n",
            "Epoch:904, step = 7239, CL continuous loss: 0.858, discrete loss: 0.786\n",
            "Epoch:904, step = 7239, Total continuous loss: 0.445, discrete loss: 0.371\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.419\n",
            "Time taken: 0.414\n",
            "Epoch:905, step = 7247, diffusion continuous loss: 0.278, discrete loss: 0.218\n",
            "Epoch:905, step = 7247, CL continuous loss: 0.860, discrete loss: 0.783\n",
            "Epoch:905, step = 7247, Total continuous loss: 0.450, discrete loss: 0.374\n",
            "Time taken: 0.411\n",
            "Time taken: 0.416\n",
            "Time taken: 0.429\n",
            "Time taken: 0.418\n",
            "Time taken: 0.453\n",
            "Time taken: 0.436\n",
            "Time taken: 0.437\n",
            "Time taken: 0.601\n",
            "Epoch:906, step = 7255, diffusion continuous loss: 0.300, discrete loss: 0.219\n",
            "Epoch:906, step = 7255, CL continuous loss: 0.879, discrete loss: 0.785\n",
            "Epoch:906, step = 7255, Total continuous loss: 0.476, discrete loss: 0.376\n",
            "Time taken: 0.445\n",
            "Time taken: 0.429\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Time taken: 0.414\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Epoch:907, step = 7263, diffusion continuous loss: 0.281, discrete loss: 0.214\n",
            "Epoch:907, step = 7263, CL continuous loss: 0.860, discrete loss: 0.807\n",
            "Epoch:907, step = 7263, Total continuous loss: 0.453, discrete loss: 0.376\n",
            "Time taken: 0.407\n",
            "Time taken: 0.420\n",
            "Time taken: 0.413\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Time taken: 0.413\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Epoch:908, step = 7271, diffusion continuous loss: 0.274, discrete loss: 0.219\n",
            "Epoch:908, step = 7271, CL continuous loss: 0.869, discrete loss: 0.785\n",
            "Epoch:908, step = 7271, Total continuous loss: 0.448, discrete loss: 0.376\n",
            "Time taken: 0.405\n",
            "Time taken: 0.422\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.414\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Time taken: 0.422\n",
            "Epoch:909, step = 7279, diffusion continuous loss: 0.331, discrete loss: 0.222\n",
            "Epoch:909, step = 7279, CL continuous loss: 0.912, discrete loss: 0.783\n",
            "Epoch:909, step = 7279, Total continuous loss: 0.513, discrete loss: 0.379\n",
            "Time taken: 0.405\n",
            "Time taken: 0.438\n",
            "Time taken: 0.436\n",
            "Time taken: 0.435\n",
            "Time taken: 0.455\n",
            "Time taken: 0.452\n",
            "Time taken: 0.419\n",
            "Time taken: 0.414\n",
            "Epoch:910, step = 7287, diffusion continuous loss: 0.315, discrete loss: 0.210\n",
            "Epoch:910, step = 7287, CL continuous loss: 0.909, discrete loss: 0.782\n",
            "Epoch:910, step = 7287, Total continuous loss: 0.497, discrete loss: 0.366\n",
            "Time taken: 0.411\n",
            "Time taken: 0.421\n",
            "Time taken: 0.415\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.428\n",
            "Time taken: 0.520\n",
            "Epoch:911, step = 7295, diffusion continuous loss: 0.278, discrete loss: 0.214\n",
            "Epoch:911, step = 7295, CL continuous loss: 0.874, discrete loss: 0.783\n",
            "Epoch:911, step = 7295, Total continuous loss: 0.453, discrete loss: 0.370\n",
            "Time taken: 0.412\n",
            "Time taken: 0.421\n",
            "Time taken: 0.413\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Epoch:912, step = 7303, diffusion continuous loss: 0.294, discrete loss: 0.222\n",
            "Epoch:912, step = 7303, CL continuous loss: 0.884, discrete loss: 0.796\n",
            "Epoch:912, step = 7303, Total continuous loss: 0.471, discrete loss: 0.381\n",
            "Time taken: 0.407\n",
            "Time taken: 0.414\n",
            "Time taken: 0.422\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.445\n",
            "Time taken: 0.445\n",
            "Epoch:913, step = 7311, diffusion continuous loss: 0.296, discrete loss: 0.229\n",
            "Epoch:913, step = 7311, CL continuous loss: 0.872, discrete loss: 0.787\n",
            "Epoch:913, step = 7311, Total continuous loss: 0.470, discrete loss: 0.386\n",
            "Time taken: 0.428\n",
            "Time taken: 0.446\n",
            "Time taken: 0.444\n",
            "Time taken: 0.414\n",
            "Time taken: 0.426\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Time taken: 0.412\n",
            "Epoch:914, step = 7319, diffusion continuous loss: 0.273, discrete loss: 0.212\n",
            "Epoch:914, step = 7319, CL continuous loss: 0.866, discrete loss: 0.798\n",
            "Epoch:914, step = 7319, Total continuous loss: 0.446, discrete loss: 0.372\n",
            "Time taken: 0.408\n",
            "Time taken: 0.430\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.421\n",
            "Time taken: 0.414\n",
            "Epoch:915, step = 7327, diffusion continuous loss: 0.266, discrete loss: 0.212\n",
            "Epoch:915, step = 7327, CL continuous loss: 0.870, discrete loss: 0.783\n",
            "Epoch:915, step = 7327, Total continuous loss: 0.440, discrete loss: 0.368\n",
            "Time taken: 0.412\n",
            "Time taken: 0.412\n",
            "Time taken: 0.419\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.517\n",
            "Time taken: 0.436\n",
            "Epoch:916, step = 7335, diffusion continuous loss: 0.272, discrete loss: 0.217\n",
            "Epoch:916, step = 7335, CL continuous loss: 0.855, discrete loss: 0.773\n",
            "Epoch:916, step = 7335, Total continuous loss: 0.443, discrete loss: 0.371\n",
            "Time taken: 0.409\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.443\n",
            "Time taken: 0.440\n",
            "Time taken: 0.438\n",
            "Time taken: 0.447\n",
            "Time taken: 0.443\n",
            "Epoch:917, step = 7343, diffusion continuous loss: 0.272, discrete loss: 0.216\n",
            "Epoch:917, step = 7343, CL continuous loss: 0.861, discrete loss: 0.786\n",
            "Epoch:917, step = 7343, Total continuous loss: 0.444, discrete loss: 0.373\n",
            "Time taken: 0.405\n",
            "Time taken: 0.414\n",
            "Time taken: 0.416\n",
            "Time taken: 0.413\n",
            "Time taken: 0.418\n",
            "Time taken: 0.413\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Epoch:918, step = 7351, diffusion continuous loss: 0.269, discrete loss: 0.218\n",
            "Epoch:918, step = 7351, CL continuous loss: 0.851, discrete loss: 0.800\n",
            "Epoch:918, step = 7351, Total continuous loss: 0.439, discrete loss: 0.378\n",
            "Time taken: 0.411\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.437\n",
            "Time taken: 0.434\n",
            "Time taken: 0.435\n",
            "Time taken: 0.434\n",
            "Time taken: 0.450\n",
            "Epoch:919, step = 7359, diffusion continuous loss: 0.266, discrete loss: 0.216\n",
            "Epoch:919, step = 7359, CL continuous loss: 0.855, discrete loss: 0.800\n",
            "Epoch:919, step = 7359, Total continuous loss: 0.437, discrete loss: 0.376\n",
            "Time taken: 0.441\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Epoch:920, step = 7367, diffusion continuous loss: 0.260, discrete loss: 0.219\n",
            "Epoch:920, step = 7367, CL continuous loss: 0.862, discrete loss: 0.800\n",
            "Epoch:920, step = 7367, Total continuous loss: 0.432, discrete loss: 0.379\n",
            "Time taken: 0.440\n",
            "Time taken: 0.438\n",
            "Time taken: 0.442\n",
            "Time taken: 0.451\n",
            "Time taken: 0.616\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Epoch:921, step = 7375, diffusion continuous loss: 0.282, discrete loss: 0.217\n",
            "Epoch:921, step = 7375, CL continuous loss: 0.897, discrete loss: 0.801\n",
            "Epoch:921, step = 7375, Total continuous loss: 0.461, discrete loss: 0.377\n",
            "Time taken: 0.410\n",
            "Time taken: 0.421\n",
            "Time taken: 0.414\n",
            "Time taken: 0.413\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.426\n",
            "Time taken: 0.417\n",
            "Epoch:922, step = 7383, diffusion continuous loss: 0.273, discrete loss: 0.219\n",
            "Epoch:922, step = 7383, CL continuous loss: 0.875, discrete loss: 0.789\n",
            "Epoch:922, step = 7383, Total continuous loss: 0.449, discrete loss: 0.377\n",
            "Time taken: 0.413\n",
            "Time taken: 0.412\n",
            "Time taken: 0.418\n",
            "Time taken: 0.413\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.415\n",
            "Epoch:923, step = 7391, diffusion continuous loss: 0.347, discrete loss: 0.209\n",
            "Epoch:923, step = 7391, CL continuous loss: 0.889, discrete loss: 0.799\n",
            "Epoch:923, step = 7391, Total continuous loss: 0.524, discrete loss: 0.369\n",
            "Time taken: 0.411\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.454\n",
            "Time taken: 0.447\n",
            "Time taken: 0.441\n",
            "Epoch:924, step = 7399, diffusion continuous loss: 0.312, discrete loss: 0.220\n",
            "Epoch:924, step = 7399, CL continuous loss: 0.860, discrete loss: 0.791\n",
            "Epoch:924, step = 7399, Total continuous loss: 0.484, discrete loss: 0.378\n",
            "Time taken: 0.442\n",
            "Time taken: 0.454\n",
            "Time taken: 0.433\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.423\n",
            "Time taken: 0.416\n",
            "Epoch:925, step = 7407, diffusion continuous loss: 0.284, discrete loss: 0.221\n",
            "Epoch:925, step = 7407, CL continuous loss: 0.890, discrete loss: 0.781\n",
            "Epoch:925, step = 7407, Total continuous loss: 0.462, discrete loss: 0.377\n",
            "Time taken: 0.410\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.531\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.423\n",
            "Time taken: 0.415\n",
            "Epoch:926, step = 7415, diffusion continuous loss: 0.292, discrete loss: 0.229\n",
            "Epoch:926, step = 7415, CL continuous loss: 0.879, discrete loss: 0.788\n",
            "Epoch:926, step = 7415, Total continuous loss: 0.468, discrete loss: 0.387\n",
            "Time taken: 0.412\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Epoch:927, step = 7423, diffusion continuous loss: 0.282, discrete loss: 0.221\n",
            "Epoch:927, step = 7423, CL continuous loss: 0.865, discrete loss: 0.786\n",
            "Epoch:927, step = 7423, Total continuous loss: 0.454, discrete loss: 0.378\n",
            "Time taken: 0.409\n",
            "Time taken: 0.416\n",
            "Time taken: 0.449\n",
            "Time taken: 0.442\n",
            "Time taken: 0.439\n",
            "Time taken: 0.457\n",
            "Time taken: 0.452\n",
            "Time taken: 0.430\n",
            "Epoch:928, step = 7431, diffusion continuous loss: 0.269, discrete loss: 0.213\n",
            "Epoch:928, step = 7431, CL continuous loss: 0.860, discrete loss: 0.797\n",
            "Epoch:928, step = 7431, Total continuous loss: 0.441, discrete loss: 0.372\n",
            "Time taken: 0.411\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.413\n",
            "Time taken: 0.418\n",
            "Time taken: 0.411\n",
            "Time taken: 0.409\n",
            "Time taken: 0.417\n",
            "Epoch:929, step = 7439, diffusion continuous loss: 0.283, discrete loss: 0.215\n",
            "Epoch:929, step = 7439, CL continuous loss: 0.893, discrete loss: 0.776\n",
            "Epoch:929, step = 7439, Total continuous loss: 0.462, discrete loss: 0.370\n",
            "Time taken: 0.402\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.408\n",
            "Time taken: 0.418\n",
            "Time taken: 0.411\n",
            "Epoch:930, step = 7447, diffusion continuous loss: 0.268, discrete loss: 0.219\n",
            "Epoch:930, step = 7447, CL continuous loss: 0.867, discrete loss: 0.786\n",
            "Epoch:930, step = 7447, Total continuous loss: 0.441, discrete loss: 0.377\n",
            "Time taken: 0.403\n",
            "Time taken: 0.511\n",
            "Time taken: 0.415\n",
            "Time taken: 0.429\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.448\n",
            "Epoch:931, step = 7455, diffusion continuous loss: 0.274, discrete loss: 0.212\n",
            "Epoch:931, step = 7455, CL continuous loss: 0.864, discrete loss: 0.792\n",
            "Epoch:931, step = 7455, Total continuous loss: 0.447, discrete loss: 0.370\n",
            "Time taken: 0.433\n",
            "Time taken: 0.438\n",
            "Time taken: 0.454\n",
            "Time taken: 0.442\n",
            "Time taken: 0.439\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.420\n",
            "Epoch:932, step = 7463, diffusion continuous loss: 0.269, discrete loss: 0.212\n",
            "Epoch:932, step = 7463, CL continuous loss: 0.873, discrete loss: 0.774\n",
            "Epoch:932, step = 7463, Total continuous loss: 0.444, discrete loss: 0.367\n",
            "Time taken: 0.408\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Epoch:933, step = 7471, diffusion continuous loss: 0.272, discrete loss: 0.216\n",
            "Epoch:933, step = 7471, CL continuous loss: 0.883, discrete loss: 0.787\n",
            "Epoch:933, step = 7471, Total continuous loss: 0.448, discrete loss: 0.373\n",
            "Time taken: 0.407\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.414\n",
            "Time taken: 0.414\n",
            "Time taken: 0.416\n",
            "Time taken: 0.426\n",
            "Time taken: 0.424\n",
            "Epoch:934, step = 7479, diffusion continuous loss: 0.261, discrete loss: 0.221\n",
            "Epoch:934, step = 7479, CL continuous loss: 0.866, discrete loss: 0.791\n",
            "Epoch:934, step = 7479, Total continuous loss: 0.434, discrete loss: 0.379\n",
            "Time taken: 0.402\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.425\n",
            "Time taken: 0.426\n",
            "Time taken: 0.446\n",
            "Time taken: 0.436\n",
            "Time taken: 0.436\n",
            "Epoch:935, step = 7487, diffusion continuous loss: 0.263, discrete loss: 0.224\n",
            "Epoch:935, step = 7487, CL continuous loss: 0.872, discrete loss: 0.791\n",
            "Epoch:935, step = 7487, Total continuous loss: 0.437, discrete loss: 0.382\n",
            "Time taken: 0.574\n",
            "Time taken: 0.437\n",
            "Time taken: 0.429\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Time taken: 0.414\n",
            "Time taken: 0.419\n",
            "Epoch:936, step = 7495, diffusion continuous loss: 0.259, discrete loss: 0.217\n",
            "Epoch:936, step = 7495, CL continuous loss: 0.865, discrete loss: 0.782\n",
            "Epoch:936, step = 7495, Total continuous loss: 0.432, discrete loss: 0.374\n",
            "Time taken: 0.403\n",
            "Time taken: 0.421\n",
            "Time taken: 0.414\n",
            "Time taken: 0.411\n",
            "Time taken: 0.417\n",
            "Time taken: 0.411\n",
            "Time taken: 0.425\n",
            "Time taken: 0.423\n",
            "Epoch:937, step = 7503, diffusion continuous loss: 0.298, discrete loss: 0.219\n",
            "Epoch:937, step = 7503, CL continuous loss: 0.875, discrete loss: 0.801\n",
            "Epoch:937, step = 7503, Total continuous loss: 0.473, discrete loss: 0.379\n",
            "Time taken: 0.404\n",
            "Time taken: 0.413\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Epoch:938, step = 7511, diffusion continuous loss: 0.286, discrete loss: 0.221\n",
            "Epoch:938, step = 7511, CL continuous loss: 0.885, discrete loss: 0.785\n",
            "Epoch:938, step = 7511, Total continuous loss: 0.463, discrete loss: 0.378\n",
            "Time taken: 0.413\n",
            "Time taken: 0.422\n",
            "Time taken: 0.443\n",
            "Time taken: 0.443\n",
            "Time taken: 0.434\n",
            "Time taken: 0.446\n",
            "Time taken: 0.440\n",
            "Time taken: 0.418\n",
            "Epoch:939, step = 7519, diffusion continuous loss: 0.309, discrete loss: 0.213\n",
            "Epoch:939, step = 7519, CL continuous loss: 0.890, discrete loss: 0.786\n",
            "Epoch:939, step = 7519, Total continuous loss: 0.488, discrete loss: 0.371\n",
            "Time taken: 0.409\n",
            "Time taken: 0.414\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.526\n",
            "Time taken: 0.414\n",
            "Epoch:940, step = 7527, diffusion continuous loss: 0.293, discrete loss: 0.218\n",
            "Epoch:940, step = 7527, CL continuous loss: 0.866, discrete loss: 0.788\n",
            "Epoch:940, step = 7527, Total continuous loss: 0.466, discrete loss: 0.375\n",
            "Time taken: 0.414\n",
            "Time taken: 0.413\n",
            "Time taken: 0.420\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Epoch:941, step = 7535, diffusion continuous loss: 0.290, discrete loss: 0.217\n",
            "Epoch:941, step = 7535, CL continuous loss: 0.902, discrete loss: 0.788\n",
            "Epoch:941, step = 7535, Total continuous loss: 0.471, discrete loss: 0.374\n",
            "Time taken: 0.405\n",
            "Time taken: 0.413\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Time taken: 0.425\n",
            "Time taken: 0.443\n",
            "Epoch:942, step = 7543, diffusion continuous loss: 0.276, discrete loss: 0.218\n",
            "Epoch:942, step = 7543, CL continuous loss: 0.899, discrete loss: 0.783\n",
            "Epoch:942, step = 7543, Total continuous loss: 0.456, discrete loss: 0.374\n",
            "Time taken: 0.442\n",
            "Time taken: 0.434\n",
            "Time taken: 0.450\n",
            "Time taken: 0.440\n",
            "Time taken: 0.411\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Epoch:943, step = 7551, diffusion continuous loss: 0.279, discrete loss: 0.212\n",
            "Epoch:943, step = 7551, CL continuous loss: 0.877, discrete loss: 0.789\n",
            "Epoch:943, step = 7551, Total continuous loss: 0.454, discrete loss: 0.370\n",
            "Time taken: 0.410\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.413\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Epoch:944, step = 7559, diffusion continuous loss: 0.274, discrete loss: 0.214\n",
            "Epoch:944, step = 7559, CL continuous loss: 0.880, discrete loss: 0.788\n",
            "Epoch:944, step = 7559, Total continuous loss: 0.450, discrete loss: 0.372\n",
            "Time taken: 0.411\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.424\n",
            "Time taken: 0.514\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Epoch:945, step = 7567, diffusion continuous loss: 0.265, discrete loss: 0.211\n",
            "Epoch:945, step = 7567, CL continuous loss: 0.878, discrete loss: 0.782\n",
            "Epoch:945, step = 7567, Total continuous loss: 0.441, discrete loss: 0.367\n",
            "Time taken: 0.402\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.426\n",
            "Time taken: 0.440\n",
            "Time taken: 0.438\n",
            "Time taken: 0.443\n",
            "Time taken: 0.466\n",
            "Epoch:946, step = 7575, diffusion continuous loss: 0.279, discrete loss: 0.215\n",
            "Epoch:946, step = 7575, CL continuous loss: 0.866, discrete loss: 0.789\n",
            "Epoch:946, step = 7575, Total continuous loss: 0.452, discrete loss: 0.373\n",
            "Time taken: 0.439\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.423\n",
            "Epoch:947, step = 7583, diffusion continuous loss: 0.274, discrete loss: 0.222\n",
            "Epoch:947, step = 7583, CL continuous loss: 0.854, discrete loss: 0.787\n",
            "Epoch:947, step = 7583, Total continuous loss: 0.445, discrete loss: 0.379\n",
            "Time taken: 0.407\n",
            "Time taken: 0.414\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.412\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Epoch:948, step = 7591, diffusion continuous loss: 0.280, discrete loss: 0.232\n",
            "Epoch:948, step = 7591, CL continuous loss: 0.857, discrete loss: 0.783\n",
            "Epoch:948, step = 7591, Total continuous loss: 0.451, discrete loss: 0.389\n",
            "Time taken: 0.410\n",
            "Time taken: 0.419\n",
            "Time taken: 0.410\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.413\n",
            "Epoch:949, step = 7599, diffusion continuous loss: 0.288, discrete loss: 0.212\n",
            "Epoch:949, step = 7599, CL continuous loss: 0.858, discrete loss: 0.779\n",
            "Epoch:949, step = 7599, Total continuous loss: 0.460, discrete loss: 0.368\n",
            "Time taken: 0.414\n",
            "Time taken: 0.438\n",
            "Time taken: 0.447\n",
            "Time taken: 0.574\n",
            "Time taken: 0.443\n",
            "Time taken: 0.444\n",
            "Time taken: 0.411\n",
            "Time taken: 0.418\n",
            "Epoch:950, step = 7607, diffusion continuous loss: 0.304, discrete loss: 0.216\n",
            "Epoch:950, step = 7607, CL continuous loss: 0.897, discrete loss: 0.778\n",
            "Epoch:950, step = 7607, Total continuous loss: 0.483, discrete loss: 0.372\n",
            "Time taken: 0.406\n",
            "Time taken: 0.411\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.412\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Epoch:951, step = 7615, diffusion continuous loss: 0.285, discrete loss: 0.202\n",
            "Epoch:951, step = 7615, CL continuous loss: 0.877, discrete loss: 0.787\n",
            "Epoch:951, step = 7615, Total continuous loss: 0.460, discrete loss: 0.360\n",
            "Time taken: 0.405\n",
            "Time taken: 0.418\n",
            "Time taken: 0.414\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.412\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Epoch:952, step = 7623, diffusion continuous loss: 0.279, discrete loss: 0.216\n",
            "Epoch:952, step = 7623, CL continuous loss: 0.842, discrete loss: 0.781\n",
            "Epoch:952, step = 7623, Total continuous loss: 0.447, discrete loss: 0.373\n",
            "Time taken: 0.404\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.440\n",
            "Time taken: 0.440\n",
            "Epoch:953, step = 7631, diffusion continuous loss: 0.268, discrete loss: 0.205\n",
            "Epoch:953, step = 7631, CL continuous loss: 0.882, discrete loss: 0.775\n",
            "Epoch:953, step = 7631, Total continuous loss: 0.444, discrete loss: 0.360\n",
            "Time taken: 0.419\n",
            "Time taken: 0.445\n",
            "Time taken: 0.456\n",
            "Time taken: 0.413\n",
            "Time taken: 0.419\n",
            "Time taken: 0.413\n",
            "Time taken: 0.418\n",
            "Time taken: 0.412\n",
            "Epoch:954, step = 7639, diffusion continuous loss: 0.275, discrete loss: 0.217\n",
            "Epoch:954, step = 7639, CL continuous loss: 0.864, discrete loss: 0.780\n",
            "Epoch:954, step = 7639, Total continuous loss: 0.447, discrete loss: 0.373\n",
            "Time taken: 0.413\n",
            "Time taken: 0.416\n",
            "Time taken: 0.521\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.411\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Epoch:955, step = 7647, diffusion continuous loss: 0.282, discrete loss: 0.212\n",
            "Epoch:955, step = 7647, CL continuous loss: 0.893, discrete loss: 0.777\n",
            "Epoch:955, step = 7647, Total continuous loss: 0.461, discrete loss: 0.367\n",
            "Time taken: 0.409\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Epoch:956, step = 7655, diffusion continuous loss: 0.280, discrete loss: 0.207\n",
            "Epoch:956, step = 7655, CL continuous loss: 0.899, discrete loss: 0.778\n",
            "Epoch:956, step = 7655, Total continuous loss: 0.460, discrete loss: 0.362\n",
            "Time taken: 0.409\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.448\n",
            "Time taken: 0.438\n",
            "Time taken: 0.435\n",
            "Time taken: 0.444\n",
            "Time taken: 0.446\n",
            "Epoch:957, step = 7663, diffusion continuous loss: 0.312, discrete loss: 0.223\n",
            "Epoch:957, step = 7663, CL continuous loss: 0.906, discrete loss: 0.788\n",
            "Epoch:957, step = 7663, Total continuous loss: 0.493, discrete loss: 0.381\n",
            "Time taken: 0.404\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.422\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Epoch:958, step = 7671, diffusion continuous loss: 0.288, discrete loss: 0.220\n",
            "Epoch:958, step = 7671, CL continuous loss: 0.859, discrete loss: 0.778\n",
            "Epoch:958, step = 7671, Total continuous loss: 0.459, discrete loss: 0.376\n",
            "Time taken: 0.418\n",
            "Time taken: 0.413\n",
            "Time taken: 0.419\n",
            "Time taken: 0.413\n",
            "Time taken: 0.423\n",
            "Time taken: 0.422\n",
            "Time taken: 0.406\n",
            "Time taken: 0.416\n",
            "Epoch:959, step = 7679, diffusion continuous loss: 0.285, discrete loss: 0.209\n",
            "Epoch:959, step = 7679, CL continuous loss: 0.876, discrete loss: 0.785\n",
            "Epoch:959, step = 7679, Total continuous loss: 0.460, discrete loss: 0.366\n",
            "Time taken: 0.511\n",
            "Time taken: 0.409\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.414\n",
            "Time taken: 0.412\n",
            "Time taken: 0.418\n",
            "Epoch:960, step = 7687, diffusion continuous loss: 0.345, discrete loss: 0.207\n",
            "Epoch:960, step = 7687, CL continuous loss: 0.911, discrete loss: 0.781\n",
            "Epoch:960, step = 7687, Total continuous loss: 0.527, discrete loss: 0.364\n",
            "Time taken: 0.430\n",
            "Time taken: 0.440\n",
            "Time taken: 0.442\n",
            "Time taken: 0.443\n",
            "Time taken: 0.447\n",
            "Time taken: 0.411\n",
            "Time taken: 0.419\n",
            "Time taken: 0.414\n",
            "Epoch:961, step = 7695, diffusion continuous loss: 0.321, discrete loss: 0.219\n",
            "Epoch:961, step = 7695, CL continuous loss: 0.902, discrete loss: 0.788\n",
            "Epoch:961, step = 7695, Total continuous loss: 0.501, discrete loss: 0.377\n",
            "Time taken: 0.414\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.421\n",
            "Time taken: 0.414\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Time taken: 0.412\n",
            "Epoch:962, step = 7703, diffusion continuous loss: 0.283, discrete loss: 0.211\n",
            "Epoch:962, step = 7703, CL continuous loss: 0.899, discrete loss: 0.784\n",
            "Epoch:962, step = 7703, Total continuous loss: 0.462, discrete loss: 0.367\n",
            "Time taken: 0.420\n",
            "Time taken: 0.412\n",
            "Time taken: 0.416\n",
            "Time taken: 0.411\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Epoch:963, step = 7711, diffusion continuous loss: 0.269, discrete loss: 0.225\n",
            "Epoch:963, step = 7711, CL continuous loss: 0.884, discrete loss: 0.804\n",
            "Epoch:963, step = 7711, Total continuous loss: 0.446, discrete loss: 0.386\n",
            "Time taken: 0.411\n",
            "Time taken: 0.415\n",
            "Time taken: 0.422\n",
            "Time taken: 0.410\n",
            "Time taken: 0.423\n",
            "Time taken: 0.442\n",
            "Time taken: 0.437\n",
            "Time taken: 0.571\n",
            "Epoch:964, step = 7719, diffusion continuous loss: 0.276, discrete loss: 0.220\n",
            "Epoch:964, step = 7719, CL continuous loss: 0.875, discrete loss: 0.804\n",
            "Epoch:964, step = 7719, Total continuous loss: 0.451, discrete loss: 0.381\n",
            "Time taken: 0.446\n",
            "Time taken: 0.452\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.413\n",
            "Time taken: 0.418\n",
            "Time taken: 0.411\n",
            "Time taken: 0.415\n",
            "Epoch:965, step = 7727, diffusion continuous loss: 0.288, discrete loss: 0.221\n",
            "Epoch:965, step = 7727, CL continuous loss: 0.871, discrete loss: 0.816\n",
            "Epoch:965, step = 7727, Total continuous loss: 0.462, discrete loss: 0.384\n",
            "Time taken: 0.410\n",
            "Time taken: 0.412\n",
            "Time taken: 0.416\n",
            "Time taken: 0.414\n",
            "Time taken: 0.412\n",
            "Time taken: 0.419\n",
            "Time taken: 0.412\n",
            "Time taken: 0.415\n",
            "Epoch:966, step = 7735, diffusion continuous loss: 0.286, discrete loss: 0.225\n",
            "Epoch:966, step = 7735, CL continuous loss: 0.872, discrete loss: 0.798\n",
            "Epoch:966, step = 7735, Total continuous loss: 0.460, discrete loss: 0.385\n",
            "Time taken: 0.403\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.410\n",
            "Time taken: 0.423\n",
            "Epoch:967, step = 7743, diffusion continuous loss: 0.284, discrete loss: 0.216\n",
            "Epoch:967, step = 7743, CL continuous loss: 0.875, discrete loss: 0.782\n",
            "Epoch:967, step = 7743, Total continuous loss: 0.459, discrete loss: 0.372\n",
            "Time taken: 0.405\n",
            "Time taken: 0.417\n",
            "Time taken: 0.430\n",
            "Time taken: 0.438\n",
            "Time taken: 0.438\n",
            "Time taken: 0.437\n",
            "Time taken: 0.444\n",
            "Time taken: 0.442\n",
            "Epoch:968, step = 7751, diffusion continuous loss: 0.291, discrete loss: 0.236\n",
            "Epoch:968, step = 7751, CL continuous loss: 0.864, discrete loss: 0.787\n",
            "Epoch:968, step = 7751, Total continuous loss: 0.464, discrete loss: 0.393\n",
            "Time taken: 0.409\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Time taken: 0.410\n",
            "Time taken: 0.411\n",
            "Time taken: 0.511\n",
            "Time taken: 0.412\n",
            "Time taken: 0.416\n",
            "Epoch:969, step = 7759, diffusion continuous loss: 0.261, discrete loss: 0.216\n",
            "Epoch:969, step = 7759, CL continuous loss: 0.879, discrete loss: 0.788\n",
            "Epoch:969, step = 7759, Total continuous loss: 0.437, discrete loss: 0.373\n",
            "Time taken: 0.410\n",
            "Time taken: 0.423\n",
            "Time taken: 0.413\n",
            "Time taken: 0.410\n",
            "Time taken: 0.418\n",
            "Time taken: 0.423\n",
            "Time taken: 0.413\n",
            "Time taken: 0.417\n",
            "Epoch:970, step = 7767, diffusion continuous loss: 0.306, discrete loss: 0.215\n",
            "Epoch:970, step = 7767, CL continuous loss: 0.895, discrete loss: 0.783\n",
            "Epoch:970, step = 7767, Total continuous loss: 0.485, discrete loss: 0.372\n",
            "Time taken: 0.406\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.413\n",
            "Time taken: 0.413\n",
            "Time taken: 0.415\n",
            "Time taken: 0.422\n",
            "Epoch:971, step = 7775, diffusion continuous loss: 0.283, discrete loss: 0.220\n",
            "Epoch:971, step = 7775, CL continuous loss: 0.882, discrete loss: 0.780\n",
            "Epoch:971, step = 7775, Total continuous loss: 0.459, discrete loss: 0.376\n",
            "Time taken: 0.431\n",
            "Time taken: 0.436\n",
            "Time taken: 0.438\n",
            "Time taken: 0.443\n",
            "Time taken: 0.453\n",
            "Time taken: 0.415\n",
            "Time taken: 0.411\n",
            "Time taken: 0.419\n",
            "Epoch:972, step = 7783, diffusion continuous loss: 0.275, discrete loss: 0.224\n",
            "Epoch:972, step = 7783, CL continuous loss: 0.889, discrete loss: 0.777\n",
            "Epoch:972, step = 7783, Total continuous loss: 0.452, discrete loss: 0.379\n",
            "Time taken: 0.403\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Time taken: 0.411\n",
            "Time taken: 0.417\n",
            "Time taken: 0.410\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Epoch:973, step = 7791, diffusion continuous loss: 0.315, discrete loss: 0.225\n",
            "Epoch:973, step = 7791, CL continuous loss: 0.897, discrete loss: 0.780\n",
            "Epoch:973, step = 7791, Total continuous loss: 0.495, discrete loss: 0.381\n",
            "Time taken: 0.402\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.514\n",
            "Time taken: 0.416\n",
            "Time taken: 0.413\n",
            "Time taken: 0.416\n",
            "Epoch:974, step = 7799, diffusion continuous loss: 0.275, discrete loss: 0.213\n",
            "Epoch:974, step = 7799, CL continuous loss: 0.881, discrete loss: 0.784\n",
            "Epoch:974, step = 7799, Total continuous loss: 0.451, discrete loss: 0.370\n",
            "Time taken: 0.404\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.447\n",
            "Time taken: 0.439\n",
            "Time taken: 0.437\n",
            "Epoch:975, step = 7807, diffusion continuous loss: 0.259, discrete loss: 0.210\n",
            "Epoch:975, step = 7807, CL continuous loss: 0.874, discrete loss: 0.772\n",
            "Epoch:975, step = 7807, Total continuous loss: 0.434, discrete loss: 0.364\n",
            "Time taken: 0.433\n",
            "Time taken: 0.449\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.414\n",
            "Time taken: 0.415\n",
            "Epoch:976, step = 7815, diffusion continuous loss: 0.277, discrete loss: 0.211\n",
            "Epoch:976, step = 7815, CL continuous loss: 0.862, discrete loss: 0.784\n",
            "Epoch:976, step = 7815, Total continuous loss: 0.449, discrete loss: 0.368\n",
            "Time taken: 0.409\n",
            "Time taken: 0.420\n",
            "Time taken: 0.411\n",
            "Time taken: 0.410\n",
            "Time taken: 0.413\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.410\n",
            "Epoch:977, step = 7823, diffusion continuous loss: 0.269, discrete loss: 0.219\n",
            "Epoch:977, step = 7823, CL continuous loss: 0.869, discrete loss: 0.779\n",
            "Epoch:977, step = 7823, Total continuous loss: 0.443, discrete loss: 0.374\n",
            "Time taken: 0.404\n",
            "Time taken: 0.414\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.413\n",
            "Time taken: 0.416\n",
            "Time taken: 0.409\n",
            "Epoch:978, step = 7831, diffusion continuous loss: 0.290, discrete loss: 0.213\n",
            "Epoch:978, step = 7831, CL continuous loss: 0.874, discrete loss: 0.775\n",
            "Epoch:978, step = 7831, Total continuous loss: 0.465, discrete loss: 0.369\n",
            "Time taken: 0.409\n",
            "Time taken: 0.422\n",
            "Time taken: 0.583\n",
            "Time taken: 0.435\n",
            "Time taken: 0.433\n",
            "Time taken: 0.441\n",
            "Time taken: 0.453\n",
            "Time taken: 0.414\n",
            "Epoch:979, step = 7839, diffusion continuous loss: 0.277, discrete loss: 0.210\n",
            "Epoch:979, step = 7839, CL continuous loss: 0.886, discrete loss: 0.785\n",
            "Epoch:979, step = 7839, Total continuous loss: 0.454, discrete loss: 0.367\n",
            "Time taken: 0.413\n",
            "Time taken: 0.413\n",
            "Time taken: 0.417\n",
            "Time taken: 0.411\n",
            "Time taken: 0.412\n",
            "Time taken: 0.414\n",
            "Time taken: 0.416\n",
            "Time taken: 0.414\n",
            "Epoch:980, step = 7847, diffusion continuous loss: 0.292, discrete loss: 0.213\n",
            "Epoch:980, step = 7847, CL continuous loss: 0.846, discrete loss: 0.775\n",
            "Epoch:980, step = 7847, Total continuous loss: 0.461, discrete loss: 0.368\n",
            "Time taken: 0.401\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.413\n",
            "Time taken: 0.412\n",
            "Time taken: 0.417\n",
            "Time taken: 0.413\n",
            "Epoch:981, step = 7855, diffusion continuous loss: 0.273, discrete loss: 0.213\n",
            "Epoch:981, step = 7855, CL continuous loss: 0.889, discrete loss: 0.783\n",
            "Epoch:981, step = 7855, Total continuous loss: 0.451, discrete loss: 0.369\n",
            "Time taken: 0.411\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.409\n",
            "Time taken: 0.416\n",
            "Time taken: 0.444\n",
            "Epoch:982, step = 7863, diffusion continuous loss: 0.276, discrete loss: 0.212\n",
            "Epoch:982, step = 7863, CL continuous loss: 0.887, discrete loss: 0.787\n",
            "Epoch:982, step = 7863, Total continuous loss: 0.454, discrete loss: 0.369\n",
            "Time taken: 0.433\n",
            "Time taken: 0.432\n",
            "Time taken: 0.439\n",
            "Time taken: 0.444\n",
            "Time taken: 0.433\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Epoch:983, step = 7871, diffusion continuous loss: 0.259, discrete loss: 0.209\n",
            "Epoch:983, step = 7871, CL continuous loss: 0.878, discrete loss: 0.785\n",
            "Epoch:983, step = 7871, Total continuous loss: 0.434, discrete loss: 0.366\n",
            "Time taken: 0.410\n",
            "Time taken: 0.510\n",
            "Time taken: 0.411\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.410\n",
            "Time taken: 0.419\n",
            "Epoch:984, step = 7879, diffusion continuous loss: 0.270, discrete loss: 0.210\n",
            "Epoch:984, step = 7879, CL continuous loss: 0.870, discrete loss: 0.770\n",
            "Epoch:984, step = 7879, Total continuous loss: 0.444, discrete loss: 0.364\n",
            "Time taken: 0.403\n",
            "Time taken: 0.421\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.414\n",
            "Time taken: 0.412\n",
            "Time taken: 0.422\n",
            "Time taken: 0.419\n",
            "Epoch:985, step = 7887, diffusion continuous loss: 0.277, discrete loss: 0.215\n",
            "Epoch:985, step = 7887, CL continuous loss: 0.874, discrete loss: 0.779\n",
            "Epoch:985, step = 7887, Total continuous loss: 0.452, discrete loss: 0.371\n",
            "Time taken: 0.405\n",
            "Time taken: 0.414\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.428\n",
            "Time taken: 0.439\n",
            "Time taken: 0.435\n",
            "Time taken: 0.438\n",
            "Epoch:986, step = 7895, diffusion continuous loss: 0.332, discrete loss: 0.213\n",
            "Epoch:986, step = 7895, CL continuous loss: 0.915, discrete loss: 0.777\n",
            "Epoch:986, step = 7895, Total continuous loss: 0.515, discrete loss: 0.368\n",
            "Time taken: 0.443\n",
            "Time taken: 0.436\n",
            "Time taken: 0.413\n",
            "Time taken: 0.415\n",
            "Time taken: 0.413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname adult --method codi --mode sample --save_path adult_codi.csv"
      ],
      "metadata": {
        "id": "Cda_gqk1U4Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Default"
      ],
      "metadata": {
        "id": "A9gD8wQuU-sX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname default --method codi --mode train"
      ],
      "metadata": {
        "id": "nNLAVNxfVSai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname default --method codi --mode sample --save_path default_codi.csv"
      ],
      "metadata": {
        "id": "4zxDwDLUVSei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Shoppers"
      ],
      "metadata": {
        "id": "X009THKcVCfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname shoppers --method codi --mode train"
      ],
      "metadata": {
        "id": "ZPswC0OMVS-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname shoppers --method codi --mode sample --save_path shoppers_codi.csv"
      ],
      "metadata": {
        "id": "46A-HjmHVD5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Magic"
      ],
      "metadata": {
        "id": "gUefXV1dVEVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname magic --method codi --mode train"
      ],
      "metadata": {
        "id": "7UV3tOfhVTft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname magic --method codi --mode sample --save_path magic_codi.csv"
      ],
      "metadata": {
        "id": "2J0O0bqoVTiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Beijing"
      ],
      "metadata": {
        "id": "vqsED83YVGb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname beijing --method codi --mode train"
      ],
      "metadata": {
        "id": "9JNz-uFvVT7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname beijing --method codi --mode sample --save_path beijing_codi.csv"
      ],
      "metadata": {
        "id": "O19nEN96VT9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metrics"
      ],
      "metadata": {
        "id": "MB9NQyIO6ep7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "!pip install sdv\n",
        "!pip install ucimlrepo\n",
        "!pio install sdmetrics\n",
        "!pip install -U kaleido\n",
        "!pip install synthcity[full]"
      ],
      "metadata": {
        "id": "9DWKxsrr6pnO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sdv\n",
        "import json\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "from sdv.metadata import SingleTableMetadata\n",
        "from sdmetrics.reports.single_table import QualityReport, DiagnosticReport\n",
        "from sdmetrics.visualization import get_column_plot\n",
        "from sdmetrics.column_pairs import CorrelationSimilarity\n",
        "from sdmetrics.column_pairs import ContingencySimilarity\n",
        "from itertools import combinations\n",
        "import statistics\n",
        "from sdmetrics.single_table import LogisticDetection\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from synthcity.plugins.core.dataloader import GenericDataLoader\n",
        "from synthcity.metrics import eval_detection, eval_performance, eval_statistical\n",
        "import torch\n",
        "from sklearn.preprocessing import OrdinalEncoder"
      ],
      "metadata": {
        "id": "Fv_9tn8_6n2C"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adult = pd.read_csv('../adult_syn.csv')"
      ],
      "metadata": {
        "id": "6KhVDuje_xwo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adult_train = pd.read_csv('/content/tabsyn/data/adult/train.csv')"
      ],
      "metadata": {
        "id": "f-qrcdEw_43N"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Metrics:\n",
        "    def __init__(self, train_path, test_path, synthetic_path, numeric_cols, cat_cols, target_col, classification=True):\n",
        "        self.real_df = pd.read_csv(train_path)\n",
        "        self.test = pd.read_csv(test_path)\n",
        "        self.synthetic_df = pd.read_csv(synthetic_path)\n",
        "        self.numeric_cols = self.real_df.columns[numeric_cols].to_list()\n",
        "        self.cat_cols = self.real_df.columns[cat_cols].to_list()\n",
        "        self.target_col = self.real_df.columns[target_col]\n",
        "        self.metadata = SingleTableMetadata()\n",
        "        self.metadata.detect_from_dataframe(data=self.real_df)\n",
        "        self.metadata = self.metadata.to_dict()\n",
        "        self.classification = classification\n",
        "        if self.classification:\n",
        "            self.cat_cols.append(self.target_col)\n",
        "\n",
        "    def preprocess_data(self, data):\n",
        "        df = data.copy()\n",
        "        enc_dict = {}\n",
        "        for column in self.cat_cols:\n",
        "            if column in df.columns:\n",
        "                enc = OrdinalEncoder(\n",
        "                    handle_unknown='use_encoded_value',\n",
        "                    unknown_value=-1\n",
        "                )\n",
        "                arr = df[[column]].astype(str)\n",
        "                df[column] = enc.fit_transform(arr).astype(int)\n",
        "                enc_dict[column] = enc\n",
        "        return df, enc_dict\n",
        "\n",
        "    def encode_data(self, data, enc_dict):\n",
        "        df = data.copy()\n",
        "        for column in self.cat_cols:\n",
        "            if column in df.columns and column in enc_dict:\n",
        "                enc = enc_dict[column]\n",
        "                arr = df[[column]].astype(str)\n",
        "                df[column] = enc.transform(arr).astype(int)\n",
        "        return df\n",
        "\n",
        "    def train_and_evaluate(self, X_train, X_test, y_train, y_test, n_splits=20):\n",
        "        param_grid = {\n",
        "            'n_estimators': [10, 50, 100],\n",
        "            'min_child_weight': [5, 10, 20],\n",
        "            'max_depth': [1, 10],\n",
        "            'gamma': [0.0, 1.0]\n",
        "        }\n",
        "\n",
        "        scores = []\n",
        "\n",
        "        for i in range(n_splits):\n",
        "            X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
        "                X_train, y_train, test_size=0.111, random_state=i\n",
        "            )\n",
        "\n",
        "            if self.classification:\n",
        "                model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "                scoring = 'roc_auc'\n",
        "            else:\n",
        "                model = XGBRegressor(use_label_encoder=False)\n",
        "                scoring = 'neg_mean_squared_error'\n",
        "            grid_search = GridSearchCV(\n",
        "                model, param_grid, scoring=scoring, cv=3\n",
        "            )\n",
        "\n",
        "            grid_search.fit(X_train_split, y_train_split)\n",
        "\n",
        "            if self.classification:\n",
        "                best_model = XGBClassifier(**grid_search.best_params_,\n",
        "                                    use_label_encoder=False,\n",
        "                                    eval_metric='auc')\n",
        "            else:\n",
        "                best_model = XGBRegressor(**grid_search.best_params_,\n",
        "                                    use_label_encoder=False, objective='reg:squarederror')\n",
        "\n",
        "            best_model.fit(X_train, y_train)\n",
        "\n",
        "            if self.classification:\n",
        "                y_pred = best_model.predict_proba(X_test)[:, 1]\n",
        "                score = roc_auc_score(y_test, y_pred)\n",
        "            else:\n",
        "                y_pred = best_model.predict(X_test)\n",
        "                score = mean_squared_error(y_test, y_pred)\n",
        "                score = np.sqrt(score)\n",
        "            scores.append(score)\n",
        "\n",
        "        return np.mean(scores), np.std(scores)\n",
        "\n",
        "    def classification_metrics(self):\n",
        "            X_train_real = self.real_df.drop(columns=[self.target_col], axis=1)\n",
        "            y_train_real = self.real_df[self.target_col]\n",
        "\n",
        "            X_test = self.test.drop(columns=[self.target_col], axis=1)\n",
        "            y_test = self.test[self.target_col]\n",
        "\n",
        "            X_train_synthetic = self.synthetic_df.drop(self.target_col, axis=1)\n",
        "            y_train_synthetic = self.synthetic_df[self.target_col]\n",
        "\n",
        "            X_train_real, enc_dict_X = self.preprocess_data(X_train_real)\n",
        "            X_test = self.encode_data(X_test, enc_dict_X)\n",
        "            X_train_synthetic = self.encode_data(X_train_synthetic, enc_dict_X)\n",
        "\n",
        "            if self.target_col in self.cat_cols:\n",
        "                enc_target = OrdinalEncoder(\n",
        "                    handle_unknown='use_encoded_value',\n",
        "                    unknown_value=-1\n",
        "                )\n",
        "\n",
        "                y_tr = y_train_real.astype(str).to_frame()\n",
        "                y_train_real = enc_target.fit_transform(y_tr).ravel().astype(int)\n",
        "                y_train_synthetic = enc_target.transform(\n",
        "                    y_train_synthetic.astype(str).to_frame()\n",
        "                ).ravel().astype(int)\n",
        "                y_test = enc_target.transform(\n",
        "                    y_test.astype(str).to_frame()\n",
        "                ).ravel().astype(int)\n",
        "\n",
        "            real_mean, real_std = self.train_and_evaluate(\n",
        "                X_train_real, X_test, y_train_real, y_test\n",
        "            )\n",
        "            synthetic_mean, synthetic_std = self.train_and_evaluate(\n",
        "                X_train_synthetic, X_test, y_train_synthetic, y_test\n",
        "            )\n",
        "\n",
        "            if self.classification:\n",
        "                print(\"Classificator results (AUC):\")\n",
        "            else:\n",
        "                print(\"Regression results (MSE):\")\n",
        "            print(f\"Real data - : {real_mean:.3f}  {real_std:.3f}\")\n",
        "            print(f\"Synthetic data - : {synthetic_mean:.3f}  {synthetic_std:.3f}\")\n",
        "\n",
        "            return {\n",
        "                'real_mean': real_mean, 'real_std': real_std,\n",
        "                'synthetic_mean': synthetic_mean, 'synthetic_std': synthetic_std\n",
        "            }\n",
        "\n",
        "\n",
        "    def density_estimation(self) -> dict:\n",
        "        qual_report = QualityReport()\n",
        "        qual_report.generate(self.real_df, self.synthetic_df, self.metadata)\n",
        "\n",
        "        diag_report = DiagnosticReport()\n",
        "        diag_report.generate(self.real_df, self.synthetic_df, self.metadata)\n",
        "\n",
        "        fig_shape = qual_report.get_visualization(property_name='Column Shapes')\n",
        "        fig_trend = qual_report.get_visualization(property_name='Column Pair Trends')\n",
        "        fig_shape.show()\n",
        "        fig_trend.show()\n",
        "\n",
        "        quality_scores = qual_report.get_score()\n",
        "        diag_scores = diag_report.get_score()\n",
        "        quality =  qual_report.get_properties()\n",
        "\n",
        "        Shape = quality['Score'][0]\n",
        "        Trend = quality['Score'][1]\n",
        "        shapes = qual_report.get_details(property_name='Column Shapes')\n",
        "        trends = qual_report.get_details(property_name='Column Pair Trends')\n",
        "        validity = diag_report.get_details('Data Validity')\n",
        "        structure = diag_report.get_details('Data Structure')\n",
        "\n",
        "        metrics = {\n",
        "            'overall_quality': {\n",
        "                'shapes': Shape,\n",
        "                'trends': Trend,\n",
        "                'total_score': (Shape + Trend) / 2\n",
        "            },\n",
        "            'details': {\n",
        "                'column_shapes': shapes,\n",
        "                'column_trends': trends,\n",
        "                'data_validity': validity,\n",
        "                'data_structure': structure\n",
        "            }\n",
        "        }\n",
        "\n",
        "        print(f\"\\n{' METRICS REPORT ':=^80}\")\n",
        "        print(f\"Column Shapes Score: {metrics['overall_quality']['shapes']:.3f}\")\n",
        "        print(f\"Column Trends Score: {metrics['overall_quality']['trends']:.3f}\")\n",
        "        print(f\"Overall Score: {metrics['overall_quality']['total_score']:.3f}\")\n",
        "\n",
        "        #fig = qual_report.get_visualization(property_name='Column Pair Trends')\n",
        "        #fig.show()\n",
        "\n",
        "        return metrics\n",
        "\n",
        "\n",
        "    def visualize_distr(self):\n",
        "        for i in self.numeric_cols:\n",
        "            fig = get_column_plot(\n",
        "                real_data=self.real_df,\n",
        "                synthetic_data=self.synthetic_df,\n",
        "                column_name= i,\n",
        "                plot_type='distplot'\n",
        "            )\n",
        "\n",
        "            fig.show()\n",
        "\n",
        "    def correlation_similarity(self):\n",
        "        correlation_score = CorrelationSimilarity.compute(\n",
        "            real_data=self.real_df[self.numeric_cols],\n",
        "            synthetic_data=self.synthetic_df[self.numeric_cols],\n",
        "            coefficient='Pearson'\n",
        "        )\n",
        "        print(f'correlation score: {correlation_score:.3f}')\n",
        "        return correlation_score\n",
        "\n",
        "    def contingency_similarity(self):\n",
        "        res = []\n",
        "        for col1, col2 in combinations(self.numeric_cols, 2):\n",
        "            similarity = ContingencySimilarity.compute(\n",
        "                real_data=self.real_df[[col1, col2]],\n",
        "                synthetic_data=self.synthetic_df[[col1, col2]],\n",
        "                continuous_column_names=[col1, col2]\n",
        "            )\n",
        "            res.append(similarity)\n",
        "        mean_similarity = statistics.mean(res)\n",
        "        print(f'contingency similarity score: {mean_similarity:.3f}')\n",
        "        return mean_similarity\n",
        "\n",
        "    def logistic_detection(self):\n",
        "        log_detection_score = LogisticDetection.compute(\n",
        "            real_data=self.real_df,\n",
        "            synthetic_data=self.synthetic_df,\n",
        "            metadata=self.metadata\n",
        "        )\n",
        "        print(f'log detection score: {log_detection_score:.3f}')\n",
        "        return log_detection_score\n",
        "\n",
        "    def alpha_precision(self):\n",
        "        num_real_data = self.real_df[self.numeric_cols]\n",
        "        cat_real_data = self.real_df[self.cat_cols]\n",
        "\n",
        "        num_syn_data = self.synthetic_df[self.numeric_cols]\n",
        "        cat_syn_data = self.synthetic_df[self.cat_cols]\n",
        "\n",
        "        encoder = OneHotEncoder()\n",
        "        cat_real_data_oh = encoder.fit_transform(cat_real_data.astype(str)).toarray()\n",
        "        cat_syn_data_oh = encoder.transform(cat_syn_data.astype(str)).toarray()\n",
        "\n",
        "        le_real_data = pd.DataFrame(np.concatenate([num_real_data.to_numpy(), cat_real_data_oh], axis=1))\n",
        "        le_syn_data = pd.DataFrame(np.concatenate([num_syn_data.to_numpy(), cat_syn_data_oh], axis=1))\n",
        "\n",
        "        X_real_loader = GenericDataLoader(le_real_data)\n",
        "        X_syn_loader = GenericDataLoader(le_syn_data)\n",
        "\n",
        "        quality_evaluator = eval_statistical.AlphaPrecision()\n",
        "        qual_res = quality_evaluator.evaluate(X_real_loader, X_syn_loader)\n",
        "\n",
        "        qual_res = {k: v for (k, v) in qual_res.items() if \"naive\" in k}\n",
        "        qual_score = np.mean(list(qual_res.values()))\n",
        "\n",
        "        print(f'Alpha Precision: {qual_res[\"delta_precision_alpha_naive\"]:.6f}, '\n",
        "              f'Beta Recall: {qual_res[\"delta_coverage_beta_naive\"]:.6f}')\n",
        "\n",
        "        return qual_res['delta_precision_alpha_naive'], qual_res['delta_coverage_beta_naive']\n",
        "\n",
        "    def dcr_score(self):\n",
        "        test_size = len(self.test)\n",
        "        train_data = self.real_df.sample(n=test_size, random_state=42)\n",
        "        test_data = self.test\n",
        "        synthetic_data = self.synthetic_df.sample(n=test_size, random_state=42)\n",
        "\n",
        "        num_train_data = train_data[self.numeric_cols]\n",
        "        num_synthetic_data = synthetic_data[self.numeric_cols]\n",
        "        num_test_data = test_data[self.numeric_cols]\n",
        "\n",
        "        num_train_data_np = num_train_data.to_numpy().astype(float)\n",
        "        num_synthetic_data_np = num_synthetic_data.to_numpy().astype(float)\n",
        "        num_test_data_np = num_test_data.to_numpy().astype(float)\n",
        "\n",
        "        num_ranges = np.array([train_data[col].max() - train_data[col].min() for col in self.numeric_cols]).astype(float)\n",
        "        num_train_data_np /= num_ranges\n",
        "        num_synthetic_data_np /= num_ranges\n",
        "        num_test_data_np /= num_ranges\n",
        "\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        train_data_th = torch.tensor(num_train_data_np).to(device)\n",
        "        synthetic_data_th = torch.tensor(num_synthetic_data_np).to(device)\n",
        "        test_data_th = torch.tensor(num_test_data_np).to(device)\n",
        "\n",
        "        batch_size = 100\n",
        "        dcrs_train = []\n",
        "        dcrs_test = []\n",
        "\n",
        "        for i in range((synthetic_data_th.shape[0] // batch_size) + 1):\n",
        "            batch_synthetic_data_th = synthetic_data_th[i*batch_size: (i+1) * batch_size]\n",
        "            dcr_train = (batch_synthetic_data_th[:, None] - train_data_th).abs().sum(dim=2).min(dim=1).values\n",
        "            dcr_test = (batch_synthetic_data_th[:, None] - test_data_th).abs().sum(dim=2).min(dim=1).values\n",
        "            dcrs_train.append(dcr_train)\n",
        "            dcrs_test.append(dcr_test)\n",
        "\n",
        "        dcrs_train = torch.cat(dcrs_train)\n",
        "        dcrs_test = torch.cat(dcrs_test)\n",
        "\n",
        "        score = (dcrs_train < dcrs_test).nonzero().shape[0] / dcrs_train.shape[0]\n",
        "        print(f'DCR Score = {score:.6f}')\n",
        "\n",
        "        return score\n",
        "\n",
        "    def collect_all_metrics(self):\n",
        "        metrics_dict = {}\n",
        "\n",
        "        #  \n",
        "        classification_metrics_result = self.classification_metrics()\n",
        "        metrics_dict.update(classification_metrics_result)\n",
        "\n",
        "        #  \n",
        "        density_metrics = self.density_estimation()\n",
        "        metrics_dict['density_metrics'] = density_metrics\n",
        "\n",
        "        #  \n",
        "        correlation_score = self.correlation_similarity()\n",
        "        metrics_dict['correlation_score'] = correlation_score\n",
        "\n",
        "        #  \n",
        "        contingency_similarity_score = self.contingency_similarity()\n",
        "        metrics_dict['contingency_similarity_score'] = contingency_similarity_score\n",
        "\n",
        "        #  \n",
        "        log_detection_score = self.logistic_detection()\n",
        "        metrics_dict['log_detection_score'] = log_detection_score\n",
        "\n",
        "        # Alpha Precision\n",
        "        alpha_precision, beta_recall = self.alpha_precision()\n",
        "        metrics_dict['alpha_precision'] = alpha_precision\n",
        "        metrics_dict['beta_recall'] = beta_recall\n",
        "\n",
        "        # DCR Score\n",
        "        dcr_score_value = self.dcr_score()\n",
        "        metrics_dict['dcr_score'] = dcr_score_value\n",
        "\n",
        "        return metrics_dict"
      ],
      "metadata": {
        "id": "-lBJFTzq6goM"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adult metrics"
      ],
      "metadata": {
        "id": "q6y5Fx-XVtUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "file_path = '/content/tabsyn/data/adult/info.json'\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    data = json.load(file)"
      ],
      "metadata": {
        "id": "ecmRcKrsDKqP"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nc5JfeE8DasU",
        "outputId": "19de2ecf-b939-4ca3-befa-29b304224f50"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'adult',\n",
              " 'task_type': 'binclass',\n",
              " 'header': None,\n",
              " 'column_names': ['age',\n",
              "  'workclass',\n",
              "  'fnlwgt',\n",
              "  'education',\n",
              "  'education.num',\n",
              "  'marital.status',\n",
              "  'occupation',\n",
              "  'relationship',\n",
              "  'race',\n",
              "  'sex',\n",
              "  'capital.gain',\n",
              "  'capital.loss',\n",
              "  'hours.per.week',\n",
              "  'native.country',\n",
              "  'income'],\n",
              " 'num_col_idx': [0, 2, 4, 10, 11, 12],\n",
              " 'cat_col_idx': [1, 3, 5, 6, 7, 8, 9, 13],\n",
              " 'target_col_idx': [14],\n",
              " 'file_type': 'csv',\n",
              " 'data_path': 'data/adult/adult.data',\n",
              " 'test_path': 'data/adult/adult.test',\n",
              " 'column_info': {'0': {},\n",
              "  'type': 'categorical',\n",
              "  'max': 99.0,\n",
              "  'min': 1.0,\n",
              "  '2': {},\n",
              "  '4': {},\n",
              "  '10': {},\n",
              "  '11': {},\n",
              "  '12': {},\n",
              "  '1': {},\n",
              "  'categorizes': [' >50K', ' <=50K'],\n",
              "  '3': {},\n",
              "  '5': {},\n",
              "  '6': {},\n",
              "  '7': {},\n",
              "  '8': {},\n",
              "  '9': {},\n",
              "  '13': {},\n",
              "  '14': {}},\n",
              " 'train_num': 32561,\n",
              " 'test_num': 16281,\n",
              " 'idx_mapping': {'0': 0,\n",
              "  '1': 6,\n",
              "  '2': 1,\n",
              "  '3': 7,\n",
              "  '4': 2,\n",
              "  '5': 8,\n",
              "  '6': 9,\n",
              "  '7': 10,\n",
              "  '8': 11,\n",
              "  '9': 12,\n",
              "  '10': 3,\n",
              "  '11': 4,\n",
              "  '12': 5,\n",
              "  '13': 13,\n",
              "  '14': 14},\n",
              " 'inverse_idx_mapping': {'0': 0,\n",
              "  '6': 1,\n",
              "  '1': 2,\n",
              "  '7': 3,\n",
              "  '2': 4,\n",
              "  '8': 5,\n",
              "  '9': 6,\n",
              "  '10': 7,\n",
              "  '11': 8,\n",
              "  '12': 9,\n",
              "  '3': 10,\n",
              "  '4': 11,\n",
              "  '5': 12,\n",
              "  '13': 13,\n",
              "  '14': 14},\n",
              " 'idx_name_mapping': {'0': 'age',\n",
              "  '1': 'workclass',\n",
              "  '2': 'fnlwgt',\n",
              "  '3': 'education',\n",
              "  '4': 'education.num',\n",
              "  '5': 'marital.status',\n",
              "  '6': 'occupation',\n",
              "  '7': 'relationship',\n",
              "  '8': 'race',\n",
              "  '9': 'sex',\n",
              "  '10': 'capital.gain',\n",
              "  '11': 'capital.loss',\n",
              "  '12': 'hours.per.week',\n",
              "  '13': 'native.country',\n",
              "  '14': 'income'},\n",
              " 'metadata': {'columns': {'0': {'sdtype': 'numerical',\n",
              "    'computer_representation': 'Float'},\n",
              "   '2': {'sdtype': 'numerical', 'computer_representation': 'Float'},\n",
              "   '4': {'sdtype': 'numerical', 'computer_representation': 'Float'},\n",
              "   '10': {'sdtype': 'numerical', 'computer_representation': 'Float'},\n",
              "   '11': {'sdtype': 'numerical', 'computer_representation': 'Float'},\n",
              "   '12': {'sdtype': 'numerical', 'computer_representation': 'Float'},\n",
              "   '1': {'sdtype': 'categorical'},\n",
              "   '3': {'sdtype': 'categorical'},\n",
              "   '5': {'sdtype': 'categorical'},\n",
              "   '6': {'sdtype': 'categorical'},\n",
              "   '7': {'sdtype': 'categorical'},\n",
              "   '8': {'sdtype': 'categorical'},\n",
              "   '9': {'sdtype': 'categorical'},\n",
              "   '13': {'sdtype': 'categorical'},\n",
              "   '14': {'sdtype': 'categorical'}}}}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adult_metrics = Metrics(train_path='/content/tabsyn/data/adult/train.csv',\n",
        "                        test_path='/content/tabsyn/data/adult/test.csv',\n",
        "                        synthetic_path='/content/adult_syn.csv',\n",
        "                        numeric_cols=data['num_col_idx'], cat_cols=data[\"cat_col_idx\"],\n",
        "                        target_col=data['target_col_idx'][0])"
      ],
      "metadata": {
        "id": "XxdI4v1nCq0a"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = adult_metrics.collect_all_metrics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E_XCVTNXDydj",
        "outputId": "189cfd40-a380-4ede-c302-db1068bf1553"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classificator results (AUC):\n",
            "Real data - : 0.925  0.000\n",
            "Synthetic data - : 0.880  0.005\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Column Shapes: || 15/15 [00:00<00:00, 66.45it/s]|\n",
            "Column Shapes Score: 87.14%\n",
            "\n",
            "(2/2) Evaluating Column Pair Trends: || 105/105 [00:01<00:00, 66.75it/s]|\n",
            "Column Pair Trends Score: 82.52%\n",
            "\n",
            "Overall Score (Average): 84.83%\n",
            "\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Data Validity: || 15/15 [00:00<00:00, 205.68it/s]|\n",
            "Data Validity Score: 100.0%\n",
            "\n",
            "(2/2) Evaluating Data Structure: || 1/1 [00:00<00:00, 332.27it/s]|\n",
            "Data Structure Score: 100.0%\n",
            "\n",
            "Overall Score (Average): 100.0%\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"6923ea9e-b05e-4ecb-9337-cd71f562d845\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6923ea9e-b05e-4ecb-9337-cd71f562d845\")) {                    Plotly.newPlot(                        \"6923ea9e-b05e-4ecb-9337-cd71f562d845\",                        [{\"alignmentgroup\":\"True\",\"customdata\":[[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"age\",\"fnlwgt\",\"education.num\",\"capital.gain\",\"capital.loss\",\"hours.per.week\"],\"legendgroup\":\"KSComplement\",\"marker\":{\"color\":\"#000036\",\"pattern\":{\"shape\":\"\"}},\"name\":\"KSComplement\",\"offsetgroup\":\"KSComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"age\",\"fnlwgt\",\"education.num\",\"capital.gain\",\"capital.loss\",\"hours.per.week\"],\"xaxis\":\"x\",\"y\":[0.8836030834433832,0.8033537053530296,0.957955836737201,0.9160038082368478,0.9706397223672492,0.8550105954976813],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"customdata\":[[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"workclass\",\"education\",\"marital.status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"native.country\",\"income\"],\"legendgroup\":\"TVComplement\",\"marker\":{\"color\":\"#03AFF1\",\"pattern\":{\"shape\":\"\\u002f\"}},\"name\":\"TVComplement\",\"offsetgroup\":\"TVComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"workclass\",\"education\",\"marital.status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"native.country\",\"income\"],\"xaxis\":\"x\",\"y\":[0.9107521267774331,0.862350664905869,0.8244218543656521,0.815884033045668,0.8392862627069193,0.8937993304873929,0.7398421424403427,0.8549184607352354,0.9427228893461503],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Column\"},\"categoryorder\":\"total ascending\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Score\"},\"range\":[0,1]},\"legend\":{\"title\":{\"text\":\"Metric\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Data Quality: Column Shapes (Average Score=0.87)\"},\"barmode\":\"relative\",\"margin\":{\"t\":150},\"font\":{\"size\":18},\"plot_bgcolor\":\"#F5F5F8\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('6923ea9e-b05e-4ecb-9337-cd71f562d845');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"dcbf179b-b90d-4778-b867-ae21aeb59a52\" class=\"plotly-graph-div\" style=\"height:900px; width:900px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"dcbf179b-b90d-4778-b867-ae21aeb59a52\")) {                    Plotly.newPlot(                        \"dcbf179b-b90d-4778-b867-ae21aeb59a52\",                        [{\"coloraxis\":\"coloraxis\",\"hovertemplate\":\"\\u003cb\\u003eColumn Pair\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSimilarity: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education.num\",\"marital.status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital.gain\",\"capital.loss\",\"hours.per.week\",\"native.country\",\"income\"],\"y\":[\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education.num\",\"marital.status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital.gain\",\"capital.loss\",\"hours.per.week\",\"native.country\",\"income\"],\"z\":[[1.0,0.832,0.99,0.815,0.992,0.79,0.776,0.808,0.843,0.71,0.971,0.987,0.991,0.815,0.876],[0.832,1.0,0.787,0.812,0.857,0.795,0.774,0.811,0.836,0.714,0.894,0.903,0.81,0.807,0.894],[0.99,0.787,1.0,0.783,0.989,0.771,0.764,0.775,0.782,0.694,0.995,1.0,0.978,0.762,0.818],[0.815,0.812,0.783,1.0,0.815,0.786,0.755,0.792,0.829,0.699,0.857,0.847,0.774,0.802,0.851],[0.992,0.857,0.989,0.815,1.0,0.804,0.785,0.82,0.866,0.715,0.999,0.985,0.997,0.831,0.893],[0.79,0.795,0.771,0.786,0.804,1.0,0.758,0.807,0.788,0.622,0.81,0.817,0.726,0.766,0.817],[0.776,0.774,0.764,0.755,0.785,0.758,1.0,0.757,0.777,0.708,0.806,0.804,0.753,0.749,0.806],[0.808,0.811,0.775,0.792,0.82,0.807,0.757,1.0,0.807,0.624,0.83,0.827,0.745,0.792,0.837],[0.843,0.836,0.782,0.829,0.866,0.788,0.777,0.807,1.0,0.739,0.877,0.891,0.804,0.807,0.89],[0.71,0.714,0.694,0.699,0.715,0.622,0.708,0.624,0.739,1.0,0.74,0.719,0.719,0.735,0.715],[0.971,0.894,0.995,0.857,0.999,0.81,0.806,0.83,0.877,0.74,1.0,0.998,0.982,0.839,0.923],[0.987,0.903,1.0,0.847,0.985,0.817,0.804,0.827,0.891,0.719,0.998,1.0,0.987,0.852,0.929],[0.991,0.81,0.978,0.774,0.997,0.726,0.753,0.745,0.804,0.719,0.982,0.987,1.0,0.775,0.833],[0.815,0.807,0.762,0.802,0.831,0.766,0.749,0.792,0.807,0.735,0.839,0.852,0.775,1.0,0.853],[0.876,0.894,0.818,0.851,0.893,0.817,0.806,0.837,0.89,0.715,0.923,0.929,0.833,0.853,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,-0.057,0.02,0.136,0.031,0.051],[-0.057,1.0,-0.021,-0.009,-0.011,-0.063],[0.02,-0.021,1.0,0.121,0.049,0.143],[0.136,-0.009,0.121,1.0,-0.027,0.115],[0.031,-0.011,0.049,-0.027,1.0,0.028],[0.051,-0.063,0.143,0.115,0.028,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"age\",\"fnlwgt\",\"education.num\",\"capital.gain\",\"capital.loss\",\"hours.per.week\"],\"y\":[\"age\",\"fnlwgt\",\"education.num\",\"capital.gain\",\"capital.loss\",\"hours.per.week\"],\"z\":[[1.0,-0.077,0.037,0.078,0.058,0.069],[-0.077,1.0,-0.043,0.0,-0.01,-0.019],[0.037,-0.043,1.0,0.123,0.08,0.148],[0.078,0.0,0.123,1.0,-0.032,0.078],[0.058,-0.01,0.08,-0.032,1.0,0.054],[0.069,-0.019,0.148,0.078,0.054,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,-0.077,0.037,0.078,0.058,0.069],[-0.077,1.0,-0.043,0.0,-0.01,-0.019],[0.037,-0.043,1.0,0.123,0.08,0.148],[0.078,0.0,0.123,1.0,-0.032,0.078],[0.058,-0.01,0.08,-0.032,1.0,0.054],[0.069,-0.019,0.148,0.078,0.054,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"age\",\"fnlwgt\",\"education.num\",\"capital.gain\",\"capital.loss\",\"hours.per.week\"],\"y\":[\"age\",\"fnlwgt\",\"education.num\",\"capital.gain\",\"capital.loss\",\"hours.per.week\"],\"z\":[[1.0,-0.057,0.02,0.136,0.031,0.051],[-0.057,1.0,-0.021,-0.009,-0.011,-0.063],[0.02,-0.021,1.0,0.121,0.049,0.143],[0.136,-0.009,0.121,1.0,-0.027,0.115],[0.031,-0.011,0.049,-0.027,1.0,0.028],[0.051,-0.063,0.143,0.115,0.028,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.26,0.74],\"tickangle\":45},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"autorange\":\"reversed\"},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,0.45],\"tickangle\":45},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.375],\"autorange\":\"reversed\"},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.55,1.0],\"tickangle\":45,\"matches\":\"x2\"},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"visible\":false,\"matches\":\"y2\",\"autorange\":\"reversed\"},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Real vs. Synthetic Similarity\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Real Data)\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Synthetic Data)\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Data Quality: Column Pair Trends (Average Score=0.83)\"},\"coloraxis\":{\"colorbar\":{\"len\":0.5,\"x\":0.8,\"y\":0.8},\"cmin\":0,\"cmax\":1,\"colorscale\":[[0.0,\"#FF0000\"],[0.5,\"#F16141\"],[1.0,\"#36B37E\"]]},\"coloraxis2\":{\"colorbar\":{\"len\":0.5,\"y\":0.2},\"cmin\":-1,\"cmax\":1,\"colorscale\":[[0.0,\"#03AFF1\"],[0.5,\"#000036\"],[1.0,\"#01E0C9\"]]},\"font\":{\"size\":18},\"height\":900,\"width\":900},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('dcbf179b-b90d-4778-b867-ae21aeb59a52');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================ METRICS REPORT ================================\n",
            "Column Shapes Score: 0.871\n",
            "Column Trends Score: 0.825\n",
            "Overall Score: 0.848\n",
            "correlation score: 0.990\n",
            "contingency similarity score: 0.841\n",
            "log detection score: 0.366\n",
            "Alpha Precision: 0.874265, Beta Recall: 0.307114\n",
            "DCR Score = 0.494748\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Default metrics"
      ],
      "metadata": {
        "id": "rAQq7--VVwyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/tabsyn/data/default/info.json'\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "default_metrics = Metrics(train_path='/content/tabsyn/data/default/train.csv',\n",
        "                        test_path='/content/tabsyn/data/default/test.csv',\n",
        "                        synthetic_path='/content/default_syn.csv',\n",
        "                        numeric_cols=data['num_col_idx'], cat_cols=data[\"cat_col_idx\"],\n",
        "                        target_col=data['target_col_idx'][0])"
      ],
      "metadata": {
        "id": "BImWzDh5RZ2e"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = default_metrics.collect_all_metrics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qu2Fb4QlRsLn",
        "outputId": "44d207ec-dc45-49f3-b4c1-99eb2f7a6644"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classificator results (AUC):\n",
            "Real data - : 0.763  0.003\n",
            "Synthetic data - : 0.735  0.000\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Column Shapes: || 24/24 [00:00<00:00, 87.49it/s]| \n",
            "Column Shapes Score: 81.97%\n",
            "\n",
            "(2/2) Evaluating Column Pair Trends: || 276/276 [00:01<00:00, 140.39it/s]|\n",
            "Column Pair Trends Score: 88.78%\n",
            "\n",
            "Overall Score (Average): 85.38%\n",
            "\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Data Validity: || 24/24 [00:00<00:00, 494.14it/s]|\n",
            "Data Validity Score: 100.0%\n",
            "\n",
            "(2/2) Evaluating Data Structure: || 1/1 [00:00<00:00, 329.20it/s]|\n",
            "Data Structure Score: 100.0%\n",
            "\n",
            "Overall Score (Average): 100.0%\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"1c4d25e2-f5fb-4a0b-90df-d0882f010239\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1c4d25e2-f5fb-4a0b-90df-d0882f010239\")) {                    Plotly.newPlot(                        \"1c4d25e2-f5fb-4a0b-90df-d0882f010239\",                        [{\"alignmentgroup\":\"True\",\"customdata\":[[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"LIMIT_BAL\",\"AGE\",\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\"],\"legendgroup\":\"KSComplement\",\"marker\":{\"color\":\"#000036\",\"pattern\":{\"shape\":\"\"}},\"name\":\"KSComplement\",\"offsetgroup\":\"KSComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"LIMIT_BAL\",\"AGE\",\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\"],\"xaxis\":\"x\",\"y\":[0.8049999999999999,0.9247407407407406,0.49003703703703705,0.684962962962963,0.8541851851851852,0.706037037037037,0.6291851851851852,0.5767037037037037,0.9687037037037037,0.9743703703703703,0.9295925925925926,0.8670740740740741,0.9360740740740741,0.9216296296296296,0.9374814814814815,0.9030740740740741,0.9081851851851852,0.9483703703703703,0.8101111111111111,0.7497777777777779],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"customdata\":[[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"SEX\",\"EDUCATION\",\"MARRIAGE\",\"default payment next month\"],\"legendgroup\":\"TVComplement\",\"marker\":{\"color\":\"#03AFF1\",\"pattern\":{\"shape\":\"\\u002f\"}},\"name\":\"TVComplement\",\"offsetgroup\":\"TVComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"SEX\",\"EDUCATION\",\"MARRIAGE\",\"default payment next month\"],\"xaxis\":\"x\",\"y\":[0.9279259259259259,0.758074074074074,0.8170740740740741,0.6452592592592593],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Column\"},\"categoryorder\":\"total ascending\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Score\"},\"range\":[0,1]},\"legend\":{\"title\":{\"text\":\"Metric\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Data Quality: Column Shapes (Average Score=0.82)\"},\"barmode\":\"relative\",\"margin\":{\"t\":150},\"font\":{\"size\":18},\"plot_bgcolor\":\"#F5F5F8\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1c4d25e2-f5fb-4a0b-90df-d0882f010239');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"e77584ed-66c2-414a-a7ec-b1f330faafe3\" class=\"plotly-graph-div\" style=\"height:900px; width:900px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e77584ed-66c2-414a-a7ec-b1f330faafe3\")) {                    Plotly.newPlot(                        \"e77584ed-66c2-414a-a7ec-b1f330faafe3\",                        [{\"coloraxis\":\"coloraxis\",\"hovertemplate\":\"\\u003cb\\u003eColumn Pair\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSimilarity: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"LIMIT_BAL\",\"SEX\",\"EDUCATION\",\"MARRIAGE\",\"AGE\",\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\",\"default payment next month\"],\"y\":[\"LIMIT_BAL\",\"SEX\",\"EDUCATION\",\"MARRIAGE\",\"AGE\",\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\",\"default payment next month\"],\"z\":[[1.0,0.8,0.722,0.769,0.99,0.984,0.964,0.966,0.989,0.987,0.984,0.938,0.943,0.946,0.934,0.967,0.969,0.998,0.982,0.994,0.981,0.965,0.997,0.645],[0.8,1.0,0.758,0.817,0.897,0.48,0.665,0.687,0.699,0.605,0.569,0.925,0.927,0.927,0.902,0.927,0.919,0.921,0.922,0.92,0.913,0.924,0.89,0.645],[0.722,0.758,1.0,0.738,0.748,0.48,0.633,0.603,0.672,0.563,0.548,0.757,0.758,0.758,0.756,0.758,0.757,0.753,0.754,0.753,0.75,0.756,0.74,0.645],[0.769,0.817,0.738,1.0,0.771,0.48,0.645,0.622,0.697,0.581,0.568,0.816,0.817,0.817,0.816,0.817,0.816,0.814,0.813,0.812,0.811,0.812,0.794,0.642],[0.99,0.897,0.748,0.771,1.0,0.989,0.987,0.995,0.997,0.988,0.981,0.991,0.999,0.999,0.996,0.999,0.997,0.996,1.0,1.0,0.994,0.989,0.974,0.635],[0.984,0.48,0.48,0.48,0.989,1.0,0.971,0.937,0.951,0.951,0.951,0.946,0.958,0.958,0.946,0.965,0.967,0.993,0.992,0.973,0.991,0.989,0.984,0.458],[0.964,0.665,0.633,0.645,0.987,0.971,1.0,0.911,0.908,0.91,0.909,0.933,0.939,0.936,0.916,0.946,0.951,0.997,0.993,0.971,0.988,0.994,0.972,0.551],[0.966,0.687,0.603,0.622,0.995,0.937,0.911,1.0,0.921,0.914,0.91,0.944,0.947,0.943,0.937,0.961,0.966,0.986,0.99,0.983,0.99,0.999,0.981,0.496],[0.989,0.699,0.672,0.697,0.997,0.951,0.908,0.921,1.0,0.911,0.904,0.92,0.924,0.922,0.918,0.94,0.947,0.986,0.986,0.973,0.979,0.998,0.96,0.559],[0.987,0.605,0.563,0.581,0.988,0.951,0.91,0.914,0.911,1.0,0.91,0.952,0.959,0.954,0.943,0.964,0.971,0.987,0.983,0.955,0.977,0.991,0.976,0.534],[0.984,0.569,0.548,0.568,0.981,0.951,0.909,0.91,0.904,0.91,1.0,0.942,0.945,0.938,0.929,0.959,0.963,0.987,0.982,0.964,0.978,0.98,0.99,0.511],[0.938,0.925,0.757,0.816,0.991,0.946,0.933,0.944,0.92,0.952,0.942,1.0,0.975,0.973,0.969,0.964,0.966,0.99,0.985,0.956,0.983,0.963,0.983,0.644],[0.943,0.927,0.758,0.817,0.999,0.958,0.939,0.947,0.924,0.959,0.945,0.975,1.0,0.981,0.97,0.964,0.964,0.972,0.98,0.949,0.975,0.964,0.98,0.645],[0.946,0.927,0.758,0.817,0.999,0.958,0.936,0.943,0.922,0.954,0.938,0.973,0.981,1.0,0.974,0.96,0.96,0.974,0.955,0.952,0.975,0.958,0.978,0.645],[0.934,0.902,0.756,0.816,0.996,0.946,0.916,0.937,0.918,0.943,0.929,0.969,0.97,0.974,1.0,0.932,0.935,1.0,0.984,0.957,0.981,0.968,0.994,0.643],[0.967,0.927,0.758,0.817,0.999,0.965,0.946,0.961,0.94,0.964,0.959,0.964,0.964,0.96,0.932,1.0,0.992,0.968,0.97,0.907,0.976,0.98,0.993,0.645],[0.969,0.919,0.757,0.816,0.997,0.967,0.951,0.966,0.947,0.971,0.963,0.966,0.964,0.96,0.935,0.992,1.0,0.966,0.964,0.913,0.974,0.942,0.996,0.644],[0.998,0.921,0.753,0.814,0.996,0.993,0.997,0.986,0.986,0.987,0.987,0.99,0.972,0.974,1.0,0.968,0.966,1.0,0.909,0.964,0.946,0.962,0.994,0.638],[0.982,0.922,0.754,0.813,1.0,0.992,0.993,0.99,0.986,0.983,0.982,0.985,0.98,0.955,0.984,0.97,0.964,0.909,1.0,0.914,0.946,0.932,0.959,0.64],[0.994,0.92,0.753,0.812,1.0,0.973,0.971,0.983,0.973,0.955,0.964,0.956,0.949,0.952,0.957,0.907,0.913,0.964,0.914,1.0,0.943,0.954,0.987,0.638],[0.981,0.913,0.75,0.811,0.994,0.991,0.988,0.99,0.979,0.977,0.978,0.983,0.975,0.975,0.981,0.976,0.974,0.946,0.946,0.943,1.0,0.972,0.994,0.636],[0.965,0.924,0.756,0.812,0.989,0.989,0.994,0.999,0.998,0.991,0.98,0.963,0.964,0.958,0.968,0.98,0.942,0.962,0.932,0.954,0.972,1.0,0.969,0.645],[0.997,0.89,0.74,0.794,0.974,0.984,0.972,0.981,0.96,0.976,0.99,0.983,0.98,0.978,0.994,0.993,0.996,0.994,0.959,0.987,0.994,0.969,1.0,0.611],[0.645,0.645,0.645,0.642,0.635,0.458,0.551,0.496,0.559,0.534,0.511,0.644,0.645,0.645,0.643,0.645,0.644,0.638,0.64,0.638,0.636,0.645,0.611,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,0.165,-0.24,-0.225,-0.22,-0.244,-0.224,-0.204,0.409,0.393,0.391,0.425,0.361,0.352,0.191,0.137,0.196,0.164,0.144,0.215],[0.165,1.0,-0.059,-0.021,-0.04,-0.054,-0.074,-0.086,0.078,0.06,0.057,0.046,0.055,0.056,0.033,0.022,0.032,0.032,0.041,0.067],[-0.24,-0.059,1.0,0.612,0.448,0.439,0.411,0.376,0.08,0.105,0.096,0.071,0.109,0.111,-0.066,-0.084,-0.126,-0.084,-0.039,-0.091],[-0.225,-0.021,0.612,1.0,0.589,0.477,0.443,0.393,0.101,0.113,0.096,0.055,0.113,0.121,-0.087,-0.072,-0.115,-0.072,-0.026,-0.091],[-0.22,-0.04,0.448,0.589,1.0,0.62,0.516,0.454,0.098,0.132,0.114,0.102,0.147,0.155,-0.029,-0.086,-0.09,-0.067,-0.034,-0.075],[-0.244,-0.054,0.439,0.477,0.62,1.0,0.642,0.525,0.043,0.075,0.09,0.082,0.122,0.132,-0.039,-0.03,-0.123,-0.087,-0.038,-0.106],[-0.224,-0.074,0.411,0.443,0.516,0.642,1.0,0.637,0.109,0.144,0.15,0.157,0.197,0.204,-0.033,-0.037,-0.081,-0.103,-0.052,-0.07],[-0.204,-0.086,0.376,0.393,0.454,0.525,0.637,1.0,0.089,0.115,0.116,0.122,0.207,0.21,-0.029,-0.044,-0.066,-0.023,-0.088,-0.047],[0.409,0.078,0.08,0.101,0.098,0.043,0.109,0.089,1.0,0.902,0.839,0.799,0.758,0.737,0.12,0.068,0.068,0.123,0.093,0.136],[0.393,0.06,0.105,0.113,0.132,0.075,0.144,0.115,0.902,1.0,0.89,0.833,0.789,0.762,0.223,0.059,0.05,0.097,0.088,0.128],[0.391,0.057,0.096,0.096,0.114,0.09,0.15,0.116,0.839,0.89,1.0,0.871,0.803,0.775,0.189,0.226,0.034,0.09,0.1,0.127],[0.425,0.046,0.071,0.055,0.102,0.082,0.157,0.122,0.799,0.833,0.871,1.0,0.802,0.772,0.23,0.171,0.21,0.09,0.098,0.182],[0.361,0.055,0.109,0.113,0.147,0.122,0.197,0.207,0.758,0.789,0.803,0.802,1.0,0.931,0.149,0.116,0.063,0.246,0.101,0.142],[0.352,0.056,0.111,0.121,0.155,0.132,0.204,0.21,0.737,0.762,0.775,0.772,0.931,1.0,0.129,0.097,0.055,0.199,0.189,0.119],[0.191,0.033,-0.066,-0.087,-0.029,-0.039,-0.033,-0.029,0.12,0.223,0.189,0.23,0.149,0.129,1.0,0.115,0.182,0.089,0.064,0.177],[0.137,0.022,-0.084,-0.072,-0.086,-0.03,-0.037,-0.044,0.068,0.059,0.226,0.171,0.116,0.097,0.115,1.0,0.077,0.072,0.048,0.069],[0.196,0.032,-0.126,-0.115,-0.09,-0.123,-0.081,-0.066,0.068,0.05,0.034,0.21,0.063,0.055,0.182,0.077,1.0,0.097,0.055,0.132],[0.164,0.032,-0.084,-0.072,-0.067,-0.087,-0.103,-0.023,0.123,0.097,0.09,0.09,0.246,0.199,0.089,0.072,0.097,1.0,0.081,0.135],[0.144,0.041,-0.039,-0.026,-0.034,-0.038,-0.052,-0.088,0.093,0.088,0.1,0.098,0.101,0.189,0.064,0.048,0.055,0.081,1.0,0.083],[0.215,0.067,-0.091,-0.091,-0.075,-0.106,-0.07,-0.047,0.136,0.128,0.127,0.182,0.142,0.119,0.177,0.069,0.132,0.135,0.083,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"LIMIT_BAL\",\"AGE\",\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\"],\"y\":[\"LIMIT_BAL\",\"AGE\",\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\"],\"z\":[[1.0,0.145,-0.272,-0.298,-0.287,-0.267,-0.25,-0.236,0.285,0.278,0.282,0.293,0.296,0.291,0.196,0.173,0.208,0.202,0.215,0.222],[0.145,1.0,-0.036,-0.047,-0.05,-0.047,-0.051,-0.049,0.059,0.057,0.056,0.054,0.052,0.05,0.026,0.021,0.031,0.021,0.02,0.014],[-0.272,-0.036,1.0,0.671,0.575,0.537,0.509,0.474,0.187,0.19,0.18,0.179,0.18,0.176,-0.079,-0.068,-0.071,-0.065,-0.06,-0.058],[-0.298,-0.047,0.671,1.0,0.768,0.661,0.624,0.576,0.235,0.235,0.224,0.223,0.221,0.219,-0.081,-0.059,-0.056,-0.048,-0.038,-0.036],[-0.287,-0.05,0.575,0.768,1.0,0.778,0.688,0.634,0.21,0.238,0.228,0.228,0.226,0.223,-0.002,-0.066,-0.056,-0.047,-0.037,-0.036],[-0.267,-0.047,0.537,0.661,0.778,1.0,0.821,0.716,0.203,0.226,0.245,0.246,0.243,0.239,-0.011,-0.003,-0.07,-0.045,-0.034,-0.026],[-0.25,-0.051,0.509,0.624,0.688,0.821,1.0,0.817,0.206,0.226,0.242,0.271,0.268,0.261,-0.008,-0.004,0.008,-0.058,-0.034,-0.023],[-0.236,-0.049,0.474,0.576,0.634,0.716,0.817,1.0,0.206,0.225,0.239,0.265,0.289,0.283,-0.003,-0.007,0.006,0.02,-0.047,-0.027],[0.285,0.059,0.187,0.235,0.21,0.203,0.206,0.206,1.0,0.952,0.892,0.861,0.831,0.806,0.14,0.098,0.156,0.157,0.167,0.17],[0.278,0.057,0.19,0.235,0.238,0.226,0.226,0.225,0.952,1.0,0.928,0.893,0.86,0.834,0.279,0.1,0.152,0.146,0.159,0.167],[0.282,0.056,0.18,0.224,0.228,0.245,0.242,0.239,0.892,0.928,1.0,0.923,0.883,0.855,0.24,0.316,0.129,0.141,0.183,0.171],[0.293,0.054,0.179,0.223,0.228,0.246,0.271,0.265,0.861,0.893,0.923,1.0,0.939,0.901,0.229,0.202,0.297,0.129,0.161,0.17],[0.296,0.052,0.18,0.221,0.226,0.243,0.268,0.289,0.831,0.86,0.883,0.939,1.0,0.947,0.214,0.175,0.249,0.294,0.141,0.156],[0.291,0.05,0.176,0.219,0.223,0.239,0.261,0.283,0.806,0.834,0.855,0.901,0.947,1.0,0.197,0.169,0.229,0.251,0.306,0.112],[0.196,0.026,-0.079,-0.081,-0.002,-0.011,-0.008,-0.003,0.14,0.279,0.24,0.229,0.214,0.197,1.0,0.298,0.254,0.196,0.14,0.188],[0.173,0.021,-0.068,-0.059,-0.066,-0.003,-0.004,-0.007,0.098,0.1,0.316,0.202,0.175,0.169,0.298,1.0,0.249,0.18,0.185,0.151],[0.208,0.031,-0.071,-0.056,-0.056,-0.07,0.008,0.006,0.156,0.152,0.129,0.297,0.249,0.229,0.254,0.249,1.0,0.212,0.147,0.158],[0.202,0.021,-0.065,-0.048,-0.047,-0.045,-0.058,0.02,0.157,0.146,0.141,0.129,0.294,0.251,0.196,0.18,0.212,1.0,0.138,0.146],[0.215,0.02,-0.06,-0.038,-0.037,-0.034,-0.034,-0.047,0.167,0.159,0.183,0.161,0.141,0.306,0.14,0.185,0.147,0.138,1.0,0.145],[0.222,0.014,-0.058,-0.036,-0.036,-0.026,-0.023,-0.027,0.17,0.167,0.171,0.17,0.156,0.112,0.188,0.151,0.158,0.146,0.145,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,0.145,-0.272,-0.298,-0.287,-0.267,-0.25,-0.236,0.285,0.278,0.282,0.293,0.296,0.291,0.196,0.173,0.208,0.202,0.215,0.222],[0.145,1.0,-0.036,-0.047,-0.05,-0.047,-0.051,-0.049,0.059,0.057,0.056,0.054,0.052,0.05,0.026,0.021,0.031,0.021,0.02,0.014],[-0.272,-0.036,1.0,0.671,0.575,0.537,0.509,0.474,0.187,0.19,0.18,0.179,0.18,0.176,-0.079,-0.068,-0.071,-0.065,-0.06,-0.058],[-0.298,-0.047,0.671,1.0,0.768,0.661,0.624,0.576,0.235,0.235,0.224,0.223,0.221,0.219,-0.081,-0.059,-0.056,-0.048,-0.038,-0.036],[-0.287,-0.05,0.575,0.768,1.0,0.778,0.688,0.634,0.21,0.238,0.228,0.228,0.226,0.223,-0.002,-0.066,-0.056,-0.047,-0.037,-0.036],[-0.267,-0.047,0.537,0.661,0.778,1.0,0.821,0.716,0.203,0.226,0.245,0.246,0.243,0.239,-0.011,-0.003,-0.07,-0.045,-0.034,-0.026],[-0.25,-0.051,0.509,0.624,0.688,0.821,1.0,0.817,0.206,0.226,0.242,0.271,0.268,0.261,-0.008,-0.004,0.008,-0.058,-0.034,-0.023],[-0.236,-0.049,0.474,0.576,0.634,0.716,0.817,1.0,0.206,0.225,0.239,0.265,0.289,0.283,-0.003,-0.007,0.006,0.02,-0.047,-0.027],[0.285,0.059,0.187,0.235,0.21,0.203,0.206,0.206,1.0,0.952,0.892,0.861,0.831,0.806,0.14,0.098,0.156,0.157,0.167,0.17],[0.278,0.057,0.19,0.235,0.238,0.226,0.226,0.225,0.952,1.0,0.928,0.893,0.86,0.834,0.279,0.1,0.152,0.146,0.159,0.167],[0.282,0.056,0.18,0.224,0.228,0.245,0.242,0.239,0.892,0.928,1.0,0.923,0.883,0.855,0.24,0.316,0.129,0.141,0.183,0.171],[0.293,0.054,0.179,0.223,0.228,0.246,0.271,0.265,0.861,0.893,0.923,1.0,0.939,0.901,0.229,0.202,0.297,0.129,0.161,0.17],[0.296,0.052,0.18,0.221,0.226,0.243,0.268,0.289,0.831,0.86,0.883,0.939,1.0,0.947,0.214,0.175,0.249,0.294,0.141,0.156],[0.291,0.05,0.176,0.219,0.223,0.239,0.261,0.283,0.806,0.834,0.855,0.901,0.947,1.0,0.197,0.169,0.229,0.251,0.306,0.112],[0.196,0.026,-0.079,-0.081,-0.002,-0.011,-0.008,-0.003,0.14,0.279,0.24,0.229,0.214,0.197,1.0,0.298,0.254,0.196,0.14,0.188],[0.173,0.021,-0.068,-0.059,-0.066,-0.003,-0.004,-0.007,0.098,0.1,0.316,0.202,0.175,0.169,0.298,1.0,0.249,0.18,0.185,0.151],[0.208,0.031,-0.071,-0.056,-0.056,-0.07,0.008,0.006,0.156,0.152,0.129,0.297,0.249,0.229,0.254,0.249,1.0,0.212,0.147,0.158],[0.202,0.021,-0.065,-0.048,-0.047,-0.045,-0.058,0.02,0.157,0.146,0.141,0.129,0.294,0.251,0.196,0.18,0.212,1.0,0.138,0.146],[0.215,0.02,-0.06,-0.038,-0.037,-0.034,-0.034,-0.047,0.167,0.159,0.183,0.161,0.141,0.306,0.14,0.185,0.147,0.138,1.0,0.145],[0.222,0.014,-0.058,-0.036,-0.036,-0.026,-0.023,-0.027,0.17,0.167,0.171,0.17,0.156,0.112,0.188,0.151,0.158,0.146,0.145,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"LIMIT_BAL\",\"AGE\",\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\"],\"y\":[\"LIMIT_BAL\",\"AGE\",\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\"],\"z\":[[1.0,0.165,-0.24,-0.225,-0.22,-0.244,-0.224,-0.204,0.409,0.393,0.391,0.425,0.361,0.352,0.191,0.137,0.196,0.164,0.144,0.215],[0.165,1.0,-0.059,-0.021,-0.04,-0.054,-0.074,-0.086,0.078,0.06,0.057,0.046,0.055,0.056,0.033,0.022,0.032,0.032,0.041,0.067],[-0.24,-0.059,1.0,0.612,0.448,0.439,0.411,0.376,0.08,0.105,0.096,0.071,0.109,0.111,-0.066,-0.084,-0.126,-0.084,-0.039,-0.091],[-0.225,-0.021,0.612,1.0,0.589,0.477,0.443,0.393,0.101,0.113,0.096,0.055,0.113,0.121,-0.087,-0.072,-0.115,-0.072,-0.026,-0.091],[-0.22,-0.04,0.448,0.589,1.0,0.62,0.516,0.454,0.098,0.132,0.114,0.102,0.147,0.155,-0.029,-0.086,-0.09,-0.067,-0.034,-0.075],[-0.244,-0.054,0.439,0.477,0.62,1.0,0.642,0.525,0.043,0.075,0.09,0.082,0.122,0.132,-0.039,-0.03,-0.123,-0.087,-0.038,-0.106],[-0.224,-0.074,0.411,0.443,0.516,0.642,1.0,0.637,0.109,0.144,0.15,0.157,0.197,0.204,-0.033,-0.037,-0.081,-0.103,-0.052,-0.07],[-0.204,-0.086,0.376,0.393,0.454,0.525,0.637,1.0,0.089,0.115,0.116,0.122,0.207,0.21,-0.029,-0.044,-0.066,-0.023,-0.088,-0.047],[0.409,0.078,0.08,0.101,0.098,0.043,0.109,0.089,1.0,0.902,0.839,0.799,0.758,0.737,0.12,0.068,0.068,0.123,0.093,0.136],[0.393,0.06,0.105,0.113,0.132,0.075,0.144,0.115,0.902,1.0,0.89,0.833,0.789,0.762,0.223,0.059,0.05,0.097,0.088,0.128],[0.391,0.057,0.096,0.096,0.114,0.09,0.15,0.116,0.839,0.89,1.0,0.871,0.803,0.775,0.189,0.226,0.034,0.09,0.1,0.127],[0.425,0.046,0.071,0.055,0.102,0.082,0.157,0.122,0.799,0.833,0.871,1.0,0.802,0.772,0.23,0.171,0.21,0.09,0.098,0.182],[0.361,0.055,0.109,0.113,0.147,0.122,0.197,0.207,0.758,0.789,0.803,0.802,1.0,0.931,0.149,0.116,0.063,0.246,0.101,0.142],[0.352,0.056,0.111,0.121,0.155,0.132,0.204,0.21,0.737,0.762,0.775,0.772,0.931,1.0,0.129,0.097,0.055,0.199,0.189,0.119],[0.191,0.033,-0.066,-0.087,-0.029,-0.039,-0.033,-0.029,0.12,0.223,0.189,0.23,0.149,0.129,1.0,0.115,0.182,0.089,0.064,0.177],[0.137,0.022,-0.084,-0.072,-0.086,-0.03,-0.037,-0.044,0.068,0.059,0.226,0.171,0.116,0.097,0.115,1.0,0.077,0.072,0.048,0.069],[0.196,0.032,-0.126,-0.115,-0.09,-0.123,-0.081,-0.066,0.068,0.05,0.034,0.21,0.063,0.055,0.182,0.077,1.0,0.097,0.055,0.132],[0.164,0.032,-0.084,-0.072,-0.067,-0.087,-0.103,-0.023,0.123,0.097,0.09,0.09,0.246,0.199,0.089,0.072,0.097,1.0,0.081,0.135],[0.144,0.041,-0.039,-0.026,-0.034,-0.038,-0.052,-0.088,0.093,0.088,0.1,0.098,0.101,0.189,0.064,0.048,0.055,0.081,1.0,0.083],[0.215,0.067,-0.091,-0.091,-0.075,-0.106,-0.07,-0.047,0.136,0.128,0.127,0.182,0.142,0.119,0.177,0.069,0.132,0.135,0.083,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.26,0.74],\"tickangle\":45},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"autorange\":\"reversed\"},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,0.45],\"tickangle\":45},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.375],\"autorange\":\"reversed\"},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.55,1.0],\"tickangle\":45,\"matches\":\"x2\"},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"visible\":false,\"matches\":\"y2\",\"autorange\":\"reversed\"},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Real vs. Synthetic Similarity\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Real Data)\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Synthetic Data)\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Data Quality: Column Pair Trends (Average Score=0.89)\"},\"coloraxis\":{\"colorbar\":{\"len\":0.5,\"x\":0.8,\"y\":0.8},\"cmin\":0,\"cmax\":1,\"colorscale\":[[0.0,\"#FF0000\"],[0.5,\"#F16141\"],[1.0,\"#36B37E\"]]},\"coloraxis2\":{\"colorbar\":{\"len\":0.5,\"y\":0.2},\"cmin\":-1,\"cmax\":1,\"colorscale\":[[0.0,\"#03AFF1\"],[0.5,\"#000036\"],[1.0,\"#01E0C9\"]]},\"font\":{\"size\":18},\"height\":900,\"width\":900},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e77584ed-66c2-414a-a7ec-b1f330faafe3');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================ METRICS REPORT ================================\n",
            "Column Shapes Score: 0.820\n",
            "Column Trends Score: 0.888\n",
            "Overall Score: 0.854\n",
            "correlation score: 0.990\n",
            "contingency similarity score: 0.920\n",
            "log detection score: 0.247\n",
            "Alpha Precision: 0.626906, Beta Recall: 0.213642\n",
            "DCR Score = 0.506667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Shoppers metrics"
      ],
      "metadata": {
        "id": "r9EePrbOV0GE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/tabsyn/data/shoppers/info.json'\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "shoppers_metrics = Metrics(train_path='/content/tabsyn/data/shoppers/train.csv',\n",
        "                        test_path='/content/tabsyn/data/shoppers/test.csv',\n",
        "                        synthetic_path='/content/shoppers_syn.csv',\n",
        "                        numeric_cols=data['num_col_idx'], cat_cols=data[\"cat_col_idx\"],\n",
        "                        target_col=data['target_col_idx'][0])\n",
        "metrics = shoppers_metrics.collect_all_metrics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0Rf6bkgXVnxu",
        "outputId": "82893b68-2ec5-42d9-f7d9-cdbd39adc763"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classificator results (AUC):\n",
            "Real data - : 0.927  0.001\n",
            "Synthetic data - : 0.896  0.000\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Column Shapes: || 18/18 [00:00<00:00, 203.38it/s]|\n",
            "Column Shapes Score: 77.04%\n",
            "\n",
            "(2/2) Evaluating Column Pair Trends: || 153/153 [00:00<00:00, 168.80it/s]|\n",
            "Column Pair Trends Score: 79.33%\n",
            "\n",
            "Overall Score (Average): 78.19%\n",
            "\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Data Validity: || 18/18 [00:00<00:00, 654.09it/s]|\n",
            "Data Validity Score: 100.0%\n",
            "\n",
            "(2/2) Evaluating Data Structure: || 1/1 [00:00<00:00, 367.57it/s]|\n",
            "Data Structure Score: 100.0%\n",
            "\n",
            "Overall Score (Average): 100.0%\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"6e3a682c-a5fa-4927-8ebe-a765edefcf68\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6e3a682c-a5fa-4927-8ebe-a765edefcf68\")) {                    Plotly.newPlot(                        \"6e3a682c-a5fa-4927-8ebe-a765edefcf68\",                        [{\"alignmentgroup\":\"True\",\"customdata\":[[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"Administrative\",\"Administrative_Duration\",\"Informational\",\"Informational_Duration\",\"ProductRelated\",\"ProductRelated_Duration\",\"BounceRates\",\"ExitRates\",\"PageValues\",\"SpecialDay\",\"Browser\",\"TrafficType\"],\"legendgroup\":\"KSComplement\",\"marker\":{\"color\":\"#000036\",\"pattern\":{\"shape\":\"\"}},\"name\":\"KSComplement\",\"offsetgroup\":\"KSComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"Administrative\",\"Administrative_Duration\",\"Informational\",\"Informational_Duration\",\"ProductRelated\",\"ProductRelated_Duration\",\"BounceRates\",\"ExitRates\",\"PageValues\",\"SpecialDay\",\"Browser\",\"TrafficType\"],\"xaxis\":\"x\",\"y\":[0.7508335586194467,0.8279715238352708,0.9473731639181762,0.9591781562584483,0.5012165450121655,0.6283680273947914,0.9316932504280435,0.6813553212579976,0.7478597819230423,0.943227899432279,0.7355141029106965,0.7143372082544832],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"customdata\":[[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"Month\",\"OperatingSystems\",\"Region\",\"VisitorType\",\"Weekend\",\"Revenue\"],\"legendgroup\":\"TVComplement\",\"marker\":{\"color\":\"#03AFF1\",\"pattern\":{\"shape\":\"\\u002f\"}},\"name\":\"TVComplement\",\"offsetgroup\":\"TVComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"Month\",\"OperatingSystems\",\"Region\",\"VisitorType\",\"Weekend\",\"Revenue\"],\"xaxis\":\"x\",\"y\":[0.8372533117058665,0.6957736325132919,0.6578354510227988,0.9188969991889699,0.8161665314949986,0.5723168423898352],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Column\"},\"categoryorder\":\"total ascending\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Score\"},\"range\":[0,1]},\"legend\":{\"title\":{\"text\":\"Metric\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Data Quality: Column Shapes (Average Score=0.77)\"},\"barmode\":\"relative\",\"margin\":{\"t\":150},\"font\":{\"size\":18},\"plot_bgcolor\":\"#F5F5F8\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('6e3a682c-a5fa-4927-8ebe-a765edefcf68');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"85f11a44-18d0-4e4e-8466-66b100a113a2\" class=\"plotly-graph-div\" style=\"height:900px; width:900px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"85f11a44-18d0-4e4e-8466-66b100a113a2\")) {                    Plotly.newPlot(                        \"85f11a44-18d0-4e4e-8466-66b100a113a2\",                        [{\"coloraxis\":\"coloraxis\",\"hovertemplate\":\"\\u003cb\\u003eColumn Pair\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSimilarity: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"Administrative\",\"Administrative_Duration\",\"Informational\",\"Informational_Duration\",\"ProductRelated\",\"ProductRelated_Duration\",\"BounceRates\",\"ExitRates\",\"PageValues\",\"SpecialDay\",\"Month\",\"OperatingSystems\",\"Browser\",\"Region\",\"TrafficType\",\"VisitorType\",\"Weekend\",\"Revenue\"],\"y\":[\"Administrative\",\"Administrative_Duration\",\"Informational\",\"Informational_Duration\",\"ProductRelated\",\"ProductRelated_Duration\",\"BounceRates\",\"ExitRates\",\"PageValues\",\"SpecialDay\",\"Month\",\"OperatingSystems\",\"Browser\",\"Region\",\"TrafficType\",\"VisitorType\",\"Weekend\",\"Revenue\"],\"z\":[[1.0,0.948,0.928,0.976,0.961,0.945,0.953,0.939,0.952,0.969,0.715,0.636,0.975,0.619,0.973,0.755,0.735,0.523],[0.948,1.0,0.904,0.94,0.955,0.917,0.972,0.967,0.96,0.979,0.801,0.675,0.977,0.647,0.985,0.909,0.816,0.559],[0.928,0.904,1.0,0.891,0.914,0.904,0.953,0.944,0.951,0.979,0.832,0.695,0.983,0.653,0.978,0.915,0.816,0.572],[0.976,0.94,0.891,1.0,0.962,0.932,0.983,0.981,0.959,0.994,0.825,0.688,0.974,0.653,0.977,0.918,0.816,0.57],[0.961,0.955,0.914,0.962,1.0,0.859,0.995,0.98,0.918,0.996,0.516,0.482,0.963,0.525,0.993,0.532,0.524,0.438],[0.945,0.917,0.904,0.932,0.859,1.0,0.973,0.95,0.956,0.995,0.784,0.645,0.98,0.627,0.994,0.881,0.811,0.538],[0.953,0.972,0.953,0.983,0.995,0.973,1.0,0.958,0.998,0.965,0.819,0.694,0.997,0.645,0.962,0.859,0.788,0.572],[0.939,0.967,0.944,0.981,0.98,0.95,0.958,1.0,0.996,0.957,0.665,0.628,0.99,0.585,0.957,0.645,0.622,0.572],[0.952,0.96,0.951,0.959,0.918,0.956,0.998,0.996,1.0,0.978,0.714,0.614,0.98,0.604,1.0,0.757,0.757,0.533],[0.969,0.979,0.979,0.994,0.996,0.995,0.965,0.957,0.978,1.0,0.821,0.685,0.996,0.632,0.972,0.853,0.747,0.571],[0.715,0.801,0.832,0.825,0.516,0.784,0.819,0.665,0.714,0.821,1.0,0.67,0.676,0.631,0.583,0.815,0.77,0.559],[0.636,0.675,0.695,0.688,0.482,0.645,0.694,0.628,0.614,0.685,0.67,1.0,0.535,0.582,0.57,0.69,0.65,0.524],[0.975,0.977,0.983,0.974,0.963,0.98,0.997,0.99,0.98,0.996,0.676,0.535,1.0,0.619,0.941,0.722,0.715,0.507],[0.619,0.647,0.653,0.653,0.525,0.627,0.645,0.585,0.604,0.632,0.631,0.582,0.619,1.0,0.569,0.643,0.583,0.568],[0.973,0.985,0.978,0.977,0.993,0.994,0.962,0.957,1.0,0.972,0.583,0.57,0.941,0.569,1.0,0.615,0.582,0.535],[0.755,0.909,0.915,0.918,0.532,0.881,0.859,0.645,0.757,0.853,0.815,0.69,0.722,0.643,0.615,1.0,0.772,0.572],[0.735,0.816,0.816,0.816,0.524,0.811,0.788,0.622,0.757,0.747,0.77,0.65,0.715,0.583,0.582,0.772,1.0,0.56],[0.523,0.559,0.572,0.57,0.438,0.538,0.572,0.572,0.533,0.571,0.559,0.524,0.507,0.568,0.535,0.572,0.56,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,0.498,0.233,0.208,0.359,0.265,-0.128,-0.193,0.191,-0.03,0.028,0.018],[0.498,1.0,0.12,0.129,0.209,0.204,-0.087,-0.138,0.145,-0.031,0.033,0.016],[0.233,0.12,1.0,0.394,0.205,0.202,-0.021,-0.05,0.147,-0.004,-0.001,0.019],[0.208,0.129,0.394,1.0,0.205,0.22,-0.039,-0.066,0.11,-0.016,0.034,0.027],[0.359,0.209,0.205,0.205,1.0,0.578,-0.192,-0.248,0.219,-0.031,0.063,-0.027],[0.265,0.204,0.202,0.22,0.578,1.0,-0.127,-0.149,0.137,-0.024,0.033,-0.025],[-0.128,-0.087,-0.021,-0.039,-0.192,-0.127,1.0,0.829,-0.122,0.006,-0.03,-0.001],[-0.193,-0.138,-0.05,-0.066,-0.248,-0.149,0.829,1.0,-0.18,0.018,-0.031,-0.011],[0.191,0.145,0.147,0.11,0.219,0.137,-0.122,-0.18,1.0,-0.019,0.008,0.015],[-0.03,-0.031,-0.004,-0.016,-0.031,-0.024,0.006,0.018,-0.019,1.0,-0.005,-0.008],[0.028,0.033,-0.001,0.034,0.063,0.033,-0.03,-0.031,0.008,-0.005,1.0,-0.011],[0.018,0.016,0.019,0.027,-0.027,-0.025,-0.001,-0.011,0.015,-0.008,-0.011,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"Administrative\",\"Administrative_Duration\",\"Informational\",\"Informational_Duration\",\"ProductRelated\",\"ProductRelated_Duration\",\"BounceRates\",\"ExitRates\",\"PageValues\",\"SpecialDay\",\"Browser\",\"TrafficType\"],\"y\":[\"Administrative\",\"Administrative_Duration\",\"Informational\",\"Informational_Duration\",\"ProductRelated\",\"ProductRelated_Duration\",\"BounceRates\",\"ExitRates\",\"PageValues\",\"SpecialDay\",\"Browser\",\"TrafficType\"],\"z\":[[1.0,0.603,0.377,0.257,0.437,0.376,-0.222,-0.315,0.096,-0.092,-0.021,-0.035],[0.603,1.0,0.313,0.249,0.299,0.369,-0.143,-0.204,0.065,-0.072,-0.013,-0.013],[0.377,0.313,1.0,0.612,0.377,0.394,-0.115,-0.163,0.048,-0.045,-0.036,-0.026],[0.257,0.249,0.612,1.0,0.282,0.356,-0.073,-0.104,0.028,-0.029,-0.018,-0.018],[0.437,0.299,0.377,0.282,1.0,0.859,-0.202,-0.289,0.054,-0.022,-0.012,-0.042],[0.376,0.369,0.394,0.356,0.859,1.0,-0.182,-0.248,0.05,-0.034,-0.006,-0.036],[-0.222,-0.143,-0.115,-0.073,-0.202,-0.182,1.0,0.912,-0.118,0.075,-0.024,0.075],[-0.315,-0.204,-0.163,-0.104,-0.289,-0.248,0.912,1.0,-0.173,0.104,-0.011,0.076],[0.096,0.065,0.048,0.028,0.054,0.05,-0.118,-0.173,1.0,-0.062,0.047,0.014],[-0.092,-0.072,-0.045,-0.029,-0.022,-0.034,0.075,0.104,-0.062,1.0,0.003,0.049],[-0.021,-0.013,-0.036,-0.018,-0.012,-0.006,-0.024,-0.011,0.047,0.003,1.0,0.106],[-0.035,-0.013,-0.026,-0.018,-0.042,-0.036,0.075,0.076,0.014,0.049,0.106,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,0.603,0.377,0.257,0.437,0.376,-0.222,-0.315,0.096,-0.092,-0.021,-0.035],[0.603,1.0,0.313,0.249,0.299,0.369,-0.143,-0.204,0.065,-0.072,-0.013,-0.013],[0.377,0.313,1.0,0.612,0.377,0.394,-0.115,-0.163,0.048,-0.045,-0.036,-0.026],[0.257,0.249,0.612,1.0,0.282,0.356,-0.073,-0.104,0.028,-0.029,-0.018,-0.018],[0.437,0.299,0.377,0.282,1.0,0.859,-0.202,-0.289,0.054,-0.022,-0.012,-0.042],[0.376,0.369,0.394,0.356,0.859,1.0,-0.182,-0.248,0.05,-0.034,-0.006,-0.036],[-0.222,-0.143,-0.115,-0.073,-0.202,-0.182,1.0,0.912,-0.118,0.075,-0.024,0.075],[-0.315,-0.204,-0.163,-0.104,-0.289,-0.248,0.912,1.0,-0.173,0.104,-0.011,0.076],[0.096,0.065,0.048,0.028,0.054,0.05,-0.118,-0.173,1.0,-0.062,0.047,0.014],[-0.092,-0.072,-0.045,-0.029,-0.022,-0.034,0.075,0.104,-0.062,1.0,0.003,0.049],[-0.021,-0.013,-0.036,-0.018,-0.012,-0.006,-0.024,-0.011,0.047,0.003,1.0,0.106],[-0.035,-0.013,-0.026,-0.018,-0.042,-0.036,0.075,0.076,0.014,0.049,0.106,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"Administrative\",\"Administrative_Duration\",\"Informational\",\"Informational_Duration\",\"ProductRelated\",\"ProductRelated_Duration\",\"BounceRates\",\"ExitRates\",\"PageValues\",\"SpecialDay\",\"Browser\",\"TrafficType\"],\"y\":[\"Administrative\",\"Administrative_Duration\",\"Informational\",\"Informational_Duration\",\"ProductRelated\",\"ProductRelated_Duration\",\"BounceRates\",\"ExitRates\",\"PageValues\",\"SpecialDay\",\"Browser\",\"TrafficType\"],\"z\":[[1.0,0.498,0.233,0.208,0.359,0.265,-0.128,-0.193,0.191,-0.03,0.028,0.018],[0.498,1.0,0.12,0.129,0.209,0.204,-0.087,-0.138,0.145,-0.031,0.033,0.016],[0.233,0.12,1.0,0.394,0.205,0.202,-0.021,-0.05,0.147,-0.004,-0.001,0.019],[0.208,0.129,0.394,1.0,0.205,0.22,-0.039,-0.066,0.11,-0.016,0.034,0.027],[0.359,0.209,0.205,0.205,1.0,0.578,-0.192,-0.248,0.219,-0.031,0.063,-0.027],[0.265,0.204,0.202,0.22,0.578,1.0,-0.127,-0.149,0.137,-0.024,0.033,-0.025],[-0.128,-0.087,-0.021,-0.039,-0.192,-0.127,1.0,0.829,-0.122,0.006,-0.03,-0.001],[-0.193,-0.138,-0.05,-0.066,-0.248,-0.149,0.829,1.0,-0.18,0.018,-0.031,-0.011],[0.191,0.145,0.147,0.11,0.219,0.137,-0.122,-0.18,1.0,-0.019,0.008,0.015],[-0.03,-0.031,-0.004,-0.016,-0.031,-0.024,0.006,0.018,-0.019,1.0,-0.005,-0.008],[0.028,0.033,-0.001,0.034,0.063,0.033,-0.03,-0.031,0.008,-0.005,1.0,-0.011],[0.018,0.016,0.019,0.027,-0.027,-0.025,-0.001,-0.011,0.015,-0.008,-0.011,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.26,0.74],\"tickangle\":45},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"autorange\":\"reversed\"},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,0.45],\"tickangle\":45},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.375],\"autorange\":\"reversed\"},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.55,1.0],\"tickangle\":45,\"matches\":\"x2\"},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"visible\":false,\"matches\":\"y2\",\"autorange\":\"reversed\"},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Real vs. Synthetic Similarity\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Real Data)\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Synthetic Data)\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Data Quality: Column Pair Trends (Average Score=0.79)\"},\"coloraxis\":{\"colorbar\":{\"len\":0.5,\"x\":0.8,\"y\":0.8},\"cmin\":0,\"cmax\":1,\"colorscale\":[[0.0,\"#FF0000\"],[0.5,\"#F16141\"],[1.0,\"#36B37E\"]]},\"coloraxis2\":{\"colorbar\":{\"len\":0.5,\"y\":0.2},\"cmin\":-1,\"cmax\":1,\"colorscale\":[[0.0,\"#03AFF1\"],[0.5,\"#000036\"],[1.0,\"#01E0C9\"]]},\"font\":{\"size\":18},\"height\":900,\"width\":900},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('85f11a44-18d0-4e4e-8466-66b100a113a2');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================ METRICS REPORT ================================\n",
            "Column Shapes Score: 0.770\n",
            "Column Trends Score: 0.793\n",
            "Overall Score: 0.782\n",
            "correlation score: 0.948\n",
            "contingency similarity score: 0.738\n",
            "log detection score: 0.182\n",
            "Alpha Precision: 0.621952, Beta Recall: 0.169163\n",
            "DCR Score = 0.492295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Magic metrics"
      ],
      "metadata": {
        "id": "SwT1TJtsV2MJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/tabsyn/data/magic/info.json'\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "magic_metrics = Metrics(train_path='/content/tabsyn/data/magic/train.csv',\n",
        "                        test_path='/content/tabsyn/data/magic/test.csv',\n",
        "                        synthetic_path='/content/magic_syn.csv',\n",
        "                        numeric_cols=data['num_col_idx'], cat_cols=data[\"cat_col_idx\"],\n",
        "                        target_col=data['target_col_idx'][0])\n",
        "metrics = magic_metrics.collect_all_metrics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6MSs6V6mWEXz",
        "outputId": "c3d39955-16c3-43fc-a56e-7ee0abab5d83"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classificator results (AUC):\n",
            "Real data - : 0.947  0.001\n",
            "Synthetic data - : 0.893  0.001\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Column Shapes: || 11/11 [00:00<00:00, 188.37it/s]|\n",
            "Column Shapes Score: 64.22%\n",
            "\n",
            "(2/2) Evaluating Column Pair Trends: || 55/55 [00:00<00:00, 122.75it/s]|\n",
            "Column Pair Trends Score: 82.58%\n",
            "\n",
            "Overall Score (Average): 73.4%\n",
            "\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Data Validity: || 11/11 [00:00<00:00, 515.47it/s]|\n",
            "Data Validity Score: 100.0%\n",
            "\n",
            "(2/2) Evaluating Data Structure: || 1/1 [00:00<00:00, 262.75it/s]|\n",
            "Data Structure Score: 100.0%\n",
            "\n",
            "Overall Score (Average): 100.0%\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"c34835d8-fde4-4f95-9fbc-592fc295df06\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c34835d8-fde4-4f95-9fbc-592fc295df06\")) {                    Plotly.newPlot(                        \"c34835d8-fde4-4f95-9fbc-592fc295df06\",                        [{\"alignmentgroup\":\"True\",\"customdata\":[[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"Length\",\"Width\",\"Size\",\"Conc\",\"Conc1\",\"Asym\",\"M3Long\",\"M3Trans\",\"Alpha\",\"Dist\"],\"legendgroup\":\"KSComplement\",\"marker\":{\"color\":\"#000036\",\"pattern\":{\"shape\":\"\"}},\"name\":\"KSComplement\",\"offsetgroup\":\"KSComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"Length\",\"Width\",\"Size\",\"Conc\",\"Conc1\",\"Asym\",\"M3Long\",\"M3Trans\",\"Alpha\",\"Dist\"],\"xaxis\":\"x\",\"y\":[0.24385114213939352,0.5340304959981306,0.6356254016474849,0.6623240053747735,0.6828883566045452,0.7701700064263597,0.5777297423613952,0.6955073903137231,0.8162645323362739,0.9044809253958054],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"customdata\":[[\"TVComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"class\"],\"legendgroup\":\"TVComplement\",\"marker\":{\"color\":\"#03AFF1\",\"pattern\":{\"shape\":\"\\u002f\"}},\"name\":\"TVComplement\",\"offsetgroup\":\"TVComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"class\"],\"xaxis\":\"x\",\"y\":[0.5418589706140094],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Column\"},\"categoryorder\":\"total ascending\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Score\"},\"range\":[0,1]},\"legend\":{\"title\":{\"text\":\"Metric\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Data Quality: Column Shapes (Average Score=0.64)\"},\"barmode\":\"relative\",\"margin\":{\"t\":150},\"font\":{\"size\":18},\"plot_bgcolor\":\"#F5F5F8\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c34835d8-fde4-4f95-9fbc-592fc295df06');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"ecbf99b4-a2b8-45eb-a21c-dad9015480eb\" class=\"plotly-graph-div\" style=\"height:900px; width:900px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ecbf99b4-a2b8-45eb-a21c-dad9015480eb\")) {                    Plotly.newPlot(                        \"ecbf99b4-a2b8-45eb-a21c-dad9015480eb\",                        [{\"coloraxis\":\"coloraxis\",\"hovertemplate\":\"\\u003cb\\u003eColumn Pair\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSimilarity: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"Length\",\"Width\",\"Size\",\"Conc\",\"Conc1\",\"Asym\",\"M3Long\",\"M3Trans\",\"Alpha\",\"Dist\",\"class\"],\"y\":[\"Length\",\"Width\",\"Size\",\"Conc\",\"Conc1\",\"Asym\",\"M3Long\",\"M3Trans\",\"Alpha\",\"Dist\",\"class\"],\"z\":[[1.0,0.86,0.833,0.901,0.9,0.791,0.853,0.929,0.8,0.715,0.252],[0.86,1.0,0.983,0.987,0.977,0.84,0.931,0.847,0.817,0.855,0.47],[0.833,0.983,1.0,0.991,0.988,0.922,0.859,0.921,0.772,0.891,0.483],[0.901,0.987,0.991,1.0,0.997,0.929,0.861,0.932,0.762,0.878,0.489],[0.9,0.977,0.988,0.997,1.0,0.968,0.87,0.935,0.774,0.892,0.499],[0.791,0.84,0.922,0.929,0.968,1.0,0.981,0.971,0.967,1.0,0.521],[0.853,0.931,0.859,0.861,0.87,0.981,1.0,0.904,0.994,0.977,0.428],[0.929,0.847,0.921,0.932,0.935,0.971,0.904,1.0,0.924,0.983,0.537],[0.8,0.817,0.772,0.762,0.774,0.967,0.994,0.924,1.0,0.994,0.542],[0.715,0.855,0.891,0.878,0.892,1.0,0.977,0.983,0.994,1.0,0.542],[0.252,0.47,0.483,0.489,0.499,0.521,0.428,0.537,0.542,0.542,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,0.492,0.369,-0.433,-0.4,0.041,-0.414,0.16,0.392,-0.151],[0.492,1.0,0.687,-0.586,-0.539,0.038,-0.318,0.357,0.43,0.05],[0.369,0.687,1.0,-0.832,-0.785,-0.008,-0.187,0.179,0.268,0.219],[-0.433,-0.586,-0.832,1.0,0.971,-0.025,0.156,-0.152,-0.24,-0.087],[-0.4,-0.539,-0.785,0.971,1.0,0.041,0.14,-0.144,-0.221,-0.091],[0.041,0.038,-0.008,-0.025,0.041,1.0,0.235,-0.072,0.012,-0.203],[-0.414,-0.318,-0.187,0.156,0.14,0.235,1.0,-0.211,-0.197,-0.008],[0.16,0.357,0.179,-0.152,-0.144,-0.072,-0.211,1.0,0.16,0.04],[0.392,0.43,0.268,-0.24,-0.221,0.012,-0.197,0.16,1.0,-0.21],[-0.151,0.05,0.219,-0.087,-0.091,-0.203,-0.008,0.04,-0.21,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"Length\",\"Width\",\"Size\",\"Conc\",\"Conc1\",\"Asym\",\"M3Long\",\"M3Trans\",\"Alpha\",\"Dist\"],\"y\":[\"Length\",\"Width\",\"Size\",\"Conc\",\"Conc1\",\"Asym\",\"M3Long\",\"M3Trans\",\"Alpha\",\"Dist\"],\"z\":[[1.0,0.773,0.703,-0.632,-0.599,-0.377,-0.12,0.019,-0.007,0.419],[0.773,1.0,0.721,-0.613,-0.584,-0.283,-0.181,0.05,0.065,0.34],[0.703,0.721,1.0,-0.851,-0.809,-0.163,0.095,0.022,-0.187,0.438],[-0.632,-0.613,-0.851,1.0,0.977,0.117,-0.122,-0.016,0.237,-0.331],[-0.599,-0.584,-0.809,0.977,1.0,0.105,-0.119,-0.015,0.231,-0.306],[-0.377,-0.283,-0.163,0.117,0.105,1.0,0.274,-0.014,-0.054,-0.204],[-0.12,-0.181,0.095,-0.122,-0.119,0.274,1.0,-0.02,-0.185,0.038],[0.019,0.05,0.022,-0.016,-0.015,-0.014,-0.02,1.0,0.007,0.006],[-0.007,0.065,-0.187,0.237,0.231,-0.054,-0.185,0.007,1.0,-0.221],[0.419,0.34,0.438,-0.331,-0.306,-0.204,0.038,0.006,-0.221,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,0.773,0.703,-0.632,-0.599,-0.377,-0.12,0.019,-0.007,0.419],[0.773,1.0,0.721,-0.613,-0.584,-0.283,-0.181,0.05,0.065,0.34],[0.703,0.721,1.0,-0.851,-0.809,-0.163,0.095,0.022,-0.187,0.438],[-0.632,-0.613,-0.851,1.0,0.977,0.117,-0.122,-0.016,0.237,-0.331],[-0.599,-0.584,-0.809,0.977,1.0,0.105,-0.119,-0.015,0.231,-0.306],[-0.377,-0.283,-0.163,0.117,0.105,1.0,0.274,-0.014,-0.054,-0.204],[-0.12,-0.181,0.095,-0.122,-0.119,0.274,1.0,-0.02,-0.185,0.038],[0.019,0.05,0.022,-0.016,-0.015,-0.014,-0.02,1.0,0.007,0.006],[-0.007,0.065,-0.187,0.237,0.231,-0.054,-0.185,0.007,1.0,-0.221],[0.419,0.34,0.438,-0.331,-0.306,-0.204,0.038,0.006,-0.221,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"Length\",\"Width\",\"Size\",\"Conc\",\"Conc1\",\"Asym\",\"M3Long\",\"M3Trans\",\"Alpha\",\"Dist\"],\"y\":[\"Length\",\"Width\",\"Size\",\"Conc\",\"Conc1\",\"Asym\",\"M3Long\",\"M3Trans\",\"Alpha\",\"Dist\"],\"z\":[[1.0,0.492,0.369,-0.433,-0.4,0.041,-0.414,0.16,0.392,-0.151],[0.492,1.0,0.687,-0.586,-0.539,0.038,-0.318,0.357,0.43,0.05],[0.369,0.687,1.0,-0.832,-0.785,-0.008,-0.187,0.179,0.268,0.219],[-0.433,-0.586,-0.832,1.0,0.971,-0.025,0.156,-0.152,-0.24,-0.087],[-0.4,-0.539,-0.785,0.971,1.0,0.041,0.14,-0.144,-0.221,-0.091],[0.041,0.038,-0.008,-0.025,0.041,1.0,0.235,-0.072,0.012,-0.203],[-0.414,-0.318,-0.187,0.156,0.14,0.235,1.0,-0.211,-0.197,-0.008],[0.16,0.357,0.179,-0.152,-0.144,-0.072,-0.211,1.0,0.16,0.04],[0.392,0.43,0.268,-0.24,-0.221,0.012,-0.197,0.16,1.0,-0.21],[-0.151,0.05,0.219,-0.087,-0.091,-0.203,-0.008,0.04,-0.21,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.26,0.74],\"tickangle\":45},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"autorange\":\"reversed\"},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,0.45],\"tickangle\":45},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.375],\"autorange\":\"reversed\"},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.55,1.0],\"tickangle\":45,\"matches\":\"x2\"},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"visible\":false,\"matches\":\"y2\",\"autorange\":\"reversed\"},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Real vs. Synthetic Similarity\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Real Data)\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Synthetic Data)\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Data Quality: Column Pair Trends (Average Score=0.83)\"},\"coloraxis\":{\"colorbar\":{\"len\":0.5,\"x\":0.8,\"y\":0.8},\"cmin\":0,\"cmax\":1,\"colorscale\":[[0.0,\"#FF0000\"],[0.5,\"#F16141\"],[1.0,\"#36B37E\"]]},\"coloraxis2\":{\"colorbar\":{\"len\":0.5,\"y\":0.2},\"cmin\":-1,\"cmax\":1,\"colorscale\":[[0.0,\"#03AFF1\"],[0.5,\"#000036\"],[1.0,\"#01E0C9\"]]},\"font\":{\"size\":18},\"height\":900,\"width\":900},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ecbf99b4-a2b8-45eb-a21c-dad9015480eb');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================ METRICS REPORT ================================\n",
            "Column Shapes Score: 0.642\n",
            "Column Trends Score: 0.826\n",
            "Overall Score: 0.734\n",
            "correlation score: 0.860\n",
            "contingency similarity score: 0.484\n",
            "log detection score: 0.069\n",
            "Alpha Precision: 0.288064, Beta Recall: 0.116936\n",
            "DCR Score = 0.514721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Beijing metrics"
      ],
      "metadata": {
        "id": "t5sVZtYGV3nx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/tabsyn/data/beijing/info.json'\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "beijing_metrics = Metrics(train_path='/content/tabsyn/data/beijing/train.csv',\n",
        "                        test_path='/content/tabsyn/data/beijing/test.csv',\n",
        "                        synthetic_path='/content/beijing_syn.csv',\n",
        "                        numeric_cols=data['num_col_idx'], cat_cols=data[\"cat_col_idx\"],\n",
        "                        target_col=data['target_col_idx'][0], classification=False)\n",
        "metrics = beijing_metrics.collect_all_metrics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V_ttfonFWThz",
        "outputId": "d4cb06c0-5d4b-4e59-f5a2-58d16324976f"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression results (MSE):\n",
            "Real data - : 35.902  0.079\n",
            "Synthetic data - : 723.950  0.000\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Column Shapes: || 12/12 [00:00<00:00, 62.33it/s]|\n",
            "Column Shapes Score: 58.56%\n",
            "\n",
            "(2/2) Evaluating Column Pair Trends: || 66/66 [00:00<00:00, 79.78it/s]|\n",
            "Column Pair Trends Score: 78.4%\n",
            "\n",
            "Overall Score (Average): 68.48%\n",
            "\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Data Validity: || 12/12 [00:00<00:00, 164.05it/s]|\n",
            "Data Validity Score: 100.0%\n",
            "\n",
            "(2/2) Evaluating Data Structure: || 1/1 [00:00<00:00, 335.04it/s]|\n",
            "Data Structure Score: 100.0%\n",
            "\n",
            "Overall Score (Average): 100.0%\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"971c0392-065e-4cd5-b276-12b99e638a46\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"971c0392-065e-4cd5-b276-12b99e638a46\")) {                    Plotly.newPlot(                        \"971c0392-065e-4cd5-b276-12b99e638a46\",                        [{\"alignmentgroup\":\"True\",\"customdata\":[[\"TVComplement\"],[\"TVComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"year\",\"cbwd\"],\"legendgroup\":\"TVComplement\",\"marker\":{\"color\":\"#03AFF1\",\"pattern\":{\"shape\":\"\"}},\"name\":\"TVComplement\",\"offsetgroup\":\"TVComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"year\",\"cbwd\"],\"xaxis\":\"x\",\"y\":[0.35956999547643753,0.6282696043213325],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"customdata\":[[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"month\",\"day\",\"hour\",\"pm2.5\",\"DEWP\",\"TEMP\",\"PRES\",\"Iws\",\"Is\",\"Ir\"],\"legendgroup\":\"KSComplement\",\"marker\":{\"color\":\"#000036\",\"pattern\":{\"shape\":\"\\u002f\"}},\"name\":\"KSComplement\",\"offsetgroup\":\"KSComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"month\",\"day\",\"hour\",\"pm2.5\",\"DEWP\",\"TEMP\",\"PRES\",\"Iws\",\"Is\",\"Ir\"],\"xaxis\":\"x\",\"y\":[0.46041882866342043,0.8279449721933956,0.39559883983928046,0.010750113089060931,0.7000878103296879,0.4250818232617546,0.49437215614273167,0.7695111891647375,0.9824911524440542,0.972778797796759],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Column\"},\"categoryorder\":\"total ascending\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Score\"},\"range\":[0,1]},\"legend\":{\"title\":{\"text\":\"Metric\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Data Quality: Column Shapes (Average Score=0.59)\"},\"barmode\":\"relative\",\"margin\":{\"t\":150},\"font\":{\"size\":18},\"plot_bgcolor\":\"#F5F5F8\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('971c0392-065e-4cd5-b276-12b99e638a46');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"2ac4ad93-613e-467a-9ef0-1a323f3a826d\" class=\"plotly-graph-div\" style=\"height:900px; width:900px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2ac4ad93-613e-467a-9ef0-1a323f3a826d\")) {                    Plotly.newPlot(                        \"2ac4ad93-613e-467a-9ef0-1a323f3a826d\",                        [{\"coloraxis\":\"coloraxis\",\"hovertemplate\":\"\\u003cb\\u003eColumn Pair\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSimilarity: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"year\",\"month\",\"day\",\"hour\",\"pm2.5\",\"DEWP\",\"TEMP\",\"PRES\",\"cbwd\",\"Iws\",\"Is\",\"Ir\"],\"y\":[\"year\",\"month\",\"day\",\"hour\",\"pm2.5\",\"DEWP\",\"TEMP\",\"PRES\",\"cbwd\",\"Iws\",\"Is\",\"Ir\"],\"z\":[[1.0,0.25,0.36,0.312,0.011,0.33,0.287,0.316,0.36,0.359,0.356,0.36],[0.25,1.0,0.99,1.0,0.986,0.98,0.999,0.973,0.362,0.995,0.986,1.0],[0.36,0.99,1.0,0.994,0.976,0.992,0.998,0.994,0.594,0.99,0.995,1.0],[0.312,1.0,0.994,1.0,0.973,0.998,0.903,0.959,0.412,0.984,0.981,0.999],[0.011,0.986,0.976,0.973,1.0,0.917,0.987,0.936,0.016,0.913,0.991,0.986],[0.33,0.98,0.992,0.998,0.917,1.0,0.979,0.912,0.533,0.863,0.955,0.998],[0.287,0.999,0.998,0.903,0.987,0.979,1.0,0.924,0.449,0.926,0.977,0.971],[0.316,0.973,0.994,0.959,0.936,0.912,0.924,1.0,0.493,0.899,0.98,0.997],[0.36,0.362,0.594,0.412,0.016,0.533,0.449,0.493,1.0,0.626,0.619,0.628],[0.359,0.995,0.99,0.984,0.913,0.863,0.926,0.899,0.626,1.0,0.959,0.996],[0.356,0.986,0.995,0.981,0.991,0.955,0.977,0.98,0.619,0.959,1.0,0.998],[0.36,1.0,1.0,0.999,0.986,0.998,0.971,0.997,0.628,0.996,0.998,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,0.029,-0.0,-0.05,0.198,0.176,-0.122,0.004,-0.037,0.041],[0.029,1.0,0.014,0.035,0.051,0.027,0.002,-0.024,-0.03,0.001],[-0.0,0.014,1.0,0.03,-0.016,-0.042,0.038,0.027,0.035,-0.009],[-0.05,0.035,0.03,1.0,0.006,-0.115,0.08,-0.074,0.002,-0.082],[0.198,0.051,-0.016,0.006,1.0,0.866,-0.602,-0.019,0.054,0.121],[0.176,0.027,-0.042,-0.115,0.866,1.0,-0.675,-0.001,-0.051,0.108],[-0.122,0.002,0.038,0.08,-0.602,-0.675,1.0,-0.023,0.031,-0.074],[0.004,-0.024,0.027,-0.074,-0.019,-0.001,-0.023,1.0,0.104,0.0],[-0.037,-0.03,0.035,0.002,0.054,-0.051,0.031,0.104,1.0,-0.013],[0.041,0.001,-0.009,-0.082,0.121,0.108,-0.074,0.0,-0.013,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"month\",\"day\",\"hour\",\"pm2.5\",\"DEWP\",\"TEMP\",\"PRES\",\"Iws\",\"Is\",\"Ir\"],\"y\":[\"month\",\"day\",\"hour\",\"pm2.5\",\"DEWP\",\"TEMP\",\"PRES\",\"Iws\",\"Is\",\"Ir\"],\"z\":[[1.0,0.01,-0.0,-0.021,0.238,0.175,-0.069,0.013,-0.065,0.041],[0.01,1.0,0.001,0.083,0.035,0.024,-0.011,-0.005,-0.04,0.001],[-0.0,0.001,1.0,-0.023,-0.02,0.151,-0.043,0.059,-0.003,-0.01],[-0.021,0.083,-0.023,1.0,0.171,-0.09,-0.048,-0.248,0.019,-0.053],[0.238,0.035,-0.02,0.171,1.0,0.825,-0.778,-0.293,-0.036,0.125],[0.175,0.024,0.151,-0.09,0.825,1.0,-0.827,-0.149,-0.097,0.049],[-0.069,-0.011,-0.043,-0.048,-0.778,-0.827,1.0,0.178,0.072,-0.08],[0.013,-0.005,0.059,-0.248,-0.293,-0.149,0.178,1.0,0.023,-0.008],[-0.065,-0.04,-0.003,0.019,-0.036,-0.097,0.072,0.023,1.0,-0.01],[0.041,0.001,-0.01,-0.053,0.125,0.049,-0.08,-0.008,-0.01,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,0.01,-0.0,-0.021,0.238,0.175,-0.069,0.013,-0.065,0.041],[0.01,1.0,0.001,0.083,0.035,0.024,-0.011,-0.005,-0.04,0.001],[-0.0,0.001,1.0,-0.023,-0.02,0.151,-0.043,0.059,-0.003,-0.01],[-0.021,0.083,-0.023,1.0,0.171,-0.09,-0.048,-0.248,0.019,-0.053],[0.238,0.035,-0.02,0.171,1.0,0.825,-0.778,-0.293,-0.036,0.125],[0.175,0.024,0.151,-0.09,0.825,1.0,-0.827,-0.149,-0.097,0.049],[-0.069,-0.011,-0.043,-0.048,-0.778,-0.827,1.0,0.178,0.072,-0.08],[0.013,-0.005,0.059,-0.248,-0.293,-0.149,0.178,1.0,0.023,-0.008],[-0.065,-0.04,-0.003,0.019,-0.036,-0.097,0.072,0.023,1.0,-0.01],[0.041,0.001,-0.01,-0.053,0.125,0.049,-0.08,-0.008,-0.01,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"month\",\"day\",\"hour\",\"pm2.5\",\"DEWP\",\"TEMP\",\"PRES\",\"Iws\",\"Is\",\"Ir\"],\"y\":[\"month\",\"day\",\"hour\",\"pm2.5\",\"DEWP\",\"TEMP\",\"PRES\",\"Iws\",\"Is\",\"Ir\"],\"z\":[[1.0,0.029,-0.0,-0.05,0.198,0.176,-0.122,0.004,-0.037,0.041],[0.029,1.0,0.014,0.035,0.051,0.027,0.002,-0.024,-0.03,0.001],[-0.0,0.014,1.0,0.03,-0.016,-0.042,0.038,0.027,0.035,-0.009],[-0.05,0.035,0.03,1.0,0.006,-0.115,0.08,-0.074,0.002,-0.082],[0.198,0.051,-0.016,0.006,1.0,0.866,-0.602,-0.019,0.054,0.121],[0.176,0.027,-0.042,-0.115,0.866,1.0,-0.675,-0.001,-0.051,0.108],[-0.122,0.002,0.038,0.08,-0.602,-0.675,1.0,-0.023,0.031,-0.074],[0.004,-0.024,0.027,-0.074,-0.019,-0.001,-0.023,1.0,0.104,0.0],[-0.037,-0.03,0.035,0.002,0.054,-0.051,0.031,0.104,1.0,-0.013],[0.041,0.001,-0.009,-0.082,0.121,0.108,-0.074,0.0,-0.013,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.26,0.74],\"tickangle\":45},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"autorange\":\"reversed\"},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,0.45],\"tickangle\":45},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.375],\"autorange\":\"reversed\"},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.55,1.0],\"tickangle\":45,\"matches\":\"x2\"},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"visible\":false,\"matches\":\"y2\",\"autorange\":\"reversed\"},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Real vs. Synthetic Similarity\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Real Data)\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Synthetic Data)\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Data Quality: Column Pair Trends (Average Score=0.78)\"},\"coloraxis\":{\"colorbar\":{\"len\":0.5,\"x\":0.8,\"y\":0.8},\"cmin\":0,\"cmax\":1,\"colorscale\":[[0.0,\"#FF0000\"],[0.5,\"#F16141\"],[1.0,\"#36B37E\"]]},\"coloraxis2\":{\"colorbar\":{\"len\":0.5,\"y\":0.2},\"cmin\":-1,\"cmax\":1,\"colorscale\":[[0.0,\"#03AFF1\"],[0.5,\"#000036\"],[1.0,\"#01E0C9\"]]},\"font\":{\"size\":18},\"height\":900,\"width\":900},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2ac4ad93-613e-467a-9ef0-1a323f3a826d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================ METRICS REPORT ================================\n",
            "Column Shapes Score: 0.586\n",
            "Column Trends Score: 0.784\n",
            "Overall Score: 0.685\n",
            "correlation score: 0.979\n",
            "contingency similarity score: 0.566\n",
            "log detection score: 0.000\n",
            "Alpha Precision: 0.775297, Beta Recall: 0.157055\n",
            "DCR Score = 0.508381\n"
          ]
        }
      ]
    }
  ]
}