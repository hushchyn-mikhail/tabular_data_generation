{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2d7PvQcc2I3",
        "outputId": "b9db44da-79f3-46dd-c191-44a01ddcc498"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tabsyn'...\n",
            "remote: Enumerating objects: 240, done.\u001b[K\n",
            "remote: Counting objects: 100% (83/83), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 240 (delta 29), reused 15 (delta 15), pack-reused 157 (from 2)\u001b[K\n",
            "Receiving objects: 100% (240/240), 1.49 MiB | 9.54 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/amazon-science/tabsyn.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd tabsyn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwFHuKsHdBAo",
        "outputId": "047da2e6-4dc4-4f18-f750-b56194059587"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tabsyn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --extra-index-url https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install -r requirements.txt\n",
        "!pip install dgl -f https://data.dgl.ai/wheels/cu117/repo.html\n",
        "!pip install torch_geometric\n",
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.1+cu117.html\n",
        "!pip install tomli"
      ],
      "metadata": {
        "id": "IhJcZ3QS8HJQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python download_dataset.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPrk1zsn-AFY",
        "outputId": "9fe86382-6858-4b41-c174-1679b1c4c66f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start processing dataset adult from UCI.\n",
            "Finish downloading dataset from https://archive.ics.uci.edu/static/public/2/adult.zip, data has been saved to data/adult.\n",
            "Finish unzipping adult.\n",
            "Start processing dataset default from UCI.\n",
            "Finish downloading dataset from https://archive.ics.uci.edu/static/public/350/default+of+credit+card+clients.zip, data has been saved to data/default.\n",
            "Finish unzipping default.\n",
            "Start processing dataset magic from UCI.\n",
            "Finish downloading dataset from https://archive.ics.uci.edu/static/public/159/magic+gamma+telescope.zip, data has been saved to data/magic.\n",
            "Finish unzipping magic.\n",
            "Start processing dataset shoppers from UCI.\n",
            "Finish downloading dataset from https://archive.ics.uci.edu/static/public/468/online+shoppers+purchasing+intention+dataset.zip, data has been saved to data/shoppers.\n",
            "Finish unzipping shoppers.\n",
            "Start processing dataset beijing from UCI.\n",
            "Finish downloading dataset from https://archive.ics.uci.edu/static/public/381/beijing+pm2+5+data.zip, data has been saved to data/beijing.\n",
            "Finish unzipping beijing.\n",
            "Start processing dataset news from UCI.\n",
            "Finish downloading dataset from https://archive.ics.uci.edu/static/public/332/online+news+popularity.zip, data has been saved to data/news.\n",
            "Finish unzipping news.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python process_dataset.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JISw4PYDHR6S",
        "outputId": "6d6c958e-fede-479a-c8e0-e3bacad28d32"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adult (32561, 15) (16281, 15) (32561, 15)\n",
            "Numerical (32561, 6)\n",
            "Categorical (32561, 8)\n",
            "Processing and Saving adult Successfully!\n",
            "adult\n",
            "Total 48842\n",
            "Train 32561\n",
            "Test 16281\n",
            "Num 6\n",
            "Cat 9\n",
            "default (27000, 24) (3000, 24) (30000, 24)\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "Numerical (27000, 14)\n",
            "Categorical (27000, 9)\n",
            "Processing and Saving default Successfully!\n",
            "default\n",
            "Total 30000\n",
            "Train 27000\n",
            "Test 3000\n",
            "Num 14\n",
            "Cat 10\n",
            "shoppers (11097, 18) (1233, 18) (12330, 18)\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "Numerical (11097, 10)\n",
            "Categorical (11097, 7)\n",
            "Processing and Saving shoppers Successfully!\n",
            "shoppers\n",
            "Total 12330\n",
            "Train 11097\n",
            "Test 1233\n",
            "Num 10\n",
            "Cat 8\n",
            "magic (17117, 11) (1902, 11) (19019, 11)\n",
            "Numerical (17117, 10)\n",
            "Categorical (17117, 0)\n",
            "Processing and Saving magic Successfully!\n",
            "magic\n",
            "Total 19019\n",
            "Train 17117\n",
            "Test 1902\n",
            "Num 10\n",
            "Cat 1\n",
            "beijing (37581, 12) (4176, 12) (41757, 12)\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "Numerical (37581, 6)\n",
            "Categorical (37581, 5)\n",
            "Processing and Saving beijing Successfully!\n",
            "beijing\n",
            "Total 41757\n",
            "Train 37581\n",
            "Test 4176\n",
            "Num 7\n",
            "Cat 5\n",
            "news (35679, 48) (3965, 48) (39644, 48)\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:243: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[train_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "/content/tabsyn/process_dataset.py:247: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  test_df.loc[test_df[col] == '?', col] = 'nan'\n",
            "Numerical (35679, 45)\n",
            "Categorical (35679, 2)\n",
            "Processing and Saving news Successfully!\n",
            "news\n",
            "Total 39644\n",
            "Train 35679\n",
            "Test 3965\n",
            "Num 46\n",
            "Cat 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname beijing --method stasy --mode train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHh5OeNg-NzX",
        "outputId": "17e8b314-9810-43ad-dcd2-5e71eea5425a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "epoch: 4441, iter: 37, training_loss: 7.04454e-02\n",
            "epoch: 4442, iter: 37, training_loss: 7.06326e-02\n",
            "epoch: 4443, iter: 37, training_loss: 7.20121e-02\n",
            "epoch: 4444, iter: 37, training_loss: 6.86370e-02\n",
            "epoch: 4445, iter: 37, training_loss: 7.53511e-02\n",
            "epoch: 4446, iter: 37, training_loss: 6.94041e-02\n",
            "epoch: 4447, iter: 37, training_loss: 7.49414e-02\n",
            "epoch: 4448, iter: 37, training_loss: 6.83690e-02\n",
            "epoch: 4449, iter: 37, training_loss: 7.03881e-02\n",
            "epoch: 4450, iter: 37, training_loss: 7.02194e-02\n",
            "epoch: 4451, iter: 37, training_loss: 7.02876e-02\n",
            "epoch: 4452, iter: 37, training_loss: 6.90416e-02\n",
            "epoch: 4453, iter: 37, training_loss: 7.13164e-02\n",
            "epoch: 4454, iter: 37, training_loss: 7.04317e-02\n",
            "epoch: 4455, iter: 37, training_loss: 7.25690e-02\n",
            "epoch: 4456, iter: 37, training_loss: 6.80600e-02\n",
            "epoch: 4457, iter: 37, training_loss: 7.11470e-02\n",
            "epoch: 4458, iter: 37, training_loss: 6.80792e-02\n",
            "epoch: 4459, iter: 37, training_loss: 7.14443e-02\n",
            "epoch: 4460, iter: 37, training_loss: 7.32531e-02\n",
            "epoch: 4461, iter: 37, training_loss: 7.27147e-02\n",
            "epoch: 4462, iter: 37, training_loss: 7.04984e-02\n",
            "epoch: 4463, iter: 37, training_loss: 7.14576e-02\n",
            "epoch: 4464, iter: 37, training_loss: 7.18911e-02\n",
            "epoch: 4465, iter: 37, training_loss: 7.33631e-02\n",
            "epoch: 4466, iter: 37, training_loss: 6.98061e-02\n",
            "epoch: 4467, iter: 37, training_loss: 7.15975e-02\n",
            "epoch: 4468, iter: 37, training_loss: 7.10287e-02\n",
            "epoch: 4469, iter: 37, training_loss: 6.81627e-02\n",
            "epoch: 4470, iter: 37, training_loss: 7.16653e-02\n",
            "epoch: 4471, iter: 37, training_loss: 6.93707e-02\n",
            "epoch: 4472, iter: 37, training_loss: 7.16334e-02\n",
            "epoch: 4473, iter: 37, training_loss: 7.30272e-02\n",
            "epoch: 4474, iter: 37, training_loss: 7.18722e-02\n",
            "epoch: 4475, iter: 37, training_loss: 7.00821e-02\n",
            "epoch: 4476, iter: 37, training_loss: 7.14588e-02\n",
            "epoch: 4477, iter: 37, training_loss: 7.31735e-02\n",
            "epoch: 4478, iter: 37, training_loss: 7.21283e-02\n",
            "epoch: 4479, iter: 37, training_loss: 6.99858e-02\n",
            "epoch: 4480, iter: 37, training_loss: 6.81882e-02\n",
            "epoch: 4481, iter: 37, training_loss: 6.97262e-02\n",
            "epoch: 4482, iter: 37, training_loss: 7.32755e-02\n",
            "epoch: 4483, iter: 37, training_loss: 7.28940e-02\n",
            "epoch: 4484, iter: 37, training_loss: 7.24956e-02\n",
            "epoch: 4485, iter: 37, training_loss: 7.39700e-02\n",
            "epoch: 4486, iter: 37, training_loss: 7.44647e-02\n",
            "epoch: 4487, iter: 37, training_loss: 7.48271e-02\n",
            "epoch: 4488, iter: 37, training_loss: 7.00515e-02\n",
            "epoch: 4489, iter: 37, training_loss: 7.18386e-02\n",
            "epoch: 4490, iter: 37, training_loss: 7.06109e-02\n",
            "epoch: 4491, iter: 37, training_loss: 6.85888e-02\n",
            "epoch: 4492, iter: 37, training_loss: 7.26824e-02\n",
            "epoch: 4493, iter: 37, training_loss: 7.02124e-02\n",
            "epoch: 4494, iter: 37, training_loss: 7.07370e-02\n",
            "epoch: 4495, iter: 37, training_loss: 7.22376e-02\n",
            "epoch: 4496, iter: 37, training_loss: 6.99275e-02\n",
            "epoch: 4497, iter: 37, training_loss: 7.01599e-02\n",
            "epoch: 4498, iter: 37, training_loss: 7.13104e-02\n",
            "epoch: 4499, iter: 37, training_loss: 7.44970e-02\n",
            "epoch: 4500, iter: 37, training_loss: 7.22911e-02\n",
            "epoch: 4501, iter: 37, training_loss: 7.09136e-02\n",
            "epoch: 4502, iter: 37, training_loss: 7.00559e-02\n",
            "epoch: 4503, iter: 37, training_loss: 7.19237e-02\n",
            "epoch: 4504, iter: 37, training_loss: 6.84062e-02\n",
            "epoch: 4505, iter: 37, training_loss: 6.98429e-02\n",
            "epoch: 4506, iter: 37, training_loss: 7.26708e-02\n",
            "epoch: 4507, iter: 37, training_loss: 7.64484e-02\n",
            "epoch: 4508, iter: 37, training_loss: 7.19715e-02\n",
            "epoch: 4509, iter: 37, training_loss: 6.90182e-02\n",
            "epoch: 4510, iter: 37, training_loss: 7.33409e-02\n",
            "epoch: 4511, iter: 37, training_loss: 7.02228e-02\n",
            "epoch: 4512, iter: 37, training_loss: 7.03940e-02\n",
            "epoch: 4513, iter: 37, training_loss: 7.15291e-02\n",
            "epoch: 4514, iter: 37, training_loss: 7.38097e-02\n",
            "epoch: 4515, iter: 37, training_loss: 7.18351e-02\n",
            "epoch: 4516, iter: 37, training_loss: 6.99603e-02\n",
            "epoch: 4517, iter: 37, training_loss: 7.18003e-02\n",
            "epoch: 4518, iter: 37, training_loss: 6.91856e-02\n",
            "epoch: 4519, iter: 37, training_loss: 7.11671e-02\n",
            "epoch: 4520, iter: 37, training_loss: 6.84987e-02\n",
            "epoch: 4521, iter: 37, training_loss: 6.85161e-02\n",
            "epoch: 4522, iter: 37, training_loss: 6.81418e-02\n",
            "epoch: 4523, iter: 37, training_loss: 7.59962e-02\n",
            "epoch: 4524, iter: 37, training_loss: 6.95079e-02\n",
            "epoch: 4525, iter: 37, training_loss: 7.23858e-02\n",
            "epoch: 4526, iter: 37, training_loss: 6.95563e-02\n",
            "epoch: 4527, iter: 37, training_loss: 7.16518e-02\n",
            "epoch: 4528, iter: 37, training_loss: 6.98322e-02\n",
            "epoch: 4529, iter: 37, training_loss: 6.92365e-02\n",
            "epoch: 4530, iter: 37, training_loss: 7.19491e-02\n",
            "epoch: 4531, iter: 37, training_loss: 6.97062e-02\n",
            "epoch: 4532, iter: 37, training_loss: 7.00286e-02\n",
            "epoch: 4533, iter: 37, training_loss: 6.84072e-02\n",
            "epoch: 4534, iter: 37, training_loss: 7.53609e-02\n",
            "epoch: 4535, iter: 37, training_loss: 6.71120e-02\n",
            "epoch: 4536, iter: 37, training_loss: 7.29437e-02\n",
            "epoch: 4537, iter: 37, training_loss: 6.81330e-02\n",
            "epoch: 4538, iter: 37, training_loss: 6.88844e-02\n",
            "epoch: 4539, iter: 37, training_loss: 7.71207e-02\n",
            "epoch: 4540, iter: 37, training_loss: 7.53883e-02\n",
            "epoch: 4541, iter: 37, training_loss: 7.16556e-02\n",
            "epoch: 4542, iter: 37, training_loss: 7.10149e-02\n",
            "epoch: 4543, iter: 37, training_loss: 6.91146e-02\n",
            "epoch: 4544, iter: 37, training_loss: 7.03741e-02\n",
            "epoch: 4545, iter: 37, training_loss: 7.00188e-02\n",
            "epoch: 4546, iter: 37, training_loss: 7.19444e-02\n",
            "epoch: 4547, iter: 37, training_loss: 7.00275e-02\n",
            "epoch: 4548, iter: 37, training_loss: 7.04497e-02\n",
            "epoch: 4549, iter: 37, training_loss: 7.01597e-02\n",
            "epoch: 4550, iter: 37, training_loss: 7.14760e-02\n",
            "epoch: 4551, iter: 37, training_loss: 6.81165e-02\n",
            "epoch: 4552, iter: 37, training_loss: 6.81326e-02\n",
            "epoch: 4553, iter: 37, training_loss: 7.03586e-02\n",
            "epoch: 4554, iter: 37, training_loss: 7.05038e-02\n",
            "epoch: 4555, iter: 37, training_loss: 7.04011e-02\n",
            "epoch: 4556, iter: 37, training_loss: 7.07543e-02\n",
            "epoch: 4557, iter: 37, training_loss: 7.06397e-02\n",
            "epoch: 4558, iter: 37, training_loss: 7.05446e-02\n",
            "epoch: 4559, iter: 37, training_loss: 6.87618e-02\n",
            "epoch: 4560, iter: 37, training_loss: 7.33373e-02\n",
            "epoch: 4561, iter: 37, training_loss: 6.84512e-02\n",
            "epoch: 4562, iter: 37, training_loss: 7.17168e-02\n",
            "epoch: 4563, iter: 37, training_loss: 7.57692e-02\n",
            "epoch: 4564, iter: 37, training_loss: 6.96710e-02\n",
            "epoch: 4565, iter: 37, training_loss: 7.48094e-02\n",
            "epoch: 4566, iter: 37, training_loss: 7.04920e-02\n",
            "epoch: 4567, iter: 37, training_loss: 6.85764e-02\n",
            "epoch: 4568, iter: 37, training_loss: 7.14577e-02\n",
            "epoch: 4569, iter: 37, training_loss: 6.86219e-02\n",
            "epoch: 4570, iter: 37, training_loss: 7.13163e-02\n",
            "epoch: 4571, iter: 37, training_loss: 7.10364e-02\n",
            "epoch: 4572, iter: 37, training_loss: 7.08164e-02\n",
            "epoch: 4573, iter: 37, training_loss: 6.90136e-02\n",
            "epoch: 4574, iter: 37, training_loss: 7.06522e-02\n",
            "epoch: 4575, iter: 37, training_loss: 7.03278e-02\n",
            "epoch: 4576, iter: 37, training_loss: 6.87680e-02\n",
            "epoch: 4577, iter: 37, training_loss: 7.17061e-02\n",
            "epoch: 4578, iter: 37, training_loss: 7.04656e-02\n",
            "epoch: 4579, iter: 37, training_loss: 7.01869e-02\n",
            "epoch: 4580, iter: 37, training_loss: 6.95063e-02\n",
            "epoch: 4581, iter: 37, training_loss: 6.92411e-02\n",
            "epoch: 4582, iter: 37, training_loss: 7.01857e-02\n",
            "epoch: 4583, iter: 37, training_loss: 6.89592e-02\n",
            "epoch: 4584, iter: 37, training_loss: 6.96551e-02\n",
            "epoch: 4585, iter: 37, training_loss: 6.82142e-02\n",
            "epoch: 4586, iter: 37, training_loss: 7.60747e-02\n",
            "epoch: 4587, iter: 37, training_loss: 7.00510e-02\n",
            "epoch: 4588, iter: 37, training_loss: 6.73004e-02\n",
            "epoch: 4589, iter: 37, training_loss: 7.27944e-02\n",
            "epoch: 4590, iter: 37, training_loss: 7.23992e-02\n",
            "epoch: 4591, iter: 37, training_loss: 7.25086e-02\n",
            "epoch: 4592, iter: 37, training_loss: 7.15113e-02\n",
            "epoch: 4593, iter: 37, training_loss: 7.03630e-02\n",
            "epoch: 4594, iter: 37, training_loss: 7.09333e-02\n",
            "epoch: 4595, iter: 37, training_loss: 6.83366e-02\n",
            "epoch: 4596, iter: 37, training_loss: 7.12151e-02\n",
            "epoch: 4597, iter: 37, training_loss: 7.10719e-02\n",
            "epoch: 4598, iter: 37, training_loss: 7.51970e-02\n",
            "epoch: 4599, iter: 37, training_loss: 7.12098e-02\n",
            "epoch: 4600, iter: 37, training_loss: 7.13075e-02\n",
            "epoch: 4601, iter: 37, training_loss: 6.90250e-02\n",
            "epoch: 4602, iter: 37, training_loss: 7.28286e-02\n",
            "epoch: 4603, iter: 37, training_loss: 7.70063e-02\n",
            "epoch: 4604, iter: 37, training_loss: 7.07868e-02\n",
            "epoch: 4605, iter: 37, training_loss: 7.18595e-02\n",
            "epoch: 4606, iter: 37, training_loss: 7.12377e-02\n",
            "epoch: 4607, iter: 37, training_loss: 7.49453e-02\n",
            "epoch: 4608, iter: 37, training_loss: 7.27617e-02\n",
            "epoch: 4609, iter: 37, training_loss: 7.07574e-02\n",
            "epoch: 4610, iter: 37, training_loss: 7.02256e-02\n",
            "epoch: 4611, iter: 37, training_loss: 7.00196e-02\n",
            "epoch: 4612, iter: 37, training_loss: 6.89600e-02\n",
            "epoch: 4613, iter: 37, training_loss: 7.08554e-02\n",
            "epoch: 4614, iter: 37, training_loss: 7.13444e-02\n",
            "epoch: 4615, iter: 37, training_loss: 7.25578e-02\n",
            "epoch: 4616, iter: 37, training_loss: 6.87713e-02\n",
            "epoch: 4617, iter: 37, training_loss: 6.99376e-02\n",
            "epoch: 4618, iter: 37, training_loss: 7.03594e-02\n",
            "epoch: 4619, iter: 37, training_loss: 7.74793e-02\n",
            "epoch: 4620, iter: 37, training_loss: 6.98058e-02\n",
            "epoch: 4621, iter: 37, training_loss: 6.70943e-02\n",
            "epoch: 4622, iter: 37, training_loss: 7.06322e-02\n",
            "epoch: 4623, iter: 37, training_loss: 7.22119e-02\n",
            "epoch: 4624, iter: 37, training_loss: 7.00454e-02\n",
            "epoch: 4625, iter: 37, training_loss: 7.04309e-02\n",
            "epoch: 4626, iter: 37, training_loss: 7.20467e-02\n",
            "epoch: 4627, iter: 37, training_loss: 7.05034e-02\n",
            "epoch: 4628, iter: 37, training_loss: 6.80672e-02\n",
            "epoch: 4629, iter: 37, training_loss: 6.77061e-02\n",
            "epoch: 4630, iter: 37, training_loss: 7.03802e-02\n",
            "epoch: 4631, iter: 37, training_loss: 7.07932e-02\n",
            "epoch: 4632, iter: 37, training_loss: 6.94425e-02\n",
            "epoch: 4633, iter: 37, training_loss: 6.90382e-02\n",
            "epoch: 4634, iter: 37, training_loss: 6.95430e-02\n",
            "epoch: 4635, iter: 37, training_loss: 7.23333e-02\n",
            "epoch: 4636, iter: 37, training_loss: 6.97902e-02\n",
            "epoch: 4637, iter: 37, training_loss: 6.82403e-02\n",
            "epoch: 4638, iter: 37, training_loss: 7.03910e-02\n",
            "epoch: 4639, iter: 37, training_loss: 6.71844e-02\n",
            "epoch: 4640, iter: 37, training_loss: 6.75984e-02\n",
            "epoch: 4641, iter: 37, training_loss: 6.96690e-02\n",
            "epoch: 4642, iter: 37, training_loss: 6.84709e-02\n",
            "epoch: 4643, iter: 37, training_loss: 6.85357e-02\n",
            "epoch: 4644, iter: 37, training_loss: 6.92580e-02\n",
            "epoch: 4645, iter: 37, training_loss: 7.05409e-02\n",
            "epoch: 4646, iter: 37, training_loss: 7.15948e-02\n",
            "epoch: 4647, iter: 37, training_loss: 7.10788e-02\n",
            "epoch: 4648, iter: 37, training_loss: 6.97215e-02\n",
            "epoch: 4649, iter: 37, training_loss: 6.87449e-02\n",
            "epoch: 4650, iter: 37, training_loss: 7.17913e-02\n",
            "epoch: 4651, iter: 37, training_loss: 6.88763e-02\n",
            "epoch: 4652, iter: 37, training_loss: 6.95242e-02\n",
            "epoch: 4653, iter: 37, training_loss: 7.06190e-02\n",
            "epoch: 4654, iter: 37, training_loss: 7.02776e-02\n",
            "epoch: 4655, iter: 37, training_loss: 6.92998e-02\n",
            "epoch: 4656, iter: 37, training_loss: 7.06741e-02\n",
            "epoch: 4657, iter: 37, training_loss: 7.11798e-02\n",
            "epoch: 4658, iter: 37, training_loss: 7.10052e-02\n",
            "epoch: 4659, iter: 37, training_loss: 7.10487e-02\n",
            "epoch: 4660, iter: 37, training_loss: 7.05816e-02\n",
            "epoch: 4661, iter: 37, training_loss: 7.00101e-02\n",
            "epoch: 4662, iter: 37, training_loss: 6.90594e-02\n",
            "epoch: 4663, iter: 37, training_loss: 7.18032e-02\n",
            "epoch: 4664, iter: 37, training_loss: 7.01595e-02\n",
            "epoch: 4665, iter: 37, training_loss: 7.35168e-02\n",
            "epoch: 4666, iter: 37, training_loss: 7.30286e-02\n",
            "epoch: 4667, iter: 37, training_loss: 7.35109e-02\n",
            "epoch: 4668, iter: 37, training_loss: 7.03338e-02\n",
            "epoch: 4669, iter: 37, training_loss: 6.86083e-02\n",
            "epoch: 4670, iter: 37, training_loss: 6.83953e-02\n",
            "epoch: 4671, iter: 37, training_loss: 7.00465e-02\n",
            "epoch: 4672, iter: 37, training_loss: 7.14005e-02\n",
            "epoch: 4673, iter: 37, training_loss: 6.87210e-02\n",
            "epoch: 4674, iter: 37, training_loss: 6.77968e-02\n",
            "epoch: 4675, iter: 37, training_loss: 7.29829e-02\n",
            "epoch: 4676, iter: 37, training_loss: 7.24970e-02\n",
            "epoch: 4677, iter: 37, training_loss: 7.13174e-02\n",
            "epoch: 4678, iter: 37, training_loss: 6.98821e-02\n",
            "epoch: 4679, iter: 37, training_loss: 7.12114e-02\n",
            "epoch: 4680, iter: 37, training_loss: 7.06519e-02\n",
            "epoch: 4681, iter: 37, training_loss: 7.30691e-02\n",
            "epoch: 4682, iter: 37, training_loss: 6.98314e-02\n",
            "epoch: 4683, iter: 37, training_loss: 7.27932e-02\n",
            "epoch: 4684, iter: 37, training_loss: 7.06835e-02\n",
            "epoch: 4685, iter: 37, training_loss: 6.96148e-02\n",
            "epoch: 4686, iter: 37, training_loss: 7.05415e-02\n",
            "epoch: 4687, iter: 37, training_loss: 6.84967e-02\n",
            "epoch: 4688, iter: 37, training_loss: 7.23581e-02\n",
            "epoch: 4689, iter: 37, training_loss: 6.79810e-02\n",
            "epoch: 4690, iter: 37, training_loss: 7.21430e-02\n",
            "epoch: 4691, iter: 37, training_loss: 7.08871e-02\n",
            "epoch: 4692, iter: 37, training_loss: 6.80910e-02\n",
            "epoch: 4693, iter: 37, training_loss: 6.91657e-02\n",
            "epoch: 4694, iter: 37, training_loss: 6.95450e-02\n",
            "epoch: 4695, iter: 37, training_loss: 6.86074e-02\n",
            "epoch: 4696, iter: 37, training_loss: 7.07612e-02\n",
            "epoch: 4697, iter: 37, training_loss: 6.71710e-02\n",
            "epoch: 4698, iter: 37, training_loss: 6.91798e-02\n",
            "epoch: 4699, iter: 37, training_loss: 7.05701e-02\n",
            "epoch: 4700, iter: 37, training_loss: 7.12047e-02\n",
            "epoch: 4701, iter: 37, training_loss: 7.05842e-02\n",
            "epoch: 4702, iter: 37, training_loss: 7.11110e-02\n",
            "epoch: 4703, iter: 37, training_loss: 7.17042e-02\n",
            "epoch: 4704, iter: 37, training_loss: 6.74337e-02\n",
            "epoch: 4705, iter: 37, training_loss: 6.93951e-02\n",
            "epoch: 4706, iter: 37, training_loss: 7.20331e-02\n",
            "epoch: 4707, iter: 37, training_loss: 6.94786e-02\n",
            "epoch: 4708, iter: 37, training_loss: 6.79012e-02\n",
            "epoch: 4709, iter: 37, training_loss: 7.33502e-02\n",
            "epoch: 4710, iter: 37, training_loss: 6.82581e-02\n",
            "epoch: 4711, iter: 37, training_loss: 7.32833e-02\n",
            "epoch: 4712, iter: 37, training_loss: 7.14134e-02\n",
            "epoch: 4713, iter: 37, training_loss: 7.25969e-02\n",
            "epoch: 4714, iter: 37, training_loss: 6.97890e-02\n",
            "epoch: 4715, iter: 37, training_loss: 6.90092e-02\n",
            "epoch: 4716, iter: 37, training_loss: 6.93045e-02\n",
            "epoch: 4717, iter: 37, training_loss: 7.06356e-02\n",
            "epoch: 4718, iter: 37, training_loss: 7.36040e-02\n",
            "epoch: 4719, iter: 37, training_loss: 7.19467e-02\n",
            "epoch: 4720, iter: 37, training_loss: 6.86553e-02\n",
            "epoch: 4721, iter: 37, training_loss: 7.13560e-02\n",
            "epoch: 4722, iter: 37, training_loss: 6.82307e-02\n",
            "epoch: 4723, iter: 37, training_loss: 7.35711e-02\n",
            "epoch: 4724, iter: 37, training_loss: 7.12403e-02\n",
            "epoch: 4725, iter: 37, training_loss: 7.14385e-02\n",
            "epoch: 4726, iter: 37, training_loss: 6.89829e-02\n",
            "epoch: 4727, iter: 37, training_loss: 6.79019e-02\n",
            "epoch: 4728, iter: 37, training_loss: 7.12420e-02\n",
            "epoch: 4729, iter: 37, training_loss: 7.23743e-02\n",
            "epoch: 4730, iter: 37, training_loss: 6.91627e-02\n",
            "epoch: 4731, iter: 37, training_loss: 6.91877e-02\n",
            "epoch: 4732, iter: 37, training_loss: 7.04036e-02\n",
            "epoch: 4733, iter: 37, training_loss: 6.82742e-02\n",
            "epoch: 4734, iter: 37, training_loss: 6.85938e-02\n",
            "epoch: 4735, iter: 37, training_loss: 7.11047e-02\n",
            "epoch: 4736, iter: 37, training_loss: 7.23418e-02\n",
            "epoch: 4737, iter: 37, training_loss: 6.66597e-02\n",
            "epoch: 4738, iter: 37, training_loss: 7.29610e-02\n",
            "epoch: 4739, iter: 37, training_loss: 6.94511e-02\n",
            "epoch: 4740, iter: 37, training_loss: 7.11214e-02\n",
            "epoch: 4741, iter: 37, training_loss: 7.12034e-02\n",
            "epoch: 4742, iter: 37, training_loss: 6.83557e-02\n",
            "epoch: 4743, iter: 37, training_loss: 7.15791e-02\n",
            "epoch: 4744, iter: 37, training_loss: 6.82129e-02\n",
            "epoch: 4745, iter: 37, training_loss: 7.25134e-02\n",
            "epoch: 4746, iter: 37, training_loss: 6.80464e-02\n",
            "epoch: 4747, iter: 37, training_loss: 6.77690e-02\n",
            "epoch: 4748, iter: 37, training_loss: 6.93681e-02\n",
            "epoch: 4749, iter: 37, training_loss: 6.88165e-02\n",
            "epoch: 4750, iter: 37, training_loss: 7.23360e-02\n",
            "epoch: 4751, iter: 37, training_loss: 7.00867e-02\n",
            "epoch: 4752, iter: 37, training_loss: 7.07263e-02\n",
            "epoch: 4753, iter: 37, training_loss: 7.22645e-02\n",
            "epoch: 4754, iter: 37, training_loss: 7.19052e-02\n",
            "epoch: 4755, iter: 37, training_loss: 6.85386e-02\n",
            "epoch: 4756, iter: 37, training_loss: 6.94445e-02\n",
            "epoch: 4757, iter: 37, training_loss: 7.15750e-02\n",
            "epoch: 4758, iter: 37, training_loss: 7.75469e-02\n",
            "epoch: 4759, iter: 37, training_loss: 6.96950e-02\n",
            "epoch: 4760, iter: 37, training_loss: 7.23202e-02\n",
            "epoch: 4761, iter: 37, training_loss: 7.07284e-02\n",
            "epoch: 4762, iter: 37, training_loss: 7.10500e-02\n",
            "epoch: 4763, iter: 37, training_loss: 7.16662e-02\n",
            "epoch: 4764, iter: 37, training_loss: 6.96870e-02\n",
            "epoch: 4765, iter: 37, training_loss: 6.93788e-02\n",
            "epoch: 4766, iter: 37, training_loss: 7.32706e-02\n",
            "epoch: 4767, iter: 37, training_loss: 7.00836e-02\n",
            "epoch: 4768, iter: 37, training_loss: 6.95187e-02\n",
            "epoch: 4769, iter: 37, training_loss: 7.16621e-02\n",
            "epoch: 4770, iter: 37, training_loss: 6.97300e-02\n",
            "epoch: 4771, iter: 37, training_loss: 7.17502e-02\n",
            "epoch: 4772, iter: 37, training_loss: 6.96981e-02\n",
            "epoch: 4773, iter: 37, training_loss: 6.91050e-02\n",
            "epoch: 4774, iter: 37, training_loss: 6.86597e-02\n",
            "epoch: 4775, iter: 37, training_loss: 6.96287e-02\n",
            "epoch: 4776, iter: 37, training_loss: 6.84605e-02\n",
            "epoch: 4777, iter: 37, training_loss: 7.23283e-02\n",
            "epoch: 4778, iter: 37, training_loss: 7.16122e-02\n",
            "epoch: 4779, iter: 37, training_loss: 6.87680e-02\n",
            "epoch: 4780, iter: 37, training_loss: 7.15298e-02\n",
            "epoch: 4781, iter: 37, training_loss: 6.90101e-02\n",
            "epoch: 4782, iter: 37, training_loss: 6.84808e-02\n",
            "epoch: 4783, iter: 37, training_loss: 6.82334e-02\n",
            "epoch: 4784, iter: 37, training_loss: 6.99471e-02\n",
            "epoch: 4785, iter: 37, training_loss: 6.74863e-02\n",
            "epoch: 4786, iter: 37, training_loss: 7.41616e-02\n",
            "epoch: 4787, iter: 37, training_loss: 7.16738e-02\n",
            "epoch: 4788, iter: 37, training_loss: 7.00475e-02\n",
            "epoch: 4789, iter: 37, training_loss: 7.20485e-02\n",
            "epoch: 4790, iter: 37, training_loss: 7.21883e-02\n",
            "epoch: 4791, iter: 37, training_loss: 6.99242e-02\n",
            "epoch: 4792, iter: 37, training_loss: 6.92692e-02\n",
            "epoch: 4793, iter: 37, training_loss: 6.96214e-02\n",
            "epoch: 4794, iter: 37, training_loss: 7.28769e-02\n",
            "epoch: 4795, iter: 37, training_loss: 6.94889e-02\n",
            "epoch: 4796, iter: 37, training_loss: 6.93086e-02\n",
            "epoch: 4797, iter: 37, training_loss: 7.03763e-02\n",
            "epoch: 4798, iter: 37, training_loss: 6.94447e-02\n",
            "epoch: 4799, iter: 37, training_loss: 6.80242e-02\n",
            "epoch: 4800, iter: 37, training_loss: 6.91041e-02\n",
            "epoch: 4801, iter: 37, training_loss: 7.00836e-02\n",
            "epoch: 4802, iter: 37, training_loss: 6.93966e-02\n",
            "epoch: 4803, iter: 37, training_loss: 6.75048e-02\n",
            "epoch: 4804, iter: 37, training_loss: 7.04796e-02\n",
            "epoch: 4805, iter: 37, training_loss: 6.63807e-02\n",
            "epoch: 4806, iter: 37, training_loss: 7.03438e-02\n",
            "epoch: 4807, iter: 37, training_loss: 6.93645e-02\n",
            "epoch: 4808, iter: 37, training_loss: 6.98594e-02\n",
            "epoch: 4809, iter: 37, training_loss: 7.08133e-02\n",
            "epoch: 4810, iter: 37, training_loss: 7.45728e-02\n",
            "epoch: 4811, iter: 37, training_loss: 7.04406e-02\n",
            "epoch: 4812, iter: 37, training_loss: 7.39814e-02\n",
            "epoch: 4813, iter: 37, training_loss: 7.28512e-02\n",
            "epoch: 4814, iter: 37, training_loss: 7.09937e-02\n",
            "epoch: 4815, iter: 37, training_loss: 7.26495e-02\n",
            "epoch: 4816, iter: 37, training_loss: 7.32110e-02\n",
            "epoch: 4817, iter: 37, training_loss: 7.17510e-02\n",
            "epoch: 4818, iter: 37, training_loss: 6.73870e-02\n",
            "epoch: 4819, iter: 37, training_loss: 6.86880e-02\n",
            "epoch: 4820, iter: 37, training_loss: 6.76185e-02\n",
            "epoch: 4821, iter: 37, training_loss: 7.18113e-02\n",
            "epoch: 4822, iter: 37, training_loss: 6.99476e-02\n",
            "epoch: 4823, iter: 37, training_loss: 6.94886e-02\n",
            "epoch: 4824, iter: 37, training_loss: 7.13138e-02\n",
            "epoch: 4825, iter: 37, training_loss: 6.96321e-02\n",
            "epoch: 4826, iter: 37, training_loss: 7.12789e-02\n",
            "epoch: 4827, iter: 37, training_loss: 6.88620e-02\n",
            "epoch: 4828, iter: 37, training_loss: 7.49969e-02\n",
            "epoch: 4829, iter: 37, training_loss: 6.97102e-02\n",
            "epoch: 4830, iter: 37, training_loss: 6.84017e-02\n",
            "epoch: 4831, iter: 37, training_loss: 6.86787e-02\n",
            "epoch: 4832, iter: 37, training_loss: 7.13358e-02\n",
            "epoch: 4833, iter: 37, training_loss: 7.16210e-02\n",
            "epoch: 4834, iter: 37, training_loss: 6.77662e-02\n",
            "epoch: 4835, iter: 37, training_loss: 6.79478e-02\n",
            "epoch: 4836, iter: 37, training_loss: 6.97504e-02\n",
            "epoch: 4837, iter: 37, training_loss: 7.25005e-02\n",
            "epoch: 4838, iter: 37, training_loss: 7.32324e-02\n",
            "epoch: 4839, iter: 37, training_loss: 7.13380e-02\n",
            "epoch: 4840, iter: 37, training_loss: 6.99530e-02\n",
            "epoch: 4841, iter: 37, training_loss: 7.13898e-02\n",
            "epoch: 4842, iter: 37, training_loss: 7.00376e-02\n",
            "epoch: 4843, iter: 37, training_loss: 6.66930e-02\n",
            "epoch: 4844, iter: 37, training_loss: 6.93416e-02\n",
            "epoch: 4845, iter: 37, training_loss: 6.91973e-02\n",
            "epoch: 4846, iter: 37, training_loss: 6.78084e-02\n",
            "epoch: 4847, iter: 37, training_loss: 7.06846e-02\n",
            "epoch: 4848, iter: 37, training_loss: 6.95410e-02\n",
            "epoch: 4849, iter: 37, training_loss: 6.81603e-02\n",
            "epoch: 4850, iter: 37, training_loss: 6.78027e-02\n",
            "epoch: 4851, iter: 37, training_loss: 7.04770e-02\n",
            "epoch: 4852, iter: 37, training_loss: 6.92374e-02\n",
            "epoch: 4853, iter: 37, training_loss: 6.66888e-02\n",
            "epoch: 4854, iter: 37, training_loss: 6.97995e-02\n",
            "epoch: 4855, iter: 37, training_loss: 6.86203e-02\n",
            "epoch: 4856, iter: 37, training_loss: 6.72162e-02\n",
            "epoch: 4857, iter: 37, training_loss: 7.18503e-02\n",
            "epoch: 4858, iter: 37, training_loss: 6.90238e-02\n",
            "epoch: 4859, iter: 37, training_loss: 7.21411e-02\n",
            "epoch: 4860, iter: 37, training_loss: 6.82339e-02\n",
            "epoch: 4861, iter: 37, training_loss: 6.89945e-02\n",
            "epoch: 4862, iter: 37, training_loss: 6.91547e-02\n",
            "epoch: 4863, iter: 37, training_loss: 7.09462e-02\n",
            "epoch: 4864, iter: 37, training_loss: 7.01123e-02\n",
            "epoch: 4865, iter: 37, training_loss: 6.92079e-02\n",
            "epoch: 4866, iter: 37, training_loss: 7.15102e-02\n",
            "epoch: 4867, iter: 37, training_loss: 7.05579e-02\n",
            "epoch: 4868, iter: 37, training_loss: 7.61538e-02\n",
            "epoch: 4869, iter: 37, training_loss: 6.90840e-02\n",
            "epoch: 4870, iter: 37, training_loss: 7.04910e-02\n",
            "epoch: 4871, iter: 37, training_loss: 6.92994e-02\n",
            "epoch: 4872, iter: 37, training_loss: 6.74542e-02\n",
            "epoch: 4873, iter: 37, training_loss: 6.98390e-02\n",
            "epoch: 4874, iter: 37, training_loss: 7.06358e-02\n",
            "epoch: 4875, iter: 37, training_loss: 7.01060e-02\n",
            "epoch: 4876, iter: 37, training_loss: 7.33903e-02\n",
            "epoch: 4877, iter: 37, training_loss: 7.22902e-02\n",
            "epoch: 4878, iter: 37, training_loss: 6.92067e-02\n",
            "epoch: 4879, iter: 37, training_loss: 7.04565e-02\n",
            "epoch: 4880, iter: 37, training_loss: 6.78161e-02\n",
            "epoch: 4881, iter: 37, training_loss: 7.09235e-02\n",
            "epoch: 4882, iter: 37, training_loss: 6.99145e-02\n",
            "epoch: 4883, iter: 37, training_loss: 7.42842e-02\n",
            "epoch: 4884, iter: 37, training_loss: 7.29600e-02\n",
            "epoch: 4885, iter: 37, training_loss: 6.73794e-02\n",
            "epoch: 4886, iter: 37, training_loss: 7.10307e-02\n",
            "epoch: 4887, iter: 37, training_loss: 6.90069e-02\n",
            "epoch: 4888, iter: 37, training_loss: 7.37606e-02\n",
            "epoch: 4889, iter: 37, training_loss: 7.12613e-02\n",
            "epoch: 4890, iter: 37, training_loss: 6.87786e-02\n",
            "epoch: 4891, iter: 37, training_loss: 7.28935e-02\n",
            "epoch: 4892, iter: 37, training_loss: 7.03251e-02\n",
            "epoch: 4893, iter: 37, training_loss: 6.96937e-02\n",
            "epoch: 4894, iter: 37, training_loss: 7.11254e-02\n",
            "epoch: 4895, iter: 37, training_loss: 7.02934e-02\n",
            "epoch: 4896, iter: 37, training_loss: 6.95689e-02\n",
            "epoch: 4897, iter: 37, training_loss: 6.94765e-02\n",
            "epoch: 4898, iter: 37, training_loss: 6.83416e-02\n",
            "epoch: 4899, iter: 37, training_loss: 7.01498e-02\n",
            "epoch: 4900, iter: 37, training_loss: 7.12831e-02\n",
            "epoch: 4901, iter: 37, training_loss: 6.93313e-02\n",
            "epoch: 4902, iter: 37, training_loss: 6.87560e-02\n",
            "epoch: 4903, iter: 37, training_loss: 6.86575e-02\n",
            "epoch: 4904, iter: 37, training_loss: 7.34659e-02\n",
            "epoch: 4905, iter: 37, training_loss: 6.91446e-02\n",
            "epoch: 4906, iter: 37, training_loss: 6.76625e-02\n",
            "epoch: 4907, iter: 37, training_loss: 6.83512e-02\n",
            "epoch: 4908, iter: 37, training_loss: 6.79426e-02\n",
            "epoch: 4909, iter: 37, training_loss: 7.02483e-02\n",
            "epoch: 4910, iter: 37, training_loss: 6.81360e-02\n",
            "epoch: 4911, iter: 37, training_loss: 7.37841e-02\n",
            "epoch: 4912, iter: 37, training_loss: 6.83806e-02\n",
            "epoch: 4913, iter: 37, training_loss: 6.78601e-02\n",
            "epoch: 4914, iter: 37, training_loss: 7.06270e-02\n",
            "epoch: 4915, iter: 37, training_loss: 6.94050e-02\n",
            "epoch: 4916, iter: 37, training_loss: 7.23227e-02\n",
            "epoch: 4917, iter: 37, training_loss: 6.90534e-02\n",
            "epoch: 4918, iter: 37, training_loss: 6.93421e-02\n",
            "epoch: 4919, iter: 37, training_loss: 6.79480e-02\n",
            "epoch: 4920, iter: 37, training_loss: 6.71796e-02\n",
            "epoch: 4921, iter: 37, training_loss: 7.01252e-02\n",
            "epoch: 4922, iter: 37, training_loss: 6.88474e-02\n",
            "epoch: 4923, iter: 37, training_loss: 6.97275e-02\n",
            "epoch: 4924, iter: 37, training_loss: 7.13956e-02\n",
            "epoch: 4925, iter: 37, training_loss: 6.85114e-02\n",
            "epoch: 4926, iter: 37, training_loss: 7.05105e-02\n",
            "epoch: 4927, iter: 37, training_loss: 7.17023e-02\n",
            "epoch: 4928, iter: 37, training_loss: 6.98673e-02\n",
            "epoch: 4929, iter: 37, training_loss: 6.71249e-02\n",
            "epoch: 4930, iter: 37, training_loss: 6.83178e-02\n",
            "epoch: 4931, iter: 37, training_loss: 7.75118e-02\n",
            "epoch: 4932, iter: 37, training_loss: 6.76307e-02\n",
            "epoch: 4933, iter: 37, training_loss: 6.99054e-02\n",
            "epoch: 4934, iter: 37, training_loss: 7.33618e-02\n",
            "epoch: 4935, iter: 37, training_loss: 7.09900e-02\n",
            "epoch: 4936, iter: 37, training_loss: 6.87033e-02\n",
            "epoch: 4937, iter: 37, training_loss: 6.71076e-02\n",
            "epoch: 4938, iter: 37, training_loss: 6.78969e-02\n",
            "epoch: 4939, iter: 37, training_loss: 6.71170e-02\n",
            "epoch: 4940, iter: 37, training_loss: 7.13656e-02\n",
            "epoch: 4941, iter: 37, training_loss: 6.98361e-02\n",
            "epoch: 4942, iter: 37, training_loss: 6.89177e-02\n",
            "epoch: 4943, iter: 37, training_loss: 6.66425e-02\n",
            "epoch: 4944, iter: 37, training_loss: 6.79956e-02\n",
            "epoch: 4945, iter: 37, training_loss: 6.73830e-02\n",
            "epoch: 4946, iter: 37, training_loss: 6.73834e-02\n",
            "epoch: 4947, iter: 37, training_loss: 7.67751e-02\n",
            "epoch: 4948, iter: 37, training_loss: 6.86639e-02\n",
            "epoch: 4949, iter: 37, training_loss: 7.16787e-02\n",
            "epoch: 4950, iter: 37, training_loss: 6.86410e-02\n",
            "epoch: 4951, iter: 37, training_loss: 6.76081e-02\n",
            "epoch: 4952, iter: 37, training_loss: 6.92672e-02\n",
            "epoch: 4953, iter: 37, training_loss: 6.80883e-02\n",
            "epoch: 4954, iter: 37, training_loss: 6.77387e-02\n",
            "epoch: 4955, iter: 37, training_loss: 6.83773e-02\n",
            "epoch: 4956, iter: 37, training_loss: 7.15706e-02\n",
            "epoch: 4957, iter: 37, training_loss: 7.07885e-02\n",
            "epoch: 4958, iter: 37, training_loss: 6.84537e-02\n",
            "epoch: 4959, iter: 37, training_loss: 6.96119e-02\n",
            "epoch: 4960, iter: 37, training_loss: 7.32839e-02\n",
            "epoch: 4961, iter: 37, training_loss: 6.92135e-02\n",
            "epoch: 4962, iter: 37, training_loss: 6.97988e-02\n",
            "epoch: 4963, iter: 37, training_loss: 7.10241e-02\n",
            "epoch: 4964, iter: 37, training_loss: 6.87110e-02\n",
            "epoch: 4965, iter: 37, training_loss: 6.75969e-02\n",
            "epoch: 4966, iter: 37, training_loss: 6.89728e-02\n",
            "epoch: 4967, iter: 37, training_loss: 6.70110e-02\n",
            "epoch: 4968, iter: 37, training_loss: 7.37312e-02\n",
            "epoch: 4969, iter: 37, training_loss: 6.66675e-02\n",
            "epoch: 4970, iter: 37, training_loss: 6.75167e-02\n",
            "epoch: 4971, iter: 37, training_loss: 6.95500e-02\n",
            "epoch: 4972, iter: 37, training_loss: 7.00012e-02\n",
            "epoch: 4973, iter: 37, training_loss: 6.99216e-02\n",
            "epoch: 4974, iter: 37, training_loss: 6.97786e-02\n",
            "epoch: 4975, iter: 37, training_loss: 7.09716e-02\n",
            "epoch: 4976, iter: 37, training_loss: 7.15789e-02\n",
            "epoch: 4977, iter: 37, training_loss: 6.88886e-02\n",
            "epoch: 4978, iter: 37, training_loss: 7.03413e-02\n",
            "epoch: 4979, iter: 37, training_loss: 7.21233e-02\n",
            "epoch: 4980, iter: 37, training_loss: 6.86460e-02\n",
            "epoch: 4981, iter: 37, training_loss: 6.71502e-02\n",
            "epoch: 4982, iter: 37, training_loss: 7.05816e-02\n",
            "epoch: 4983, iter: 37, training_loss: 6.89920e-02\n",
            "epoch: 4984, iter: 37, training_loss: 6.74586e-02\n",
            "epoch: 4985, iter: 37, training_loss: 7.05541e-02\n",
            "epoch: 4986, iter: 37, training_loss: 6.81310e-02\n",
            "epoch: 4987, iter: 37, training_loss: 6.81931e-02\n",
            "epoch: 4988, iter: 37, training_loss: 6.57110e-02\n",
            "epoch: 4989, iter: 37, training_loss: 6.91222e-02\n",
            "epoch: 4990, iter: 37, training_loss: 6.72516e-02\n",
            "epoch: 4991, iter: 37, training_loss: 7.62509e-02\n",
            "epoch: 4992, iter: 37, training_loss: 6.84553e-02\n",
            "epoch: 4993, iter: 37, training_loss: 6.69660e-02\n",
            "epoch: 4994, iter: 37, training_loss: 6.87269e-02\n",
            "epoch: 4995, iter: 37, training_loss: 6.68643e-02\n",
            "epoch: 4996, iter: 37, training_loss: 6.74765e-02\n",
            "epoch: 4997, iter: 37, training_loss: 6.86732e-02\n",
            "epoch: 4998, iter: 37, training_loss: 7.48415e-02\n",
            "epoch: 4999, iter: 37, training_loss: 7.02960e-02\n",
            "epoch: 5000, iter: 37, training_loss: 6.87330e-02\n",
            "epoch: 5001, iter: 37, training_loss: 7.18898e-02\n",
            "epoch: 5002, iter: 37, training_loss: 6.87814e-02\n",
            "epoch: 5003, iter: 37, training_loss: 6.81802e-02\n",
            "epoch: 5004, iter: 37, training_loss: 6.94840e-02\n",
            "epoch: 5005, iter: 37, training_loss: 7.20800e-02\n",
            "epoch: 5006, iter: 37, training_loss: 6.72323e-02\n",
            "epoch: 5007, iter: 37, training_loss: 6.82861e-02\n",
            "epoch: 5008, iter: 37, training_loss: 7.00509e-02\n",
            "epoch: 5009, iter: 37, training_loss: 6.94308e-02\n",
            "epoch: 5010, iter: 37, training_loss: 6.67654e-02\n",
            "epoch: 5011, iter: 37, training_loss: 6.94203e-02\n",
            "epoch: 5012, iter: 37, training_loss: 7.09441e-02\n",
            "epoch: 5013, iter: 37, training_loss: 6.94001e-02\n",
            "epoch: 5014, iter: 37, training_loss: 6.89379e-02\n",
            "epoch: 5015, iter: 37, training_loss: 7.07484e-02\n",
            "epoch: 5016, iter: 37, training_loss: 6.74177e-02\n",
            "epoch: 5017, iter: 37, training_loss: 7.17507e-02\n",
            "epoch: 5018, iter: 37, training_loss: 6.79008e-02\n",
            "epoch: 5019, iter: 37, training_loss: 6.92177e-02\n",
            "epoch: 5020, iter: 37, training_loss: 6.76210e-02\n",
            "epoch: 5021, iter: 37, training_loss: 6.97808e-02\n",
            "epoch: 5022, iter: 37, training_loss: 6.67739e-02\n",
            "epoch: 5023, iter: 37, training_loss: 6.83170e-02\n",
            "epoch: 5024, iter: 37, training_loss: 6.66792e-02\n",
            "epoch: 5025, iter: 37, training_loss: 6.98776e-02\n",
            "epoch: 5026, iter: 37, training_loss: 6.72192e-02\n",
            "epoch: 5027, iter: 37, training_loss: 6.69872e-02\n",
            "epoch: 5028, iter: 37, training_loss: 6.91608e-02\n",
            "epoch: 5029, iter: 37, training_loss: 6.68209e-02\n",
            "epoch: 5030, iter: 37, training_loss: 7.09529e-02\n",
            "epoch: 5031, iter: 37, training_loss: 7.08811e-02\n",
            "epoch: 5032, iter: 37, training_loss: 6.78811e-02\n",
            "epoch: 5033, iter: 37, training_loss: 6.69405e-02\n",
            "epoch: 5034, iter: 37, training_loss: 7.09770e-02\n",
            "epoch: 5035, iter: 37, training_loss: 6.79967e-02\n",
            "epoch: 5036, iter: 37, training_loss: 6.71355e-02\n",
            "epoch: 5037, iter: 37, training_loss: 6.78752e-02\n",
            "epoch: 5038, iter: 37, training_loss: 6.75457e-02\n",
            "epoch: 5039, iter: 37, training_loss: 6.72645e-02\n",
            "epoch: 5040, iter: 37, training_loss: 6.73079e-02\n",
            "epoch: 5041, iter: 37, training_loss: 6.60697e-02\n",
            "epoch: 5042, iter: 37, training_loss: 6.75061e-02\n",
            "epoch: 5043, iter: 37, training_loss: 6.69131e-02\n",
            "epoch: 5044, iter: 37, training_loss: 6.76106e-02\n",
            "epoch: 5045, iter: 37, training_loss: 7.13163e-02\n",
            "epoch: 5046, iter: 37, training_loss: 7.09431e-02\n",
            "epoch: 5047, iter: 37, training_loss: 6.53254e-02\n",
            "epoch: 5048, iter: 37, training_loss: 7.09665e-02\n",
            "epoch: 5049, iter: 37, training_loss: 6.70366e-02\n",
            "epoch: 5050, iter: 37, training_loss: 7.24280e-02\n",
            "epoch: 5051, iter: 37, training_loss: 6.91488e-02\n",
            "epoch: 5052, iter: 37, training_loss: 6.79317e-02\n",
            "epoch: 5053, iter: 37, training_loss: 7.17226e-02\n",
            "epoch: 5054, iter: 37, training_loss: 6.98350e-02\n",
            "epoch: 5055, iter: 37, training_loss: 6.85242e-02\n",
            "epoch: 5056, iter: 37, training_loss: 7.53231e-02\n",
            "epoch: 5057, iter: 37, training_loss: 7.33824e-02\n",
            "epoch: 5058, iter: 37, training_loss: 6.88443e-02\n",
            "epoch: 5059, iter: 37, training_loss: 6.88133e-02\n",
            "epoch: 5060, iter: 37, training_loss: 7.19166e-02\n",
            "epoch: 5061, iter: 37, training_loss: 7.18717e-02\n",
            "epoch: 5062, iter: 37, training_loss: 7.17064e-02\n",
            "epoch: 5063, iter: 37, training_loss: 7.34301e-02\n",
            "epoch: 5064, iter: 37, training_loss: 6.88248e-02\n",
            "epoch: 5065, iter: 37, training_loss: 6.64283e-02\n",
            "epoch: 5066, iter: 37, training_loss: 6.99520e-02\n",
            "epoch: 5067, iter: 37, training_loss: 7.12959e-02\n",
            "epoch: 5068, iter: 37, training_loss: 6.90011e-02\n",
            "epoch: 5069, iter: 37, training_loss: 6.61889e-02\n",
            "epoch: 5070, iter: 37, training_loss: 6.79185e-02\n",
            "epoch: 5071, iter: 37, training_loss: 7.20515e-02\n",
            "epoch: 5072, iter: 37, training_loss: 7.14466e-02\n",
            "epoch: 5073, iter: 37, training_loss: 7.18576e-02\n",
            "epoch: 5074, iter: 37, training_loss: 6.82984e-02\n",
            "epoch: 5075, iter: 37, training_loss: 6.87638e-02\n",
            "epoch: 5076, iter: 37, training_loss: 7.08982e-02\n",
            "epoch: 5077, iter: 37, training_loss: 6.69329e-02\n",
            "epoch: 5078, iter: 37, training_loss: 7.14102e-02\n",
            "epoch: 5079, iter: 37, training_loss: 6.84818e-02\n",
            "epoch: 5080, iter: 37, training_loss: 7.00926e-02\n",
            "epoch: 5081, iter: 37, training_loss: 6.63087e-02\n",
            "epoch: 5082, iter: 37, training_loss: 6.68506e-02\n",
            "epoch: 5083, iter: 37, training_loss: 6.89130e-02\n",
            "epoch: 5084, iter: 37, training_loss: 6.85332e-02\n",
            "epoch: 5085, iter: 37, training_loss: 6.79017e-02\n",
            "epoch: 5086, iter: 37, training_loss: 6.92486e-02\n",
            "epoch: 5087, iter: 37, training_loss: 6.62097e-02\n",
            "epoch: 5088, iter: 37, training_loss: 6.97340e-02\n",
            "epoch: 5089, iter: 37, training_loss: 6.82608e-02\n",
            "epoch: 5090, iter: 37, training_loss: 6.75977e-02\n",
            "epoch: 5091, iter: 37, training_loss: 6.85181e-02\n",
            "epoch: 5092, iter: 37, training_loss: 6.84353e-02\n",
            "epoch: 5093, iter: 37, training_loss: 6.77869e-02\n",
            "epoch: 5094, iter: 37, training_loss: 6.78816e-02\n",
            "epoch: 5095, iter: 37, training_loss: 7.12965e-02\n",
            "epoch: 5096, iter: 37, training_loss: 7.02596e-02\n",
            "epoch: 5097, iter: 37, training_loss: 7.09685e-02\n",
            "epoch: 5098, iter: 37, training_loss: 6.83486e-02\n",
            "epoch: 5099, iter: 37, training_loss: 6.97827e-02\n",
            "epoch: 5100, iter: 37, training_loss: 6.69644e-02\n",
            "epoch: 5101, iter: 37, training_loss: 6.91341e-02\n",
            "epoch: 5102, iter: 37, training_loss: 7.06824e-02\n",
            "epoch: 5103, iter: 37, training_loss: 6.70799e-02\n",
            "epoch: 5104, iter: 37, training_loss: 7.05488e-02\n",
            "epoch: 5105, iter: 37, training_loss: 7.43728e-02\n",
            "epoch: 5106, iter: 37, training_loss: 6.71578e-02\n",
            "epoch: 5107, iter: 37, training_loss: 7.06659e-02\n",
            "epoch: 5108, iter: 37, training_loss: 6.93858e-02\n",
            "epoch: 5109, iter: 37, training_loss: 6.84214e-02\n",
            "epoch: 5110, iter: 37, training_loss: 6.81137e-02\n",
            "epoch: 5111, iter: 37, training_loss: 7.18086e-02\n",
            "epoch: 5112, iter: 37, training_loss: 6.72345e-02\n",
            "epoch: 5113, iter: 37, training_loss: 7.13991e-02\n",
            "epoch: 5114, iter: 37, training_loss: 6.98593e-02\n",
            "epoch: 5115, iter: 37, training_loss: 7.20160e-02\n",
            "epoch: 5116, iter: 37, training_loss: 7.29447e-02\n",
            "epoch: 5117, iter: 37, training_loss: 7.25319e-02\n",
            "epoch: 5118, iter: 37, training_loss: 7.61249e-02\n",
            "epoch: 5119, iter: 37, training_loss: 6.70876e-02\n",
            "epoch: 5120, iter: 37, training_loss: 7.03762e-02\n",
            "epoch: 5121, iter: 37, training_loss: 7.09571e-02\n",
            "epoch: 5122, iter: 37, training_loss: 6.81335e-02\n",
            "epoch: 5123, iter: 37, training_loss: 6.89398e-02\n",
            "epoch: 5124, iter: 37, training_loss: 6.91745e-02\n",
            "epoch: 5125, iter: 37, training_loss: 6.78332e-02\n",
            "epoch: 5126, iter: 37, training_loss: 6.96467e-02\n",
            "epoch: 5127, iter: 37, training_loss: 6.90471e-02\n",
            "epoch: 5128, iter: 37, training_loss: 7.06085e-02\n",
            "epoch: 5129, iter: 37, training_loss: 6.62902e-02\n",
            "epoch: 5130, iter: 37, training_loss: 6.89540e-02\n",
            "epoch: 5131, iter: 37, training_loss: 6.87606e-02\n",
            "epoch: 5132, iter: 37, training_loss: 6.78570e-02\n",
            "epoch: 5133, iter: 37, training_loss: 6.91444e-02\n",
            "epoch: 5134, iter: 37, training_loss: 6.90310e-02\n",
            "epoch: 5135, iter: 37, training_loss: 7.08172e-02\n",
            "epoch: 5136, iter: 37, training_loss: 7.00969e-02\n",
            "epoch: 5137, iter: 37, training_loss: 6.80313e-02\n",
            "epoch: 5138, iter: 37, training_loss: 7.15295e-02\n",
            "epoch: 5139, iter: 37, training_loss: 6.83631e-02\n",
            "epoch: 5140, iter: 37, training_loss: 6.65926e-02\n",
            "epoch: 5141, iter: 37, training_loss: 6.78782e-02\n",
            "epoch: 5142, iter: 37, training_loss: 6.79211e-02\n",
            "epoch: 5143, iter: 37, training_loss: 7.03797e-02\n",
            "epoch: 5144, iter: 37, training_loss: 6.82776e-02\n",
            "epoch: 5145, iter: 37, training_loss: 7.26412e-02\n",
            "epoch: 5146, iter: 37, training_loss: 6.60441e-02\n",
            "epoch: 5147, iter: 37, training_loss: 7.02737e-02\n",
            "epoch: 5148, iter: 37, training_loss: 6.61777e-02\n",
            "epoch: 5149, iter: 37, training_loss: 7.32677e-02\n",
            "epoch: 5150, iter: 37, training_loss: 6.68795e-02\n",
            "epoch: 5151, iter: 37, training_loss: 7.04952e-02\n",
            "epoch: 5152, iter: 37, training_loss: 7.20358e-02\n",
            "epoch: 5153, iter: 37, training_loss: 6.98929e-02\n",
            "epoch: 5154, iter: 37, training_loss: 6.77331e-02\n",
            "epoch: 5155, iter: 37, training_loss: 6.80203e-02\n",
            "epoch: 5156, iter: 37, training_loss: 6.99037e-02\n",
            "epoch: 5157, iter: 37, training_loss: 7.12344e-02\n",
            "epoch: 5158, iter: 37, training_loss: 6.83498e-02\n",
            "epoch: 5159, iter: 37, training_loss: 7.05671e-02\n",
            "epoch: 5160, iter: 37, training_loss: 6.99355e-02\n",
            "epoch: 5161, iter: 37, training_loss: 7.27024e-02\n",
            "epoch: 5162, iter: 37, training_loss: 7.15633e-02\n",
            "epoch: 5163, iter: 37, training_loss: 6.94983e-02\n",
            "epoch: 5164, iter: 37, training_loss: 7.07415e-02\n",
            "epoch: 5165, iter: 37, training_loss: 6.76627e-02\n",
            "epoch: 5166, iter: 37, training_loss: 6.74381e-02\n",
            "epoch: 5167, iter: 37, training_loss: 7.23531e-02\n",
            "epoch: 5168, iter: 37, training_loss: 6.89981e-02\n",
            "epoch: 5169, iter: 37, training_loss: 6.66791e-02\n",
            "epoch: 5170, iter: 37, training_loss: 6.68404e-02\n",
            "epoch: 5171, iter: 37, training_loss: 6.60016e-02\n",
            "epoch: 5172, iter: 37, training_loss: 6.66030e-02\n",
            "epoch: 5173, iter: 37, training_loss: 6.62541e-02\n",
            "epoch: 5174, iter: 37, training_loss: 6.69615e-02\n",
            "epoch: 5175, iter: 37, training_loss: 7.09295e-02\n",
            "epoch: 5176, iter: 37, training_loss: 6.97032e-02\n",
            "epoch: 5177, iter: 37, training_loss: 7.02029e-02\n",
            "epoch: 5178, iter: 37, training_loss: 6.66726e-02\n",
            "epoch: 5179, iter: 37, training_loss: 7.03909e-02\n",
            "epoch: 5180, iter: 37, training_loss: 7.10785e-02\n",
            "epoch: 5181, iter: 37, training_loss: 6.79490e-02\n",
            "epoch: 5182, iter: 37, training_loss: 7.03976e-02\n",
            "epoch: 5183, iter: 37, training_loss: 6.75311e-02\n",
            "epoch: 5184, iter: 37, training_loss: 7.16521e-02\n",
            "epoch: 5185, iter: 37, training_loss: 7.25437e-02\n",
            "epoch: 5186, iter: 37, training_loss: 6.94411e-02\n",
            "epoch: 5187, iter: 37, training_loss: 6.75257e-02\n",
            "epoch: 5188, iter: 37, training_loss: 7.31155e-02\n",
            "epoch: 5189, iter: 37, training_loss: 6.83112e-02\n",
            "epoch: 5190, iter: 37, training_loss: 6.78753e-02\n",
            "epoch: 5191, iter: 37, training_loss: 6.99951e-02\n",
            "epoch: 5192, iter: 37, training_loss: 6.73727e-02\n",
            "epoch: 5193, iter: 37, training_loss: 6.94655e-02\n",
            "epoch: 5194, iter: 37, training_loss: 6.79644e-02\n",
            "epoch: 5195, iter: 37, training_loss: 6.87670e-02\n",
            "epoch: 5196, iter: 37, training_loss: 6.71440e-02\n",
            "epoch: 5197, iter: 37, training_loss: 6.81479e-02\n",
            "epoch: 5198, iter: 37, training_loss: 6.74394e-02\n",
            "epoch: 5199, iter: 37, training_loss: 7.38149e-02\n",
            "epoch: 5200, iter: 37, training_loss: 6.74470e-02\n",
            "epoch: 5201, iter: 37, training_loss: 6.86056e-02\n",
            "epoch: 5202, iter: 37, training_loss: 6.72839e-02\n",
            "epoch: 5203, iter: 37, training_loss: 6.97536e-02\n",
            "epoch: 5204, iter: 37, training_loss: 7.04080e-02\n",
            "epoch: 5205, iter: 37, training_loss: 6.81955e-02\n",
            "epoch: 5206, iter: 37, training_loss: 6.67331e-02\n",
            "epoch: 5207, iter: 37, training_loss: 6.96150e-02\n",
            "epoch: 5208, iter: 37, training_loss: 6.81738e-02\n",
            "epoch: 5209, iter: 37, training_loss: 6.83083e-02\n",
            "epoch: 5210, iter: 37, training_loss: 6.68642e-02\n",
            "epoch: 5211, iter: 37, training_loss: 7.04013e-02\n",
            "epoch: 5212, iter: 37, training_loss: 7.21770e-02\n",
            "epoch: 5213, iter: 37, training_loss: 7.10860e-02\n",
            "epoch: 5214, iter: 37, training_loss: 6.75964e-02\n",
            "epoch: 5215, iter: 37, training_loss: 7.09948e-02\n",
            "epoch: 5216, iter: 37, training_loss: 7.00077e-02\n",
            "epoch: 5217, iter: 37, training_loss: 6.79965e-02\n",
            "epoch: 5218, iter: 37, training_loss: 7.14918e-02\n",
            "epoch: 5219, iter: 37, training_loss: 6.86683e-02\n",
            "epoch: 5220, iter: 37, training_loss: 7.26769e-02\n",
            "epoch: 5221, iter: 37, training_loss: 7.05288e-02\n",
            "epoch: 5222, iter: 37, training_loss: 7.25115e-02\n",
            "epoch: 5223, iter: 37, training_loss: 6.93676e-02\n",
            "epoch: 5224, iter: 37, training_loss: 7.07239e-02\n",
            "epoch: 5225, iter: 37, training_loss: 6.98912e-02\n",
            "epoch: 5226, iter: 37, training_loss: 6.96906e-02\n",
            "epoch: 5227, iter: 37, training_loss: 6.81464e-02\n",
            "epoch: 5228, iter: 37, training_loss: 7.06467e-02\n",
            "epoch: 5229, iter: 37, training_loss: 7.08689e-02\n",
            "epoch: 5230, iter: 37, training_loss: 6.68196e-02\n",
            "epoch: 5231, iter: 37, training_loss: 6.73956e-02\n",
            "epoch: 5232, iter: 37, training_loss: 6.68184e-02\n",
            "epoch: 5233, iter: 37, training_loss: 6.88083e-02\n",
            "epoch: 5234, iter: 37, training_loss: 7.09323e-02\n",
            "epoch: 5235, iter: 37, training_loss: 6.88679e-02\n",
            "epoch: 5236, iter: 37, training_loss: 7.26004e-02\n",
            "epoch: 5237, iter: 37, training_loss: 6.75133e-02\n",
            "epoch: 5238, iter: 37, training_loss: 6.68351e-02\n",
            "epoch: 5239, iter: 37, training_loss: 6.92501e-02\n",
            "epoch: 5240, iter: 37, training_loss: 6.98065e-02\n",
            "epoch: 5241, iter: 37, training_loss: 6.72875e-02\n",
            "epoch: 5242, iter: 37, training_loss: 7.04546e-02\n",
            "epoch: 5243, iter: 37, training_loss: 6.89072e-02\n",
            "epoch: 5244, iter: 37, training_loss: 7.01631e-02\n",
            "epoch: 5245, iter: 37, training_loss: 6.91396e-02\n",
            "epoch: 5246, iter: 37, training_loss: 7.18393e-02\n",
            "epoch: 5247, iter: 37, training_loss: 6.78510e-02\n",
            "epoch: 5248, iter: 37, training_loss: 7.09160e-02\n",
            "epoch: 5249, iter: 37, training_loss: 6.99494e-02\n",
            "epoch: 5250, iter: 37, training_loss: 6.73826e-02\n",
            "epoch: 5251, iter: 37, training_loss: 6.79414e-02\n",
            "epoch: 5252, iter: 37, training_loss: 6.54740e-02\n",
            "epoch: 5253, iter: 37, training_loss: 6.89871e-02\n",
            "epoch: 5254, iter: 37, training_loss: 6.72979e-02\n",
            "epoch: 5255, iter: 37, training_loss: 6.73293e-02\n",
            "epoch: 5256, iter: 37, training_loss: 6.68853e-02\n",
            "epoch: 5257, iter: 37, training_loss: 6.75652e-02\n",
            "epoch: 5258, iter: 37, training_loss: 7.19546e-02\n",
            "epoch: 5259, iter: 37, training_loss: 7.22953e-02\n",
            "epoch: 5260, iter: 37, training_loss: 6.78355e-02\n",
            "epoch: 5261, iter: 37, training_loss: 6.87747e-02\n",
            "epoch: 5262, iter: 37, training_loss: 6.95074e-02\n",
            "epoch: 5263, iter: 37, training_loss: 6.65839e-02\n",
            "epoch: 5264, iter: 37, training_loss: 6.92885e-02\n",
            "epoch: 5265, iter: 37, training_loss: 7.11142e-02\n",
            "epoch: 5266, iter: 37, training_loss: 6.70684e-02\n",
            "epoch: 5267, iter: 37, training_loss: 6.74079e-02\n",
            "epoch: 5268, iter: 37, training_loss: 6.57328e-02\n",
            "epoch: 5269, iter: 37, training_loss: 6.89496e-02\n",
            "epoch: 5270, iter: 37, training_loss: 6.50640e-02\n",
            "epoch: 5271, iter: 37, training_loss: 6.89990e-02\n",
            "epoch: 5272, iter: 37, training_loss: 6.88358e-02\n",
            "epoch: 5273, iter: 37, training_loss: 6.76329e-02\n",
            "epoch: 5274, iter: 37, training_loss: 7.12972e-02\n",
            "epoch: 5275, iter: 37, training_loss: 6.85778e-02\n",
            "epoch: 5276, iter: 37, training_loss: 6.78963e-02\n",
            "epoch: 5277, iter: 37, training_loss: 6.70493e-02\n",
            "epoch: 5278, iter: 37, training_loss: 6.90618e-02\n",
            "epoch: 5279, iter: 37, training_loss: 7.08119e-02\n",
            "epoch: 5280, iter: 37, training_loss: 6.79686e-02\n",
            "epoch: 5281, iter: 37, training_loss: 6.70159e-02\n",
            "epoch: 5282, iter: 37, training_loss: 6.87041e-02\n",
            "epoch: 5283, iter: 37, training_loss: 7.00891e-02\n",
            "epoch: 5284, iter: 37, training_loss: 7.24353e-02\n",
            "epoch: 5285, iter: 37, training_loss: 6.58121e-02\n",
            "epoch: 5286, iter: 37, training_loss: 6.67632e-02\n",
            "epoch: 5287, iter: 37, training_loss: 6.64554e-02\n",
            "epoch: 5288, iter: 37, training_loss: 6.83106e-02\n",
            "epoch: 5289, iter: 37, training_loss: 6.79385e-02\n",
            "epoch: 5290, iter: 37, training_loss: 6.73137e-02\n",
            "epoch: 5291, iter: 37, training_loss: 6.94536e-02\n",
            "epoch: 5292, iter: 37, training_loss: 6.59016e-02\n",
            "epoch: 5293, iter: 37, training_loss: 6.75987e-02\n",
            "epoch: 5294, iter: 37, training_loss: 6.87015e-02\n",
            "epoch: 5295, iter: 37, training_loss: 6.65024e-02\n",
            "epoch: 5296, iter: 37, training_loss: 7.34647e-02\n",
            "epoch: 5297, iter: 37, training_loss: 6.76587e-02\n",
            "epoch: 5298, iter: 37, training_loss: 6.78038e-02\n",
            "epoch: 5299, iter: 37, training_loss: 6.64493e-02\n",
            "epoch: 5300, iter: 37, training_loss: 6.73792e-02\n",
            "epoch: 5301, iter: 37, training_loss: 6.77941e-02\n",
            "epoch: 5302, iter: 37, training_loss: 6.59550e-02\n",
            "epoch: 5303, iter: 37, training_loss: 6.80106e-02\n",
            "epoch: 5304, iter: 37, training_loss: 6.69934e-02\n",
            "epoch: 5305, iter: 37, training_loss: 6.81239e-02\n",
            "epoch: 5306, iter: 37, training_loss: 7.03626e-02\n",
            "epoch: 5307, iter: 37, training_loss: 6.77095e-02\n",
            "epoch: 5308, iter: 37, training_loss: 7.09195e-02\n",
            "epoch: 5309, iter: 37, training_loss: 6.67118e-02\n",
            "epoch: 5310, iter: 37, training_loss: 6.99630e-02\n",
            "epoch: 5311, iter: 37, training_loss: 6.88044e-02\n",
            "epoch: 5312, iter: 37, training_loss: 6.90209e-02\n",
            "epoch: 5313, iter: 37, training_loss: 6.79529e-02\n",
            "epoch: 5314, iter: 37, training_loss: 7.02781e-02\n",
            "epoch: 5315, iter: 37, training_loss: 6.89647e-02\n",
            "epoch: 5316, iter: 37, training_loss: 7.11518e-02\n",
            "epoch: 5317, iter: 37, training_loss: 6.74994e-02\n",
            "epoch: 5318, iter: 37, training_loss: 6.73691e-02\n",
            "epoch: 5319, iter: 37, training_loss: 6.62810e-02\n",
            "epoch: 5320, iter: 37, training_loss: 6.80874e-02\n",
            "epoch: 5321, iter: 37, training_loss: 6.82552e-02\n",
            "epoch: 5322, iter: 37, training_loss: 6.75283e-02\n",
            "epoch: 5323, iter: 37, training_loss: 6.74788e-02\n",
            "epoch: 5324, iter: 37, training_loss: 6.55617e-02\n",
            "epoch: 5325, iter: 37, training_loss: 7.05746e-02\n",
            "epoch: 5326, iter: 37, training_loss: 6.55697e-02\n",
            "epoch: 5327, iter: 37, training_loss: 6.97974e-02\n",
            "epoch: 5328, iter: 37, training_loss: 6.79722e-02\n",
            "epoch: 5329, iter: 37, training_loss: 6.97416e-02\n",
            "epoch: 5330, iter: 37, training_loss: 6.82905e-02\n",
            "epoch: 5331, iter: 37, training_loss: 6.80803e-02\n",
            "epoch: 5332, iter: 37, training_loss: 6.69587e-02\n",
            "epoch: 5333, iter: 37, training_loss: 6.56828e-02\n",
            "epoch: 5334, iter: 37, training_loss: 6.99630e-02\n",
            "epoch: 5335, iter: 37, training_loss: 6.82452e-02\n",
            "epoch: 5336, iter: 37, training_loss: 6.80143e-02\n",
            "epoch: 5337, iter: 37, training_loss: 6.84899e-02\n",
            "epoch: 5338, iter: 37, training_loss: 6.72961e-02\n",
            "epoch: 5339, iter: 37, training_loss: 6.68492e-02\n",
            "epoch: 5340, iter: 37, training_loss: 6.75681e-02\n",
            "epoch: 5341, iter: 37, training_loss: 6.88019e-02\n",
            "epoch: 5342, iter: 37, training_loss: 6.88585e-02\n",
            "epoch: 5343, iter: 37, training_loss: 6.91323e-02\n",
            "epoch: 5344, iter: 37, training_loss: 6.72104e-02\n",
            "epoch: 5345, iter: 37, training_loss: 6.91007e-02\n",
            "epoch: 5346, iter: 37, training_loss: 7.01351e-02\n",
            "epoch: 5347, iter: 37, training_loss: 6.78878e-02\n",
            "epoch: 5348, iter: 37, training_loss: 6.94969e-02\n",
            "epoch: 5349, iter: 37, training_loss: 6.61633e-02\n",
            "epoch: 5350, iter: 37, training_loss: 6.92875e-02\n",
            "epoch: 5351, iter: 37, training_loss: 6.66022e-02\n",
            "epoch: 5352, iter: 37, training_loss: 6.92324e-02\n",
            "epoch: 5353, iter: 37, training_loss: 6.85420e-02\n",
            "epoch: 5354, iter: 37, training_loss: 6.81375e-02\n",
            "epoch: 5355, iter: 37, training_loss: 6.90168e-02\n",
            "epoch: 5356, iter: 37, training_loss: 6.68694e-02\n",
            "epoch: 5357, iter: 37, training_loss: 7.15732e-02\n",
            "epoch: 5358, iter: 37, training_loss: 6.75781e-02\n",
            "epoch: 5359, iter: 37, training_loss: 6.95408e-02\n",
            "epoch: 5360, iter: 37, training_loss: 7.03983e-02\n",
            "epoch: 5361, iter: 37, training_loss: 6.77593e-02\n",
            "epoch: 5362, iter: 37, training_loss: 6.68549e-02\n",
            "epoch: 5363, iter: 37, training_loss: 6.58530e-02\n",
            "epoch: 5364, iter: 37, training_loss: 6.75814e-02\n",
            "epoch: 5365, iter: 37, training_loss: 6.99470e-02\n",
            "epoch: 5366, iter: 37, training_loss: 7.55234e-02\n",
            "epoch: 5367, iter: 37, training_loss: 6.83737e-02\n",
            "epoch: 5368, iter: 37, training_loss: 6.67558e-02\n",
            "epoch: 5369, iter: 37, training_loss: 6.97878e-02\n",
            "epoch: 5370, iter: 37, training_loss: 6.58333e-02\n",
            "epoch: 5371, iter: 37, training_loss: 6.81914e-02\n",
            "epoch: 5372, iter: 37, training_loss: 7.02923e-02\n",
            "epoch: 5373, iter: 37, training_loss: 7.01352e-02\n",
            "epoch: 5374, iter: 37, training_loss: 6.73985e-02\n",
            "epoch: 5375, iter: 37, training_loss: 6.47324e-02\n",
            "epoch: 5376, iter: 37, training_loss: 6.89788e-02\n",
            "epoch: 5377, iter: 37, training_loss: 7.03453e-02\n",
            "epoch: 5378, iter: 37, training_loss: 6.67542e-02\n",
            "epoch: 5379, iter: 37, training_loss: 6.69764e-02\n",
            "epoch: 5380, iter: 37, training_loss: 6.62023e-02\n",
            "epoch: 5381, iter: 37, training_loss: 6.70135e-02\n",
            "epoch: 5382, iter: 37, training_loss: 6.87239e-02\n",
            "epoch: 5383, iter: 37, training_loss: 6.55942e-02\n",
            "epoch: 5384, iter: 37, training_loss: 6.71335e-02\n",
            "epoch: 5385, iter: 37, training_loss: 6.71330e-02\n",
            "epoch: 5386, iter: 37, training_loss: 6.80273e-02\n",
            "epoch: 5387, iter: 37, training_loss: 6.61797e-02\n",
            "epoch: 5388, iter: 37, training_loss: 6.80940e-02\n",
            "epoch: 5389, iter: 37, training_loss: 6.65346e-02\n",
            "epoch: 5390, iter: 37, training_loss: 6.77652e-02\n",
            "epoch: 5391, iter: 37, training_loss: 6.74966e-02\n",
            "epoch: 5392, iter: 37, training_loss: 6.81805e-02\n",
            "epoch: 5393, iter: 37, training_loss: 6.78163e-02\n",
            "epoch: 5394, iter: 37, training_loss: 6.65791e-02\n",
            "epoch: 5395, iter: 37, training_loss: 6.78137e-02\n",
            "epoch: 5396, iter: 37, training_loss: 6.78330e-02\n",
            "epoch: 5397, iter: 37, training_loss: 6.87034e-02\n",
            "epoch: 5398, iter: 37, training_loss: 6.77345e-02\n",
            "epoch: 5399, iter: 37, training_loss: 7.20704e-02\n",
            "epoch: 5400, iter: 37, training_loss: 6.96830e-02\n",
            "epoch: 5401, iter: 37, training_loss: 6.77087e-02\n",
            "epoch: 5402, iter: 37, training_loss: 6.65772e-02\n",
            "epoch: 5403, iter: 37, training_loss: 6.78782e-02\n",
            "epoch: 5404, iter: 37, training_loss: 6.88834e-02\n",
            "epoch: 5405, iter: 37, training_loss: 6.89690e-02\n",
            "epoch: 5406, iter: 37, training_loss: 6.67313e-02\n",
            "epoch: 5407, iter: 37, training_loss: 6.84221e-02\n",
            "epoch: 5408, iter: 37, training_loss: 6.93594e-02\n",
            "epoch: 5409, iter: 37, training_loss: 6.88455e-02\n",
            "epoch: 5410, iter: 37, training_loss: 6.91740e-02\n",
            "epoch: 5411, iter: 37, training_loss: 6.63288e-02\n",
            "epoch: 5412, iter: 37, training_loss: 6.62674e-02\n",
            "epoch: 5413, iter: 37, training_loss: 6.79856e-02\n",
            "epoch: 5414, iter: 37, training_loss: 6.66783e-02\n",
            "epoch: 5415, iter: 37, training_loss: 6.89890e-02\n",
            "epoch: 5416, iter: 37, training_loss: 6.83824e-02\n",
            "epoch: 5417, iter: 37, training_loss: 7.12722e-02\n",
            "epoch: 5418, iter: 37, training_loss: 6.71700e-02\n",
            "epoch: 5419, iter: 37, training_loss: 6.56700e-02\n",
            "epoch: 5420, iter: 37, training_loss: 6.91688e-02\n",
            "epoch: 5421, iter: 37, training_loss: 6.94549e-02\n",
            "epoch: 5422, iter: 37, training_loss: 6.92352e-02\n",
            "epoch: 5423, iter: 37, training_loss: 6.93535e-02\n",
            "epoch: 5424, iter: 37, training_loss: 6.88002e-02\n",
            "epoch: 5425, iter: 37, training_loss: 6.75425e-02\n",
            "epoch: 5426, iter: 37, training_loss: 6.75472e-02\n",
            "epoch: 5427, iter: 37, training_loss: 6.63021e-02\n",
            "epoch: 5428, iter: 37, training_loss: 7.02009e-02\n",
            "epoch: 5429, iter: 37, training_loss: 6.90575e-02\n",
            "epoch: 5430, iter: 37, training_loss: 6.67486e-02\n",
            "epoch: 5431, iter: 37, training_loss: 6.87543e-02\n",
            "epoch: 5432, iter: 37, training_loss: 6.93833e-02\n",
            "epoch: 5433, iter: 37, training_loss: 6.92270e-02\n",
            "epoch: 5434, iter: 37, training_loss: 6.69602e-02\n",
            "epoch: 5435, iter: 37, training_loss: 6.71287e-02\n",
            "epoch: 5436, iter: 37, training_loss: 6.70086e-02\n",
            "epoch: 5437, iter: 37, training_loss: 6.82910e-02\n",
            "epoch: 5438, iter: 37, training_loss: 6.96024e-02\n",
            "epoch: 5439, iter: 37, training_loss: 6.77972e-02\n",
            "epoch: 5440, iter: 37, training_loss: 6.64178e-02\n",
            "epoch: 5441, iter: 37, training_loss: 6.58974e-02\n",
            "epoch: 5442, iter: 37, training_loss: 6.70989e-02\n",
            "epoch: 5443, iter: 37, training_loss: 6.53587e-02\n",
            "epoch: 5444, iter: 37, training_loss: 6.75235e-02\n",
            "epoch: 5445, iter: 37, training_loss: 6.98438e-02\n",
            "epoch: 5446, iter: 37, training_loss: 6.80629e-02\n",
            "epoch: 5447, iter: 37, training_loss: 6.82221e-02\n",
            "epoch: 5448, iter: 37, training_loss: 6.53998e-02\n",
            "epoch: 5449, iter: 37, training_loss: 6.55509e-02\n",
            "epoch: 5450, iter: 37, training_loss: 6.81441e-02\n",
            "epoch: 5451, iter: 37, training_loss: 6.61028e-02\n",
            "epoch: 5452, iter: 37, training_loss: 6.59209e-02\n",
            "epoch: 5453, iter: 37, training_loss: 6.80586e-02\n",
            "epoch: 5454, iter: 37, training_loss: 6.68319e-02\n",
            "epoch: 5455, iter: 37, training_loss: 6.46009e-02\n",
            "epoch: 5456, iter: 37, training_loss: 7.12692e-02\n",
            "epoch: 5457, iter: 37, training_loss: 6.97499e-02\n",
            "epoch: 5458, iter: 37, training_loss: 6.97355e-02\n",
            "epoch: 5459, iter: 37, training_loss: 6.70139e-02\n",
            "epoch: 5460, iter: 37, training_loss: 6.94045e-02\n",
            "epoch: 5461, iter: 37, training_loss: 6.73544e-02\n",
            "epoch: 5462, iter: 37, training_loss: 6.74705e-02\n",
            "epoch: 5463, iter: 37, training_loss: 6.52776e-02\n",
            "epoch: 5464, iter: 37, training_loss: 6.94495e-02\n",
            "epoch: 5465, iter: 37, training_loss: 6.51709e-02\n",
            "epoch: 5466, iter: 37, training_loss: 6.53850e-02\n",
            "epoch: 5467, iter: 37, training_loss: 7.29407e-02\n",
            "epoch: 5468, iter: 37, training_loss: 6.69809e-02\n",
            "epoch: 5469, iter: 37, training_loss: 6.64281e-02\n",
            "epoch: 5470, iter: 37, training_loss: 6.69635e-02\n",
            "epoch: 5471, iter: 37, training_loss: 6.90219e-02\n",
            "epoch: 5472, iter: 37, training_loss: 6.92891e-02\n",
            "epoch: 5473, iter: 37, training_loss: 6.71341e-02\n",
            "epoch: 5474, iter: 37, training_loss: 6.81018e-02\n",
            "epoch: 5475, iter: 37, training_loss: 6.70664e-02\n",
            "epoch: 5476, iter: 37, training_loss: 6.84327e-02\n",
            "epoch: 5477, iter: 37, training_loss: 6.96091e-02\n",
            "epoch: 5478, iter: 37, training_loss: 6.63060e-02\n",
            "epoch: 5479, iter: 37, training_loss: 6.64727e-02\n",
            "epoch: 5480, iter: 37, training_loss: 6.56977e-02\n",
            "epoch: 5481, iter: 37, training_loss: 6.79609e-02\n",
            "epoch: 5482, iter: 37, training_loss: 6.89904e-02\n",
            "epoch: 5483, iter: 37, training_loss: 6.75442e-02\n",
            "epoch: 5484, iter: 37, training_loss: 6.56849e-02\n",
            "epoch: 5485, iter: 37, training_loss: 6.92138e-02\n",
            "epoch: 5486, iter: 37, training_loss: 6.73085e-02\n",
            "epoch: 5487, iter: 37, training_loss: 6.68013e-02\n",
            "epoch: 5488, iter: 37, training_loss: 6.55194e-02\n",
            "epoch: 5489, iter: 37, training_loss: 6.58408e-02\n",
            "epoch: 5490, iter: 37, training_loss: 6.82948e-02\n",
            "epoch: 5491, iter: 37, training_loss: 7.00636e-02\n",
            "epoch: 5492, iter: 37, training_loss: 6.90982e-02\n",
            "epoch: 5493, iter: 37, training_loss: 6.85964e-02\n",
            "epoch: 5494, iter: 37, training_loss: 6.66327e-02\n",
            "epoch: 5495, iter: 37, training_loss: 6.64396e-02\n",
            "epoch: 5496, iter: 37, training_loss: 6.75089e-02\n",
            "epoch: 5497, iter: 37, training_loss: 6.98751e-02\n",
            "epoch: 5498, iter: 37, training_loss: 6.63855e-02\n",
            "epoch: 5499, iter: 37, training_loss: 6.61627e-02\n",
            "epoch: 5500, iter: 37, training_loss: 7.02887e-02\n",
            "epoch: 5501, iter: 37, training_loss: 6.81370e-02\n",
            "epoch: 5502, iter: 37, training_loss: 6.58622e-02\n",
            "epoch: 5503, iter: 37, training_loss: 6.82868e-02\n",
            "epoch: 5504, iter: 37, training_loss: 6.79070e-02\n",
            "epoch: 5505, iter: 37, training_loss: 6.52307e-02\n",
            "epoch: 5506, iter: 37, training_loss: 7.03322e-02\n",
            "epoch: 5507, iter: 37, training_loss: 6.79369e-02\n",
            "epoch: 5508, iter: 37, training_loss: 6.88263e-02\n",
            "epoch: 5509, iter: 37, training_loss: 6.73376e-02\n",
            "epoch: 5510, iter: 37, training_loss: 6.64323e-02\n",
            "epoch: 5511, iter: 37, training_loss: 6.64752e-02\n",
            "epoch: 5512, iter: 37, training_loss: 7.01595e-02\n",
            "epoch: 5513, iter: 37, training_loss: 6.60292e-02\n",
            "epoch: 5514, iter: 37, training_loss: 6.44367e-02\n",
            "epoch: 5515, iter: 37, training_loss: 6.72003e-02\n",
            "epoch: 5516, iter: 37, training_loss: 6.72336e-02\n",
            "epoch: 5517, iter: 37, training_loss: 6.99221e-02\n",
            "epoch: 5518, iter: 37, training_loss: 6.56035e-02\n",
            "epoch: 5519, iter: 37, training_loss: 6.65345e-02\n",
            "epoch: 5520, iter: 37, training_loss: 6.75615e-02\n",
            "epoch: 5521, iter: 37, training_loss: 6.53176e-02\n",
            "epoch: 5522, iter: 37, training_loss: 6.60516e-02\n",
            "epoch: 5523, iter: 37, training_loss: 6.44337e-02\n",
            "epoch: 5524, iter: 37, training_loss: 6.85038e-02\n",
            "epoch: 5525, iter: 37, training_loss: 6.52758e-02\n",
            "epoch: 5526, iter: 37, training_loss: 7.14916e-02\n",
            "epoch: 5527, iter: 37, training_loss: 6.42676e-02\n",
            "epoch: 5528, iter: 37, training_loss: 6.83633e-02\n",
            "epoch: 5529, iter: 37, training_loss: 6.65442e-02\n",
            "epoch: 5530, iter: 37, training_loss: 6.59002e-02\n",
            "epoch: 5531, iter: 37, training_loss: 6.81671e-02\n",
            "epoch: 5532, iter: 37, training_loss: 6.79571e-02\n",
            "epoch: 5533, iter: 37, training_loss: 6.84169e-02\n",
            "epoch: 5534, iter: 37, training_loss: 6.65503e-02\n",
            "epoch: 5535, iter: 37, training_loss: 6.65371e-02\n",
            "epoch: 5536, iter: 37, training_loss: 6.90747e-02\n",
            "epoch: 5537, iter: 37, training_loss: 6.48822e-02\n",
            "epoch: 5538, iter: 37, training_loss: 6.72125e-02\n",
            "epoch: 5539, iter: 37, training_loss: 6.66287e-02\n",
            "epoch: 5540, iter: 37, training_loss: 6.59060e-02\n",
            "epoch: 5541, iter: 37, training_loss: 6.72060e-02\n",
            "epoch: 5542, iter: 37, training_loss: 6.46215e-02\n",
            "epoch: 5543, iter: 37, training_loss: 6.98934e-02\n",
            "epoch: 5544, iter: 37, training_loss: 6.69226e-02\n",
            "epoch: 5545, iter: 37, training_loss: 6.63460e-02\n",
            "epoch: 5546, iter: 37, training_loss: 6.82720e-02\n",
            "epoch: 5547, iter: 37, training_loss: 6.57203e-02\n",
            "epoch: 5548, iter: 37, training_loss: 6.76172e-02\n",
            "epoch: 5549, iter: 37, training_loss: 6.94288e-02\n",
            "epoch: 5550, iter: 37, training_loss: 6.96441e-02\n",
            "epoch: 5551, iter: 37, training_loss: 6.59228e-02\n",
            "epoch: 5552, iter: 37, training_loss: 6.59240e-02\n",
            "epoch: 5553, iter: 37, training_loss: 6.64520e-02\n",
            "epoch: 5554, iter: 37, training_loss: 6.52956e-02\n",
            "epoch: 5555, iter: 37, training_loss: 7.00443e-02\n",
            "epoch: 5556, iter: 37, training_loss: 6.59252e-02\n",
            "epoch: 5557, iter: 37, training_loss: 6.95602e-02\n",
            "epoch: 5558, iter: 37, training_loss: 6.78363e-02\n",
            "epoch: 5559, iter: 37, training_loss: 6.68568e-02\n",
            "epoch: 5560, iter: 37, training_loss: 6.61392e-02\n",
            "epoch: 5561, iter: 37, training_loss: 6.82815e-02\n",
            "epoch: 5562, iter: 37, training_loss: 6.61898e-02\n",
            "epoch: 5563, iter: 37, training_loss: 6.48587e-02\n",
            "epoch: 5564, iter: 37, training_loss: 6.73692e-02\n",
            "epoch: 5565, iter: 37, training_loss: 6.61704e-02\n",
            "epoch: 5566, iter: 37, training_loss: 6.71439e-02\n",
            "epoch: 5567, iter: 37, training_loss: 6.59010e-02\n",
            "epoch: 5568, iter: 37, training_loss: 6.67660e-02\n",
            "epoch: 5569, iter: 37, training_loss: 6.85043e-02\n",
            "epoch: 5570, iter: 37, training_loss: 6.46824e-02\n",
            "epoch: 5571, iter: 37, training_loss: 6.59364e-02\n",
            "epoch: 5572, iter: 37, training_loss: 7.18605e-02\n",
            "epoch: 5573, iter: 37, training_loss: 6.90968e-02\n",
            "epoch: 5574, iter: 37, training_loss: 6.64889e-02\n",
            "epoch: 5575, iter: 37, training_loss: 6.57844e-02\n",
            "epoch: 5576, iter: 37, training_loss: 6.82450e-02\n",
            "epoch: 5577, iter: 37, training_loss: 6.64150e-02\n",
            "epoch: 5578, iter: 37, training_loss: 6.71445e-02\n",
            "epoch: 5579, iter: 37, training_loss: 6.55419e-02\n",
            "epoch: 5580, iter: 37, training_loss: 6.93708e-02\n",
            "epoch: 5581, iter: 37, training_loss: 6.64297e-02\n",
            "epoch: 5582, iter: 37, training_loss: 6.89938e-02\n",
            "epoch: 5583, iter: 37, training_loss: 6.68058e-02\n",
            "epoch: 5584, iter: 37, training_loss: 6.67685e-02\n",
            "epoch: 5585, iter: 37, training_loss: 6.57445e-02\n",
            "epoch: 5586, iter: 37, training_loss: 6.94775e-02\n",
            "epoch: 5587, iter: 37, training_loss: 7.03450e-02\n",
            "epoch: 5588, iter: 37, training_loss: 6.59462e-02\n",
            "epoch: 5589, iter: 37, training_loss: 6.87432e-02\n",
            "epoch: 5590, iter: 37, training_loss: 6.92248e-02\n",
            "epoch: 5591, iter: 37, training_loss: 6.58763e-02\n",
            "epoch: 5592, iter: 37, training_loss: 6.88733e-02\n",
            "epoch: 5593, iter: 37, training_loss: 6.86097e-02\n",
            "epoch: 5594, iter: 37, training_loss: 6.75450e-02\n",
            "epoch: 5595, iter: 37, training_loss: 6.64456e-02\n",
            "epoch: 5596, iter: 37, training_loss: 6.72433e-02\n",
            "epoch: 5597, iter: 37, training_loss: 6.76546e-02\n",
            "epoch: 5598, iter: 37, training_loss: 6.71128e-02\n",
            "epoch: 5599, iter: 37, training_loss: 6.61905e-02\n",
            "epoch: 5600, iter: 37, training_loss: 6.77912e-02\n",
            "epoch: 5601, iter: 37, training_loss: 6.65635e-02\n",
            "epoch: 5602, iter: 37, training_loss: 6.60672e-02\n",
            "epoch: 5603, iter: 37, training_loss: 6.70682e-02\n",
            "epoch: 5604, iter: 37, training_loss: 6.70845e-02\n",
            "epoch: 5605, iter: 37, training_loss: 6.75083e-02\n",
            "epoch: 5606, iter: 37, training_loss: 6.77306e-02\n",
            "epoch: 5607, iter: 37, training_loss: 6.87324e-02\n",
            "epoch: 5608, iter: 37, training_loss: 6.55974e-02\n",
            "epoch: 5609, iter: 37, training_loss: 6.83017e-02\n",
            "epoch: 5610, iter: 37, training_loss: 6.68153e-02\n",
            "epoch: 5611, iter: 37, training_loss: 6.81980e-02\n",
            "epoch: 5612, iter: 37, training_loss: 6.78882e-02\n",
            "epoch: 5613, iter: 37, training_loss: 6.60105e-02\n",
            "epoch: 5614, iter: 37, training_loss: 6.76948e-02\n",
            "epoch: 5615, iter: 37, training_loss: 6.73924e-02\n",
            "epoch: 5616, iter: 37, training_loss: 6.86009e-02\n",
            "epoch: 5617, iter: 37, training_loss: 6.58750e-02\n",
            "epoch: 5618, iter: 37, training_loss: 6.86194e-02\n",
            "epoch: 5619, iter: 37, training_loss: 6.69904e-02\n",
            "epoch: 5620, iter: 37, training_loss: 6.79080e-02\n",
            "epoch: 5621, iter: 37, training_loss: 6.65579e-02\n",
            "epoch: 5622, iter: 37, training_loss: 6.83792e-02\n",
            "epoch: 5623, iter: 37, training_loss: 6.95218e-02\n",
            "epoch: 5624, iter: 37, training_loss: 6.61718e-02\n",
            "epoch: 5625, iter: 37, training_loss: 6.82891e-02\n",
            "epoch: 5626, iter: 37, training_loss: 6.85296e-02\n",
            "epoch: 5627, iter: 37, training_loss: 6.65253e-02\n",
            "epoch: 5628, iter: 37, training_loss: 6.41665e-02\n",
            "epoch: 5629, iter: 37, training_loss: 7.19824e-02\n",
            "epoch: 5630, iter: 37, training_loss: 6.62382e-02\n",
            "epoch: 5631, iter: 37, training_loss: 6.69212e-02\n",
            "epoch: 5632, iter: 37, training_loss: 6.88049e-02\n",
            "epoch: 5633, iter: 37, training_loss: 6.71298e-02\n",
            "epoch: 5634, iter: 37, training_loss: 6.62809e-02\n",
            "epoch: 5635, iter: 37, training_loss: 6.35152e-02\n",
            "epoch: 5636, iter: 37, training_loss: 7.11055e-02\n",
            "epoch: 5637, iter: 37, training_loss: 6.74454e-02\n",
            "epoch: 5638, iter: 37, training_loss: 6.64201e-02\n",
            "epoch: 5639, iter: 37, training_loss: 6.75526e-02\n",
            "epoch: 5640, iter: 37, training_loss: 6.91196e-02\n",
            "epoch: 5641, iter: 37, training_loss: 6.71834e-02\n",
            "epoch: 5642, iter: 37, training_loss: 6.88076e-02\n",
            "epoch: 5643, iter: 37, training_loss: 6.87113e-02\n",
            "epoch: 5644, iter: 37, training_loss: 6.46952e-02\n",
            "epoch: 5645, iter: 37, training_loss: 6.76566e-02\n",
            "epoch: 5646, iter: 37, training_loss: 6.74237e-02\n",
            "epoch: 5647, iter: 37, training_loss: 6.81012e-02\n",
            "epoch: 5648, iter: 37, training_loss: 6.43225e-02\n",
            "epoch: 5649, iter: 37, training_loss: 7.20958e-02\n",
            "epoch: 5650, iter: 37, training_loss: 6.74687e-02\n",
            "epoch: 5651, iter: 37, training_loss: 6.46716e-02\n",
            "epoch: 5652, iter: 37, training_loss: 7.01923e-02\n",
            "epoch: 5653, iter: 37, training_loss: 6.68375e-02\n",
            "epoch: 5654, iter: 37, training_loss: 6.69873e-02\n",
            "epoch: 5655, iter: 37, training_loss: 6.81697e-02\n",
            "epoch: 5656, iter: 37, training_loss: 6.56790e-02\n",
            "epoch: 5657, iter: 37, training_loss: 6.66700e-02\n",
            "epoch: 5658, iter: 37, training_loss: 6.76030e-02\n",
            "epoch: 5659, iter: 37, training_loss: 6.47881e-02\n",
            "epoch: 5660, iter: 37, training_loss: 6.92526e-02\n",
            "epoch: 5661, iter: 37, training_loss: 6.68107e-02\n",
            "epoch: 5662, iter: 37, training_loss: 6.78442e-02\n",
            "epoch: 5663, iter: 37, training_loss: 6.64489e-02\n",
            "epoch: 5664, iter: 37, training_loss: 6.60712e-02\n",
            "epoch: 5665, iter: 37, training_loss: 6.85764e-02\n",
            "epoch: 5666, iter: 37, training_loss: 6.49154e-02\n",
            "epoch: 5667, iter: 37, training_loss: 6.50533e-02\n",
            "epoch: 5668, iter: 37, training_loss: 6.71432e-02\n",
            "epoch: 5669, iter: 37, training_loss: 6.54618e-02\n",
            "epoch: 5670, iter: 37, training_loss: 6.81905e-02\n",
            "epoch: 5671, iter: 37, training_loss: 6.42314e-02\n",
            "epoch: 5672, iter: 37, training_loss: 6.84836e-02\n",
            "epoch: 5673, iter: 37, training_loss: 6.61232e-02\n",
            "epoch: 5674, iter: 37, training_loss: 6.90820e-02\n",
            "epoch: 5675, iter: 37, training_loss: 6.70363e-02\n",
            "epoch: 5676, iter: 37, training_loss: 6.73351e-02\n",
            "epoch: 5677, iter: 37, training_loss: 6.81300e-02\n",
            "epoch: 5678, iter: 37, training_loss: 6.68360e-02\n",
            "epoch: 5679, iter: 37, training_loss: 6.84215e-02\n",
            "epoch: 5680, iter: 37, training_loss: 6.53084e-02\n",
            "epoch: 5681, iter: 37, training_loss: 6.57468e-02\n",
            "epoch: 5682, iter: 37, training_loss: 6.69196e-02\n",
            "epoch: 5683, iter: 37, training_loss: 6.58536e-02\n",
            "epoch: 5684, iter: 37, training_loss: 6.91855e-02\n",
            "epoch: 5685, iter: 37, training_loss: 6.72033e-02\n",
            "epoch: 5686, iter: 37, training_loss: 6.50084e-02\n",
            "epoch: 5687, iter: 37, training_loss: 6.46096e-02\n",
            "epoch: 5688, iter: 37, training_loss: 6.80145e-02\n",
            "epoch: 5689, iter: 37, training_loss: 6.61063e-02\n",
            "epoch: 5690, iter: 37, training_loss: 6.74731e-02\n",
            "epoch: 5691, iter: 37, training_loss: 6.76377e-02\n",
            "epoch: 5692, iter: 37, training_loss: 6.64365e-02\n",
            "epoch: 5693, iter: 37, training_loss: 6.59202e-02\n",
            "epoch: 5694, iter: 37, training_loss: 6.45131e-02\n",
            "epoch: 5695, iter: 37, training_loss: 6.86369e-02\n",
            "epoch: 5696, iter: 37, training_loss: 6.57733e-02\n",
            "epoch: 5697, iter: 37, training_loss: 7.23173e-02\n",
            "epoch: 5698, iter: 37, training_loss: 6.65201e-02\n",
            "epoch: 5699, iter: 37, training_loss: 6.69112e-02\n",
            "epoch: 5700, iter: 37, training_loss: 6.65411e-02\n",
            "epoch: 5701, iter: 37, training_loss: 6.59938e-02\n",
            "epoch: 5702, iter: 37, training_loss: 6.82284e-02\n",
            "epoch: 5703, iter: 37, training_loss: 6.73569e-02\n",
            "epoch: 5704, iter: 37, training_loss: 6.71615e-02\n",
            "epoch: 5705, iter: 37, training_loss: 6.76341e-02\n",
            "epoch: 5706, iter: 37, training_loss: 6.99152e-02\n",
            "epoch: 5707, iter: 37, training_loss: 6.50311e-02\n",
            "epoch: 5708, iter: 37, training_loss: 6.49547e-02\n",
            "epoch: 5709, iter: 37, training_loss: 6.63131e-02\n",
            "epoch: 5710, iter: 37, training_loss: 6.46920e-02\n",
            "epoch: 5711, iter: 37, training_loss: 6.69580e-02\n",
            "epoch: 5712, iter: 37, training_loss: 6.74724e-02\n",
            "epoch: 5713, iter: 37, training_loss: 7.07823e-02\n",
            "epoch: 5714, iter: 37, training_loss: 6.58579e-02\n",
            "epoch: 5715, iter: 37, training_loss: 6.59219e-02\n",
            "epoch: 5716, iter: 37, training_loss: 6.52229e-02\n",
            "epoch: 5717, iter: 37, training_loss: 6.49738e-02\n",
            "epoch: 5718, iter: 37, training_loss: 6.77039e-02\n",
            "epoch: 5719, iter: 37, training_loss: 6.62930e-02\n",
            "epoch: 5720, iter: 37, training_loss: 6.92079e-02\n",
            "epoch: 5721, iter: 37, training_loss: 6.65074e-02\n",
            "epoch: 5722, iter: 37, training_loss: 6.55222e-02\n",
            "epoch: 5723, iter: 37, training_loss: 7.01610e-02\n",
            "epoch: 5724, iter: 37, training_loss: 6.60432e-02\n",
            "epoch: 5725, iter: 37, training_loss: 6.65226e-02\n",
            "epoch: 5726, iter: 37, training_loss: 6.64741e-02\n",
            "epoch: 5727, iter: 37, training_loss: 6.65022e-02\n",
            "epoch: 5728, iter: 37, training_loss: 6.85747e-02\n",
            "epoch: 5729, iter: 37, training_loss: 6.63764e-02\n",
            "epoch: 5730, iter: 37, training_loss: 6.65502e-02\n",
            "epoch: 5731, iter: 37, training_loss: 6.68890e-02\n",
            "epoch: 5732, iter: 37, training_loss: 6.56988e-02\n",
            "epoch: 5733, iter: 37, training_loss: 6.72811e-02\n",
            "epoch: 5734, iter: 37, training_loss: 7.01531e-02\n",
            "epoch: 5735, iter: 37, training_loss: 6.65043e-02\n",
            "epoch: 5736, iter: 37, training_loss: 6.60362e-02\n",
            "epoch: 5737, iter: 37, training_loss: 6.85102e-02\n",
            "epoch: 5738, iter: 37, training_loss: 6.60477e-02\n",
            "epoch: 5739, iter: 37, training_loss: 6.57654e-02\n",
            "epoch: 5740, iter: 37, training_loss: 6.60351e-02\n",
            "epoch: 5741, iter: 37, training_loss: 6.70550e-02\n",
            "epoch: 5742, iter: 37, training_loss: 6.65816e-02\n",
            "epoch: 5743, iter: 37, training_loss: 6.64474e-02\n",
            "epoch: 5744, iter: 37, training_loss: 6.99185e-02\n",
            "epoch: 5745, iter: 37, training_loss: 6.82418e-02\n",
            "epoch: 5746, iter: 37, training_loss: 6.38640e-02\n",
            "epoch: 5747, iter: 37, training_loss: 6.55514e-02\n",
            "epoch: 5748, iter: 37, training_loss: 6.39456e-02\n",
            "epoch: 5749, iter: 37, training_loss: 6.67571e-02\n",
            "epoch: 5750, iter: 37, training_loss: 6.43531e-02\n",
            "epoch: 5751, iter: 37, training_loss: 6.89036e-02\n",
            "epoch: 5752, iter: 37, training_loss: 6.60688e-02\n",
            "epoch: 5753, iter: 37, training_loss: 7.00783e-02\n",
            "epoch: 5754, iter: 37, training_loss: 6.53387e-02\n",
            "epoch: 5755, iter: 37, training_loss: 6.65650e-02\n",
            "epoch: 5756, iter: 37, training_loss: 6.79728e-02\n",
            "epoch: 5757, iter: 37, training_loss: 6.40236e-02\n",
            "epoch: 5758, iter: 37, training_loss: 6.65988e-02\n",
            "epoch: 5759, iter: 37, training_loss: 6.64369e-02\n",
            "epoch: 5760, iter: 37, training_loss: 6.74836e-02\n",
            "epoch: 5761, iter: 37, training_loss: 6.66203e-02\n",
            "epoch: 5762, iter: 37, training_loss: 6.86159e-02\n",
            "epoch: 5763, iter: 37, training_loss: 6.58010e-02\n",
            "epoch: 5764, iter: 37, training_loss: 6.61540e-02\n",
            "epoch: 5765, iter: 37, training_loss: 6.47150e-02\n",
            "epoch: 5766, iter: 37, training_loss: 6.60222e-02\n",
            "epoch: 5767, iter: 37, training_loss: 6.49031e-02\n",
            "epoch: 5768, iter: 37, training_loss: 6.51817e-02\n",
            "epoch: 5769, iter: 37, training_loss: 6.44403e-02\n",
            "epoch: 5770, iter: 37, training_loss: 6.53437e-02\n",
            "epoch: 5771, iter: 37, training_loss: 6.82768e-02\n",
            "epoch: 5772, iter: 37, training_loss: 6.76404e-02\n",
            "epoch: 5773, iter: 37, training_loss: 6.80678e-02\n",
            "epoch: 5774, iter: 37, training_loss: 6.80680e-02\n",
            "epoch: 5775, iter: 37, training_loss: 6.76547e-02\n",
            "epoch: 5776, iter: 37, training_loss: 6.61441e-02\n",
            "epoch: 5777, iter: 37, training_loss: 6.79427e-02\n",
            "epoch: 5778, iter: 37, training_loss: 6.78257e-02\n",
            "epoch: 5779, iter: 37, training_loss: 6.84796e-02\n",
            "epoch: 5780, iter: 37, training_loss: 6.62154e-02\n",
            "epoch: 5781, iter: 37, training_loss: 6.73048e-02\n",
            "epoch: 5782, iter: 37, training_loss: 6.63558e-02\n",
            "epoch: 5783, iter: 37, training_loss: 6.62817e-02\n",
            "epoch: 5784, iter: 37, training_loss: 6.62152e-02\n",
            "epoch: 5785, iter: 37, training_loss: 6.65005e-02\n",
            "epoch: 5786, iter: 37, training_loss: 6.52625e-02\n",
            "epoch: 5787, iter: 37, training_loss: 6.79561e-02\n",
            "epoch: 5788, iter: 37, training_loss: 6.57496e-02\n",
            "epoch: 5789, iter: 37, training_loss: 6.59424e-02\n",
            "epoch: 5790, iter: 37, training_loss: 6.59262e-02\n",
            "epoch: 5791, iter: 37, training_loss: 6.59159e-02\n",
            "epoch: 5792, iter: 37, training_loss: 6.54582e-02\n",
            "epoch: 5793, iter: 37, training_loss: 7.55695e-02\n",
            "epoch: 5794, iter: 37, training_loss: 6.69239e-02\n",
            "epoch: 5795, iter: 37, training_loss: 6.51711e-02\n",
            "epoch: 5796, iter: 37, training_loss: 6.72995e-02\n",
            "epoch: 5797, iter: 37, training_loss: 6.81347e-02\n",
            "epoch: 5798, iter: 37, training_loss: 6.53664e-02\n",
            "epoch: 5799, iter: 37, training_loss: 6.54095e-02\n",
            "epoch: 5800, iter: 37, training_loss: 6.64831e-02\n",
            "epoch: 5801, iter: 37, training_loss: 6.58707e-02\n",
            "epoch: 5802, iter: 37, training_loss: 6.63138e-02\n",
            "epoch: 5803, iter: 37, training_loss: 6.45237e-02\n",
            "epoch: 5804, iter: 37, training_loss: 6.69427e-02\n",
            "epoch: 5805, iter: 37, training_loss: 6.74357e-02\n",
            "epoch: 5806, iter: 37, training_loss: 6.59999e-02\n",
            "epoch: 5807, iter: 37, training_loss: 6.59159e-02\n",
            "epoch: 5808, iter: 37, training_loss: 6.69518e-02\n",
            "epoch: 5809, iter: 37, training_loss: 6.99708e-02\n",
            "epoch: 5810, iter: 37, training_loss: 6.75886e-02\n",
            "epoch: 5811, iter: 37, training_loss: 6.44559e-02\n",
            "epoch: 5812, iter: 37, training_loss: 6.64308e-02\n",
            "epoch: 5813, iter: 37, training_loss: 6.59903e-02\n",
            "epoch: 5814, iter: 37, training_loss: 6.78502e-02\n",
            "epoch: 5815, iter: 37, training_loss: 6.76154e-02\n",
            "epoch: 5816, iter: 37, training_loss: 6.86423e-02\n",
            "epoch: 5817, iter: 37, training_loss: 6.48624e-02\n",
            "epoch: 5818, iter: 37, training_loss: 6.43724e-02\n",
            "epoch: 5819, iter: 37, training_loss: 6.54567e-02\n",
            "epoch: 5820, iter: 37, training_loss: 6.70185e-02\n",
            "epoch: 5821, iter: 37, training_loss: 6.83578e-02\n",
            "epoch: 5822, iter: 37, training_loss: 6.75496e-02\n",
            "epoch: 5823, iter: 37, training_loss: 6.55272e-02\n",
            "epoch: 5824, iter: 37, training_loss: 6.69758e-02\n",
            "epoch: 5825, iter: 37, training_loss: 6.64585e-02\n",
            "epoch: 5826, iter: 37, training_loss: 6.70857e-02\n",
            "epoch: 5827, iter: 37, training_loss: 6.87479e-02\n",
            "epoch: 5828, iter: 37, training_loss: 6.42372e-02\n",
            "epoch: 5829, iter: 37, training_loss: 6.66545e-02\n",
            "epoch: 5830, iter: 37, training_loss: 6.37445e-02\n",
            "epoch: 5831, iter: 37, training_loss: 6.70364e-02\n",
            "epoch: 5832, iter: 37, training_loss: 7.00153e-02\n",
            "epoch: 5833, iter: 37, training_loss: 6.69350e-02\n",
            "epoch: 5834, iter: 37, training_loss: 6.50016e-02\n",
            "epoch: 5835, iter: 37, training_loss: 6.56668e-02\n",
            "epoch: 5836, iter: 37, training_loss: 6.64583e-02\n",
            "epoch: 5837, iter: 37, training_loss: 6.69928e-02\n",
            "epoch: 5838, iter: 37, training_loss: 6.58875e-02\n",
            "epoch: 5839, iter: 37, training_loss: 6.50053e-02\n",
            "epoch: 5840, iter: 37, training_loss: 6.67188e-02\n",
            "epoch: 5841, iter: 37, training_loss: 6.67892e-02\n",
            "epoch: 5842, iter: 37, training_loss: 6.68897e-02\n",
            "epoch: 5843, iter: 37, training_loss: 6.51101e-02\n",
            "epoch: 5844, iter: 37, training_loss: 6.66493e-02\n",
            "epoch: 5845, iter: 37, training_loss: 6.52777e-02\n",
            "epoch: 5846, iter: 37, training_loss: 6.51816e-02\n",
            "epoch: 5847, iter: 37, training_loss: 6.62874e-02\n",
            "epoch: 5848, iter: 37, training_loss: 6.54236e-02\n",
            "epoch: 5849, iter: 37, training_loss: 6.72694e-02\n",
            "epoch: 5850, iter: 37, training_loss: 6.60369e-02\n",
            "epoch: 5851, iter: 37, training_loss: 6.41761e-02\n",
            "epoch: 5852, iter: 37, training_loss: 6.42509e-02\n",
            "epoch: 5853, iter: 37, training_loss: 6.48406e-02\n",
            "epoch: 5854, iter: 37, training_loss: 6.60005e-02\n",
            "epoch: 5855, iter: 37, training_loss: 6.57551e-02\n",
            "epoch: 5856, iter: 37, training_loss: 6.63760e-02\n",
            "epoch: 5857, iter: 37, training_loss: 6.67175e-02\n",
            "epoch: 5858, iter: 37, training_loss: 6.51428e-02\n",
            "epoch: 5859, iter: 37, training_loss: 6.73945e-02\n",
            "epoch: 5860, iter: 37, training_loss: 6.45261e-02\n",
            "epoch: 5861, iter: 37, training_loss: 6.63750e-02\n",
            "epoch: 5862, iter: 37, training_loss: 6.35501e-02\n",
            "epoch: 5863, iter: 37, training_loss: 6.99972e-02\n",
            "epoch: 5864, iter: 37, training_loss: 6.42411e-02\n",
            "epoch: 5865, iter: 37, training_loss: 6.80021e-02\n",
            "epoch: 5866, iter: 37, training_loss: 6.71366e-02\n",
            "epoch: 5867, iter: 37, training_loss: 6.65996e-02\n",
            "epoch: 5868, iter: 37, training_loss: 6.55349e-02\n",
            "epoch: 5869, iter: 37, training_loss: 6.64809e-02\n",
            "epoch: 5870, iter: 37, training_loss: 6.81776e-02\n",
            "epoch: 5871, iter: 37, training_loss: 6.65858e-02\n",
            "epoch: 5872, iter: 37, training_loss: 6.49382e-02\n",
            "epoch: 5873, iter: 37, training_loss: 6.51394e-02\n",
            "epoch: 5874, iter: 37, training_loss: 6.51052e-02\n",
            "epoch: 5875, iter: 37, training_loss: 6.64534e-02\n",
            "epoch: 5876, iter: 37, training_loss: 6.68143e-02\n",
            "epoch: 5877, iter: 37, training_loss: 6.48458e-02\n",
            "epoch: 5878, iter: 37, training_loss: 6.75170e-02\n",
            "epoch: 5879, iter: 37, training_loss: 6.46478e-02\n",
            "epoch: 5880, iter: 37, training_loss: 6.54160e-02\n",
            "epoch: 5881, iter: 37, training_loss: 6.48244e-02\n",
            "epoch: 5882, iter: 37, training_loss: 6.72887e-02\n",
            "epoch: 5883, iter: 37, training_loss: 6.64631e-02\n",
            "epoch: 5884, iter: 37, training_loss: 6.72990e-02\n",
            "epoch: 5885, iter: 37, training_loss: 6.61171e-02\n",
            "epoch: 5886, iter: 37, training_loss: 6.82267e-02\n",
            "epoch: 5887, iter: 37, training_loss: 6.57323e-02\n",
            "epoch: 5888, iter: 37, training_loss: 6.52660e-02\n",
            "epoch: 5889, iter: 37, training_loss: 6.53016e-02\n",
            "epoch: 5890, iter: 37, training_loss: 6.49345e-02\n",
            "epoch: 5891, iter: 37, training_loss: 6.48265e-02\n",
            "epoch: 5892, iter: 37, training_loss: 6.54930e-02\n",
            "epoch: 5893, iter: 37, training_loss: 6.85178e-02\n",
            "epoch: 5894, iter: 37, training_loss: 6.81028e-02\n",
            "epoch: 5895, iter: 37, training_loss: 6.57525e-02\n",
            "epoch: 5896, iter: 37, training_loss: 6.63984e-02\n",
            "epoch: 5897, iter: 37, training_loss: 7.05888e-02\n",
            "epoch: 5898, iter: 37, training_loss: 6.73650e-02\n",
            "epoch: 5899, iter: 37, training_loss: 6.58245e-02\n",
            "epoch: 5900, iter: 37, training_loss: 6.51411e-02\n",
            "epoch: 5901, iter: 37, training_loss: 6.52730e-02\n",
            "epoch: 5902, iter: 37, training_loss: 6.39951e-02\n",
            "epoch: 5903, iter: 37, training_loss: 6.53581e-02\n",
            "epoch: 5904, iter: 37, training_loss: 6.67814e-02\n",
            "epoch: 5905, iter: 37, training_loss: 6.62894e-02\n",
            "epoch: 5906, iter: 37, training_loss: 6.61891e-02\n",
            "epoch: 5907, iter: 37, training_loss: 6.42803e-02\n",
            "epoch: 5908, iter: 37, training_loss: 6.46575e-02\n",
            "epoch: 5909, iter: 37, training_loss: 7.02114e-02\n",
            "epoch: 5910, iter: 37, training_loss: 6.44687e-02\n",
            "epoch: 5911, iter: 37, training_loss: 6.53223e-02\n",
            "epoch: 5912, iter: 37, training_loss: 6.51274e-02\n",
            "epoch: 5913, iter: 37, training_loss: 7.08405e-02\n",
            "epoch: 5914, iter: 37, training_loss: 6.76587e-02\n",
            "epoch: 5915, iter: 37, training_loss: 6.46717e-02\n",
            "epoch: 5916, iter: 37, training_loss: 6.49623e-02\n",
            "epoch: 5917, iter: 37, training_loss: 6.57525e-02\n",
            "epoch: 5918, iter: 37, training_loss: 6.88309e-02\n",
            "epoch: 5919, iter: 37, training_loss: 6.75702e-02\n",
            "epoch: 5920, iter: 37, training_loss: 6.81787e-02\n",
            "epoch: 5921, iter: 37, training_loss: 6.68959e-02\n",
            "epoch: 5922, iter: 37, training_loss: 6.59891e-02\n",
            "epoch: 5923, iter: 37, training_loss: 6.58788e-02\n",
            "epoch: 5924, iter: 37, training_loss: 6.62648e-02\n",
            "epoch: 5925, iter: 37, training_loss: 6.56130e-02\n",
            "epoch: 5926, iter: 37, training_loss: 6.44418e-02\n",
            "epoch: 5927, iter: 37, training_loss: 6.89820e-02\n",
            "epoch: 5928, iter: 37, training_loss: 6.57364e-02\n",
            "epoch: 5929, iter: 37, training_loss: 6.51004e-02\n",
            "epoch: 5930, iter: 37, training_loss: 6.55750e-02\n",
            "epoch: 5931, iter: 37, training_loss: 6.63260e-02\n",
            "epoch: 5932, iter: 37, training_loss: 6.53766e-02\n",
            "epoch: 5933, iter: 37, training_loss: 6.66758e-02\n",
            "epoch: 5934, iter: 37, training_loss: 6.53641e-02\n",
            "epoch: 5935, iter: 37, training_loss: 6.50201e-02\n",
            "epoch: 5936, iter: 37, training_loss: 6.60094e-02\n",
            "epoch: 5937, iter: 37, training_loss: 6.49955e-02\n",
            "epoch: 5938, iter: 37, training_loss: 6.32988e-02\n",
            "epoch: 5939, iter: 37, training_loss: 6.51485e-02\n",
            "epoch: 5940, iter: 37, training_loss: 6.56725e-02\n",
            "epoch: 5941, iter: 37, training_loss: 6.54214e-02\n",
            "epoch: 5942, iter: 37, training_loss: 6.52321e-02\n",
            "epoch: 5943, iter: 37, training_loss: 6.59918e-02\n",
            "epoch: 5944, iter: 37, training_loss: 6.72672e-02\n",
            "epoch: 5945, iter: 37, training_loss: 6.51267e-02\n",
            "epoch: 5946, iter: 37, training_loss: 6.53284e-02\n",
            "epoch: 5947, iter: 37, training_loss: 6.50231e-02\n",
            "epoch: 5948, iter: 37, training_loss: 6.89928e-02\n",
            "epoch: 5949, iter: 37, training_loss: 6.88641e-02\n",
            "epoch: 5950, iter: 37, training_loss: 6.79237e-02\n",
            "epoch: 5951, iter: 37, training_loss: 6.51053e-02\n",
            "epoch: 5952, iter: 37, training_loss: 6.50547e-02\n",
            "epoch: 5953, iter: 37, training_loss: 6.76716e-02\n",
            "epoch: 5954, iter: 37, training_loss: 6.44944e-02\n",
            "epoch: 5955, iter: 37, training_loss: 6.55885e-02\n",
            "epoch: 5956, iter: 37, training_loss: 6.69755e-02\n",
            "epoch: 5957, iter: 37, training_loss: 6.56982e-02\n",
            "epoch: 5958, iter: 37, training_loss: 6.68355e-02\n",
            "epoch: 5959, iter: 37, training_loss: 6.58081e-02\n",
            "epoch: 5960, iter: 37, training_loss: 6.49524e-02\n",
            "epoch: 5961, iter: 37, training_loss: 6.75270e-02\n",
            "epoch: 5962, iter: 37, training_loss: 6.41040e-02\n",
            "epoch: 5963, iter: 37, training_loss: 6.58722e-02\n",
            "epoch: 5964, iter: 37, training_loss: 6.57332e-02\n",
            "epoch: 5965, iter: 37, training_loss: 6.69034e-02\n",
            "epoch: 5966, iter: 37, training_loss: 6.55936e-02\n",
            "epoch: 5967, iter: 37, training_loss: 6.54713e-02\n",
            "epoch: 5968, iter: 37, training_loss: 6.92928e-02\n",
            "epoch: 5969, iter: 37, training_loss: 6.57245e-02\n",
            "epoch: 5970, iter: 37, training_loss: 6.42177e-02\n",
            "epoch: 5971, iter: 37, training_loss: 6.80826e-02\n",
            "epoch: 5972, iter: 37, training_loss: 6.67848e-02\n",
            "epoch: 5973, iter: 37, training_loss: 6.56284e-02\n",
            "epoch: 5974, iter: 37, training_loss: 6.40067e-02\n",
            "epoch: 5975, iter: 37, training_loss: 6.74106e-02\n",
            "epoch: 5976, iter: 37, training_loss: 6.86448e-02\n",
            "epoch: 5977, iter: 37, training_loss: 6.82304e-02\n",
            "epoch: 5978, iter: 37, training_loss: 6.50439e-02\n",
            "epoch: 5979, iter: 37, training_loss: 6.44286e-02\n",
            "epoch: 5980, iter: 37, training_loss: 6.47452e-02\n",
            "epoch: 5981, iter: 37, training_loss: 6.87725e-02\n",
            "epoch: 5982, iter: 37, training_loss: 6.32537e-02\n",
            "epoch: 5983, iter: 37, training_loss: 6.50394e-02\n",
            "epoch: 5984, iter: 37, training_loss: 6.55713e-02\n",
            "epoch: 5985, iter: 37, training_loss: 6.52448e-02\n",
            "epoch: 5986, iter: 37, training_loss: 6.97789e-02\n",
            "epoch: 5987, iter: 37, training_loss: 6.49884e-02\n",
            "epoch: 5988, iter: 37, training_loss: 6.82353e-02\n",
            "epoch: 5989, iter: 37, training_loss: 6.36802e-02\n",
            "epoch: 5990, iter: 37, training_loss: 6.56054e-02\n",
            "epoch: 5991, iter: 37, training_loss: 6.74938e-02\n",
            "epoch: 5992, iter: 37, training_loss: 6.44375e-02\n",
            "epoch: 5993, iter: 37, training_loss: 6.78842e-02\n",
            "epoch: 5994, iter: 37, training_loss: 6.61559e-02\n",
            "epoch: 5995, iter: 37, training_loss: 6.48574e-02\n",
            "epoch: 5996, iter: 37, training_loss: 6.58414e-02\n",
            "epoch: 5997, iter: 37, training_loss: 6.71559e-02\n",
            "epoch: 5998, iter: 37, training_loss: 6.59243e-02\n",
            "epoch: 5999, iter: 37, training_loss: 6.44899e-02\n",
            "epoch: 6000, iter: 37, training_loss: 6.74324e-02\n",
            "epoch: 6001, iter: 37, training_loss: 6.50733e-02\n",
            "epoch: 6002, iter: 37, training_loss: 6.55150e-02\n",
            "epoch: 6003, iter: 37, training_loss: 6.42955e-02\n",
            "epoch: 6004, iter: 37, training_loss: 6.56018e-02\n",
            "epoch: 6005, iter: 37, training_loss: 6.53624e-02\n",
            "epoch: 6006, iter: 37, training_loss: 6.61553e-02\n",
            "epoch: 6007, iter: 37, training_loss: 6.55856e-02\n",
            "epoch: 6008, iter: 37, training_loss: 6.43306e-02\n",
            "epoch: 6009, iter: 37, training_loss: 6.47834e-02\n",
            "epoch: 6010, iter: 37, training_loss: 6.49112e-02\n",
            "epoch: 6011, iter: 37, training_loss: 6.62534e-02\n",
            "epoch: 6012, iter: 37, training_loss: 6.57080e-02\n",
            "epoch: 6013, iter: 37, training_loss: 6.59133e-02\n",
            "epoch: 6014, iter: 37, training_loss: 6.64192e-02\n",
            "epoch: 6015, iter: 37, training_loss: 6.55139e-02\n",
            "epoch: 6016, iter: 37, training_loss: 6.43984e-02\n",
            "epoch: 6017, iter: 37, training_loss: 6.62136e-02\n",
            "epoch: 6018, iter: 37, training_loss: 6.56566e-02\n",
            "epoch: 6019, iter: 37, training_loss: 6.36549e-02\n",
            "epoch: 6020, iter: 37, training_loss: 6.45837e-02\n",
            "epoch: 6021, iter: 37, training_loss: 6.85442e-02\n",
            "epoch: 6022, iter: 37, training_loss: 6.46090e-02\n",
            "epoch: 6023, iter: 37, training_loss: 6.29639e-02\n",
            "epoch: 6024, iter: 37, training_loss: 6.36012e-02\n",
            "epoch: 6025, iter: 37, training_loss: 6.60651e-02\n",
            "epoch: 6026, iter: 37, training_loss: 6.68305e-02\n",
            "epoch: 6027, iter: 37, training_loss: 6.57076e-02\n",
            "epoch: 6028, iter: 37, training_loss: 6.36243e-02\n",
            "epoch: 6029, iter: 37, training_loss: 6.66146e-02\n",
            "epoch: 6030, iter: 37, training_loss: 6.51824e-02\n",
            "epoch: 6031, iter: 37, training_loss: 6.68613e-02\n",
            "epoch: 6032, iter: 37, training_loss: 6.72858e-02\n",
            "epoch: 6033, iter: 37, training_loss: 6.58430e-02\n",
            "epoch: 6034, iter: 37, training_loss: 6.49959e-02\n",
            "epoch: 6035, iter: 37, training_loss: 6.54813e-02\n",
            "epoch: 6036, iter: 37, training_loss: 6.66312e-02\n",
            "epoch: 6037, iter: 37, training_loss: 6.82451e-02\n",
            "epoch: 6038, iter: 37, training_loss: 7.07949e-02\n",
            "epoch: 6039, iter: 37, training_loss: 6.63699e-02\n",
            "epoch: 6040, iter: 37, training_loss: 6.48858e-02\n",
            "epoch: 6041, iter: 37, training_loss: 6.60662e-02\n",
            "epoch: 6042, iter: 37, training_loss: 6.44854e-02\n",
            "epoch: 6043, iter: 37, training_loss: 6.43825e-02\n",
            "epoch: 6044, iter: 37, training_loss: 6.66463e-02\n",
            "epoch: 6045, iter: 37, training_loss: 6.78100e-02\n",
            "epoch: 6046, iter: 37, training_loss: 6.61320e-02\n",
            "epoch: 6047, iter: 37, training_loss: 6.60658e-02\n",
            "epoch: 6048, iter: 37, training_loss: 6.50186e-02\n",
            "epoch: 6049, iter: 37, training_loss: 6.65199e-02\n",
            "epoch: 6050, iter: 37, training_loss: 6.44155e-02\n",
            "epoch: 6051, iter: 37, training_loss: 6.60181e-02\n",
            "epoch: 6052, iter: 37, training_loss: 6.47631e-02\n",
            "epoch: 6053, iter: 37, training_loss: 6.45423e-02\n",
            "epoch: 6054, iter: 37, training_loss: 6.42636e-02\n",
            "epoch: 6055, iter: 37, training_loss: 6.48295e-02\n",
            "epoch: 6056, iter: 37, training_loss: 6.52919e-02\n",
            "epoch: 6057, iter: 37, training_loss: 6.40512e-02\n",
            "epoch: 6058, iter: 37, training_loss: 6.73229e-02\n",
            "epoch: 6059, iter: 37, training_loss: 6.55725e-02\n",
            "epoch: 6060, iter: 37, training_loss: 6.58724e-02\n",
            "epoch: 6061, iter: 37, training_loss: 6.47981e-02\n",
            "epoch: 6062, iter: 37, training_loss: 6.49950e-02\n",
            "epoch: 6063, iter: 37, training_loss: 6.46866e-02\n",
            "epoch: 6064, iter: 37, training_loss: 6.51279e-02\n",
            "epoch: 6065, iter: 37, training_loss: 6.85475e-02\n",
            "epoch: 6066, iter: 37, training_loss: 6.42643e-02\n",
            "epoch: 6067, iter: 37, training_loss: 6.45945e-02\n",
            "epoch: 6068, iter: 37, training_loss: 6.52007e-02\n",
            "epoch: 6069, iter: 37, training_loss: 6.37451e-02\n",
            "epoch: 6070, iter: 37, training_loss: 6.51236e-02\n",
            "epoch: 6071, iter: 37, training_loss: 6.51073e-02\n",
            "epoch: 6072, iter: 37, training_loss: 6.71437e-02\n",
            "epoch: 6073, iter: 37, training_loss: 6.54579e-02\n",
            "epoch: 6074, iter: 37, training_loss: 6.50276e-02\n",
            "epoch: 6075, iter: 37, training_loss: 6.52296e-02\n",
            "epoch: 6076, iter: 37, training_loss: 6.87285e-02\n",
            "epoch: 6077, iter: 37, training_loss: 6.49988e-02\n",
            "epoch: 6078, iter: 37, training_loss: 6.50330e-02\n",
            "epoch: 6079, iter: 37, training_loss: 6.71780e-02\n",
            "epoch: 6080, iter: 37, training_loss: 6.44530e-02\n",
            "epoch: 6081, iter: 37, training_loss: 6.95123e-02\n",
            "epoch: 6082, iter: 37, training_loss: 6.51213e-02\n",
            "epoch: 6083, iter: 37, training_loss: 6.30378e-02\n",
            "epoch: 6084, iter: 37, training_loss: 6.76963e-02\n",
            "epoch: 6085, iter: 37, training_loss: 6.52157e-02\n",
            "epoch: 6086, iter: 37, training_loss: 6.56084e-02\n",
            "epoch: 6087, iter: 37, training_loss: 6.60970e-02\n",
            "epoch: 6088, iter: 37, training_loss: 6.55559e-02\n",
            "epoch: 6089, iter: 37, training_loss: 6.61705e-02\n",
            "epoch: 6090, iter: 37, training_loss: 6.73368e-02\n",
            "epoch: 6091, iter: 37, training_loss: 6.86088e-02\n",
            "epoch: 6092, iter: 37, training_loss: 6.46015e-02\n",
            "epoch: 6093, iter: 37, training_loss: 6.52189e-02\n",
            "epoch: 6094, iter: 37, training_loss: 6.72192e-02\n",
            "epoch: 6095, iter: 37, training_loss: 6.49646e-02\n",
            "epoch: 6096, iter: 37, training_loss: 6.23316e-02\n",
            "epoch: 6097, iter: 37, training_loss: 6.46552e-02\n",
            "epoch: 6098, iter: 37, training_loss: 6.52581e-02\n",
            "epoch: 6099, iter: 37, training_loss: 6.99651e-02\n",
            "epoch: 6100, iter: 37, training_loss: 6.72417e-02\n",
            "epoch: 6101, iter: 37, training_loss: 6.52677e-02\n",
            "epoch: 6102, iter: 37, training_loss: 6.41138e-02\n",
            "epoch: 6103, iter: 37, training_loss: 6.51916e-02\n",
            "epoch: 6104, iter: 37, training_loss: 6.88093e-02\n",
            "epoch: 6105, iter: 37, training_loss: 6.69065e-02\n",
            "epoch: 6106, iter: 37, training_loss: 6.67510e-02\n",
            "epoch: 6107, iter: 37, training_loss: 6.62844e-02\n",
            "epoch: 6108, iter: 37, training_loss: 6.67313e-02\n",
            "epoch: 6109, iter: 37, training_loss: 6.34402e-02\n",
            "epoch: 6110, iter: 37, training_loss: 6.70317e-02\n",
            "epoch: 6111, iter: 37, training_loss: 6.42550e-02\n",
            "epoch: 6112, iter: 37, training_loss: 6.52673e-02\n",
            "epoch: 6113, iter: 37, training_loss: 6.58431e-02\n",
            "epoch: 6114, iter: 37, training_loss: 6.48711e-02\n",
            "epoch: 6115, iter: 37, training_loss: 6.42813e-02\n",
            "epoch: 6116, iter: 37, training_loss: 6.30760e-02\n",
            "epoch: 6117, iter: 37, training_loss: 6.65729e-02\n",
            "epoch: 6118, iter: 37, training_loss: 6.60144e-02\n",
            "epoch: 6119, iter: 37, training_loss: 6.50306e-02\n",
            "epoch: 6120, iter: 37, training_loss: 6.46537e-02\n",
            "epoch: 6121, iter: 37, training_loss: 6.33607e-02\n",
            "epoch: 6122, iter: 37, training_loss: 6.63149e-02\n",
            "epoch: 6123, iter: 37, training_loss: 6.73547e-02\n",
            "epoch: 6124, iter: 37, training_loss: 6.36450e-02\n",
            "epoch: 6125, iter: 37, training_loss: 6.92478e-02\n",
            "epoch: 6126, iter: 37, training_loss: 6.55488e-02\n",
            "epoch: 6127, iter: 37, training_loss: 6.49371e-02\n",
            "epoch: 6128, iter: 37, training_loss: 6.66930e-02\n",
            "epoch: 6129, iter: 37, training_loss: 6.58038e-02\n",
            "epoch: 6130, iter: 37, training_loss: 6.39632e-02\n",
            "epoch: 6131, iter: 37, training_loss: 6.37442e-02\n",
            "epoch: 6132, iter: 37, training_loss: 6.46997e-02\n",
            "epoch: 6133, iter: 37, training_loss: 6.46485e-02\n",
            "epoch: 6134, iter: 37, training_loss: 6.60994e-02\n",
            "epoch: 6135, iter: 37, training_loss: 6.46078e-02\n",
            "epoch: 6136, iter: 37, training_loss: 6.65040e-02\n",
            "epoch: 6137, iter: 37, training_loss: 6.68937e-02\n",
            "epoch: 6138, iter: 37, training_loss: 6.58121e-02\n",
            "epoch: 6139, iter: 37, training_loss: 6.40698e-02\n",
            "epoch: 6140, iter: 37, training_loss: 6.71727e-02\n",
            "epoch: 6141, iter: 37, training_loss: 6.64284e-02\n",
            "epoch: 6142, iter: 37, training_loss: 6.57492e-02\n",
            "epoch: 6143, iter: 37, training_loss: 6.45995e-02\n",
            "epoch: 6144, iter: 37, training_loss: 6.58824e-02\n",
            "epoch: 6145, iter: 37, training_loss: 6.63829e-02\n",
            "epoch: 6146, iter: 37, training_loss: 6.70188e-02\n",
            "epoch: 6147, iter: 37, training_loss: 6.88770e-02\n",
            "epoch: 6148, iter: 37, training_loss: 6.44519e-02\n",
            "epoch: 6149, iter: 37, training_loss: 6.39976e-02\n",
            "epoch: 6150, iter: 37, training_loss: 6.61437e-02\n",
            "epoch: 6151, iter: 37, training_loss: 6.47286e-02\n",
            "epoch: 6152, iter: 37, training_loss: 6.52742e-02\n",
            "epoch: 6153, iter: 37, training_loss: 6.39953e-02\n",
            "epoch: 6154, iter: 37, training_loss: 6.49150e-02\n",
            "epoch: 6155, iter: 37, training_loss: 6.44524e-02\n",
            "epoch: 6156, iter: 37, training_loss: 6.94278e-02\n",
            "epoch: 6157, iter: 37, training_loss: 6.47458e-02\n",
            "epoch: 6158, iter: 37, training_loss: 6.67017e-02\n",
            "epoch: 6159, iter: 37, training_loss: 6.38483e-02\n",
            "epoch: 6160, iter: 37, training_loss: 6.41957e-02\n",
            "epoch: 6161, iter: 37, training_loss: 6.42365e-02\n",
            "epoch: 6162, iter: 37, training_loss: 6.66658e-02\n",
            "epoch: 6163, iter: 37, training_loss: 6.62232e-02\n",
            "epoch: 6164, iter: 37, training_loss: 6.70855e-02\n",
            "epoch: 6165, iter: 37, training_loss: 6.49251e-02\n",
            "epoch: 6166, iter: 37, training_loss: 6.68850e-02\n",
            "epoch: 6167, iter: 37, training_loss: 6.47239e-02\n",
            "epoch: 6168, iter: 37, training_loss: 6.60767e-02\n",
            "epoch: 6169, iter: 37, training_loss: 6.64973e-02\n",
            "epoch: 6170, iter: 37, training_loss: 6.63136e-02\n",
            "epoch: 6171, iter: 37, training_loss: 6.49212e-02\n",
            "epoch: 6172, iter: 37, training_loss: 6.36631e-02\n",
            "epoch: 6173, iter: 37, training_loss: 6.93047e-02\n",
            "epoch: 6174, iter: 37, training_loss: 6.37457e-02\n",
            "epoch: 6175, iter: 37, training_loss: 6.65071e-02\n",
            "epoch: 6176, iter: 37, training_loss: 6.69829e-02\n",
            "epoch: 6177, iter: 37, training_loss: 6.48807e-02\n",
            "epoch: 6178, iter: 37, training_loss: 6.40116e-02\n",
            "epoch: 6179, iter: 37, training_loss: 6.71506e-02\n",
            "epoch: 6180, iter: 37, training_loss: 6.52586e-02\n",
            "epoch: 6181, iter: 37, training_loss: 6.45060e-02\n",
            "epoch: 6182, iter: 37, training_loss: 6.86185e-02\n",
            "epoch: 6183, iter: 37, training_loss: 6.74238e-02\n",
            "epoch: 6184, iter: 37, training_loss: 6.33988e-02\n",
            "epoch: 6185, iter: 37, training_loss: 6.76108e-02\n",
            "epoch: 6186, iter: 37, training_loss: 6.57060e-02\n",
            "epoch: 6187, iter: 37, training_loss: 6.44289e-02\n",
            "epoch: 6188, iter: 37, training_loss: 6.50179e-02\n",
            "epoch: 6189, iter: 37, training_loss: 6.36186e-02\n",
            "epoch: 6190, iter: 37, training_loss: 6.79241e-02\n",
            "epoch: 6191, iter: 37, training_loss: 6.26610e-02\n",
            "epoch: 6192, iter: 37, training_loss: 6.88058e-02\n",
            "epoch: 6193, iter: 37, training_loss: 6.26356e-02\n",
            "epoch: 6194, iter: 37, training_loss: 6.29102e-02\n",
            "epoch: 6195, iter: 37, training_loss: 6.67504e-02\n",
            "epoch: 6196, iter: 37, training_loss: 6.47160e-02\n",
            "epoch: 6197, iter: 37, training_loss: 6.47079e-02\n",
            "epoch: 6198, iter: 37, training_loss: 6.86008e-02\n",
            "epoch: 6199, iter: 37, training_loss: 6.35231e-02\n",
            "epoch: 6200, iter: 37, training_loss: 6.45081e-02\n",
            "epoch: 6201, iter: 37, training_loss: 6.50009e-02\n",
            "epoch: 6202, iter: 37, training_loss: 6.61286e-02\n",
            "epoch: 6203, iter: 37, training_loss: 6.48931e-02\n",
            "epoch: 6204, iter: 37, training_loss: 6.66983e-02\n",
            "epoch: 6205, iter: 37, training_loss: 6.63117e-02\n",
            "epoch: 6206, iter: 37, training_loss: 6.39913e-02\n",
            "epoch: 6207, iter: 37, training_loss: 6.81778e-02\n",
            "epoch: 6208, iter: 37, training_loss: 6.55179e-02\n",
            "epoch: 6209, iter: 37, training_loss: 6.57401e-02\n",
            "epoch: 6210, iter: 37, training_loss: 6.51766e-02\n",
            "epoch: 6211, iter: 37, training_loss: 6.57708e-02\n",
            "epoch: 6212, iter: 37, training_loss: 6.47459e-02\n",
            "epoch: 6213, iter: 37, training_loss: 6.60315e-02\n",
            "epoch: 6214, iter: 37, training_loss: 6.69654e-02\n",
            "epoch: 6215, iter: 37, training_loss: 6.41037e-02\n",
            "epoch: 6216, iter: 37, training_loss: 6.44394e-02\n",
            "epoch: 6217, iter: 37, training_loss: 6.48275e-02\n",
            "epoch: 6218, iter: 37, training_loss: 6.33984e-02\n",
            "epoch: 6219, iter: 37, training_loss: 6.34107e-02\n",
            "epoch: 6220, iter: 37, training_loss: 6.51941e-02\n",
            "epoch: 6221, iter: 37, training_loss: 6.52483e-02\n",
            "epoch: 6222, iter: 37, training_loss: 6.42116e-02\n",
            "epoch: 6223, iter: 37, training_loss: 6.40403e-02\n",
            "epoch: 6224, iter: 37, training_loss: 6.77748e-02\n",
            "epoch: 6225, iter: 37, training_loss: 6.39402e-02\n",
            "epoch: 6226, iter: 37, training_loss: 6.41863e-02\n",
            "epoch: 6227, iter: 37, training_loss: 6.43396e-02\n",
            "epoch: 6228, iter: 37, training_loss: 6.54798e-02\n",
            "epoch: 6229, iter: 37, training_loss: 6.40996e-02\n",
            "epoch: 6230, iter: 37, training_loss: 6.72759e-02\n",
            "epoch: 6231, iter: 37, training_loss: 6.79684e-02\n",
            "epoch: 6232, iter: 37, training_loss: 6.37709e-02\n",
            "epoch: 6233, iter: 37, training_loss: 6.52677e-02\n",
            "epoch: 6234, iter: 37, training_loss: 6.44167e-02\n",
            "epoch: 6235, iter: 37, training_loss: 6.32850e-02\n",
            "epoch: 6236, iter: 37, training_loss: 6.42007e-02\n",
            "epoch: 6237, iter: 37, training_loss: 6.55547e-02\n",
            "epoch: 6238, iter: 37, training_loss: 6.54034e-02\n",
            "epoch: 6239, iter: 37, training_loss: 6.51545e-02\n",
            "epoch: 6240, iter: 37, training_loss: 6.52094e-02\n",
            "epoch: 6241, iter: 37, training_loss: 6.48387e-02\n",
            "epoch: 6242, iter: 37, training_loss: 6.49621e-02\n",
            "epoch: 6243, iter: 37, training_loss: 6.59624e-02\n",
            "epoch: 6244, iter: 37, training_loss: 6.39125e-02\n",
            "epoch: 6245, iter: 37, training_loss: 6.24164e-02\n",
            "epoch: 6246, iter: 37, training_loss: 6.56943e-02\n",
            "epoch: 6247, iter: 37, training_loss: 6.29759e-02\n",
            "epoch: 6248, iter: 37, training_loss: 6.31792e-02\n",
            "epoch: 6249, iter: 37, training_loss: 6.54404e-02\n",
            "epoch: 6250, iter: 37, training_loss: 6.53234e-02\n",
            "epoch: 6251, iter: 37, training_loss: 6.39116e-02\n",
            "epoch: 6252, iter: 37, training_loss: 6.50398e-02\n",
            "epoch: 6253, iter: 37, training_loss: 6.59667e-02\n",
            "epoch: 6254, iter: 37, training_loss: 6.66261e-02\n",
            "epoch: 6255, iter: 37, training_loss: 6.61091e-02\n",
            "epoch: 6256, iter: 37, training_loss: 6.55764e-02\n",
            "epoch: 6257, iter: 37, training_loss: 6.47498e-02\n",
            "epoch: 6258, iter: 37, training_loss: 6.44551e-02\n",
            "epoch: 6259, iter: 37, training_loss: 6.71777e-02\n",
            "epoch: 6260, iter: 37, training_loss: 6.50269e-02\n",
            "epoch: 6261, iter: 37, training_loss: 6.45802e-02\n",
            "epoch: 6262, iter: 37, training_loss: 6.50257e-02\n",
            "epoch: 6263, iter: 37, training_loss: 6.45788e-02\n",
            "epoch: 6264, iter: 37, training_loss: 6.73280e-02\n",
            "epoch: 6265, iter: 37, training_loss: 6.58733e-02\n",
            "epoch: 6266, iter: 37, training_loss: 6.70728e-02\n",
            "epoch: 6267, iter: 37, training_loss: 6.30843e-02\n",
            "epoch: 6268, iter: 37, training_loss: 6.55216e-02\n",
            "epoch: 6269, iter: 37, training_loss: 6.69725e-02\n",
            "epoch: 6270, iter: 37, training_loss: 6.55726e-02\n",
            "epoch: 6271, iter: 37, training_loss: 6.48401e-02\n",
            "epoch: 6272, iter: 37, training_loss: 6.38486e-02\n",
            "epoch: 6273, iter: 37, training_loss: 6.53619e-02\n",
            "epoch: 6274, iter: 37, training_loss: 6.44990e-02\n",
            "epoch: 6275, iter: 37, training_loss: 6.46569e-02\n",
            "epoch: 6276, iter: 37, training_loss: 6.40356e-02\n",
            "epoch: 6277, iter: 37, training_loss: 6.43524e-02\n",
            "epoch: 6278, iter: 37, training_loss: 6.42410e-02\n",
            "epoch: 6279, iter: 37, training_loss: 6.86371e-02\n",
            "epoch: 6280, iter: 37, training_loss: 6.54381e-02\n",
            "epoch: 6281, iter: 37, training_loss: 6.59043e-02\n",
            "epoch: 6282, iter: 37, training_loss: 6.83573e-02\n",
            "epoch: 6283, iter: 37, training_loss: 6.49577e-02\n",
            "epoch: 6284, iter: 37, training_loss: 6.88750e-02\n",
            "epoch: 6285, iter: 37, training_loss: 6.55792e-02\n",
            "epoch: 6286, iter: 37, training_loss: 6.50062e-02\n",
            "epoch: 6287, iter: 37, training_loss: 6.63116e-02\n",
            "epoch: 6288, iter: 37, training_loss: 6.53452e-02\n",
            "epoch: 6289, iter: 37, training_loss: 6.56549e-02\n",
            "epoch: 6290, iter: 37, training_loss: 6.61656e-02\n",
            "epoch: 6291, iter: 37, training_loss: 6.39868e-02\n",
            "epoch: 6292, iter: 37, training_loss: 6.45928e-02\n",
            "epoch: 6293, iter: 37, training_loss: 6.59216e-02\n",
            "epoch: 6294, iter: 37, training_loss: 6.53783e-02\n",
            "epoch: 6295, iter: 37, training_loss: 6.56916e-02\n",
            "epoch: 6296, iter: 37, training_loss: 6.59174e-02\n",
            "epoch: 6297, iter: 37, training_loss: 6.38246e-02\n",
            "epoch: 6298, iter: 37, training_loss: 6.30702e-02\n",
            "epoch: 6299, iter: 37, training_loss: 6.99043e-02\n",
            "epoch: 6300, iter: 37, training_loss: 6.36303e-02\n",
            "epoch: 6301, iter: 37, training_loss: 6.34666e-02\n",
            "epoch: 6302, iter: 37, training_loss: 6.46272e-02\n",
            "epoch: 6303, iter: 37, training_loss: 6.27665e-02\n",
            "epoch: 6304, iter: 37, training_loss: 6.60659e-02\n",
            "epoch: 6305, iter: 37, training_loss: 6.52899e-02\n",
            "epoch: 6306, iter: 37, training_loss: 6.44919e-02\n",
            "epoch: 6307, iter: 37, training_loss: 6.56976e-02\n",
            "epoch: 6308, iter: 37, training_loss: 6.52817e-02\n",
            "epoch: 6309, iter: 37, training_loss: 6.44639e-02\n",
            "epoch: 6310, iter: 37, training_loss: 6.32309e-02\n",
            "epoch: 6311, iter: 37, training_loss: 6.65382e-02\n",
            "epoch: 6312, iter: 37, training_loss: 6.38779e-02\n",
            "epoch: 6313, iter: 37, training_loss: 6.48216e-02\n",
            "epoch: 6314, iter: 37, training_loss: 6.80160e-02\n",
            "epoch: 6315, iter: 37, training_loss: 6.32899e-02\n",
            "epoch: 6316, iter: 37, training_loss: 6.52673e-02\n",
            "epoch: 6317, iter: 37, training_loss: 6.62972e-02\n",
            "epoch: 6318, iter: 37, training_loss: 6.39935e-02\n",
            "epoch: 6319, iter: 37, training_loss: 6.70787e-02\n",
            "epoch: 6320, iter: 37, training_loss: 6.64143e-02\n",
            "epoch: 6321, iter: 37, training_loss: 6.40913e-02\n",
            "epoch: 6322, iter: 37, training_loss: 6.68545e-02\n",
            "epoch: 6323, iter: 37, training_loss: 6.34468e-02\n",
            "epoch: 6324, iter: 37, training_loss: 6.62205e-02\n",
            "epoch: 6325, iter: 37, training_loss: 6.56669e-02\n",
            "epoch: 6326, iter: 37, training_loss: 6.71982e-02\n",
            "epoch: 6327, iter: 37, training_loss: 6.34337e-02\n",
            "epoch: 6328, iter: 37, training_loss: 6.77581e-02\n",
            "epoch: 6329, iter: 37, training_loss: 6.47740e-02\n",
            "epoch: 6330, iter: 37, training_loss: 6.54899e-02\n",
            "epoch: 6331, iter: 37, training_loss: 6.51706e-02\n",
            "epoch: 6332, iter: 37, training_loss: 6.41760e-02\n",
            "epoch: 6333, iter: 37, training_loss: 6.50919e-02\n",
            "epoch: 6334, iter: 37, training_loss: 6.43692e-02\n",
            "epoch: 6335, iter: 37, training_loss: 6.32885e-02\n",
            "epoch: 6336, iter: 37, training_loss: 7.17223e-02\n",
            "epoch: 6337, iter: 37, training_loss: 6.44278e-02\n",
            "epoch: 6338, iter: 37, training_loss: 6.60968e-02\n",
            "epoch: 6339, iter: 37, training_loss: 6.61134e-02\n",
            "epoch: 6340, iter: 37, training_loss: 6.70878e-02\n",
            "epoch: 6341, iter: 37, training_loss: 6.70684e-02\n",
            "epoch: 6342, iter: 37, training_loss: 6.59050e-02\n",
            "epoch: 6343, iter: 37, training_loss: 6.19664e-02\n",
            "epoch: 6344, iter: 37, training_loss: 6.48179e-02\n",
            "epoch: 6345, iter: 37, training_loss: 6.53713e-02\n",
            "epoch: 6346, iter: 37, training_loss: 6.52773e-02\n",
            "epoch: 6347, iter: 37, training_loss: 6.43355e-02\n",
            "epoch: 6348, iter: 37, training_loss: 6.41380e-02\n",
            "epoch: 6349, iter: 37, training_loss: 6.37771e-02\n",
            "epoch: 6350, iter: 37, training_loss: 6.41772e-02\n",
            "epoch: 6351, iter: 37, training_loss: 6.57891e-02\n",
            "epoch: 6352, iter: 37, training_loss: 6.58451e-02\n",
            "epoch: 6353, iter: 37, training_loss: 6.67864e-02\n",
            "epoch: 6354, iter: 37, training_loss: 6.53226e-02\n",
            "epoch: 6355, iter: 37, training_loss: 6.74600e-02\n",
            "epoch: 6356, iter: 37, training_loss: 6.78485e-02\n",
            "epoch: 6357, iter: 37, training_loss: 6.77316e-02\n",
            "epoch: 6358, iter: 37, training_loss: 6.49672e-02\n",
            "epoch: 6359, iter: 37, training_loss: 6.59127e-02\n",
            "epoch: 6360, iter: 37, training_loss: 6.44587e-02\n",
            "epoch: 6361, iter: 37, training_loss: 6.54651e-02\n",
            "epoch: 6362, iter: 37, training_loss: 6.42982e-02\n",
            "epoch: 6363, iter: 37, training_loss: 6.45639e-02\n",
            "epoch: 6364, iter: 37, training_loss: 6.58147e-02\n",
            "epoch: 6365, iter: 37, training_loss: 6.56505e-02\n",
            "epoch: 6366, iter: 37, training_loss: 6.48344e-02\n",
            "epoch: 6367, iter: 37, training_loss: 6.48235e-02\n",
            "epoch: 6368, iter: 37, training_loss: 6.62432e-02\n",
            "epoch: 6369, iter: 37, training_loss: 6.55773e-02\n",
            "epoch: 6370, iter: 37, training_loss: 6.47451e-02\n",
            "epoch: 6371, iter: 37, training_loss: 6.27305e-02\n",
            "epoch: 6372, iter: 37, training_loss: 6.38197e-02\n",
            "epoch: 6373, iter: 37, training_loss: 6.69441e-02\n",
            "epoch: 6374, iter: 37, training_loss: 6.67726e-02\n",
            "epoch: 6375, iter: 37, training_loss: 6.35016e-02\n",
            "epoch: 6376, iter: 37, training_loss: 6.47589e-02\n",
            "epoch: 6377, iter: 37, training_loss: 6.36462e-02\n",
            "epoch: 6378, iter: 37, training_loss: 6.50679e-02\n",
            "epoch: 6379, iter: 37, training_loss: 6.48400e-02\n",
            "epoch: 6380, iter: 37, training_loss: 6.33365e-02\n",
            "epoch: 6381, iter: 37, training_loss: 6.59700e-02\n",
            "epoch: 6382, iter: 37, training_loss: 6.34495e-02\n",
            "epoch: 6383, iter: 37, training_loss: 6.55162e-02\n",
            "epoch: 6384, iter: 37, training_loss: 6.37178e-02\n",
            "epoch: 6385, iter: 37, training_loss: 6.50530e-02\n",
            "epoch: 6386, iter: 37, training_loss: 6.63440e-02\n",
            "epoch: 6387, iter: 37, training_loss: 6.56706e-02\n",
            "epoch: 6388, iter: 37, training_loss: 6.44860e-02\n",
            "epoch: 6389, iter: 37, training_loss: 6.44742e-02\n",
            "epoch: 6390, iter: 37, training_loss: 6.66887e-02\n",
            "epoch: 6391, iter: 37, training_loss: 6.40340e-02\n",
            "epoch: 6392, iter: 37, training_loss: 6.56914e-02\n",
            "epoch: 6393, iter: 37, training_loss: 6.32427e-02\n",
            "epoch: 6394, iter: 37, training_loss: 6.29655e-02\n",
            "epoch: 6395, iter: 37, training_loss: 6.34074e-02\n",
            "epoch: 6396, iter: 37, training_loss: 6.40937e-02\n",
            "epoch: 6397, iter: 37, training_loss: 6.20127e-02\n",
            "epoch: 6398, iter: 37, training_loss: 6.47043e-02\n",
            "epoch: 6399, iter: 37, training_loss: 6.80755e-02\n",
            "epoch: 6400, iter: 37, training_loss: 6.47479e-02\n",
            "epoch: 6401, iter: 37, training_loss: 6.48343e-02\n",
            "epoch: 6402, iter: 37, training_loss: 6.36848e-02\n",
            "epoch: 6403, iter: 37, training_loss: 6.60969e-02\n",
            "epoch: 6404, iter: 37, training_loss: 6.66191e-02\n",
            "epoch: 6405, iter: 37, training_loss: 6.27259e-02\n",
            "epoch: 6406, iter: 37, training_loss: 6.48420e-02\n",
            "epoch: 6407, iter: 37, training_loss: 6.37402e-02\n",
            "epoch: 6408, iter: 37, training_loss: 6.37854e-02\n",
            "epoch: 6409, iter: 37, training_loss: 6.37849e-02\n",
            "epoch: 6410, iter: 37, training_loss: 6.47792e-02\n",
            "epoch: 6411, iter: 37, training_loss: 6.47850e-02\n",
            "epoch: 6412, iter: 37, training_loss: 6.62835e-02\n",
            "epoch: 6413, iter: 37, training_loss: 6.42723e-02\n",
            "epoch: 6414, iter: 37, training_loss: 6.44773e-02\n",
            "epoch: 6415, iter: 37, training_loss: 6.86279e-02\n",
            "epoch: 6416, iter: 37, training_loss: 6.47579e-02\n",
            "epoch: 6417, iter: 37, training_loss: 6.33199e-02\n",
            "epoch: 6418, iter: 37, training_loss: 6.42844e-02\n",
            "epoch: 6419, iter: 37, training_loss: 6.52591e-02\n",
            "epoch: 6420, iter: 37, training_loss: 6.40199e-02\n",
            "epoch: 6421, iter: 37, training_loss: 6.43815e-02\n",
            "epoch: 6422, iter: 37, training_loss: 6.33376e-02\n",
            "epoch: 6423, iter: 37, training_loss: 6.26524e-02\n",
            "epoch: 6424, iter: 37, training_loss: 6.31927e-02\n",
            "epoch: 6425, iter: 37, training_loss: 6.45976e-02\n",
            "epoch: 6426, iter: 37, training_loss: 6.96108e-02\n",
            "epoch: 6427, iter: 37, training_loss: 6.32400e-02\n",
            "epoch: 6428, iter: 37, training_loss: 6.40495e-02\n",
            "epoch: 6429, iter: 37, training_loss: 6.62902e-02\n",
            "epoch: 6430, iter: 37, training_loss: 6.41460e-02\n",
            "epoch: 6431, iter: 37, training_loss: 6.46241e-02\n",
            "epoch: 6432, iter: 37, training_loss: 6.50230e-02\n",
            "epoch: 6433, iter: 37, training_loss: 6.46755e-02\n",
            "epoch: 6434, iter: 37, training_loss: 6.52535e-02\n",
            "epoch: 6435, iter: 37, training_loss: 6.37788e-02\n",
            "epoch: 6436, iter: 37, training_loss: 6.93229e-02\n",
            "epoch: 6437, iter: 37, training_loss: 6.35783e-02\n",
            "epoch: 6438, iter: 37, training_loss: 6.41872e-02\n",
            "epoch: 6439, iter: 37, training_loss: 6.33376e-02\n",
            "epoch: 6440, iter: 37, training_loss: 6.56775e-02\n",
            "epoch: 6441, iter: 37, training_loss: 6.42438e-02\n",
            "epoch: 6442, iter: 37, training_loss: 6.42390e-02\n",
            "epoch: 6443, iter: 37, training_loss: 6.31959e-02\n",
            "epoch: 6444, iter: 37, training_loss: 6.51301e-02\n",
            "epoch: 6445, iter: 37, training_loss: 6.44027e-02\n",
            "epoch: 6446, iter: 37, training_loss: 6.52836e-02\n",
            "epoch: 6447, iter: 37, training_loss: 6.46452e-02\n",
            "epoch: 6448, iter: 37, training_loss: 6.49263e-02\n",
            "epoch: 6449, iter: 37, training_loss: 6.38226e-02\n",
            "epoch: 6450, iter: 37, training_loss: 6.34577e-02\n",
            "epoch: 6451, iter: 37, training_loss: 6.44453e-02\n",
            "epoch: 6452, iter: 37, training_loss: 6.31929e-02\n",
            "epoch: 6453, iter: 37, training_loss: 6.46096e-02\n",
            "epoch: 6454, iter: 37, training_loss: 6.50297e-02\n",
            "epoch: 6455, iter: 37, training_loss: 6.57441e-02\n",
            "epoch: 6456, iter: 37, training_loss: 6.71525e-02\n",
            "epoch: 6457, iter: 37, training_loss: 6.42045e-02\n",
            "epoch: 6458, iter: 37, training_loss: 6.17480e-02\n",
            "epoch: 6459, iter: 37, training_loss: 6.33788e-02\n",
            "epoch: 6460, iter: 37, training_loss: 6.40227e-02\n",
            "epoch: 6461, iter: 37, training_loss: 6.41261e-02\n",
            "epoch: 6462, iter: 37, training_loss: 6.24450e-02\n",
            "epoch: 6463, iter: 37, training_loss: 6.80472e-02\n",
            "epoch: 6464, iter: 37, training_loss: 6.46952e-02\n",
            "epoch: 6465, iter: 37, training_loss: 6.39824e-02\n",
            "epoch: 6466, iter: 37, training_loss: 6.31252e-02\n",
            "epoch: 6467, iter: 37, training_loss: 6.40665e-02\n",
            "epoch: 6468, iter: 37, training_loss: 6.45059e-02\n",
            "epoch: 6469, iter: 37, training_loss: 6.26889e-02\n",
            "epoch: 6470, iter: 37, training_loss: 7.03460e-02\n",
            "epoch: 6471, iter: 37, training_loss: 6.47834e-02\n",
            "epoch: 6472, iter: 37, training_loss: 6.41426e-02\n",
            "epoch: 6473, iter: 37, training_loss: 6.43299e-02\n",
            "epoch: 6474, iter: 37, training_loss: 7.07020e-02\n",
            "epoch: 6475, iter: 37, training_loss: 6.64166e-02\n",
            "epoch: 6476, iter: 37, training_loss: 6.32445e-02\n",
            "epoch: 6477, iter: 37, training_loss: 6.48287e-02\n",
            "epoch: 6478, iter: 37, training_loss: 6.28537e-02\n",
            "epoch: 6479, iter: 37, training_loss: 6.42058e-02\n",
            "epoch: 6480, iter: 37, training_loss: 6.56336e-02\n",
            "epoch: 6481, iter: 37, training_loss: 6.39675e-02\n",
            "epoch: 6482, iter: 37, training_loss: 6.32596e-02\n",
            "epoch: 6483, iter: 37, training_loss: 6.47560e-02\n",
            "epoch: 6484, iter: 37, training_loss: 6.26762e-02\n",
            "epoch: 6485, iter: 37, training_loss: 6.31874e-02\n",
            "epoch: 6486, iter: 37, training_loss: 6.58038e-02\n",
            "epoch: 6487, iter: 37, training_loss: 6.36908e-02\n",
            "epoch: 6488, iter: 37, training_loss: 6.56624e-02\n",
            "epoch: 6489, iter: 37, training_loss: 6.51964e-02\n",
            "epoch: 6490, iter: 37, training_loss: 6.84702e-02\n",
            "epoch: 6491, iter: 37, training_loss: 6.50751e-02\n",
            "epoch: 6492, iter: 37, training_loss: 6.58232e-02\n",
            "epoch: 6493, iter: 37, training_loss: 6.44339e-02\n",
            "epoch: 6494, iter: 37, training_loss: 6.51637e-02\n",
            "epoch: 6495, iter: 37, training_loss: 6.39892e-02\n",
            "epoch: 6496, iter: 37, training_loss: 6.57245e-02\n",
            "epoch: 6497, iter: 37, training_loss: 6.38720e-02\n",
            "epoch: 6498, iter: 37, training_loss: 6.37362e-02\n",
            "epoch: 6499, iter: 37, training_loss: 6.55175e-02\n",
            "epoch: 6500, iter: 37, training_loss: 6.51413e-02\n",
            "epoch: 6501, iter: 37, training_loss: 6.36137e-02\n",
            "epoch: 6502, iter: 37, training_loss: 6.45530e-02\n",
            "epoch: 6503, iter: 37, training_loss: 6.47007e-02\n",
            "epoch: 6504, iter: 37, training_loss: 6.35779e-02\n",
            "epoch: 6505, iter: 37, training_loss: 6.48494e-02\n",
            "epoch: 6506, iter: 37, training_loss: 6.55742e-02\n",
            "epoch: 6507, iter: 37, training_loss: 6.42858e-02\n",
            "epoch: 6508, iter: 37, training_loss: 6.31175e-02\n",
            "epoch: 6509, iter: 37, training_loss: 6.54249e-02\n",
            "epoch: 6510, iter: 37, training_loss: 6.45744e-02\n",
            "epoch: 6511, iter: 37, training_loss: 6.67851e-02\n",
            "epoch: 6512, iter: 37, training_loss: 6.56465e-02\n",
            "epoch: 6513, iter: 37, training_loss: 6.42993e-02\n",
            "epoch: 6514, iter: 37, training_loss: 6.49640e-02\n",
            "epoch: 6515, iter: 37, training_loss: 6.50596e-02\n",
            "epoch: 6516, iter: 37, training_loss: 6.46512e-02\n",
            "epoch: 6517, iter: 37, training_loss: 6.57827e-02\n",
            "epoch: 6518, iter: 37, training_loss: 6.43643e-02\n",
            "epoch: 6519, iter: 37, training_loss: 6.29013e-02\n",
            "epoch: 6520, iter: 37, training_loss: 6.42757e-02\n",
            "epoch: 6521, iter: 37, training_loss: 6.61172e-02\n",
            "epoch: 6522, iter: 37, training_loss: 6.34528e-02\n",
            "epoch: 6523, iter: 37, training_loss: 6.38040e-02\n",
            "epoch: 6524, iter: 37, training_loss: 6.42626e-02\n",
            "epoch: 6525, iter: 37, training_loss: 6.26579e-02\n",
            "epoch: 6526, iter: 37, training_loss: 6.69726e-02\n",
            "epoch: 6527, iter: 37, training_loss: 6.33619e-02\n",
            "epoch: 6528, iter: 37, training_loss: 6.39903e-02\n",
            "epoch: 6529, iter: 37, training_loss: 6.33462e-02\n",
            "epoch: 6530, iter: 37, training_loss: 6.71405e-02\n",
            "epoch: 6531, iter: 37, training_loss: 6.35301e-02\n",
            "epoch: 6532, iter: 37, training_loss: 6.28899e-02\n",
            "epoch: 6533, iter: 37, training_loss: 6.33132e-02\n",
            "epoch: 6534, iter: 37, training_loss: 6.49647e-02\n",
            "epoch: 6535, iter: 37, training_loss: 6.41184e-02\n",
            "epoch: 6536, iter: 37, training_loss: 6.49806e-02\n",
            "epoch: 6537, iter: 37, training_loss: 6.46846e-02\n",
            "epoch: 6538, iter: 37, training_loss: 6.56716e-02\n",
            "epoch: 6539, iter: 37, training_loss: 6.51292e-02\n",
            "epoch: 6540, iter: 37, training_loss: 6.48136e-02\n",
            "epoch: 6541, iter: 37, training_loss: 6.49173e-02\n",
            "epoch: 6542, iter: 37, training_loss: 6.55594e-02\n",
            "epoch: 6543, iter: 37, training_loss: 6.46510e-02\n",
            "epoch: 6544, iter: 37, training_loss: 6.56455e-02\n",
            "epoch: 6545, iter: 37, training_loss: 6.27726e-02\n",
            "epoch: 6546, iter: 37, training_loss: 6.42607e-02\n",
            "epoch: 6547, iter: 37, training_loss: 6.34581e-02\n",
            "epoch: 6548, iter: 37, training_loss: 6.67373e-02\n",
            "epoch: 6549, iter: 37, training_loss: 6.64610e-02\n",
            "epoch: 6550, iter: 37, training_loss: 6.58977e-02\n",
            "epoch: 6551, iter: 37, training_loss: 6.73590e-02\n",
            "epoch: 6552, iter: 37, training_loss: 6.35872e-02\n",
            "epoch: 6553, iter: 37, training_loss: 6.28948e-02\n",
            "epoch: 6554, iter: 37, training_loss: 6.48363e-02\n",
            "epoch: 6555, iter: 37, training_loss: 6.36466e-02\n",
            "epoch: 6556, iter: 37, training_loss: 6.56362e-02\n",
            "epoch: 6557, iter: 37, training_loss: 6.44974e-02\n",
            "epoch: 6558, iter: 37, training_loss: 6.51677e-02\n",
            "epoch: 6559, iter: 37, training_loss: 6.44578e-02\n",
            "epoch: 6560, iter: 37, training_loss: 6.42743e-02\n",
            "epoch: 6561, iter: 37, training_loss: 6.64662e-02\n",
            "epoch: 6562, iter: 37, training_loss: 6.54620e-02\n",
            "epoch: 6563, iter: 37, training_loss: 6.47188e-02\n",
            "epoch: 6564, iter: 37, training_loss: 6.44262e-02\n",
            "epoch: 6565, iter: 37, training_loss: 6.62396e-02\n",
            "epoch: 6566, iter: 37, training_loss: 6.48628e-02\n",
            "epoch: 6567, iter: 37, training_loss: 6.33287e-02\n",
            "epoch: 6568, iter: 37, training_loss: 6.33059e-02\n",
            "epoch: 6569, iter: 37, training_loss: 6.47595e-02\n",
            "epoch: 6570, iter: 37, training_loss: 6.53217e-02\n",
            "epoch: 6571, iter: 37, training_loss: 6.56982e-02\n",
            "epoch: 6572, iter: 37, training_loss: 6.60582e-02\n",
            "epoch: 6573, iter: 37, training_loss: 6.50186e-02\n",
            "epoch: 6574, iter: 37, training_loss: 6.29619e-02\n",
            "epoch: 6575, iter: 37, training_loss: 6.47203e-02\n",
            "epoch: 6576, iter: 37, training_loss: 6.53845e-02\n",
            "epoch: 6577, iter: 37, training_loss: 6.34998e-02\n",
            "epoch: 6578, iter: 37, training_loss: 6.56833e-02\n",
            "epoch: 6579, iter: 37, training_loss: 6.59054e-02\n",
            "epoch: 6580, iter: 37, training_loss: 6.58531e-02\n",
            "epoch: 6581, iter: 37, training_loss: 6.46057e-02\n",
            "epoch: 6582, iter: 37, training_loss: 6.40388e-02\n",
            "epoch: 6583, iter: 37, training_loss: 6.34454e-02\n",
            "epoch: 6584, iter: 37, training_loss: 6.29718e-02\n",
            "epoch: 6585, iter: 37, training_loss: 6.25509e-02\n",
            "epoch: 6586, iter: 37, training_loss: 6.65247e-02\n",
            "epoch: 6587, iter: 37, training_loss: 6.32500e-02\n",
            "epoch: 6588, iter: 37, training_loss: 6.31982e-02\n",
            "epoch: 6589, iter: 37, training_loss: 6.35194e-02\n",
            "epoch: 6590, iter: 37, training_loss: 6.74790e-02\n",
            "epoch: 6591, iter: 37, training_loss: 6.57813e-02\n",
            "epoch: 6592, iter: 37, training_loss: 6.41277e-02\n",
            "epoch: 6593, iter: 37, training_loss: 6.61786e-02\n",
            "epoch: 6594, iter: 37, training_loss: 6.35414e-02\n",
            "epoch: 6595, iter: 37, training_loss: 6.35764e-02\n",
            "epoch: 6596, iter: 37, training_loss: 6.41335e-02\n",
            "epoch: 6597, iter: 37, training_loss: 6.36473e-02\n",
            "epoch: 6598, iter: 37, training_loss: 6.44952e-02\n",
            "epoch: 6599, iter: 37, training_loss: 6.56082e-02\n",
            "epoch: 6600, iter: 37, training_loss: 6.48891e-02\n",
            "epoch: 6601, iter: 37, training_loss: 6.42380e-02\n",
            "epoch: 6602, iter: 37, training_loss: 6.45053e-02\n",
            "epoch: 6603, iter: 37, training_loss: 6.55925e-02\n",
            "epoch: 6604, iter: 37, training_loss: 6.37768e-02\n",
            "epoch: 6605, iter: 37, training_loss: 6.45192e-02\n",
            "epoch: 6606, iter: 37, training_loss: 6.41486e-02\n",
            "epoch: 6607, iter: 37, training_loss: 6.44565e-02\n",
            "epoch: 6608, iter: 37, training_loss: 6.39445e-02\n",
            "epoch: 6609, iter: 37, training_loss: 6.45965e-02\n",
            "epoch: 6610, iter: 37, training_loss: 6.40526e-02\n",
            "epoch: 6611, iter: 37, training_loss: 6.66740e-02\n",
            "epoch: 6612, iter: 37, training_loss: 6.55836e-02\n",
            "epoch: 6613, iter: 37, training_loss: 6.40888e-02\n",
            "epoch: 6614, iter: 37, training_loss: 6.43540e-02\n",
            "epoch: 6615, iter: 37, training_loss: 6.48947e-02\n",
            "epoch: 6616, iter: 37, training_loss: 6.35750e-02\n",
            "epoch: 6617, iter: 37, training_loss: 6.27497e-02\n",
            "epoch: 6618, iter: 37, training_loss: 6.35358e-02\n",
            "epoch: 6619, iter: 37, training_loss: 6.42562e-02\n",
            "epoch: 6620, iter: 37, training_loss: 6.62403e-02\n",
            "epoch: 6621, iter: 37, training_loss: 6.24187e-02\n",
            "epoch: 6622, iter: 37, training_loss: 6.47520e-02\n",
            "epoch: 6623, iter: 37, training_loss: 6.51268e-02\n",
            "epoch: 6624, iter: 37, training_loss: 6.54885e-02\n",
            "epoch: 6625, iter: 37, training_loss: 6.27246e-02\n",
            "epoch: 6626, iter: 37, training_loss: 6.60457e-02\n",
            "epoch: 6627, iter: 37, training_loss: 6.44692e-02\n",
            "epoch: 6628, iter: 37, training_loss: 6.44972e-02\n",
            "epoch: 6629, iter: 37, training_loss: 6.63826e-02\n",
            "epoch: 6630, iter: 37, training_loss: 6.27317e-02\n",
            "epoch: 6631, iter: 37, training_loss: 6.27826e-02\n",
            "epoch: 6632, iter: 37, training_loss: 6.36191e-02\n",
            "epoch: 6633, iter: 37, training_loss: 6.43473e-02\n",
            "epoch: 6634, iter: 37, training_loss: 6.24518e-02\n",
            "epoch: 6635, iter: 37, training_loss: 6.30459e-02\n",
            "epoch: 6636, iter: 37, training_loss: 6.33936e-02\n",
            "epoch: 6637, iter: 37, training_loss: 6.33441e-02\n",
            "epoch: 6638, iter: 37, training_loss: 6.47783e-02\n",
            "epoch: 6639, iter: 37, training_loss: 6.49561e-02\n",
            "epoch: 6640, iter: 37, training_loss: 6.40564e-02\n",
            "epoch: 6641, iter: 37, training_loss: 6.28657e-02\n",
            "epoch: 6642, iter: 37, training_loss: 6.29047e-02\n",
            "epoch: 6643, iter: 37, training_loss: 6.33882e-02\n",
            "epoch: 6644, iter: 37, training_loss: 6.29018e-02\n",
            "epoch: 6645, iter: 37, training_loss: 6.41542e-02\n",
            "epoch: 6646, iter: 37, training_loss: 6.56426e-02\n",
            "epoch: 6647, iter: 37, training_loss: 6.42192e-02\n",
            "epoch: 6648, iter: 37, training_loss: 6.35672e-02\n",
            "epoch: 6649, iter: 37, training_loss: 6.64958e-02\n",
            "epoch: 6650, iter: 37, training_loss: 6.43031e-02\n",
            "epoch: 6651, iter: 37, training_loss: 6.56647e-02\n",
            "epoch: 6652, iter: 37, training_loss: 6.64403e-02\n",
            "epoch: 6653, iter: 37, training_loss: 6.51812e-02\n",
            "epoch: 6654, iter: 37, training_loss: 6.37737e-02\n",
            "epoch: 6655, iter: 37, training_loss: 6.53770e-02\n",
            "epoch: 6656, iter: 37, training_loss: 6.55540e-02\n",
            "epoch: 6657, iter: 37, training_loss: 6.33347e-02\n",
            "epoch: 6658, iter: 37, training_loss: 6.25959e-02\n",
            "epoch: 6659, iter: 37, training_loss: 6.68862e-02\n",
            "epoch: 6660, iter: 37, training_loss: 6.52923e-02\n",
            "epoch: 6661, iter: 37, training_loss: 6.39859e-02\n",
            "epoch: 6662, iter: 37, training_loss: 6.51419e-02\n",
            "epoch: 6663, iter: 37, training_loss: 6.47173e-02\n",
            "epoch: 6664, iter: 37, training_loss: 6.33501e-02\n",
            "epoch: 6665, iter: 37, training_loss: 6.54375e-02\n",
            "epoch: 6666, iter: 37, training_loss: 6.55068e-02\n",
            "epoch: 6667, iter: 37, training_loss: 6.29442e-02\n",
            "epoch: 6668, iter: 37, training_loss: 6.51691e-02\n",
            "epoch: 6669, iter: 37, training_loss: 6.60607e-02\n",
            "epoch: 6670, iter: 37, training_loss: 6.39635e-02\n",
            "epoch: 6671, iter: 37, training_loss: 6.29721e-02\n",
            "epoch: 6672, iter: 37, training_loss: 6.39285e-02\n",
            "epoch: 6673, iter: 37, training_loss: 6.54970e-02\n",
            "epoch: 6674, iter: 37, training_loss: 6.40928e-02\n",
            "epoch: 6675, iter: 37, training_loss: 6.63246e-02\n",
            "epoch: 6676, iter: 37, training_loss: 6.28196e-02\n",
            "epoch: 6677, iter: 37, training_loss: 6.53837e-02\n",
            "epoch: 6678, iter: 37, training_loss: 6.41902e-02\n",
            "epoch: 6679, iter: 37, training_loss: 6.34904e-02\n",
            "epoch: 6680, iter: 37, training_loss: 6.52060e-02\n",
            "epoch: 6681, iter: 37, training_loss: 6.34289e-02\n",
            "epoch: 6682, iter: 37, training_loss: 6.40113e-02\n",
            "epoch: 6683, iter: 37, training_loss: 6.42111e-02\n",
            "epoch: 6684, iter: 37, training_loss: 6.64547e-02\n",
            "epoch: 6685, iter: 37, training_loss: 6.56515e-02\n",
            "epoch: 6686, iter: 37, training_loss: 6.47284e-02\n",
            "epoch: 6687, iter: 37, training_loss: 6.61860e-02\n",
            "epoch: 6688, iter: 37, training_loss: 6.44100e-02\n",
            "epoch: 6689, iter: 37, training_loss: 6.55820e-02\n",
            "epoch: 6690, iter: 37, training_loss: 6.34237e-02\n",
            "epoch: 6691, iter: 37, training_loss: 6.41819e-02\n",
            "epoch: 6692, iter: 37, training_loss: 6.47741e-02\n",
            "epoch: 6693, iter: 37, training_loss: 6.45641e-02\n",
            "epoch: 6694, iter: 37, training_loss: 6.32864e-02\n",
            "epoch: 6695, iter: 37, training_loss: 6.33830e-02\n",
            "epoch: 6696, iter: 37, training_loss: 6.37947e-02\n",
            "epoch: 6697, iter: 37, training_loss: 6.49437e-02\n",
            "epoch: 6698, iter: 37, training_loss: 6.23495e-02\n",
            "epoch: 6699, iter: 37, training_loss: 6.24020e-02\n",
            "epoch: 6700, iter: 37, training_loss: 6.61612e-02\n",
            "epoch: 6701, iter: 37, training_loss: 6.33658e-02\n",
            "epoch: 6702, iter: 37, training_loss: 6.34024e-02\n",
            "epoch: 6703, iter: 37, training_loss: 6.40267e-02\n",
            "epoch: 6704, iter: 37, training_loss: 6.47258e-02\n",
            "epoch: 6705, iter: 37, training_loss: 6.49086e-02\n",
            "epoch: 6706, iter: 37, training_loss: 6.77105e-02\n",
            "epoch: 6707, iter: 37, training_loss: 6.17003e-02\n",
            "epoch: 6708, iter: 37, training_loss: 6.46936e-02\n",
            "epoch: 6709, iter: 37, training_loss: 6.58035e-02\n",
            "epoch: 6710, iter: 37, training_loss: 6.42535e-02\n",
            "epoch: 6711, iter: 37, training_loss: 6.47222e-02\n",
            "epoch: 6712, iter: 37, training_loss: 6.68749e-02\n",
            "epoch: 6713, iter: 37, training_loss: 6.49630e-02\n",
            "epoch: 6714, iter: 37, training_loss: 6.46292e-02\n",
            "epoch: 6715, iter: 37, training_loss: 6.33726e-02\n",
            "epoch: 6716, iter: 37, training_loss: 6.42078e-02\n",
            "epoch: 6717, iter: 37, training_loss: 6.57271e-02\n",
            "epoch: 6718, iter: 37, training_loss: 6.35784e-02\n",
            "epoch: 6719, iter: 37, training_loss: 6.44763e-02\n",
            "epoch: 6720, iter: 37, training_loss: 6.38822e-02\n",
            "epoch: 6721, iter: 37, training_loss: 6.45458e-02\n",
            "epoch: 6722, iter: 37, training_loss: 6.39317e-02\n",
            "epoch: 6723, iter: 37, training_loss: 6.53548e-02\n",
            "epoch: 6724, iter: 37, training_loss: 6.49846e-02\n",
            "epoch: 6725, iter: 37, training_loss: 6.31251e-02\n",
            "epoch: 6726, iter: 37, training_loss: 6.38773e-02\n",
            "epoch: 6727, iter: 37, training_loss: 6.65830e-02\n",
            "epoch: 6728, iter: 37, training_loss: 6.39559e-02\n",
            "epoch: 6729, iter: 37, training_loss: 6.27934e-02\n",
            "epoch: 6730, iter: 37, training_loss: 6.29462e-02\n",
            "epoch: 6731, iter: 37, training_loss: 6.17631e-02\n",
            "epoch: 6732, iter: 37, training_loss: 6.75893e-02\n",
            "epoch: 6733, iter: 37, training_loss: 6.58960e-02\n",
            "epoch: 6734, iter: 37, training_loss: 6.49239e-02\n",
            "epoch: 6735, iter: 37, training_loss: 6.47073e-02\n",
            "epoch: 6736, iter: 37, training_loss: 6.29394e-02\n",
            "epoch: 6737, iter: 37, training_loss: 6.31829e-02\n",
            "epoch: 6738, iter: 37, training_loss: 6.46971e-02\n",
            "epoch: 6739, iter: 37, training_loss: 6.21206e-02\n",
            "epoch: 6740, iter: 37, training_loss: 6.47865e-02\n",
            "epoch: 6741, iter: 37, training_loss: 6.57542e-02\n",
            "epoch: 6742, iter: 37, training_loss: 6.17382e-02\n",
            "epoch: 6743, iter: 37, training_loss: 6.37108e-02\n",
            "epoch: 6744, iter: 37, training_loss: 6.45875e-02\n",
            "epoch: 6745, iter: 37, training_loss: 6.45524e-02\n",
            "epoch: 6746, iter: 37, training_loss: 6.35851e-02\n",
            "epoch: 6747, iter: 37, training_loss: 6.39953e-02\n",
            "epoch: 6748, iter: 37, training_loss: 6.33623e-02\n",
            "epoch: 6749, iter: 37, training_loss: 6.39262e-02\n",
            "epoch: 6750, iter: 37, training_loss: 6.40317e-02\n",
            "epoch: 6751, iter: 37, training_loss: 6.38469e-02\n",
            "epoch: 6752, iter: 37, training_loss: 6.64637e-02\n",
            "epoch: 6753, iter: 37, training_loss: 6.50948e-02\n",
            "epoch: 6754, iter: 37, training_loss: 6.36548e-02\n",
            "epoch: 6755, iter: 37, training_loss: 6.71204e-02\n",
            "epoch: 6756, iter: 37, training_loss: 6.33496e-02\n",
            "epoch: 6757, iter: 37, training_loss: 6.64862e-02\n",
            "epoch: 6758, iter: 37, training_loss: 6.36507e-02\n",
            "epoch: 6759, iter: 37, training_loss: 6.37821e-02\n",
            "epoch: 6760, iter: 37, training_loss: 6.39485e-02\n",
            "epoch: 6761, iter: 37, training_loss: 6.49852e-02\n",
            "epoch: 6762, iter: 37, training_loss: 6.28567e-02\n",
            "epoch: 6763, iter: 37, training_loss: 6.30928e-02\n",
            "epoch: 6764, iter: 37, training_loss: 6.40739e-02\n",
            "epoch: 6765, iter: 37, training_loss: 6.49080e-02\n",
            "epoch: 6766, iter: 37, training_loss: 6.45184e-02\n",
            "epoch: 6767, iter: 37, training_loss: 6.45900e-02\n",
            "epoch: 6768, iter: 37, training_loss: 6.55293e-02\n",
            "epoch: 6769, iter: 37, training_loss: 6.56497e-02\n",
            "epoch: 6770, iter: 37, training_loss: 6.44994e-02\n",
            "epoch: 6771, iter: 37, training_loss: 6.41850e-02\n",
            "epoch: 6772, iter: 37, training_loss: 6.41994e-02\n",
            "epoch: 6773, iter: 37, training_loss: 6.26957e-02\n",
            "epoch: 6774, iter: 37, training_loss: 6.45269e-02\n",
            "epoch: 6775, iter: 37, training_loss: 6.34419e-02\n",
            "epoch: 6776, iter: 37, training_loss: 6.68731e-02\n",
            "epoch: 6777, iter: 37, training_loss: 6.38928e-02\n",
            "epoch: 6778, iter: 37, training_loss: 6.46834e-02\n",
            "epoch: 6779, iter: 37, training_loss: 6.37292e-02\n",
            "epoch: 6780, iter: 37, training_loss: 6.35441e-02\n",
            "epoch: 6781, iter: 37, training_loss: 6.37294e-02\n",
            "epoch: 6782, iter: 37, training_loss: 6.73959e-02\n",
            "epoch: 6783, iter: 37, training_loss: 6.34708e-02\n",
            "epoch: 6784, iter: 37, training_loss: 6.41683e-02\n",
            "epoch: 6785, iter: 37, training_loss: 6.61591e-02\n",
            "epoch: 6786, iter: 37, training_loss: 6.48508e-02\n",
            "epoch: 6787, iter: 37, training_loss: 6.55873e-02\n",
            "epoch: 6788, iter: 37, training_loss: 6.47034e-02\n",
            "epoch: 6789, iter: 37, training_loss: 6.37230e-02\n",
            "epoch: 6790, iter: 37, training_loss: 6.38258e-02\n",
            "epoch: 6791, iter: 37, training_loss: 6.36390e-02\n",
            "epoch: 6792, iter: 37, training_loss: 6.42456e-02\n",
            "epoch: 6793, iter: 37, training_loss: 6.85499e-02\n",
            "epoch: 6794, iter: 37, training_loss: 6.41908e-02\n",
            "epoch: 6795, iter: 37, training_loss: 6.52567e-02\n",
            "epoch: 6796, iter: 37, training_loss: 6.39352e-02\n",
            "epoch: 6797, iter: 37, training_loss: 6.63478e-02\n",
            "epoch: 6798, iter: 37, training_loss: 6.55144e-02\n",
            "epoch: 6799, iter: 37, training_loss: 6.50161e-02\n",
            "epoch: 6800, iter: 37, training_loss: 6.67073e-02\n",
            "epoch: 6801, iter: 37, training_loss: 6.35955e-02\n",
            "epoch: 6802, iter: 37, training_loss: 6.28088e-02\n",
            "epoch: 6803, iter: 37, training_loss: 6.28288e-02\n",
            "epoch: 6804, iter: 37, training_loss: 6.25274e-02\n",
            "epoch: 6805, iter: 37, training_loss: 6.46824e-02\n",
            "epoch: 6806, iter: 37, training_loss: 6.49937e-02\n",
            "epoch: 6807, iter: 37, training_loss: 6.40862e-02\n",
            "epoch: 6808, iter: 37, training_loss: 6.41950e-02\n",
            "epoch: 6809, iter: 37, training_loss: 6.71211e-02\n",
            "epoch: 6810, iter: 37, training_loss: 6.42441e-02\n",
            "epoch: 6811, iter: 37, training_loss: 6.46646e-02\n",
            "epoch: 6812, iter: 37, training_loss: 6.58137e-02\n",
            "epoch: 6813, iter: 37, training_loss: 6.33811e-02\n",
            "epoch: 6814, iter: 37, training_loss: 6.29714e-02\n",
            "epoch: 6815, iter: 37, training_loss: 6.55226e-02\n",
            "epoch: 6816, iter: 37, training_loss: 6.24695e-02\n",
            "epoch: 6817, iter: 37, training_loss: 6.55719e-02\n",
            "epoch: 6818, iter: 37, training_loss: 6.25000e-02\n",
            "epoch: 6819, iter: 37, training_loss: 6.49359e-02\n",
            "epoch: 6820, iter: 37, training_loss: 6.41186e-02\n",
            "epoch: 6821, iter: 37, training_loss: 6.61815e-02\n",
            "epoch: 6822, iter: 37, training_loss: 6.43175e-02\n",
            "epoch: 6823, iter: 37, training_loss: 6.68339e-02\n",
            "epoch: 6824, iter: 37, training_loss: 6.34986e-02\n",
            "epoch: 6825, iter: 37, training_loss: 6.48498e-02\n",
            "epoch: 6826, iter: 37, training_loss: 6.33644e-02\n",
            "epoch: 6827, iter: 37, training_loss: 6.24086e-02\n",
            "epoch: 6828, iter: 37, training_loss: 6.41352e-02\n",
            "epoch: 6829, iter: 37, training_loss: 6.48849e-02\n",
            "epoch: 6830, iter: 37, training_loss: 6.55183e-02\n",
            "epoch: 6831, iter: 37, training_loss: 6.37642e-02\n",
            "epoch: 6832, iter: 37, training_loss: 6.34576e-02\n",
            "epoch: 6833, iter: 37, training_loss: 6.67354e-02\n",
            "epoch: 6834, iter: 37, training_loss: 6.36210e-02\n",
            "epoch: 6835, iter: 37, training_loss: 6.41769e-02\n",
            "epoch: 6836, iter: 37, training_loss: 6.27629e-02\n",
            "epoch: 6837, iter: 37, training_loss: 6.40974e-02\n",
            "epoch: 6838, iter: 37, training_loss: 6.72877e-02\n",
            "epoch: 6839, iter: 37, training_loss: 6.29714e-02\n",
            "epoch: 6840, iter: 37, training_loss: 6.37352e-02\n",
            "epoch: 6841, iter: 37, training_loss: 6.57633e-02\n",
            "epoch: 6842, iter: 37, training_loss: 6.40539e-02\n",
            "epoch: 6843, iter: 37, training_loss: 6.64252e-02\n",
            "epoch: 6844, iter: 37, training_loss: 6.33386e-02\n",
            "epoch: 6845, iter: 37, training_loss: 6.37353e-02\n",
            "epoch: 6846, iter: 37, training_loss: 6.24187e-02\n",
            "epoch: 6847, iter: 37, training_loss: 6.41550e-02\n",
            "epoch: 6848, iter: 37, training_loss: 6.21326e-02\n",
            "epoch: 6849, iter: 37, training_loss: 6.50375e-02\n",
            "epoch: 6850, iter: 37, training_loss: 6.34677e-02\n",
            "epoch: 6851, iter: 37, training_loss: 6.50869e-02\n",
            "epoch: 6852, iter: 37, training_loss: 6.23654e-02\n",
            "epoch: 6853, iter: 37, training_loss: 6.25561e-02\n",
            "epoch: 6854, iter: 37, training_loss: 6.53457e-02\n",
            "epoch: 6855, iter: 37, training_loss: 6.44654e-02\n",
            "epoch: 6856, iter: 37, training_loss: 6.25353e-02\n",
            "epoch: 6857, iter: 37, training_loss: 6.61378e-02\n",
            "epoch: 6858, iter: 37, training_loss: 6.28246e-02\n",
            "epoch: 6859, iter: 37, training_loss: 6.30033e-02\n",
            "epoch: 6860, iter: 37, training_loss: 6.47840e-02\n",
            "epoch: 6861, iter: 37, training_loss: 6.33162e-02\n",
            "epoch: 6862, iter: 37, training_loss: 6.40009e-02\n",
            "epoch: 6863, iter: 37, training_loss: 6.42770e-02\n",
            "epoch: 6864, iter: 37, training_loss: 6.47076e-02\n",
            "epoch: 6865, iter: 37, training_loss: 6.57287e-02\n",
            "epoch: 6866, iter: 37, training_loss: 6.42541e-02\n",
            "epoch: 6867, iter: 37, training_loss: 6.22911e-02\n",
            "epoch: 6868, iter: 37, training_loss: 6.32104e-02\n",
            "epoch: 6869, iter: 37, training_loss: 6.22288e-02\n",
            "epoch: 6870, iter: 37, training_loss: 6.33766e-02\n",
            "epoch: 6871, iter: 37, training_loss: 6.51111e-02\n",
            "epoch: 6872, iter: 37, training_loss: 6.46842e-02\n",
            "epoch: 6873, iter: 37, training_loss: 6.29635e-02\n",
            "epoch: 6874, iter: 37, training_loss: 6.30156e-02\n",
            "epoch: 6875, iter: 37, training_loss: 6.48956e-02\n",
            "epoch: 6876, iter: 37, training_loss: 6.48087e-02\n",
            "epoch: 6877, iter: 37, training_loss: 6.49027e-02\n",
            "epoch: 6878, iter: 37, training_loss: 6.45774e-02\n",
            "epoch: 6879, iter: 37, training_loss: 6.61272e-02\n",
            "epoch: 6880, iter: 37, training_loss: 6.41571e-02\n",
            "epoch: 6881, iter: 37, training_loss: 6.39604e-02\n",
            "epoch: 6882, iter: 37, training_loss: 6.21637e-02\n",
            "epoch: 6883, iter: 37, training_loss: 6.33669e-02\n",
            "epoch: 6884, iter: 37, training_loss: 6.41432e-02\n",
            "epoch: 6885, iter: 37, training_loss: 6.39843e-02\n",
            "epoch: 6886, iter: 37, training_loss: 6.50306e-02\n",
            "epoch: 6887, iter: 37, training_loss: 6.41643e-02\n",
            "epoch: 6888, iter: 37, training_loss: 6.60244e-02\n",
            "epoch: 6889, iter: 37, training_loss: 6.37616e-02\n",
            "epoch: 6890, iter: 37, training_loss: 6.52952e-02\n",
            "epoch: 6891, iter: 37, training_loss: 6.53826e-02\n",
            "epoch: 6892, iter: 37, training_loss: 6.46609e-02\n",
            "epoch: 6893, iter: 37, training_loss: 6.32819e-02\n",
            "epoch: 6894, iter: 37, training_loss: 6.49054e-02\n",
            "epoch: 6895, iter: 37, training_loss: 6.61747e-02\n",
            "epoch: 6896, iter: 37, training_loss: 6.36029e-02\n",
            "epoch: 6897, iter: 37, training_loss: 6.31990e-02\n",
            "epoch: 6898, iter: 37, training_loss: 6.80923e-02\n",
            "epoch: 6899, iter: 37, training_loss: 6.81277e-02\n",
            "epoch: 6900, iter: 37, training_loss: 6.33479e-02\n",
            "epoch: 6901, iter: 37, training_loss: 6.29085e-02\n",
            "epoch: 6902, iter: 37, training_loss: 6.49406e-02\n",
            "epoch: 6903, iter: 37, training_loss: 6.58395e-02\n",
            "epoch: 6904, iter: 37, training_loss: 6.29835e-02\n",
            "epoch: 6905, iter: 37, training_loss: 6.25305e-02\n",
            "epoch: 6906, iter: 37, training_loss: 6.40782e-02\n",
            "epoch: 6907, iter: 37, training_loss: 6.57425e-02\n",
            "epoch: 6908, iter: 37, training_loss: 6.40321e-02\n",
            "epoch: 6909, iter: 37, training_loss: 6.40496e-02\n",
            "epoch: 6910, iter: 37, training_loss: 6.62549e-02\n",
            "epoch: 6911, iter: 37, training_loss: 6.45596e-02\n",
            "epoch: 6912, iter: 37, training_loss: 6.51128e-02\n",
            "epoch: 6913, iter: 37, training_loss: 6.24111e-02\n",
            "epoch: 6914, iter: 37, training_loss: 6.43885e-02\n",
            "epoch: 6915, iter: 37, training_loss: 6.48087e-02\n",
            "epoch: 6916, iter: 37, training_loss: 6.31565e-02\n",
            "epoch: 6917, iter: 37, training_loss: 6.50567e-02\n",
            "epoch: 6918, iter: 37, training_loss: 6.64056e-02\n",
            "epoch: 6919, iter: 37, training_loss: 6.59583e-02\n",
            "epoch: 6920, iter: 37, training_loss: 6.34604e-02\n",
            "epoch: 6921, iter: 37, training_loss: 6.51079e-02\n",
            "epoch: 6922, iter: 37, training_loss: 6.50026e-02\n",
            "epoch: 6923, iter: 37, training_loss: 6.37431e-02\n",
            "epoch: 6924, iter: 37, training_loss: 6.36363e-02\n",
            "epoch: 6925, iter: 37, training_loss: 6.28373e-02\n",
            "epoch: 6926, iter: 37, training_loss: 6.50594e-02\n",
            "epoch: 6927, iter: 37, training_loss: 6.36617e-02\n",
            "epoch: 6928, iter: 37, training_loss: 6.46284e-02\n",
            "epoch: 6929, iter: 37, training_loss: 6.25574e-02\n",
            "epoch: 6930, iter: 37, training_loss: 6.44185e-02\n",
            "epoch: 6931, iter: 37, training_loss: 6.26514e-02\n",
            "epoch: 6932, iter: 37, training_loss: 6.17900e-02\n",
            "epoch: 6933, iter: 37, training_loss: 6.84165e-02\n",
            "epoch: 6934, iter: 37, training_loss: 6.19727e-02\n",
            "epoch: 6935, iter: 37, training_loss: 6.38626e-02\n",
            "epoch: 6936, iter: 37, training_loss: 6.42407e-02\n",
            "epoch: 6937, iter: 37, training_loss: 6.42254e-02\n",
            "epoch: 6938, iter: 37, training_loss: 6.59301e-02\n",
            "epoch: 6939, iter: 37, training_loss: 6.32850e-02\n",
            "epoch: 6940, iter: 37, training_loss: 6.33028e-02\n",
            "epoch: 6941, iter: 37, training_loss: 6.31097e-02\n",
            "epoch: 6942, iter: 37, training_loss: 6.43885e-02\n",
            "epoch: 6943, iter: 37, training_loss: 6.44235e-02\n",
            "epoch: 6944, iter: 37, training_loss: 6.43145e-02\n",
            "epoch: 6945, iter: 37, training_loss: 6.46919e-02\n",
            "epoch: 6946, iter: 37, training_loss: 6.50791e-02\n",
            "epoch: 6947, iter: 37, training_loss: 6.42505e-02\n",
            "epoch: 6948, iter: 37, training_loss: 6.29764e-02\n",
            "epoch: 6949, iter: 37, training_loss: 6.67893e-02\n",
            "epoch: 6950, iter: 37, training_loss: 6.42017e-02\n",
            "epoch: 6951, iter: 37, training_loss: 6.53814e-02\n",
            "epoch: 6952, iter: 37, training_loss: 6.42729e-02\n",
            "epoch: 6953, iter: 37, training_loss: 6.44407e-02\n",
            "epoch: 6954, iter: 37, training_loss: 6.32833e-02\n",
            "epoch: 6955, iter: 37, training_loss: 6.46272e-02\n",
            "epoch: 6956, iter: 37, training_loss: 6.50210e-02\n",
            "epoch: 6957, iter: 37, training_loss: 6.37422e-02\n",
            "epoch: 6958, iter: 37, training_loss: 6.23002e-02\n",
            "epoch: 6959, iter: 37, training_loss: 6.34130e-02\n",
            "epoch: 6960, iter: 37, training_loss: 6.39099e-02\n",
            "epoch: 6961, iter: 37, training_loss: 6.33404e-02\n",
            "epoch: 6962, iter: 37, training_loss: 6.72833e-02\n",
            "epoch: 6963, iter: 37, training_loss: 6.39373e-02\n",
            "epoch: 6964, iter: 37, training_loss: 6.47443e-02\n",
            "epoch: 6965, iter: 37, training_loss: 6.23391e-02\n",
            "epoch: 6966, iter: 37, training_loss: 6.29801e-02\n",
            "epoch: 6967, iter: 37, training_loss: 6.35485e-02\n",
            "epoch: 6968, iter: 37, training_loss: 6.23407e-02\n",
            "epoch: 6969, iter: 37, training_loss: 6.68448e-02\n",
            "epoch: 6970, iter: 37, training_loss: 6.33589e-02\n",
            "epoch: 6971, iter: 37, training_loss: 6.43001e-02\n",
            "epoch: 6972, iter: 37, training_loss: 6.36906e-02\n",
            "epoch: 6973, iter: 37, training_loss: 6.52126e-02\n",
            "epoch: 6974, iter: 37, training_loss: 6.54632e-02\n",
            "epoch: 6975, iter: 37, training_loss: 6.28816e-02\n",
            "epoch: 6976, iter: 37, training_loss: 6.38037e-02\n",
            "epoch: 6977, iter: 37, training_loss: 6.34835e-02\n",
            "epoch: 6978, iter: 37, training_loss: 6.32018e-02\n",
            "epoch: 6979, iter: 37, training_loss: 6.43044e-02\n",
            "epoch: 6980, iter: 37, training_loss: 6.45454e-02\n",
            "epoch: 6981, iter: 37, training_loss: 6.28524e-02\n",
            "epoch: 6982, iter: 37, training_loss: 6.28164e-02\n",
            "epoch: 6983, iter: 37, training_loss: 6.43840e-02\n",
            "epoch: 6984, iter: 37, training_loss: 6.50599e-02\n",
            "epoch: 6985, iter: 37, training_loss: 6.49756e-02\n",
            "epoch: 6986, iter: 37, training_loss: 6.39822e-02\n",
            "epoch: 6987, iter: 37, training_loss: 6.46315e-02\n",
            "epoch: 6988, iter: 37, training_loss: 6.51403e-02\n",
            "epoch: 6989, iter: 37, training_loss: 6.56268e-02\n",
            "epoch: 6990, iter: 37, training_loss: 6.41243e-02\n",
            "epoch: 6991, iter: 37, training_loss: 6.45673e-02\n",
            "epoch: 6992, iter: 37, training_loss: 6.27629e-02\n",
            "epoch: 6993, iter: 37, training_loss: 6.33940e-02\n",
            "epoch: 6994, iter: 37, training_loss: 6.48246e-02\n",
            "epoch: 6995, iter: 37, training_loss: 6.34595e-02\n",
            "epoch: 6996, iter: 37, training_loss: 6.47076e-02\n",
            "epoch: 6997, iter: 37, training_loss: 6.50980e-02\n",
            "epoch: 6998, iter: 37, training_loss: 6.44969e-02\n",
            "epoch: 6999, iter: 37, training_loss: 6.34968e-02\n",
            "epoch: 7000, iter: 37, training_loss: 6.45648e-02\n",
            "epoch: 7001, iter: 37, training_loss: 6.48065e-02\n",
            "epoch: 7002, iter: 37, training_loss: 6.31156e-02\n",
            "epoch: 7003, iter: 37, training_loss: 6.19385e-02\n",
            "epoch: 7004, iter: 37, training_loss: 6.53856e-02\n",
            "epoch: 7005, iter: 37, training_loss: 6.27386e-02\n",
            "epoch: 7006, iter: 37, training_loss: 6.67741e-02\n",
            "epoch: 7007, iter: 37, training_loss: 6.29634e-02\n",
            "epoch: 7008, iter: 37, training_loss: 6.34731e-02\n",
            "epoch: 7009, iter: 37, training_loss: 6.26529e-02\n",
            "epoch: 7010, iter: 37, training_loss: 6.48713e-02\n",
            "epoch: 7011, iter: 37, training_loss: 6.34031e-02\n",
            "epoch: 7012, iter: 37, training_loss: 6.32265e-02\n",
            "epoch: 7013, iter: 37, training_loss: 6.44425e-02\n",
            "epoch: 7014, iter: 37, training_loss: 6.38547e-02\n",
            "epoch: 7015, iter: 37, training_loss: 6.38918e-02\n",
            "epoch: 7016, iter: 37, training_loss: 6.32720e-02\n",
            "epoch: 7017, iter: 37, training_loss: 6.33869e-02\n",
            "epoch: 7018, iter: 37, training_loss: 6.23028e-02\n",
            "epoch: 7019, iter: 37, training_loss: 6.51133e-02\n",
            "epoch: 7020, iter: 37, training_loss: 6.32474e-02\n",
            "epoch: 7021, iter: 37, training_loss: 6.48624e-02\n",
            "epoch: 7022, iter: 37, training_loss: 6.22569e-02\n",
            "epoch: 7023, iter: 37, training_loss: 6.32038e-02\n",
            "epoch: 7024, iter: 37, training_loss: 6.65459e-02\n",
            "epoch: 7025, iter: 37, training_loss: 6.34910e-02\n",
            "epoch: 7026, iter: 37, training_loss: 6.47555e-02\n",
            "epoch: 7027, iter: 37, training_loss: 6.31035e-02\n",
            "epoch: 7028, iter: 37, training_loss: 6.54196e-02\n",
            "epoch: 7029, iter: 37, training_loss: 6.22378e-02\n",
            "epoch: 7030, iter: 37, training_loss: 6.53059e-02\n",
            "epoch: 7031, iter: 37, training_loss: 6.56852e-02\n",
            "epoch: 7032, iter: 37, training_loss: 6.54326e-02\n",
            "epoch: 7033, iter: 37, training_loss: 6.44742e-02\n",
            "epoch: 7034, iter: 37, training_loss: 6.48038e-02\n",
            "epoch: 7035, iter: 37, training_loss: 6.45508e-02\n",
            "epoch: 7036, iter: 37, training_loss: 6.51366e-02\n",
            "epoch: 7037, iter: 37, training_loss: 6.49630e-02\n",
            "epoch: 7038, iter: 37, training_loss: 6.46591e-02\n",
            "epoch: 7039, iter: 37, training_loss: 6.18753e-02\n",
            "epoch: 7040, iter: 37, training_loss: 6.31163e-02\n",
            "epoch: 7041, iter: 37, training_loss: 6.27427e-02\n",
            "epoch: 7042, iter: 37, training_loss: 6.40192e-02\n",
            "epoch: 7043, iter: 37, training_loss: 6.46767e-02\n",
            "epoch: 7044, iter: 37, training_loss: 6.31403e-02\n",
            "epoch: 7045, iter: 37, training_loss: 6.36411e-02\n",
            "epoch: 7046, iter: 37, training_loss: 6.23543e-02\n",
            "epoch: 7047, iter: 37, training_loss: 6.23031e-02\n",
            "epoch: 7048, iter: 37, training_loss: 6.23962e-02\n",
            "epoch: 7049, iter: 37, training_loss: 6.44085e-02\n",
            "epoch: 7050, iter: 37, training_loss: 6.56067e-02\n",
            "epoch: 7051, iter: 37, training_loss: 6.31449e-02\n",
            "epoch: 7052, iter: 37, training_loss: 6.66194e-02\n",
            "epoch: 7053, iter: 37, training_loss: 6.45644e-02\n",
            "epoch: 7054, iter: 37, training_loss: 6.37552e-02\n",
            "epoch: 7055, iter: 37, training_loss: 6.29564e-02\n",
            "epoch: 7056, iter: 37, training_loss: 6.50653e-02\n",
            "epoch: 7057, iter: 37, training_loss: 6.27892e-02\n",
            "epoch: 7058, iter: 37, training_loss: 6.39598e-02\n",
            "epoch: 7059, iter: 37, training_loss: 6.37919e-02\n",
            "epoch: 7060, iter: 37, training_loss: 6.53060e-02\n",
            "epoch: 7061, iter: 37, training_loss: 6.26706e-02\n",
            "epoch: 7062, iter: 37, training_loss: 6.42436e-02\n",
            "epoch: 7063, iter: 37, training_loss: 6.59890e-02\n",
            "epoch: 7064, iter: 37, training_loss: 6.25570e-02\n",
            "epoch: 7065, iter: 37, training_loss: 6.47694e-02\n",
            "epoch: 7066, iter: 37, training_loss: 6.24331e-02\n",
            "epoch: 7067, iter: 37, training_loss: 6.36479e-02\n",
            "epoch: 7068, iter: 37, training_loss: 6.45219e-02\n",
            "epoch: 7069, iter: 37, training_loss: 6.45482e-02\n",
            "epoch: 7070, iter: 37, training_loss: 6.51231e-02\n",
            "epoch: 7071, iter: 37, training_loss: 6.30759e-02\n",
            "epoch: 7072, iter: 37, training_loss: 6.40123e-02\n",
            "epoch: 7073, iter: 37, training_loss: 6.33707e-02\n",
            "epoch: 7074, iter: 37, training_loss: 6.33350e-02\n",
            "epoch: 7075, iter: 37, training_loss: 6.43900e-02\n",
            "epoch: 7076, iter: 37, training_loss: 6.46210e-02\n",
            "epoch: 7077, iter: 37, training_loss: 6.34695e-02\n",
            "epoch: 7078, iter: 37, training_loss: 6.33195e-02\n",
            "epoch: 7079, iter: 37, training_loss: 6.74102e-02\n",
            "epoch: 7080, iter: 37, training_loss: 6.35385e-02\n",
            "epoch: 7081, iter: 37, training_loss: 6.50591e-02\n",
            "epoch: 7082, iter: 37, training_loss: 6.22913e-02\n",
            "epoch: 7083, iter: 37, training_loss: 6.21325e-02\n",
            "epoch: 7084, iter: 37, training_loss: 6.26658e-02\n",
            "epoch: 7085, iter: 37, training_loss: 6.35073e-02\n",
            "epoch: 7086, iter: 37, training_loss: 6.46088e-02\n",
            "epoch: 7087, iter: 37, training_loss: 6.31543e-02\n",
            "epoch: 7088, iter: 37, training_loss: 6.48362e-02\n",
            "epoch: 7089, iter: 37, training_loss: 6.27985e-02\n",
            "epoch: 7090, iter: 37, training_loss: 6.36876e-02\n",
            "epoch: 7091, iter: 37, training_loss: 6.30193e-02\n",
            "epoch: 7092, iter: 37, training_loss: 6.55635e-02\n",
            "epoch: 7093, iter: 37, training_loss: 6.51444e-02\n",
            "epoch: 7094, iter: 37, training_loss: 6.47649e-02\n",
            "epoch: 7095, iter: 37, training_loss: 6.34829e-02\n",
            "epoch: 7096, iter: 37, training_loss: 6.24452e-02\n",
            "epoch: 7097, iter: 37, training_loss: 6.51884e-02\n",
            "epoch: 7098, iter: 37, training_loss: 6.29257e-02\n",
            "epoch: 7099, iter: 37, training_loss: 6.26652e-02\n",
            "epoch: 7100, iter: 37, training_loss: 6.10732e-02\n",
            "epoch: 7101, iter: 37, training_loss: 6.36708e-02\n",
            "epoch: 7102, iter: 37, training_loss: 6.28156e-02\n",
            "epoch: 7103, iter: 37, training_loss: 6.23788e-02\n",
            "epoch: 7104, iter: 37, training_loss: 6.54242e-02\n",
            "epoch: 7105, iter: 37, training_loss: 6.37172e-02\n",
            "epoch: 7106, iter: 37, training_loss: 6.37593e-02\n",
            "epoch: 7107, iter: 37, training_loss: 6.40087e-02\n",
            "epoch: 7108, iter: 37, training_loss: 6.38380e-02\n",
            "epoch: 7109, iter: 37, training_loss: 6.61080e-02\n",
            "epoch: 7110, iter: 37, training_loss: 6.45079e-02\n",
            "epoch: 7111, iter: 37, training_loss: 6.40072e-02\n",
            "epoch: 7112, iter: 37, training_loss: 6.47377e-02\n",
            "epoch: 7113, iter: 37, training_loss: 6.36476e-02\n",
            "epoch: 7114, iter: 37, training_loss: 6.27977e-02\n",
            "epoch: 7115, iter: 37, training_loss: 6.18116e-02\n",
            "epoch: 7116, iter: 37, training_loss: 6.60654e-02\n",
            "epoch: 7117, iter: 37, training_loss: 6.41326e-02\n",
            "epoch: 7118, iter: 37, training_loss: 6.45318e-02\n",
            "epoch: 7119, iter: 37, training_loss: 6.43297e-02\n",
            "epoch: 7120, iter: 37, training_loss: 6.39238e-02\n",
            "epoch: 7121, iter: 37, training_loss: 6.61166e-02\n",
            "epoch: 7122, iter: 37, training_loss: 6.39433e-02\n",
            "epoch: 7123, iter: 37, training_loss: 6.31059e-02\n",
            "epoch: 7124, iter: 37, training_loss: 6.54385e-02\n",
            "epoch: 7125, iter: 37, training_loss: 6.23204e-02\n",
            "epoch: 7126, iter: 37, training_loss: 6.21916e-02\n",
            "epoch: 7127, iter: 37, training_loss: 6.33713e-02\n",
            "epoch: 7128, iter: 37, training_loss: 6.25638e-02\n",
            "epoch: 7129, iter: 37, training_loss: 6.34209e-02\n",
            "epoch: 7130, iter: 37, training_loss: 6.19747e-02\n",
            "epoch: 7131, iter: 37, training_loss: 6.37734e-02\n",
            "epoch: 7132, iter: 37, training_loss: 6.36881e-02\n",
            "epoch: 7133, iter: 37, training_loss: 6.39025e-02\n",
            "epoch: 7134, iter: 37, training_loss: 6.58300e-02\n",
            "epoch: 7135, iter: 37, training_loss: 6.41117e-02\n",
            "epoch: 7136, iter: 37, training_loss: 6.49946e-02\n",
            "epoch: 7137, iter: 37, training_loss: 6.35057e-02\n",
            "epoch: 7138, iter: 37, training_loss: 6.34844e-02\n",
            "epoch: 7139, iter: 37, training_loss: 6.45174e-02\n",
            "epoch: 7140, iter: 37, training_loss: 6.22886e-02\n",
            "epoch: 7141, iter: 37, training_loss: 6.39843e-02\n",
            "epoch: 7142, iter: 37, training_loss: 6.17003e-02\n",
            "epoch: 7143, iter: 37, training_loss: 6.25838e-02\n",
            "epoch: 7144, iter: 37, training_loss: 6.48487e-02\n",
            "epoch: 7145, iter: 37, training_loss: 6.33491e-02\n",
            "epoch: 7146, iter: 37, training_loss: 6.49779e-02\n",
            "epoch: 7147, iter: 37, training_loss: 6.24615e-02\n",
            "epoch: 7148, iter: 37, training_loss: 6.31936e-02\n",
            "epoch: 7149, iter: 37, training_loss: 6.35361e-02\n",
            "epoch: 7150, iter: 37, training_loss: 6.36308e-02\n",
            "epoch: 7151, iter: 37, training_loss: 6.51727e-02\n",
            "epoch: 7152, iter: 37, training_loss: 6.41207e-02\n",
            "epoch: 7153, iter: 37, training_loss: 6.36347e-02\n",
            "epoch: 7154, iter: 37, training_loss: 6.28834e-02\n",
            "epoch: 7155, iter: 37, training_loss: 6.16418e-02\n",
            "epoch: 7156, iter: 37, training_loss: 6.40860e-02\n",
            "epoch: 7157, iter: 37, training_loss: 6.60534e-02\n",
            "epoch: 7158, iter: 37, training_loss: 6.36184e-02\n",
            "epoch: 7159, iter: 37, training_loss: 6.45953e-02\n",
            "epoch: 7160, iter: 37, training_loss: 6.31891e-02\n",
            "epoch: 7161, iter: 37, training_loss: 6.25933e-02\n",
            "epoch: 7162, iter: 37, training_loss: 6.38785e-02\n",
            "epoch: 7163, iter: 37, training_loss: 6.49465e-02\n",
            "epoch: 7164, iter: 37, training_loss: 6.48746e-02\n",
            "epoch: 7165, iter: 37, training_loss: 6.28297e-02\n",
            "epoch: 7166, iter: 37, training_loss: 6.53048e-02\n",
            "epoch: 7167, iter: 37, training_loss: 6.21645e-02\n",
            "epoch: 7168, iter: 37, training_loss: 6.58272e-02\n",
            "epoch: 7169, iter: 37, training_loss: 6.33314e-02\n",
            "epoch: 7170, iter: 37, training_loss: 6.33861e-02\n",
            "epoch: 7171, iter: 37, training_loss: 6.46467e-02\n",
            "epoch: 7172, iter: 37, training_loss: 6.36794e-02\n",
            "epoch: 7173, iter: 37, training_loss: 6.37704e-02\n",
            "epoch: 7174, iter: 37, training_loss: 6.28164e-02\n",
            "epoch: 7175, iter: 37, training_loss: 6.23595e-02\n",
            "epoch: 7176, iter: 37, training_loss: 6.55511e-02\n",
            "epoch: 7177, iter: 37, training_loss: 6.30325e-02\n",
            "epoch: 7178, iter: 37, training_loss: 6.18727e-02\n",
            "epoch: 7179, iter: 37, training_loss: 6.30717e-02\n",
            "epoch: 7180, iter: 37, training_loss: 6.27232e-02\n",
            "epoch: 7181, iter: 37, training_loss: 6.49807e-02\n",
            "epoch: 7182, iter: 37, training_loss: 6.31909e-02\n",
            "epoch: 7183, iter: 37, training_loss: 6.22736e-02\n",
            "epoch: 7184, iter: 37, training_loss: 6.21159e-02\n",
            "epoch: 7185, iter: 37, training_loss: 6.34674e-02\n",
            "epoch: 7186, iter: 37, training_loss: 6.30366e-02\n",
            "epoch: 7187, iter: 37, training_loss: 6.49748e-02\n",
            "epoch: 7188, iter: 37, training_loss: 6.24835e-02\n",
            "epoch: 7189, iter: 37, training_loss: 6.84917e-02\n",
            "epoch: 7190, iter: 37, training_loss: 6.23826e-02\n",
            "epoch: 7191, iter: 37, training_loss: 6.40575e-02\n",
            "epoch: 7192, iter: 37, training_loss: 6.50716e-02\n",
            "epoch: 7193, iter: 37, training_loss: 6.37220e-02\n",
            "epoch: 7194, iter: 37, training_loss: 6.46041e-02\n",
            "epoch: 7195, iter: 37, training_loss: 6.32896e-02\n",
            "epoch: 7196, iter: 37, training_loss: 6.29182e-02\n",
            "epoch: 7197, iter: 37, training_loss: 6.32192e-02\n",
            "epoch: 7198, iter: 37, training_loss: 6.34812e-02\n",
            "epoch: 7199, iter: 37, training_loss: 6.90739e-02\n",
            "epoch: 7200, iter: 37, training_loss: 6.46871e-02\n",
            "epoch: 7201, iter: 37, training_loss: 6.25674e-02\n",
            "epoch: 7202, iter: 37, training_loss: 6.30747e-02\n",
            "epoch: 7203, iter: 37, training_loss: 6.47537e-02\n",
            "epoch: 7204, iter: 37, training_loss: 6.42377e-02\n",
            "epoch: 7205, iter: 37, training_loss: 6.16842e-02\n",
            "epoch: 7206, iter: 37, training_loss: 6.45051e-02\n",
            "epoch: 7207, iter: 37, training_loss: 6.25948e-02\n",
            "epoch: 7208, iter: 37, training_loss: 6.49620e-02\n",
            "epoch: 7209, iter: 37, training_loss: 6.31682e-02\n",
            "epoch: 7210, iter: 37, training_loss: 6.26480e-02\n",
            "epoch: 7211, iter: 37, training_loss: 6.34395e-02\n",
            "epoch: 7212, iter: 37, training_loss: 6.40726e-02\n",
            "epoch: 7213, iter: 37, training_loss: 6.36696e-02\n",
            "epoch: 7214, iter: 37, training_loss: 6.59780e-02\n",
            "epoch: 7215, iter: 37, training_loss: 6.44704e-02\n",
            "epoch: 7216, iter: 37, training_loss: 6.36047e-02\n",
            "epoch: 7217, iter: 37, training_loss: 6.63754e-02\n",
            "epoch: 7218, iter: 37, training_loss: 6.46222e-02\n",
            "epoch: 7219, iter: 37, training_loss: 6.26621e-02\n",
            "epoch: 7220, iter: 37, training_loss: 6.39940e-02\n",
            "epoch: 7221, iter: 37, training_loss: 6.35896e-02\n",
            "epoch: 7222, iter: 37, training_loss: 6.57472e-02\n",
            "epoch: 7223, iter: 37, training_loss: 6.47791e-02\n",
            "epoch: 7224, iter: 37, training_loss: 6.39275e-02\n",
            "epoch: 7225, iter: 37, training_loss: 6.37141e-02\n",
            "epoch: 7226, iter: 37, training_loss: 6.26686e-02\n",
            "epoch: 7227, iter: 37, training_loss: 6.38163e-02\n",
            "epoch: 7228, iter: 37, training_loss: 6.56263e-02\n",
            "epoch: 7229, iter: 37, training_loss: 6.50581e-02\n",
            "epoch: 7230, iter: 37, training_loss: 6.47505e-02\n",
            "epoch: 7231, iter: 37, training_loss: 6.22791e-02\n",
            "epoch: 7232, iter: 37, training_loss: 6.32132e-02\n",
            "epoch: 7233, iter: 37, training_loss: 6.43914e-02\n",
            "epoch: 7234, iter: 37, training_loss: 6.29957e-02\n",
            "epoch: 7235, iter: 37, training_loss: 6.59476e-02\n",
            "epoch: 7236, iter: 37, training_loss: 6.27073e-02\n",
            "epoch: 7237, iter: 37, training_loss: 6.35115e-02\n",
            "epoch: 7238, iter: 37, training_loss: 6.39106e-02\n",
            "epoch: 7239, iter: 37, training_loss: 6.30450e-02\n",
            "epoch: 7240, iter: 37, training_loss: 6.50772e-02\n",
            "epoch: 7241, iter: 37, training_loss: 6.22307e-02\n",
            "epoch: 7242, iter: 37, training_loss: 6.35837e-02\n",
            "epoch: 7243, iter: 37, training_loss: 6.50813e-02\n",
            "epoch: 7244, iter: 37, training_loss: 6.53895e-02\n",
            "epoch: 7245, iter: 37, training_loss: 6.42011e-02\n",
            "epoch: 7246, iter: 37, training_loss: 6.25854e-02\n",
            "epoch: 7247, iter: 37, training_loss: 6.30005e-02\n",
            "epoch: 7248, iter: 37, training_loss: 6.25937e-02\n",
            "epoch: 7249, iter: 37, training_loss: 6.37616e-02\n",
            "epoch: 7250, iter: 37, training_loss: 6.44574e-02\n",
            "epoch: 7251, iter: 37, training_loss: 6.33366e-02\n",
            "epoch: 7252, iter: 37, training_loss: 6.45068e-02\n",
            "epoch: 7253, iter: 37, training_loss: 6.28707e-02\n",
            "epoch: 7254, iter: 37, training_loss: 6.25858e-02\n",
            "epoch: 7255, iter: 37, training_loss: 6.26949e-02\n",
            "epoch: 7256, iter: 37, training_loss: 6.50246e-02\n",
            "epoch: 7257, iter: 37, training_loss: 6.51074e-02\n",
            "epoch: 7258, iter: 37, training_loss: 6.48902e-02\n",
            "epoch: 7259, iter: 37, training_loss: 6.49877e-02\n",
            "epoch: 7260, iter: 37, training_loss: 6.30887e-02\n",
            "epoch: 7261, iter: 37, training_loss: 6.43638e-02\n",
            "epoch: 7262, iter: 37, training_loss: 6.25611e-02\n",
            "epoch: 7263, iter: 37, training_loss: 6.16812e-02\n",
            "epoch: 7264, iter: 37, training_loss: 6.31078e-02\n",
            "epoch: 7265, iter: 37, training_loss: 6.48429e-02\n",
            "epoch: 7266, iter: 37, training_loss: 6.51091e-02\n",
            "epoch: 7267, iter: 37, training_loss: 6.32560e-02\n",
            "epoch: 7268, iter: 37, training_loss: 6.42349e-02\n",
            "epoch: 7269, iter: 37, training_loss: 6.27261e-02\n",
            "epoch: 7270, iter: 37, training_loss: 6.33167e-02\n",
            "epoch: 7271, iter: 37, training_loss: 6.25140e-02\n",
            "epoch: 7272, iter: 37, training_loss: 6.33815e-02\n",
            "epoch: 7273, iter: 37, training_loss: 6.24296e-02\n",
            "epoch: 7274, iter: 37, training_loss: 6.25394e-02\n",
            "epoch: 7275, iter: 37, training_loss: 6.23428e-02\n",
            "epoch: 7276, iter: 37, training_loss: 6.33823e-02\n",
            "epoch: 7277, iter: 37, training_loss: 6.37396e-02\n",
            "epoch: 7278, iter: 37, training_loss: 6.53122e-02\n",
            "epoch: 7279, iter: 37, training_loss: 6.55678e-02\n",
            "epoch: 7280, iter: 37, training_loss: 6.57011e-02\n",
            "epoch: 7281, iter: 37, training_loss: 6.65376e-02\n",
            "epoch: 7282, iter: 37, training_loss: 6.39617e-02\n",
            "epoch: 7283, iter: 37, training_loss: 6.15655e-02\n",
            "epoch: 7284, iter: 37, training_loss: 6.62266e-02\n",
            "epoch: 7285, iter: 37, training_loss: 6.52256e-02\n",
            "epoch: 7286, iter: 37, training_loss: 6.28651e-02\n",
            "epoch: 7287, iter: 37, training_loss: 6.30844e-02\n",
            "epoch: 7288, iter: 37, training_loss: 6.37784e-02\n",
            "epoch: 7289, iter: 37, training_loss: 6.79030e-02\n",
            "epoch: 7290, iter: 37, training_loss: 6.55565e-02\n",
            "epoch: 7291, iter: 37, training_loss: 6.45887e-02\n",
            "epoch: 7292, iter: 37, training_loss: 6.37413e-02\n",
            "epoch: 7293, iter: 37, training_loss: 6.37133e-02\n",
            "epoch: 7294, iter: 37, training_loss: 6.63525e-02\n",
            "epoch: 7295, iter: 37, training_loss: 6.35919e-02\n",
            "epoch: 7296, iter: 37, training_loss: 6.24216e-02\n",
            "epoch: 7297, iter: 37, training_loss: 6.40462e-02\n",
            "epoch: 7298, iter: 37, training_loss: 6.16590e-02\n",
            "epoch: 7299, iter: 37, training_loss: 6.35943e-02\n",
            "epoch: 7300, iter: 37, training_loss: 6.14827e-02\n",
            "epoch: 7301, iter: 37, training_loss: 6.30448e-02\n",
            "epoch: 7302, iter: 37, training_loss: 6.18949e-02\n",
            "epoch: 7303, iter: 37, training_loss: 6.34114e-02\n",
            "epoch: 7304, iter: 37, training_loss: 6.34754e-02\n",
            "epoch: 7305, iter: 37, training_loss: 6.36112e-02\n",
            "epoch: 7306, iter: 37, training_loss: 6.31341e-02\n",
            "epoch: 7307, iter: 37, training_loss: 6.36113e-02\n",
            "epoch: 7308, iter: 37, training_loss: 6.28145e-02\n",
            "epoch: 7309, iter: 37, training_loss: 6.29607e-02\n",
            "epoch: 7310, iter: 37, training_loss: 6.33138e-02\n",
            "epoch: 7311, iter: 37, training_loss: 6.39185e-02\n",
            "epoch: 7312, iter: 37, training_loss: 6.60901e-02\n",
            "epoch: 7313, iter: 37, training_loss: 6.47340e-02\n",
            "epoch: 7314, iter: 37, training_loss: 6.37840e-02\n",
            "epoch: 7315, iter: 37, training_loss: 6.15892e-02\n",
            "epoch: 7316, iter: 37, training_loss: 6.31169e-02\n",
            "epoch: 7317, iter: 37, training_loss: 6.50138e-02\n",
            "epoch: 7318, iter: 37, training_loss: 6.30391e-02\n",
            "epoch: 7319, iter: 37, training_loss: 6.79478e-02\n",
            "epoch: 7320, iter: 37, training_loss: 6.21740e-02\n",
            "epoch: 7321, iter: 37, training_loss: 6.46363e-02\n",
            "epoch: 7322, iter: 37, training_loss: 6.33443e-02\n",
            "epoch: 7323, iter: 37, training_loss: 6.26327e-02\n",
            "epoch: 7324, iter: 37, training_loss: 6.19204e-02\n",
            "epoch: 7325, iter: 37, training_loss: 6.46404e-02\n",
            "epoch: 7326, iter: 37, training_loss: 6.27910e-02\n",
            "epoch: 7327, iter: 37, training_loss: 6.67845e-02\n",
            "epoch: 7328, iter: 37, training_loss: 6.49418e-02\n",
            "epoch: 7329, iter: 37, training_loss: 6.25409e-02\n",
            "epoch: 7330, iter: 37, training_loss: 6.30623e-02\n",
            "epoch: 7331, iter: 37, training_loss: 6.47986e-02\n",
            "epoch: 7332, iter: 37, training_loss: 6.23005e-02\n",
            "epoch: 7333, iter: 37, training_loss: 6.19814e-02\n",
            "epoch: 7334, iter: 37, training_loss: 6.28707e-02\n",
            "epoch: 7335, iter: 37, training_loss: 6.50412e-02\n",
            "epoch: 7336, iter: 37, training_loss: 6.25527e-02\n",
            "epoch: 7337, iter: 37, training_loss: 6.26370e-02\n",
            "epoch: 7338, iter: 37, training_loss: 6.39917e-02\n",
            "epoch: 7339, iter: 37, training_loss: 6.30805e-02\n",
            "epoch: 7340, iter: 37, training_loss: 6.30104e-02\n",
            "epoch: 7341, iter: 37, training_loss: 6.44406e-02\n",
            "epoch: 7342, iter: 37, training_loss: 6.45873e-02\n",
            "epoch: 7343, iter: 37, training_loss: 6.17115e-02\n",
            "epoch: 7344, iter: 37, training_loss: 6.25027e-02\n",
            "epoch: 7345, iter: 37, training_loss: 6.24921e-02\n",
            "epoch: 7346, iter: 37, training_loss: 6.35804e-02\n",
            "epoch: 7347, iter: 37, training_loss: 6.27019e-02\n",
            "epoch: 7348, iter: 37, training_loss: 6.27851e-02\n",
            "epoch: 7349, iter: 37, training_loss: 6.34474e-02\n",
            "epoch: 7350, iter: 37, training_loss: 6.31609e-02\n",
            "epoch: 7351, iter: 37, training_loss: 6.17735e-02\n",
            "epoch: 7352, iter: 37, training_loss: 6.34019e-02\n",
            "epoch: 7353, iter: 37, training_loss: 6.30415e-02\n",
            "epoch: 7354, iter: 37, training_loss: 6.35000e-02\n",
            "epoch: 7355, iter: 37, training_loss: 6.25595e-02\n",
            "epoch: 7356, iter: 37, training_loss: 6.31931e-02\n",
            "epoch: 7357, iter: 37, training_loss: 6.27880e-02\n",
            "epoch: 7358, iter: 37, training_loss: 6.57358e-02\n",
            "epoch: 7359, iter: 37, training_loss: 6.32352e-02\n",
            "epoch: 7360, iter: 37, training_loss: 6.27247e-02\n",
            "epoch: 7361, iter: 37, training_loss: 6.39979e-02\n",
            "epoch: 7362, iter: 37, training_loss: 6.45151e-02\n",
            "epoch: 7363, iter: 37, training_loss: 6.53666e-02\n",
            "epoch: 7364, iter: 37, training_loss: 6.24317e-02\n",
            "epoch: 7365, iter: 37, training_loss: 6.31108e-02\n",
            "epoch: 7366, iter: 37, training_loss: 6.31283e-02\n",
            "epoch: 7367, iter: 37, training_loss: 6.50128e-02\n",
            "epoch: 7368, iter: 37, training_loss: 6.38530e-02\n",
            "epoch: 7369, iter: 37, training_loss: 6.34821e-02\n",
            "epoch: 7370, iter: 37, training_loss: 6.36632e-02\n",
            "epoch: 7371, iter: 37, training_loss: 6.68091e-02\n",
            "epoch: 7372, iter: 37, training_loss: 6.34239e-02\n",
            "epoch: 7373, iter: 37, training_loss: 6.33621e-02\n",
            "epoch: 7374, iter: 37, training_loss: 6.33195e-02\n",
            "epoch: 7375, iter: 37, training_loss: 6.30827e-02\n",
            "epoch: 7376, iter: 37, training_loss: 6.26390e-02\n",
            "epoch: 7377, iter: 37, training_loss: 6.20360e-02\n",
            "epoch: 7378, iter: 37, training_loss: 6.34862e-02\n",
            "epoch: 7379, iter: 37, training_loss: 6.27761e-02\n",
            "epoch: 7380, iter: 37, training_loss: 6.37285e-02\n",
            "epoch: 7381, iter: 37, training_loss: 6.30468e-02\n",
            "epoch: 7382, iter: 37, training_loss: 6.50332e-02\n",
            "epoch: 7383, iter: 37, training_loss: 6.28124e-02\n",
            "epoch: 7384, iter: 37, training_loss: 6.32113e-02\n",
            "epoch: 7385, iter: 37, training_loss: 6.43053e-02\n",
            "epoch: 7386, iter: 37, training_loss: 6.14470e-02\n",
            "epoch: 7387, iter: 37, training_loss: 6.41042e-02\n",
            "epoch: 7388, iter: 37, training_loss: 6.42187e-02\n",
            "epoch: 7389, iter: 37, training_loss: 6.32218e-02\n",
            "epoch: 7390, iter: 37, training_loss: 6.27295e-02\n",
            "epoch: 7391, iter: 37, training_loss: 6.15671e-02\n",
            "epoch: 7392, iter: 37, training_loss: 6.23249e-02\n",
            "epoch: 7393, iter: 37, training_loss: 6.19001e-02\n",
            "epoch: 7394, iter: 37, training_loss: 6.19451e-02\n",
            "epoch: 7395, iter: 37, training_loss: 6.45584e-02\n",
            "epoch: 7396, iter: 37, training_loss: 6.50686e-02\n",
            "epoch: 7397, iter: 37, training_loss: 6.30011e-02\n",
            "epoch: 7398, iter: 37, training_loss: 6.32815e-02\n",
            "epoch: 7399, iter: 37, training_loss: 6.40154e-02\n",
            "epoch: 7400, iter: 37, training_loss: 6.41602e-02\n",
            "epoch: 7401, iter: 37, training_loss: 6.28074e-02\n",
            "epoch: 7402, iter: 37, training_loss: 6.65587e-02\n",
            "epoch: 7403, iter: 37, training_loss: 6.59055e-02\n",
            "epoch: 7404, iter: 37, training_loss: 6.29238e-02\n",
            "epoch: 7405, iter: 37, training_loss: 6.10182e-02\n",
            "epoch: 7406, iter: 37, training_loss: 6.37147e-02\n",
            "epoch: 7407, iter: 37, training_loss: 6.32773e-02\n",
            "epoch: 7408, iter: 37, training_loss: 6.18695e-02\n",
            "epoch: 7409, iter: 37, training_loss: 6.40217e-02\n",
            "epoch: 7410, iter: 37, training_loss: 6.32291e-02\n",
            "epoch: 7411, iter: 37, training_loss: 6.25883e-02\n",
            "epoch: 7412, iter: 37, training_loss: 6.26537e-02\n",
            "epoch: 7413, iter: 37, training_loss: 6.55254e-02\n",
            "epoch: 7414, iter: 37, training_loss: 6.13461e-02\n",
            "epoch: 7415, iter: 37, training_loss: 6.30650e-02\n",
            "epoch: 7416, iter: 37, training_loss: 6.51889e-02\n",
            "epoch: 7417, iter: 37, training_loss: 6.17861e-02\n",
            "epoch: 7418, iter: 37, training_loss: 6.28241e-02\n",
            "epoch: 7419, iter: 37, training_loss: 6.39341e-02\n",
            "epoch: 7420, iter: 37, training_loss: 6.32694e-02\n",
            "epoch: 7421, iter: 37, training_loss: 6.45406e-02\n",
            "epoch: 7422, iter: 37, training_loss: 6.28233e-02\n",
            "epoch: 7423, iter: 37, training_loss: 6.38396e-02\n",
            "epoch: 7424, iter: 37, training_loss: 6.34082e-02\n",
            "epoch: 7425, iter: 37, training_loss: 6.11039e-02\n",
            "epoch: 7426, iter: 37, training_loss: 6.32739e-02\n",
            "epoch: 7427, iter: 37, training_loss: 6.19160e-02\n",
            "epoch: 7428, iter: 37, training_loss: 6.26108e-02\n",
            "epoch: 7429, iter: 37, training_loss: 6.27233e-02\n",
            "epoch: 7430, iter: 37, training_loss: 6.13218e-02\n",
            "epoch: 7431, iter: 37, training_loss: 6.47636e-02\n",
            "epoch: 7432, iter: 37, training_loss: 6.36428e-02\n",
            "epoch: 7433, iter: 37, training_loss: 6.34753e-02\n",
            "epoch: 7434, iter: 37, training_loss: 6.39820e-02\n",
            "epoch: 7435, iter: 37, training_loss: 6.22819e-02\n",
            "epoch: 7436, iter: 37, training_loss: 6.22983e-02\n",
            "epoch: 7437, iter: 37, training_loss: 6.38589e-02\n",
            "epoch: 7438, iter: 37, training_loss: 6.44568e-02\n",
            "epoch: 7439, iter: 37, training_loss: 6.21216e-02\n",
            "epoch: 7440, iter: 37, training_loss: 6.17512e-02\n",
            "epoch: 7441, iter: 37, training_loss: 6.29242e-02\n",
            "epoch: 7442, iter: 37, training_loss: 6.45830e-02\n",
            "epoch: 7443, iter: 37, training_loss: 6.39608e-02\n",
            "epoch: 7444, iter: 37, training_loss: 6.50542e-02\n",
            "epoch: 7445, iter: 37, training_loss: 6.33720e-02\n",
            "epoch: 7446, iter: 37, training_loss: 6.34090e-02\n",
            "epoch: 7447, iter: 37, training_loss: 6.29677e-02\n",
            "epoch: 7448, iter: 37, training_loss: 6.38275e-02\n",
            "epoch: 7449, iter: 37, training_loss: 6.35861e-02\n",
            "epoch: 7450, iter: 37, training_loss: 6.30102e-02\n",
            "epoch: 7451, iter: 37, training_loss: 6.57862e-02\n",
            "epoch: 7452, iter: 37, training_loss: 6.38578e-02\n",
            "epoch: 7453, iter: 37, training_loss: 6.11984e-02\n",
            "epoch: 7454, iter: 37, training_loss: 6.50719e-02\n",
            "epoch: 7455, iter: 37, training_loss: 6.37732e-02\n",
            "epoch: 7456, iter: 37, training_loss: 6.29407e-02\n",
            "epoch: 7457, iter: 37, training_loss: 6.19430e-02\n",
            "epoch: 7458, iter: 37, training_loss: 6.33009e-02\n",
            "epoch: 7459, iter: 37, training_loss: 6.36093e-02\n",
            "epoch: 7460, iter: 37, training_loss: 6.28898e-02\n",
            "epoch: 7461, iter: 37, training_loss: 6.47344e-02\n",
            "epoch: 7462, iter: 37, training_loss: 6.20971e-02\n",
            "epoch: 7463, iter: 37, training_loss: 6.34299e-02\n",
            "epoch: 7464, iter: 37, training_loss: 6.38585e-02\n",
            "epoch: 7465, iter: 37, training_loss: 6.47899e-02\n",
            "epoch: 7466, iter: 37, training_loss: 6.38135e-02\n",
            "epoch: 7467, iter: 37, training_loss: 6.41182e-02\n",
            "epoch: 7468, iter: 37, training_loss: 6.52218e-02\n",
            "epoch: 7469, iter: 37, training_loss: 6.29765e-02\n",
            "epoch: 7470, iter: 37, training_loss: 6.24654e-02\n",
            "epoch: 7471, iter: 37, training_loss: 6.41469e-02\n",
            "epoch: 7472, iter: 37, training_loss: 6.52254e-02\n",
            "epoch: 7473, iter: 37, training_loss: 6.43367e-02\n",
            "epoch: 7474, iter: 37, training_loss: 6.30779e-02\n",
            "epoch: 7475, iter: 37, training_loss: 6.33726e-02\n",
            "epoch: 7476, iter: 37, training_loss: 6.40311e-02\n",
            "epoch: 7477, iter: 37, training_loss: 6.40405e-02\n",
            "epoch: 7478, iter: 37, training_loss: 6.29813e-02\n",
            "epoch: 7479, iter: 37, training_loss: 6.34874e-02\n",
            "epoch: 7480, iter: 37, training_loss: 6.32699e-02\n",
            "epoch: 7481, iter: 37, training_loss: 6.46179e-02\n",
            "epoch: 7482, iter: 37, training_loss: 6.33524e-02\n",
            "epoch: 7483, iter: 37, training_loss: 6.47436e-02\n",
            "epoch: 7484, iter: 37, training_loss: 6.11364e-02\n",
            "epoch: 7485, iter: 37, training_loss: 6.31864e-02\n",
            "epoch: 7486, iter: 37, training_loss: 6.24590e-02\n",
            "epoch: 7487, iter: 37, training_loss: 6.32536e-02\n",
            "epoch: 7488, iter: 37, training_loss: 6.45118e-02\n",
            "epoch: 7489, iter: 37, training_loss: 6.32425e-02\n",
            "epoch: 7490, iter: 37, training_loss: 6.50576e-02\n",
            "epoch: 7491, iter: 37, training_loss: 6.47176e-02\n",
            "epoch: 7492, iter: 37, training_loss: 6.31860e-02\n",
            "epoch: 7493, iter: 37, training_loss: 6.47499e-02\n",
            "epoch: 7494, iter: 37, training_loss: 6.21513e-02\n",
            "epoch: 7495, iter: 37, training_loss: 6.31338e-02\n",
            "epoch: 7496, iter: 37, training_loss: 6.42757e-02\n",
            "epoch: 7497, iter: 37, training_loss: 6.33312e-02\n",
            "epoch: 7498, iter: 37, training_loss: 6.27796e-02\n",
            "epoch: 7499, iter: 37, training_loss: 6.36310e-02\n",
            "epoch: 7500, iter: 37, training_loss: 6.52125e-02\n",
            "epoch: 7501, iter: 37, training_loss: 6.20625e-02\n",
            "epoch: 7502, iter: 37, training_loss: 6.20437e-02\n",
            "epoch: 7503, iter: 37, training_loss: 6.44525e-02\n",
            "epoch: 7504, iter: 37, training_loss: 6.25440e-02\n",
            "epoch: 7505, iter: 37, training_loss: 6.16307e-02\n",
            "epoch: 7506, iter: 37, training_loss: 6.29647e-02\n",
            "epoch: 7507, iter: 37, training_loss: 6.44974e-02\n",
            "epoch: 7508, iter: 37, training_loss: 6.23984e-02\n",
            "epoch: 7509, iter: 37, training_loss: 6.29520e-02\n",
            "epoch: 7510, iter: 37, training_loss: 6.27222e-02\n",
            "epoch: 7511, iter: 37, training_loss: 6.22378e-02\n",
            "epoch: 7512, iter: 37, training_loss: 6.32868e-02\n",
            "epoch: 7513, iter: 37, training_loss: 6.20429e-02\n",
            "epoch: 7514, iter: 37, training_loss: 6.43964e-02\n",
            "epoch: 7515, iter: 37, training_loss: 6.15798e-02\n",
            "epoch: 7516, iter: 37, training_loss: 6.27545e-02\n",
            "epoch: 7517, iter: 37, training_loss: 6.27915e-02\n",
            "epoch: 7518, iter: 37, training_loss: 6.42687e-02\n",
            "epoch: 7519, iter: 37, training_loss: 6.34421e-02\n",
            "epoch: 7520, iter: 37, training_loss: 6.52684e-02\n",
            "epoch: 7521, iter: 37, training_loss: 6.45735e-02\n",
            "epoch: 7522, iter: 37, training_loss: 6.44763e-02\n",
            "epoch: 7523, iter: 37, training_loss: 6.35419e-02\n",
            "epoch: 7524, iter: 37, training_loss: 6.24239e-02\n",
            "epoch: 7525, iter: 37, training_loss: 6.17043e-02\n",
            "epoch: 7526, iter: 37, training_loss: 6.60157e-02\n",
            "epoch: 7527, iter: 37, training_loss: 6.47196e-02\n",
            "epoch: 7528, iter: 37, training_loss: 6.48395e-02\n",
            "epoch: 7529, iter: 37, training_loss: 6.45353e-02\n",
            "epoch: 7530, iter: 37, training_loss: 6.28086e-02\n",
            "epoch: 7531, iter: 37, training_loss: 6.26336e-02\n",
            "epoch: 7532, iter: 37, training_loss: 6.27798e-02\n",
            "epoch: 7533, iter: 37, training_loss: 6.21249e-02\n",
            "epoch: 7534, iter: 37, training_loss: 6.42952e-02\n",
            "epoch: 7535, iter: 37, training_loss: 6.28284e-02\n",
            "epoch: 7536, iter: 37, training_loss: 6.19580e-02\n",
            "epoch: 7537, iter: 37, training_loss: 6.52287e-02\n",
            "epoch: 7538, iter: 37, training_loss: 6.51989e-02\n",
            "epoch: 7539, iter: 37, training_loss: 6.25776e-02\n",
            "epoch: 7540, iter: 37, training_loss: 6.45656e-02\n",
            "epoch: 7541, iter: 37, training_loss: 6.23904e-02\n",
            "epoch: 7542, iter: 37, training_loss: 6.38722e-02\n",
            "epoch: 7543, iter: 37, training_loss: 6.38800e-02\n",
            "epoch: 7544, iter: 37, training_loss: 6.29898e-02\n",
            "epoch: 7545, iter: 37, training_loss: 6.31136e-02\n",
            "epoch: 7546, iter: 37, training_loss: 6.39994e-02\n",
            "epoch: 7547, iter: 37, training_loss: 6.29676e-02\n",
            "epoch: 7548, iter: 37, training_loss: 6.56981e-02\n",
            "epoch: 7549, iter: 37, training_loss: 6.38569e-02\n",
            "epoch: 7550, iter: 37, training_loss: 6.20768e-02\n",
            "epoch: 7551, iter: 37, training_loss: 6.29248e-02\n",
            "epoch: 7552, iter: 37, training_loss: 6.30855e-02\n",
            "epoch: 7553, iter: 37, training_loss: 6.39798e-02\n",
            "epoch: 7554, iter: 37, training_loss: 6.43045e-02\n",
            "epoch: 7555, iter: 37, training_loss: 6.23646e-02\n",
            "epoch: 7556, iter: 37, training_loss: 6.17234e-02\n",
            "epoch: 7557, iter: 37, training_loss: 6.31593e-02\n",
            "epoch: 7558, iter: 37, training_loss: 6.43171e-02\n",
            "epoch: 7559, iter: 37, training_loss: 6.51707e-02\n",
            "epoch: 7560, iter: 37, training_loss: 6.28019e-02\n",
            "epoch: 7561, iter: 37, training_loss: 6.25485e-02\n",
            "epoch: 7562, iter: 37, training_loss: 6.28304e-02\n",
            "epoch: 7563, iter: 37, training_loss: 6.31529e-02\n",
            "epoch: 7564, iter: 37, training_loss: 6.26015e-02\n",
            "epoch: 7565, iter: 37, training_loss: 6.60267e-02\n",
            "epoch: 7566, iter: 37, training_loss: 6.48169e-02\n",
            "epoch: 7567, iter: 37, training_loss: 6.34629e-02\n",
            "epoch: 7568, iter: 37, training_loss: 6.25616e-02\n",
            "epoch: 7569, iter: 37, training_loss: 6.20795e-02\n",
            "epoch: 7570, iter: 37, training_loss: 6.24670e-02\n",
            "epoch: 7571, iter: 37, training_loss: 6.66442e-02\n",
            "epoch: 7572, iter: 37, training_loss: 6.35055e-02\n",
            "epoch: 7573, iter: 37, training_loss: 6.27776e-02\n",
            "epoch: 7574, iter: 37, training_loss: 6.29643e-02\n",
            "epoch: 7575, iter: 37, training_loss: 6.47148e-02\n",
            "epoch: 7576, iter: 37, training_loss: 6.21435e-02\n",
            "epoch: 7577, iter: 37, training_loss: 6.26019e-02\n",
            "epoch: 7578, iter: 37, training_loss: 6.32794e-02\n",
            "epoch: 7579, iter: 37, training_loss: 6.22160e-02\n",
            "epoch: 7580, iter: 37, training_loss: 6.38364e-02\n",
            "epoch: 7581, iter: 37, training_loss: 6.34322e-02\n",
            "epoch: 7582, iter: 37, training_loss: 6.36325e-02\n",
            "epoch: 7583, iter: 37, training_loss: 6.21594e-02\n",
            "epoch: 7584, iter: 37, training_loss: 6.20901e-02\n",
            "epoch: 7585, iter: 37, training_loss: 6.09715e-02\n",
            "epoch: 7586, iter: 37, training_loss: 6.23909e-02\n",
            "epoch: 7587, iter: 37, training_loss: 6.31805e-02\n",
            "epoch: 7588, iter: 37, training_loss: 6.38247e-02\n",
            "epoch: 7589, iter: 37, training_loss: 6.47087e-02\n",
            "epoch: 7590, iter: 37, training_loss: 6.48496e-02\n",
            "epoch: 7591, iter: 37, training_loss: 6.40534e-02\n",
            "epoch: 7592, iter: 37, training_loss: 6.29679e-02\n",
            "epoch: 7593, iter: 37, training_loss: 6.23931e-02\n",
            "epoch: 7594, iter: 37, training_loss: 6.10218e-02\n",
            "epoch: 7595, iter: 37, training_loss: 6.21068e-02\n",
            "epoch: 7596, iter: 37, training_loss: 6.38390e-02\n",
            "epoch: 7597, iter: 37, training_loss: 6.28558e-02\n",
            "epoch: 7598, iter: 37, training_loss: 6.22831e-02\n",
            "epoch: 7599, iter: 37, training_loss: 6.54765e-02\n",
            "epoch: 7600, iter: 37, training_loss: 6.34182e-02\n",
            "epoch: 7601, iter: 37, training_loss: 6.52365e-02\n",
            "epoch: 7602, iter: 37, training_loss: 6.21406e-02\n",
            "epoch: 7603, iter: 37, training_loss: 6.20995e-02\n",
            "epoch: 7604, iter: 37, training_loss: 6.29415e-02\n",
            "epoch: 7605, iter: 37, training_loss: 6.34663e-02\n",
            "epoch: 7606, iter: 37, training_loss: 6.26806e-02\n",
            "epoch: 7607, iter: 37, training_loss: 6.44586e-02\n",
            "epoch: 7608, iter: 37, training_loss: 6.37393e-02\n",
            "epoch: 7609, iter: 37, training_loss: 6.38104e-02\n",
            "epoch: 7610, iter: 37, training_loss: 6.50314e-02\n",
            "epoch: 7611, iter: 37, training_loss: 6.35142e-02\n",
            "epoch: 7612, iter: 37, training_loss: 6.85780e-02\n",
            "epoch: 7613, iter: 37, training_loss: 6.37968e-02\n",
            "epoch: 7614, iter: 37, training_loss: 6.44128e-02\n",
            "epoch: 7615, iter: 37, training_loss: 6.39383e-02\n",
            "epoch: 7616, iter: 37, training_loss: 6.49012e-02\n",
            "epoch: 7617, iter: 37, training_loss: 6.41846e-02\n",
            "epoch: 7618, iter: 37, training_loss: 6.30015e-02\n",
            "epoch: 7619, iter: 37, training_loss: 6.42597e-02\n",
            "epoch: 7620, iter: 37, training_loss: 6.38630e-02\n",
            "epoch: 7621, iter: 37, training_loss: 6.31127e-02\n",
            "epoch: 7622, iter: 37, training_loss: 6.36654e-02\n",
            "epoch: 7623, iter: 37, training_loss: 6.17867e-02\n",
            "epoch: 7624, iter: 37, training_loss: 6.30712e-02\n",
            "epoch: 7625, iter: 37, training_loss: 6.16973e-02\n",
            "epoch: 7626, iter: 37, training_loss: 6.57765e-02\n",
            "epoch: 7627, iter: 37, training_loss: 6.31196e-02\n",
            "epoch: 7628, iter: 37, training_loss: 6.30194e-02\n",
            "epoch: 7629, iter: 37, training_loss: 6.10457e-02\n",
            "epoch: 7630, iter: 37, training_loss: 6.20979e-02\n",
            "epoch: 7631, iter: 37, training_loss: 6.21110e-02\n",
            "epoch: 7632, iter: 37, training_loss: 6.38087e-02\n",
            "epoch: 7633, iter: 37, training_loss: 6.36887e-02\n",
            "epoch: 7634, iter: 37, training_loss: 6.46415e-02\n",
            "epoch: 7635, iter: 37, training_loss: 6.27989e-02\n",
            "epoch: 7636, iter: 37, training_loss: 6.17166e-02\n",
            "epoch: 7637, iter: 37, training_loss: 6.42244e-02\n",
            "epoch: 7638, iter: 37, training_loss: 6.21255e-02\n",
            "epoch: 7639, iter: 37, training_loss: 6.12689e-02\n",
            "epoch: 7640, iter: 37, training_loss: 6.33534e-02\n",
            "epoch: 7641, iter: 37, training_loss: 6.26774e-02\n",
            "epoch: 7642, iter: 37, training_loss: 6.38870e-02\n",
            "epoch: 7643, iter: 37, training_loss: 6.34578e-02\n",
            "epoch: 7644, iter: 37, training_loss: 6.35770e-02\n",
            "epoch: 7645, iter: 37, training_loss: 6.53168e-02\n",
            "epoch: 7646, iter: 37, training_loss: 6.38318e-02\n",
            "epoch: 7647, iter: 37, training_loss: 6.24843e-02\n",
            "epoch: 7648, iter: 37, training_loss: 6.19926e-02\n",
            "epoch: 7649, iter: 37, training_loss: 6.62923e-02\n",
            "epoch: 7650, iter: 37, training_loss: 6.35592e-02\n",
            "epoch: 7651, iter: 37, training_loss: 6.26090e-02\n",
            "epoch: 7652, iter: 37, training_loss: 6.28798e-02\n",
            "epoch: 7653, iter: 37, training_loss: 6.22133e-02\n",
            "epoch: 7654, iter: 37, training_loss: 6.58359e-02\n",
            "epoch: 7655, iter: 37, training_loss: 6.19055e-02\n",
            "epoch: 7656, iter: 37, training_loss: 6.59542e-02\n",
            "epoch: 7657, iter: 37, training_loss: 6.22662e-02\n",
            "epoch: 7658, iter: 37, training_loss: 6.18260e-02\n",
            "epoch: 7659, iter: 37, training_loss: 6.34844e-02\n",
            "epoch: 7660, iter: 37, training_loss: 6.72693e-02\n",
            "epoch: 7661, iter: 37, training_loss: 6.17115e-02\n",
            "epoch: 7662, iter: 37, training_loss: 6.29815e-02\n",
            "epoch: 7663, iter: 37, training_loss: 6.28179e-02\n",
            "epoch: 7664, iter: 37, training_loss: 6.40561e-02\n",
            "epoch: 7665, iter: 37, training_loss: 6.28238e-02\n",
            "epoch: 7666, iter: 37, training_loss: 6.63764e-02\n",
            "epoch: 7667, iter: 37, training_loss: 6.35246e-02\n",
            "epoch: 7668, iter: 37, training_loss: 6.24465e-02\n",
            "epoch: 7669, iter: 37, training_loss: 6.29074e-02\n",
            "epoch: 7670, iter: 37, training_loss: 6.22191e-02\n",
            "epoch: 7671, iter: 37, training_loss: 6.23193e-02\n",
            "epoch: 7672, iter: 37, training_loss: 6.23878e-02\n",
            "epoch: 7673, iter: 37, training_loss: 6.20808e-02\n",
            "epoch: 7674, iter: 37, training_loss: 6.23977e-02\n",
            "epoch: 7675, iter: 37, training_loss: 6.31721e-02\n",
            "epoch: 7676, iter: 37, training_loss: 6.19368e-02\n",
            "epoch: 7677, iter: 37, training_loss: 6.32990e-02\n",
            "epoch: 7678, iter: 37, training_loss: 6.38757e-02\n",
            "epoch: 7679, iter: 37, training_loss: 6.43334e-02\n",
            "epoch: 7680, iter: 37, training_loss: 6.26098e-02\n",
            "epoch: 7681, iter: 37, training_loss: 6.35499e-02\n",
            "epoch: 7682, iter: 37, training_loss: 6.29942e-02\n",
            "epoch: 7683, iter: 37, training_loss: 6.38341e-02\n",
            "epoch: 7684, iter: 37, training_loss: 6.47072e-02\n",
            "epoch: 7685, iter: 37, training_loss: 6.22551e-02\n",
            "epoch: 7686, iter: 37, training_loss: 6.22981e-02\n",
            "epoch: 7687, iter: 37, training_loss: 6.45903e-02\n",
            "epoch: 7688, iter: 37, training_loss: 6.32796e-02\n",
            "epoch: 7689, iter: 37, training_loss: 6.76720e-02\n",
            "epoch: 7690, iter: 37, training_loss: 6.19853e-02\n",
            "epoch: 7691, iter: 37, training_loss: 6.32477e-02\n",
            "epoch: 7692, iter: 37, training_loss: 6.49749e-02\n",
            "epoch: 7693, iter: 37, training_loss: 6.32128e-02\n",
            "epoch: 7694, iter: 37, training_loss: 6.17040e-02\n",
            "epoch: 7695, iter: 37, training_loss: 6.46125e-02\n",
            "epoch: 7696, iter: 37, training_loss: 6.19376e-02\n",
            "epoch: 7697, iter: 37, training_loss: 6.59286e-02\n",
            "epoch: 7698, iter: 37, training_loss: 6.25312e-02\n",
            "epoch: 7699, iter: 37, training_loss: 6.30533e-02\n",
            "epoch: 7700, iter: 37, training_loss: 6.44213e-02\n",
            "epoch: 7701, iter: 37, training_loss: 6.58182e-02\n",
            "epoch: 7702, iter: 37, training_loss: 6.30759e-02\n",
            "epoch: 7703, iter: 37, training_loss: 6.27140e-02\n",
            "epoch: 7704, iter: 37, training_loss: 6.28242e-02\n",
            "epoch: 7705, iter: 37, training_loss: 6.26553e-02\n",
            "epoch: 7706, iter: 37, training_loss: 6.32254e-02\n",
            "epoch: 7707, iter: 37, training_loss: 6.22091e-02\n",
            "epoch: 7708, iter: 37, training_loss: 6.34168e-02\n",
            "epoch: 7709, iter: 37, training_loss: 6.45640e-02\n",
            "epoch: 7710, iter: 37, training_loss: 6.24481e-02\n",
            "epoch: 7711, iter: 37, training_loss: 6.22691e-02\n",
            "epoch: 7712, iter: 37, training_loss: 6.39897e-02\n",
            "epoch: 7713, iter: 37, training_loss: 6.27007e-02\n",
            "epoch: 7714, iter: 37, training_loss: 6.11416e-02\n",
            "epoch: 7715, iter: 37, training_loss: 6.49487e-02\n",
            "epoch: 7716, iter: 37, training_loss: 6.11984e-02\n",
            "epoch: 7717, iter: 37, training_loss: 6.17720e-02\n",
            "epoch: 7718, iter: 37, training_loss: 6.16639e-02\n",
            "epoch: 7719, iter: 37, training_loss: 6.55674e-02\n",
            "epoch: 7720, iter: 37, training_loss: 6.34905e-02\n",
            "epoch: 7721, iter: 37, training_loss: 6.24211e-02\n",
            "epoch: 7722, iter: 37, training_loss: 6.04877e-02\n",
            "epoch: 7723, iter: 37, training_loss: 6.53749e-02\n",
            "epoch: 7724, iter: 37, training_loss: 6.25533e-02\n",
            "epoch: 7725, iter: 37, training_loss: 6.30378e-02\n",
            "epoch: 7726, iter: 37, training_loss: 6.33131e-02\n",
            "epoch: 7727, iter: 37, training_loss: 6.09060e-02\n",
            "epoch: 7728, iter: 37, training_loss: 6.23652e-02\n",
            "epoch: 7729, iter: 37, training_loss: 6.25540e-02\n",
            "epoch: 7730, iter: 37, training_loss: 6.23938e-02\n",
            "epoch: 7731, iter: 37, training_loss: 6.29557e-02\n",
            "epoch: 7732, iter: 37, training_loss: 6.33566e-02\n",
            "epoch: 7733, iter: 37, training_loss: 6.21368e-02\n",
            "epoch: 7734, iter: 37, training_loss: 6.54117e-02\n",
            "epoch: 7735, iter: 37, training_loss: 6.42051e-02\n",
            "epoch: 7736, iter: 37, training_loss: 6.19440e-02\n",
            "epoch: 7737, iter: 37, training_loss: 6.50322e-02\n",
            "epoch: 7738, iter: 37, training_loss: 6.22614e-02\n",
            "epoch: 7739, iter: 37, training_loss: 6.38141e-02\n",
            "epoch: 7740, iter: 37, training_loss: 6.51459e-02\n",
            "epoch: 7741, iter: 37, training_loss: 6.36033e-02\n",
            "epoch: 7742, iter: 37, training_loss: 6.31646e-02\n",
            "epoch: 7743, iter: 37, training_loss: 6.34696e-02\n",
            "epoch: 7744, iter: 37, training_loss: 6.46155e-02\n",
            "epoch: 7745, iter: 37, training_loss: 6.28755e-02\n",
            "epoch: 7746, iter: 37, training_loss: 6.38820e-02\n",
            "epoch: 7747, iter: 37, training_loss: 6.49017e-02\n",
            "epoch: 7748, iter: 37, training_loss: 6.32986e-02\n",
            "epoch: 7749, iter: 37, training_loss: 6.49038e-02\n",
            "epoch: 7750, iter: 37, training_loss: 6.36598e-02\n",
            "epoch: 7751, iter: 37, training_loss: 6.43335e-02\n",
            "epoch: 7752, iter: 37, training_loss: 6.34138e-02\n",
            "epoch: 7753, iter: 37, training_loss: 6.34906e-02\n",
            "epoch: 7754, iter: 37, training_loss: 6.51132e-02\n",
            "epoch: 7755, iter: 37, training_loss: 6.24005e-02\n",
            "epoch: 7756, iter: 37, training_loss: 6.39071e-02\n",
            "epoch: 7757, iter: 37, training_loss: 6.45651e-02\n",
            "epoch: 7758, iter: 37, training_loss: 6.25103e-02\n",
            "epoch: 7759, iter: 37, training_loss: 6.13934e-02\n",
            "epoch: 7760, iter: 37, training_loss: 6.43814e-02\n",
            "epoch: 7761, iter: 37, training_loss: 6.20496e-02\n",
            "epoch: 7762, iter: 37, training_loss: 6.32695e-02\n",
            "epoch: 7763, iter: 37, training_loss: 6.47900e-02\n",
            "epoch: 7764, iter: 37, training_loss: 6.31501e-02\n",
            "epoch: 7765, iter: 37, training_loss: 6.26153e-02\n",
            "epoch: 7766, iter: 37, training_loss: 6.24871e-02\n",
            "epoch: 7767, iter: 37, training_loss: 6.47315e-02\n",
            "epoch: 7768, iter: 37, training_loss: 6.52023e-02\n",
            "epoch: 7769, iter: 37, training_loss: 6.28099e-02\n",
            "epoch: 7770, iter: 37, training_loss: 6.27705e-02\n",
            "epoch: 7771, iter: 37, training_loss: 6.20087e-02\n",
            "epoch: 7772, iter: 37, training_loss: 6.29204e-02\n",
            "epoch: 7773, iter: 37, training_loss: 6.17127e-02\n",
            "epoch: 7774, iter: 37, training_loss: 6.28643e-02\n",
            "epoch: 7775, iter: 37, training_loss: 6.15170e-02\n",
            "epoch: 7776, iter: 37, training_loss: 6.51334e-02\n",
            "epoch: 7777, iter: 37, training_loss: 6.52464e-02\n",
            "epoch: 7778, iter: 37, training_loss: 6.17365e-02\n",
            "epoch: 7779, iter: 37, training_loss: 6.26201e-02\n",
            "epoch: 7780, iter: 37, training_loss: 6.32503e-02\n",
            "epoch: 7781, iter: 37, training_loss: 6.30338e-02\n",
            "epoch: 7782, iter: 37, training_loss: 6.21561e-02\n",
            "epoch: 7783, iter: 37, training_loss: 6.26934e-02\n",
            "epoch: 7784, iter: 37, training_loss: 6.42374e-02\n",
            "epoch: 7785, iter: 37, training_loss: 6.33817e-02\n",
            "epoch: 7786, iter: 37, training_loss: 6.42872e-02\n",
            "epoch: 7787, iter: 37, training_loss: 6.34860e-02\n",
            "epoch: 7788, iter: 37, training_loss: 6.14177e-02\n",
            "epoch: 7789, iter: 37, training_loss: 6.36479e-02\n",
            "epoch: 7790, iter: 37, training_loss: 6.18315e-02\n",
            "epoch: 7791, iter: 37, training_loss: 6.16780e-02\n",
            "epoch: 7792, iter: 37, training_loss: 6.30186e-02\n",
            "epoch: 7793, iter: 37, training_loss: 6.25851e-02\n",
            "epoch: 7794, iter: 37, training_loss: 6.44931e-02\n",
            "epoch: 7795, iter: 37, training_loss: 6.41687e-02\n",
            "epoch: 7796, iter: 37, training_loss: 6.24922e-02\n",
            "epoch: 7797, iter: 37, training_loss: 6.33314e-02\n",
            "epoch: 7798, iter: 37, training_loss: 6.32675e-02\n",
            "epoch: 7799, iter: 37, training_loss: 6.15295e-02\n",
            "epoch: 7800, iter: 37, training_loss: 6.34040e-02\n",
            "epoch: 7801, iter: 37, training_loss: 6.22262e-02\n",
            "epoch: 7802, iter: 37, training_loss: 6.42813e-02\n",
            "epoch: 7803, iter: 37, training_loss: 6.48348e-02\n",
            "epoch: 7804, iter: 37, training_loss: 6.11205e-02\n",
            "epoch: 7805, iter: 37, training_loss: 6.25626e-02\n",
            "epoch: 7806, iter: 37, training_loss: 6.15486e-02\n",
            "epoch: 7807, iter: 37, training_loss: 6.15121e-02\n",
            "epoch: 7808, iter: 37, training_loss: 6.12357e-02\n",
            "epoch: 7809, iter: 37, training_loss: 6.32442e-02\n",
            "epoch: 7810, iter: 37, training_loss: 6.50418e-02\n",
            "epoch: 7811, iter: 37, training_loss: 6.35435e-02\n",
            "epoch: 7812, iter: 37, training_loss: 6.27818e-02\n",
            "epoch: 7813, iter: 37, training_loss: 6.25902e-02\n",
            "epoch: 7814, iter: 37, training_loss: 6.24865e-02\n",
            "epoch: 7815, iter: 37, training_loss: 6.28465e-02\n",
            "epoch: 7816, iter: 37, training_loss: 6.33459e-02\n",
            "epoch: 7817, iter: 37, training_loss: 6.26483e-02\n",
            "epoch: 7818, iter: 37, training_loss: 6.23158e-02\n",
            "epoch: 7819, iter: 37, training_loss: 6.31348e-02\n",
            "epoch: 7820, iter: 37, training_loss: 6.23610e-02\n",
            "epoch: 7821, iter: 37, training_loss: 6.21708e-02\n",
            "epoch: 7822, iter: 37, training_loss: 6.12945e-02\n",
            "epoch: 7823, iter: 37, training_loss: 6.33262e-02\n",
            "epoch: 7824, iter: 37, training_loss: 6.52576e-02\n",
            "epoch: 7825, iter: 37, training_loss: 6.36208e-02\n",
            "epoch: 7826, iter: 37, training_loss: 6.23296e-02\n",
            "epoch: 7827, iter: 37, training_loss: 6.53311e-02\n",
            "epoch: 7828, iter: 37, training_loss: 6.31551e-02\n",
            "epoch: 7829, iter: 37, training_loss: 6.49415e-02\n",
            "epoch: 7830, iter: 37, training_loss: 6.29992e-02\n",
            "epoch: 7831, iter: 37, training_loss: 6.27053e-02\n",
            "epoch: 7832, iter: 37, training_loss: 6.39040e-02\n",
            "epoch: 7833, iter: 37, training_loss: 6.28232e-02\n",
            "epoch: 7834, iter: 37, training_loss: 6.28922e-02\n",
            "epoch: 7835, iter: 37, training_loss: 6.20102e-02\n",
            "epoch: 7836, iter: 37, training_loss: 6.17947e-02\n",
            "epoch: 7837, iter: 37, training_loss: 6.50889e-02\n",
            "epoch: 7838, iter: 37, training_loss: 6.28420e-02\n",
            "epoch: 7839, iter: 37, training_loss: 6.52016e-02\n",
            "epoch: 7840, iter: 37, training_loss: 6.21659e-02\n",
            "epoch: 7841, iter: 37, training_loss: 6.21528e-02\n",
            "epoch: 7842, iter: 37, training_loss: 6.39341e-02\n",
            "epoch: 7843, iter: 37, training_loss: 6.22051e-02\n",
            "epoch: 7844, iter: 37, training_loss: 6.15630e-02\n",
            "epoch: 7845, iter: 37, training_loss: 6.37326e-02\n",
            "epoch: 7846, iter: 37, training_loss: 6.44838e-02\n",
            "epoch: 7847, iter: 37, training_loss: 6.15016e-02\n",
            "epoch: 7848, iter: 37, training_loss: 6.10131e-02\n",
            "epoch: 7849, iter: 37, training_loss: 6.50301e-02\n",
            "epoch: 7850, iter: 37, training_loss: 6.31674e-02\n",
            "epoch: 7851, iter: 37, training_loss: 6.45417e-02\n",
            "epoch: 7852, iter: 37, training_loss: 6.58799e-02\n",
            "epoch: 7853, iter: 37, training_loss: 6.27669e-02\n",
            "epoch: 7854, iter: 37, training_loss: 6.28828e-02\n",
            "epoch: 7855, iter: 37, training_loss: 6.37058e-02\n",
            "epoch: 7856, iter: 37, training_loss: 6.33583e-02\n",
            "epoch: 7857, iter: 37, training_loss: 6.42892e-02\n",
            "epoch: 7858, iter: 37, training_loss: 6.14695e-02\n",
            "epoch: 7859, iter: 37, training_loss: 6.32921e-02\n",
            "epoch: 7860, iter: 37, training_loss: 6.36553e-02\n",
            "epoch: 7861, iter: 37, training_loss: 6.23614e-02\n",
            "epoch: 7862, iter: 37, training_loss: 6.35557e-02\n",
            "epoch: 7863, iter: 37, training_loss: 6.22470e-02\n",
            "epoch: 7864, iter: 37, training_loss: 6.12253e-02\n",
            "epoch: 7865, iter: 37, training_loss: 6.53151e-02\n",
            "epoch: 7866, iter: 37, training_loss: 6.46816e-02\n",
            "epoch: 7867, iter: 37, training_loss: 6.24132e-02\n",
            "epoch: 7868, iter: 37, training_loss: 6.24421e-02\n",
            "epoch: 7869, iter: 37, training_loss: 6.23205e-02\n",
            "epoch: 7870, iter: 37, training_loss: 6.15695e-02\n",
            "epoch: 7871, iter: 37, training_loss: 6.21280e-02\n",
            "epoch: 7872, iter: 37, training_loss: 6.17283e-02\n",
            "epoch: 7873, iter: 37, training_loss: 6.19561e-02\n",
            "epoch: 7874, iter: 37, training_loss: 6.32419e-02\n",
            "epoch: 7875, iter: 37, training_loss: 6.40064e-02\n",
            "epoch: 7876, iter: 37, training_loss: 6.26549e-02\n",
            "epoch: 7877, iter: 37, training_loss: 6.14962e-02\n",
            "epoch: 7878, iter: 37, training_loss: 6.24530e-02\n",
            "epoch: 7879, iter: 37, training_loss: 6.22363e-02\n",
            "epoch: 7880, iter: 37, training_loss: 6.32018e-02\n",
            "epoch: 7881, iter: 37, training_loss: 6.37200e-02\n",
            "epoch: 7882, iter: 37, training_loss: 6.11065e-02\n",
            "epoch: 7883, iter: 37, training_loss: 6.18979e-02\n",
            "epoch: 7884, iter: 37, training_loss: 6.20289e-02\n",
            "epoch: 7885, iter: 37, training_loss: 6.50218e-02\n",
            "epoch: 7886, iter: 37, training_loss: 6.29018e-02\n",
            "epoch: 7887, iter: 37, training_loss: 6.47741e-02\n",
            "epoch: 7888, iter: 37, training_loss: 6.24681e-02\n",
            "epoch: 7889, iter: 37, training_loss: 6.40377e-02\n",
            "epoch: 7890, iter: 37, training_loss: 6.30055e-02\n",
            "epoch: 7891, iter: 37, training_loss: 6.30611e-02\n",
            "epoch: 7892, iter: 37, training_loss: 6.21377e-02\n",
            "epoch: 7893, iter: 37, training_loss: 6.17631e-02\n",
            "epoch: 7894, iter: 37, training_loss: 6.14667e-02\n",
            "epoch: 7895, iter: 37, training_loss: 6.28628e-02\n",
            "epoch: 7896, iter: 37, training_loss: 6.36318e-02\n",
            "epoch: 7897, iter: 37, training_loss: 6.14289e-02\n",
            "epoch: 7898, iter: 37, training_loss: 6.27000e-02\n",
            "epoch: 7899, iter: 37, training_loss: 6.26872e-02\n",
            "epoch: 7900, iter: 37, training_loss: 6.20501e-02\n",
            "epoch: 7901, iter: 37, training_loss: 6.37886e-02\n",
            "epoch: 7902, iter: 37, training_loss: 6.33461e-02\n",
            "epoch: 7903, iter: 37, training_loss: 6.23653e-02\n",
            "epoch: 7904, iter: 37, training_loss: 6.43832e-02\n",
            "epoch: 7905, iter: 37, training_loss: 6.25033e-02\n",
            "epoch: 7906, iter: 37, training_loss: 6.43412e-02\n",
            "epoch: 7907, iter: 37, training_loss: 6.33099e-02\n",
            "epoch: 7908, iter: 37, training_loss: 6.31615e-02\n",
            "epoch: 7909, iter: 37, training_loss: 6.40196e-02\n",
            "epoch: 7910, iter: 37, training_loss: 6.39219e-02\n",
            "epoch: 7911, iter: 37, training_loss: 6.27117e-02\n",
            "epoch: 7912, iter: 37, training_loss: 6.15344e-02\n",
            "epoch: 7913, iter: 37, training_loss: 6.35870e-02\n",
            "epoch: 7914, iter: 37, training_loss: 6.31128e-02\n",
            "epoch: 7915, iter: 37, training_loss: 6.20185e-02\n",
            "epoch: 7916, iter: 37, training_loss: 6.45466e-02\n",
            "epoch: 7917, iter: 37, training_loss: 6.18913e-02\n",
            "epoch: 7918, iter: 37, training_loss: 6.28734e-02\n",
            "epoch: 7919, iter: 37, training_loss: 6.51863e-02\n",
            "epoch: 7920, iter: 37, training_loss: 6.46076e-02\n",
            "epoch: 7921, iter: 37, training_loss: 6.25741e-02\n",
            "epoch: 7922, iter: 37, training_loss: 6.33739e-02\n",
            "epoch: 7923, iter: 37, training_loss: 6.27659e-02\n",
            "epoch: 7924, iter: 37, training_loss: 6.41066e-02\n",
            "epoch: 7925, iter: 37, training_loss: 6.29392e-02\n",
            "epoch: 7926, iter: 37, training_loss: 6.38067e-02\n",
            "epoch: 7927, iter: 37, training_loss: 6.35158e-02\n",
            "epoch: 7928, iter: 37, training_loss: 6.14924e-02\n",
            "epoch: 7929, iter: 37, training_loss: 6.16586e-02\n",
            "epoch: 7930, iter: 37, training_loss: 6.25898e-02\n",
            "epoch: 7931, iter: 37, training_loss: 6.11632e-02\n",
            "epoch: 7932, iter: 37, training_loss: 6.11209e-02\n",
            "epoch: 7933, iter: 37, training_loss: 6.42957e-02\n",
            "epoch: 7934, iter: 37, training_loss: 6.42212e-02\n",
            "epoch: 7935, iter: 37, training_loss: 6.23593e-02\n",
            "epoch: 7936, iter: 37, training_loss: 6.30896e-02\n",
            "epoch: 7937, iter: 37, training_loss: 6.52228e-02\n",
            "epoch: 7938, iter: 37, training_loss: 6.29465e-02\n",
            "epoch: 7939, iter: 37, training_loss: 6.35346e-02\n",
            "epoch: 7940, iter: 37, training_loss: 6.29230e-02\n",
            "epoch: 7941, iter: 37, training_loss: 6.13866e-02\n",
            "epoch: 7942, iter: 37, training_loss: 6.13186e-02\n",
            "epoch: 7943, iter: 37, training_loss: 6.34693e-02\n",
            "epoch: 7944, iter: 37, training_loss: 6.39638e-02\n",
            "epoch: 7945, iter: 37, training_loss: 6.26568e-02\n",
            "epoch: 7946, iter: 37, training_loss: 6.19606e-02\n",
            "epoch: 7947, iter: 37, training_loss: 6.25299e-02\n",
            "epoch: 7948, iter: 37, training_loss: 6.27704e-02\n",
            "epoch: 7949, iter: 37, training_loss: 6.32038e-02\n",
            "epoch: 7950, iter: 37, training_loss: 6.34281e-02\n",
            "epoch: 7951, iter: 37, training_loss: 6.25466e-02\n",
            "epoch: 7952, iter: 37, training_loss: 6.30637e-02\n",
            "epoch: 7953, iter: 37, training_loss: 6.19141e-02\n",
            "epoch: 7954, iter: 37, training_loss: 6.20948e-02\n",
            "epoch: 7955, iter: 37, training_loss: 6.38291e-02\n",
            "epoch: 7956, iter: 37, training_loss: 6.12587e-02\n",
            "epoch: 7957, iter: 37, training_loss: 6.49223e-02\n",
            "epoch: 7958, iter: 37, training_loss: 6.19129e-02\n",
            "epoch: 7959, iter: 37, training_loss: 6.19462e-02\n",
            "epoch: 7960, iter: 37, training_loss: 6.36713e-02\n",
            "epoch: 7961, iter: 37, training_loss: 6.32886e-02\n",
            "epoch: 7962, iter: 37, training_loss: 6.42142e-02\n",
            "epoch: 7963, iter: 37, training_loss: 6.51052e-02\n",
            "epoch: 7964, iter: 37, training_loss: 6.36311e-02\n",
            "epoch: 7965, iter: 37, training_loss: 6.19377e-02\n",
            "epoch: 7966, iter: 37, training_loss: 6.19626e-02\n",
            "epoch: 7967, iter: 37, training_loss: 6.14265e-02\n",
            "epoch: 7968, iter: 37, training_loss: 6.31614e-02\n",
            "epoch: 7969, iter: 37, training_loss: 6.35995e-02\n",
            "epoch: 7970, iter: 37, training_loss: 6.24325e-02\n",
            "epoch: 7971, iter: 37, training_loss: 6.32166e-02\n",
            "epoch: 7972, iter: 37, training_loss: 6.25621e-02\n",
            "epoch: 7973, iter: 37, training_loss: 6.31489e-02\n",
            "epoch: 7974, iter: 37, training_loss: 6.20572e-02\n",
            "epoch: 7975, iter: 37, training_loss: 6.24898e-02\n",
            "epoch: 7976, iter: 37, training_loss: 6.29776e-02\n",
            "epoch: 7977, iter: 37, training_loss: 6.81618e-02\n",
            "epoch: 7978, iter: 37, training_loss: 6.27854e-02\n",
            "epoch: 7979, iter: 37, training_loss: 6.20668e-02\n",
            "epoch: 7980, iter: 37, training_loss: 6.47577e-02\n",
            "epoch: 7981, iter: 37, training_loss: 6.27923e-02\n",
            "epoch: 7982, iter: 37, training_loss: 6.43986e-02\n",
            "epoch: 7983, iter: 37, training_loss: 6.23301e-02\n",
            "epoch: 7984, iter: 37, training_loss: 6.24878e-02\n",
            "epoch: 7985, iter: 37, training_loss: 6.24639e-02\n",
            "epoch: 7986, iter: 37, training_loss: 6.33733e-02\n",
            "epoch: 7987, iter: 37, training_loss: 6.30202e-02\n",
            "epoch: 7988, iter: 37, training_loss: 6.21685e-02\n",
            "epoch: 7989, iter: 37, training_loss: 6.45633e-02\n",
            "epoch: 7990, iter: 37, training_loss: 6.32599e-02\n",
            "epoch: 7991, iter: 37, training_loss: 6.43984e-02\n",
            "epoch: 7992, iter: 37, training_loss: 6.29023e-02\n",
            "epoch: 7993, iter: 37, training_loss: 6.44442e-02\n",
            "epoch: 7994, iter: 37, training_loss: 6.31786e-02\n",
            "epoch: 7995, iter: 37, training_loss: 6.39403e-02\n",
            "epoch: 7996, iter: 37, training_loss: 6.23215e-02\n",
            "epoch: 7997, iter: 37, training_loss: 6.22144e-02\n",
            "epoch: 7998, iter: 37, training_loss: 6.15370e-02\n",
            "epoch: 7999, iter: 37, training_loss: 6.41626e-02\n",
            "epoch: 8000, iter: 37, training_loss: 6.13134e-02\n",
            "epoch: 8001, iter: 37, training_loss: 6.30745e-02\n",
            "epoch: 8002, iter: 37, training_loss: 6.33688e-02\n",
            "epoch: 8003, iter: 37, training_loss: 6.41810e-02\n",
            "epoch: 8004, iter: 37, training_loss: 6.15765e-02\n",
            "epoch: 8005, iter: 37, training_loss: 6.62881e-02\n",
            "epoch: 8006, iter: 37, training_loss: 6.29099e-02\n",
            "epoch: 8007, iter: 37, training_loss: 6.37011e-02\n",
            "epoch: 8008, iter: 37, training_loss: 6.34676e-02\n",
            "epoch: 8009, iter: 37, training_loss: 6.47147e-02\n",
            "epoch: 8010, iter: 37, training_loss: 6.39914e-02\n",
            "epoch: 8011, iter: 37, training_loss: 6.41432e-02\n",
            "epoch: 8012, iter: 37, training_loss: 6.31660e-02\n",
            "epoch: 8013, iter: 37, training_loss: 6.27837e-02\n",
            "epoch: 8014, iter: 37, training_loss: 6.28196e-02\n",
            "epoch: 8015, iter: 37, training_loss: 6.38013e-02\n",
            "epoch: 8016, iter: 37, training_loss: 6.34410e-02\n",
            "epoch: 8017, iter: 37, training_loss: 6.33000e-02\n",
            "epoch: 8018, iter: 37, training_loss: 6.22706e-02\n",
            "epoch: 8019, iter: 37, training_loss: 6.34786e-02\n",
            "epoch: 8020, iter: 37, training_loss: 6.05667e-02\n",
            "epoch: 8021, iter: 37, training_loss: 6.49337e-02\n",
            "epoch: 8022, iter: 37, training_loss: 6.28988e-02\n",
            "epoch: 8023, iter: 37, training_loss: 6.34225e-02\n",
            "epoch: 8024, iter: 37, training_loss: 6.13766e-02\n",
            "epoch: 8025, iter: 37, training_loss: 6.24845e-02\n",
            "epoch: 8026, iter: 37, training_loss: 6.15965e-02\n",
            "epoch: 8027, iter: 37, training_loss: 6.13975e-02\n",
            "epoch: 8028, iter: 37, training_loss: 6.31401e-02\n",
            "epoch: 8029, iter: 37, training_loss: 6.31332e-02\n",
            "epoch: 8030, iter: 37, training_loss: 6.30774e-02\n",
            "epoch: 8031, iter: 37, training_loss: 6.44354e-02\n",
            "epoch: 8032, iter: 37, training_loss: 6.40290e-02\n",
            "epoch: 8033, iter: 37, training_loss: 6.26005e-02\n",
            "epoch: 8034, iter: 37, training_loss: 6.17811e-02\n",
            "epoch: 8035, iter: 37, training_loss: 6.38928e-02\n",
            "epoch: 8036, iter: 37, training_loss: 6.29437e-02\n",
            "epoch: 8037, iter: 37, training_loss: 6.27436e-02\n",
            "epoch: 8038, iter: 37, training_loss: 6.12324e-02\n",
            "epoch: 8039, iter: 37, training_loss: 6.40593e-02\n",
            "epoch: 8040, iter: 37, training_loss: 6.40818e-02\n",
            "epoch: 8041, iter: 37, training_loss: 6.23158e-02\n",
            "epoch: 8042, iter: 37, training_loss: 6.21915e-02\n",
            "epoch: 8043, iter: 37, training_loss: 6.39647e-02\n",
            "epoch: 8044, iter: 37, training_loss: 6.38682e-02\n",
            "epoch: 8045, iter: 37, training_loss: 6.49783e-02\n",
            "epoch: 8046, iter: 37, training_loss: 6.30223e-02\n",
            "epoch: 8047, iter: 37, training_loss: 6.38319e-02\n",
            "epoch: 8048, iter: 37, training_loss: 6.21289e-02\n",
            "epoch: 8049, iter: 37, training_loss: 6.09059e-02\n",
            "epoch: 8050, iter: 37, training_loss: 6.22489e-02\n",
            "epoch: 8051, iter: 37, training_loss: 6.34766e-02\n",
            "epoch: 8052, iter: 37, training_loss: 6.30995e-02\n",
            "epoch: 8053, iter: 37, training_loss: 6.52456e-02\n",
            "epoch: 8054, iter: 37, training_loss: 6.24273e-02\n",
            "epoch: 8055, iter: 37, training_loss: 6.33456e-02\n",
            "epoch: 8056, iter: 37, training_loss: 6.17853e-02\n",
            "epoch: 8057, iter: 37, training_loss: 6.34198e-02\n",
            "epoch: 8058, iter: 37, training_loss: 6.36112e-02\n",
            "epoch: 8059, iter: 37, training_loss: 6.66452e-02\n",
            "epoch: 8060, iter: 37, training_loss: 6.19473e-02\n",
            "epoch: 8061, iter: 37, training_loss: 6.33064e-02\n",
            "epoch: 8062, iter: 37, training_loss: 6.31010e-02\n",
            "epoch: 8063, iter: 37, training_loss: 6.28604e-02\n",
            "epoch: 8064, iter: 37, training_loss: 6.41052e-02\n",
            "epoch: 8065, iter: 37, training_loss: 6.37072e-02\n",
            "epoch: 8066, iter: 37, training_loss: 6.25842e-02\n",
            "epoch: 8067, iter: 37, training_loss: 6.23680e-02\n",
            "epoch: 8068, iter: 37, training_loss: 6.36116e-02\n",
            "epoch: 8069, iter: 37, training_loss: 6.23502e-02\n",
            "epoch: 8070, iter: 37, training_loss: 6.41235e-02\n",
            "epoch: 8071, iter: 37, training_loss: 6.31004e-02\n",
            "epoch: 8072, iter: 37, training_loss: 6.20316e-02\n",
            "epoch: 8073, iter: 37, training_loss: 6.08743e-02\n",
            "epoch: 8074, iter: 37, training_loss: 6.33920e-02\n",
            "epoch: 8075, iter: 37, training_loss: 6.18695e-02\n",
            "epoch: 8076, iter: 37, training_loss: 6.13986e-02\n",
            "epoch: 8077, iter: 37, training_loss: 6.22590e-02\n",
            "epoch: 8078, iter: 37, training_loss: 6.28367e-02\n",
            "epoch: 8079, iter: 37, training_loss: 6.08244e-02\n",
            "epoch: 8080, iter: 37, training_loss: 6.24749e-02\n",
            "epoch: 8081, iter: 37, training_loss: 6.43973e-02\n",
            "epoch: 8082, iter: 37, training_loss: 6.07882e-02\n",
            "epoch: 8083, iter: 37, training_loss: 6.40728e-02\n",
            "epoch: 8084, iter: 37, training_loss: 6.65657e-02\n",
            "epoch: 8085, iter: 37, training_loss: 6.12966e-02\n",
            "epoch: 8086, iter: 37, training_loss: 6.20876e-02\n",
            "epoch: 8087, iter: 37, training_loss: 6.29645e-02\n",
            "epoch: 8088, iter: 37, training_loss: 6.28271e-02\n",
            "epoch: 8089, iter: 37, training_loss: 6.43019e-02\n",
            "epoch: 8090, iter: 37, training_loss: 6.47862e-02\n",
            "epoch: 8091, iter: 37, training_loss: 6.45327e-02\n",
            "epoch: 8092, iter: 37, training_loss: 6.24135e-02\n",
            "epoch: 8093, iter: 37, training_loss: 6.24469e-02\n",
            "epoch: 8094, iter: 37, training_loss: 6.25425e-02\n",
            "epoch: 8095, iter: 37, training_loss: 6.33432e-02\n",
            "epoch: 8096, iter: 37, training_loss: 6.15955e-02\n",
            "epoch: 8097, iter: 37, training_loss: 6.35308e-02\n",
            "epoch: 8098, iter: 37, training_loss: 6.10502e-02\n",
            "epoch: 8099, iter: 37, training_loss: 6.62634e-02\n",
            "epoch: 8100, iter: 37, training_loss: 6.42279e-02\n",
            "epoch: 8101, iter: 37, training_loss: 6.41388e-02\n",
            "epoch: 8102, iter: 37, training_loss: 6.33381e-02\n",
            "epoch: 8103, iter: 37, training_loss: 6.26177e-02\n",
            "epoch: 8104, iter: 37, training_loss: 6.34670e-02\n",
            "epoch: 8105, iter: 37, training_loss: 6.10466e-02\n",
            "epoch: 8106, iter: 37, training_loss: 6.20595e-02\n",
            "epoch: 8107, iter: 37, training_loss: 6.35171e-02\n",
            "epoch: 8108, iter: 37, training_loss: 6.43808e-02\n",
            "epoch: 8109, iter: 37, training_loss: 6.34643e-02\n",
            "epoch: 8110, iter: 37, training_loss: 6.39418e-02\n",
            "epoch: 8111, iter: 37, training_loss: 6.22520e-02\n",
            "epoch: 8112, iter: 37, training_loss: 6.43714e-02\n",
            "epoch: 8113, iter: 37, training_loss: 6.18826e-02\n",
            "epoch: 8114, iter: 37, training_loss: 6.09812e-02\n",
            "epoch: 8115, iter: 37, training_loss: 6.23503e-02\n",
            "epoch: 8116, iter: 37, training_loss: 6.66007e-02\n",
            "epoch: 8117, iter: 37, training_loss: 6.31784e-02\n",
            "epoch: 8118, iter: 37, training_loss: 6.22505e-02\n",
            "epoch: 8119, iter: 37, training_loss: 6.09907e-02\n",
            "epoch: 8120, iter: 37, training_loss: 6.34088e-02\n",
            "epoch: 8121, iter: 37, training_loss: 6.28056e-02\n",
            "epoch: 8122, iter: 37, training_loss: 6.03459e-02\n",
            "epoch: 8123, iter: 37, training_loss: 6.21726e-02\n",
            "epoch: 8124, iter: 37, training_loss: 6.41007e-02\n",
            "epoch: 8125, iter: 37, training_loss: 6.36172e-02\n",
            "epoch: 8126, iter: 37, training_loss: 6.35542e-02\n",
            "epoch: 8127, iter: 37, training_loss: 6.55264e-02\n",
            "epoch: 8128, iter: 37, training_loss: 6.14189e-02\n",
            "epoch: 8129, iter: 37, training_loss: 6.38027e-02\n",
            "epoch: 8130, iter: 37, training_loss: 6.21803e-02\n",
            "epoch: 8131, iter: 37, training_loss: 6.29283e-02\n",
            "epoch: 8132, iter: 37, training_loss: 6.35349e-02\n",
            "epoch: 8133, iter: 37, training_loss: 6.29111e-02\n",
            "epoch: 8134, iter: 37, training_loss: 6.31434e-02\n",
            "epoch: 8135, iter: 37, training_loss: 6.47222e-02\n",
            "epoch: 8136, iter: 37, training_loss: 6.21242e-02\n",
            "epoch: 8137, iter: 37, training_loss: 6.13637e-02\n",
            "epoch: 8138, iter: 37, training_loss: 6.19125e-02\n",
            "epoch: 8139, iter: 37, training_loss: 6.44186e-02\n",
            "epoch: 8140, iter: 37, training_loss: 6.33351e-02\n",
            "epoch: 8141, iter: 37, training_loss: 6.21022e-02\n",
            "epoch: 8142, iter: 37, training_loss: 6.31771e-02\n",
            "epoch: 8143, iter: 37, training_loss: 6.19427e-02\n",
            "epoch: 8144, iter: 37, training_loss: 6.35265e-02\n",
            "epoch: 8145, iter: 37, training_loss: 6.28283e-02\n",
            "epoch: 8146, iter: 37, training_loss: 6.25084e-02\n",
            "epoch: 8147, iter: 37, training_loss: 6.22329e-02\n",
            "epoch: 8148, iter: 37, training_loss: 6.37675e-02\n",
            "epoch: 8149, iter: 37, training_loss: 6.26056e-02\n",
            "epoch: 8150, iter: 37, training_loss: 6.03844e-02\n",
            "epoch: 8151, iter: 37, training_loss: 6.24367e-02\n",
            "epoch: 8152, iter: 37, training_loss: 6.11120e-02\n",
            "epoch: 8153, iter: 37, training_loss: 6.25432e-02\n",
            "epoch: 8154, iter: 37, training_loss: 6.23405e-02\n",
            "epoch: 8155, iter: 37, training_loss: 6.19290e-02\n",
            "epoch: 8156, iter: 37, training_loss: 6.21595e-02\n",
            "epoch: 8157, iter: 37, training_loss: 6.25243e-02\n",
            "epoch: 8158, iter: 37, training_loss: 6.13250e-02\n",
            "epoch: 8159, iter: 37, training_loss: 6.45365e-02\n",
            "epoch: 8160, iter: 37, training_loss: 6.37764e-02\n",
            "epoch: 8161, iter: 37, training_loss: 6.62004e-02\n",
            "epoch: 8162, iter: 37, training_loss: 6.27741e-02\n",
            "epoch: 8163, iter: 37, training_loss: 6.22859e-02\n",
            "epoch: 8164, iter: 37, training_loss: 6.15906e-02\n",
            "epoch: 8165, iter: 37, training_loss: 6.07358e-02\n",
            "epoch: 8166, iter: 37, training_loss: 6.44231e-02\n",
            "epoch: 8167, iter: 37, training_loss: 6.12692e-02\n",
            "epoch: 8168, iter: 37, training_loss: 6.16418e-02\n",
            "epoch: 8169, iter: 37, training_loss: 6.23199e-02\n",
            "epoch: 8170, iter: 37, training_loss: 6.28149e-02\n",
            "epoch: 8171, iter: 37, training_loss: 6.35945e-02\n",
            "epoch: 8172, iter: 37, training_loss: 6.18434e-02\n",
            "epoch: 8173, iter: 37, training_loss: 6.23130e-02\n",
            "epoch: 8174, iter: 37, training_loss: 5.99122e-02\n",
            "epoch: 8175, iter: 37, training_loss: 6.19792e-02\n",
            "epoch: 8176, iter: 37, training_loss: 6.25287e-02\n",
            "epoch: 8177, iter: 37, training_loss: 6.11790e-02\n",
            "epoch: 8178, iter: 37, training_loss: 6.17634e-02\n",
            "epoch: 8179, iter: 37, training_loss: 6.27004e-02\n",
            "epoch: 8180, iter: 37, training_loss: 6.24840e-02\n",
            "epoch: 8181, iter: 37, training_loss: 6.21485e-02\n",
            "epoch: 8182, iter: 37, training_loss: 6.11568e-02\n",
            "epoch: 8183, iter: 37, training_loss: 6.40279e-02\n",
            "epoch: 8184, iter: 37, training_loss: 6.24685e-02\n",
            "epoch: 8185, iter: 37, training_loss: 6.28572e-02\n",
            "epoch: 8186, iter: 37, training_loss: 6.09582e-02\n",
            "epoch: 8187, iter: 37, training_loss: 6.30166e-02\n",
            "epoch: 8188, iter: 37, training_loss: 6.24618e-02\n",
            "epoch: 8189, iter: 37, training_loss: 6.27569e-02\n",
            "epoch: 8190, iter: 37, training_loss: 6.17052e-02\n",
            "epoch: 8191, iter: 37, training_loss: 6.18505e-02\n",
            "epoch: 8192, iter: 37, training_loss: 6.19507e-02\n",
            "epoch: 8193, iter: 37, training_loss: 6.35582e-02\n",
            "epoch: 8194, iter: 37, training_loss: 6.11571e-02\n",
            "epoch: 8195, iter: 37, training_loss: 6.22862e-02\n",
            "epoch: 8196, iter: 37, training_loss: 6.17897e-02\n",
            "epoch: 8197, iter: 37, training_loss: 6.11853e-02\n",
            "epoch: 8198, iter: 37, training_loss: 6.33418e-02\n",
            "epoch: 8199, iter: 37, training_loss: 6.22516e-02\n",
            "epoch: 8200, iter: 37, training_loss: 6.19889e-02\n",
            "epoch: 8201, iter: 37, training_loss: 6.09564e-02\n",
            "epoch: 8202, iter: 37, training_loss: 6.19236e-02\n",
            "epoch: 8203, iter: 37, training_loss: 6.36675e-02\n",
            "epoch: 8204, iter: 37, training_loss: 6.38747e-02\n",
            "epoch: 8205, iter: 37, training_loss: 6.41661e-02\n",
            "epoch: 8206, iter: 37, training_loss: 6.34453e-02\n",
            "epoch: 8207, iter: 37, training_loss: 6.22243e-02\n",
            "epoch: 8208, iter: 37, training_loss: 6.18141e-02\n",
            "epoch: 8209, iter: 37, training_loss: 6.13940e-02\n",
            "epoch: 8210, iter: 37, training_loss: 6.13172e-02\n",
            "epoch: 8211, iter: 37, training_loss: 6.21425e-02\n",
            "epoch: 8212, iter: 37, training_loss: 6.33027e-02\n",
            "epoch: 8213, iter: 37, training_loss: 6.27764e-02\n",
            "epoch: 8214, iter: 37, training_loss: 6.21358e-02\n",
            "epoch: 8215, iter: 37, training_loss: 6.37190e-02\n",
            "epoch: 8216, iter: 37, training_loss: 6.07812e-02\n",
            "epoch: 8217, iter: 37, training_loss: 6.23663e-02\n",
            "epoch: 8218, iter: 37, training_loss: 6.21788e-02\n",
            "epoch: 8219, iter: 37, training_loss: 6.24602e-02\n",
            "epoch: 8220, iter: 37, training_loss: 6.14301e-02\n",
            "epoch: 8221, iter: 37, training_loss: 6.35472e-02\n",
            "epoch: 8222, iter: 37, training_loss: 6.35127e-02\n",
            "epoch: 8223, iter: 37, training_loss: 6.41402e-02\n",
            "epoch: 8224, iter: 37, training_loss: 6.27438e-02\n",
            "epoch: 8225, iter: 37, training_loss: 6.21311e-02\n",
            "epoch: 8226, iter: 37, training_loss: 6.34960e-02\n",
            "epoch: 8227, iter: 37, training_loss: 6.17275e-02\n",
            "epoch: 8228, iter: 37, training_loss: 6.20187e-02\n",
            "epoch: 8229, iter: 37, training_loss: 6.33530e-02\n",
            "epoch: 8230, iter: 37, training_loss: 6.28817e-02\n",
            "epoch: 8231, iter: 37, training_loss: 6.25477e-02\n",
            "epoch: 8232, iter: 37, training_loss: 6.14209e-02\n",
            "epoch: 8233, iter: 37, training_loss: 6.29646e-02\n",
            "epoch: 8234, iter: 37, training_loss: 6.45209e-02\n",
            "epoch: 8235, iter: 37, training_loss: 6.28802e-02\n",
            "epoch: 8236, iter: 37, training_loss: 6.15457e-02\n",
            "epoch: 8237, iter: 37, training_loss: 6.26728e-02\n",
            "epoch: 8238, iter: 37, training_loss: 6.09269e-02\n",
            "epoch: 8239, iter: 37, training_loss: 6.15990e-02\n",
            "epoch: 8240, iter: 37, training_loss: 6.34884e-02\n",
            "epoch: 8241, iter: 37, training_loss: 6.30021e-02\n",
            "epoch: 8242, iter: 37, training_loss: 6.11907e-02\n",
            "epoch: 8243, iter: 37, training_loss: 6.30271e-02\n",
            "epoch: 8244, iter: 37, training_loss: 6.15285e-02\n",
            "epoch: 8245, iter: 37, training_loss: 6.26644e-02\n",
            "epoch: 8246, iter: 37, training_loss: 6.53466e-02\n",
            "epoch: 8247, iter: 37, training_loss: 6.31709e-02\n",
            "epoch: 8248, iter: 37, training_loss: 6.20388e-02\n",
            "epoch: 8249, iter: 37, training_loss: 6.19244e-02\n",
            "epoch: 8250, iter: 37, training_loss: 6.39926e-02\n",
            "epoch: 8251, iter: 37, training_loss: 6.19180e-02\n",
            "epoch: 8252, iter: 37, training_loss: 6.16789e-02\n",
            "epoch: 8253, iter: 37, training_loss: 6.68581e-02\n",
            "epoch: 8254, iter: 37, training_loss: 6.53597e-02\n",
            "epoch: 8255, iter: 37, training_loss: 6.26648e-02\n",
            "epoch: 8256, iter: 37, training_loss: 6.28589e-02\n",
            "epoch: 8257, iter: 37, training_loss: 6.20844e-02\n",
            "epoch: 8258, iter: 37, training_loss: 6.26874e-02\n",
            "epoch: 8259, iter: 37, training_loss: 6.19153e-02\n",
            "epoch: 8260, iter: 37, training_loss: 6.31515e-02\n",
            "epoch: 8261, iter: 37, training_loss: 6.35498e-02\n",
            "epoch: 8262, iter: 37, training_loss: 6.09426e-02\n",
            "epoch: 8263, iter: 37, training_loss: 6.11098e-02\n",
            "epoch: 8264, iter: 37, training_loss: 6.17385e-02\n",
            "epoch: 8265, iter: 37, training_loss: 6.39781e-02\n",
            "epoch: 8266, iter: 37, training_loss: 6.10943e-02\n",
            "epoch: 8267, iter: 37, training_loss: 6.37893e-02\n",
            "epoch: 8268, iter: 37, training_loss: 6.35672e-02\n",
            "epoch: 8269, iter: 37, training_loss: 6.30468e-02\n",
            "epoch: 8270, iter: 37, training_loss: 6.46769e-02\n",
            "epoch: 8271, iter: 37, training_loss: 6.23724e-02\n",
            "epoch: 8272, iter: 37, training_loss: 6.19007e-02\n",
            "epoch: 8273, iter: 37, training_loss: 6.33007e-02\n",
            "epoch: 8274, iter: 37, training_loss: 6.31889e-02\n",
            "epoch: 8275, iter: 37, training_loss: 6.27886e-02\n",
            "epoch: 8276, iter: 37, training_loss: 6.24311e-02\n",
            "epoch: 8277, iter: 37, training_loss: 6.24530e-02\n",
            "epoch: 8278, iter: 37, training_loss: 6.19234e-02\n",
            "epoch: 8279, iter: 37, training_loss: 6.34559e-02\n",
            "epoch: 8280, iter: 37, training_loss: 6.24569e-02\n",
            "epoch: 8281, iter: 37, training_loss: 6.29051e-02\n",
            "epoch: 8282, iter: 37, training_loss: 6.30619e-02\n",
            "epoch: 8283, iter: 37, training_loss: 6.19709e-02\n",
            "epoch: 8284, iter: 37, training_loss: 6.41289e-02\n",
            "epoch: 8285, iter: 37, training_loss: 6.06431e-02\n",
            "epoch: 8286, iter: 37, training_loss: 6.27464e-02\n",
            "epoch: 8287, iter: 37, training_loss: 6.12723e-02\n",
            "epoch: 8288, iter: 37, training_loss: 6.44732e-02\n",
            "epoch: 8289, iter: 37, training_loss: 6.42007e-02\n",
            "epoch: 8290, iter: 37, training_loss: 6.67144e-02\n",
            "epoch: 8291, iter: 37, training_loss: 6.42660e-02\n",
            "epoch: 8292, iter: 37, training_loss: 6.49469e-02\n",
            "epoch: 8293, iter: 37, training_loss: 6.21060e-02\n",
            "epoch: 8294, iter: 37, training_loss: 6.24896e-02\n",
            "epoch: 8295, iter: 37, training_loss: 6.34727e-02\n",
            "epoch: 8296, iter: 37, training_loss: 6.11922e-02\n",
            "epoch: 8297, iter: 37, training_loss: 6.14551e-02\n",
            "epoch: 8298, iter: 37, training_loss: 6.27177e-02\n",
            "epoch: 8299, iter: 37, training_loss: 6.28024e-02\n",
            "epoch: 8300, iter: 37, training_loss: 6.28731e-02\n",
            "epoch: 8301, iter: 37, training_loss: 6.16140e-02\n",
            "epoch: 8302, iter: 37, training_loss: 6.45596e-02\n",
            "epoch: 8303, iter: 37, training_loss: 6.47082e-02\n",
            "epoch: 8304, iter: 37, training_loss: 6.13594e-02\n",
            "epoch: 8305, iter: 37, training_loss: 6.26852e-02\n",
            "epoch: 8306, iter: 37, training_loss: 6.32452e-02\n",
            "epoch: 8307, iter: 37, training_loss: 6.41167e-02\n",
            "epoch: 8308, iter: 37, training_loss: 6.22761e-02\n",
            "epoch: 8309, iter: 37, training_loss: 6.26804e-02\n",
            "epoch: 8310, iter: 37, training_loss: 6.23822e-02\n",
            "epoch: 8311, iter: 37, training_loss: 6.34167e-02\n",
            "epoch: 8312, iter: 37, training_loss: 6.48854e-02\n",
            "epoch: 8313, iter: 37, training_loss: 6.25829e-02\n",
            "epoch: 8314, iter: 37, training_loss: 6.27314e-02\n",
            "epoch: 8315, iter: 37, training_loss: 6.41996e-02\n",
            "epoch: 8316, iter: 37, training_loss: 6.14809e-02\n",
            "epoch: 8317, iter: 37, training_loss: 6.19712e-02\n",
            "epoch: 8318, iter: 37, training_loss: 6.37413e-02\n",
            "epoch: 8319, iter: 37, training_loss: 6.18226e-02\n",
            "epoch: 8320, iter: 37, training_loss: 6.23682e-02\n",
            "epoch: 8321, iter: 37, training_loss: 6.22410e-02\n",
            "epoch: 8322, iter: 37, training_loss: 6.28333e-02\n",
            "epoch: 8323, iter: 37, training_loss: 6.18281e-02\n",
            "epoch: 8324, iter: 37, training_loss: 6.28329e-02\n",
            "epoch: 8325, iter: 37, training_loss: 6.30444e-02\n",
            "epoch: 8326, iter: 37, training_loss: 6.14491e-02\n",
            "epoch: 8327, iter: 37, training_loss: 6.40407e-02\n",
            "epoch: 8328, iter: 37, training_loss: 6.12594e-02\n",
            "epoch: 8329, iter: 37, training_loss: 6.30211e-02\n",
            "epoch: 8330, iter: 37, training_loss: 6.14080e-02\n",
            "epoch: 8331, iter: 37, training_loss: 6.26704e-02\n",
            "epoch: 8332, iter: 37, training_loss: 6.12855e-02\n",
            "epoch: 8333, iter: 37, training_loss: 6.33952e-02\n",
            "epoch: 8334, iter: 37, training_loss: 6.33663e-02\n",
            "epoch: 8335, iter: 37, training_loss: 6.24676e-02\n",
            "epoch: 8336, iter: 37, training_loss: 6.35837e-02\n",
            "epoch: 8337, iter: 37, training_loss: 6.36463e-02\n",
            "epoch: 8338, iter: 37, training_loss: 6.19420e-02\n",
            "epoch: 8339, iter: 37, training_loss: 6.12613e-02\n",
            "epoch: 8340, iter: 37, training_loss: 6.39452e-02\n",
            "epoch: 8341, iter: 37, training_loss: 6.22625e-02\n",
            "epoch: 8342, iter: 37, training_loss: 6.50831e-02\n",
            "epoch: 8343, iter: 37, training_loss: 6.22596e-02\n",
            "epoch: 8344, iter: 37, training_loss: 6.24467e-02\n",
            "epoch: 8345, iter: 37, training_loss: 6.18142e-02\n",
            "epoch: 8346, iter: 37, training_loss: 6.15388e-02\n",
            "epoch: 8347, iter: 37, training_loss: 6.26920e-02\n",
            "epoch: 8348, iter: 37, training_loss: 6.43309e-02\n",
            "epoch: 8349, iter: 37, training_loss: 6.28031e-02\n",
            "epoch: 8350, iter: 37, training_loss: 6.34227e-02\n",
            "epoch: 8351, iter: 37, training_loss: 6.22190e-02\n",
            "epoch: 8352, iter: 37, training_loss: 6.28263e-02\n",
            "epoch: 8353, iter: 37, training_loss: 6.18684e-02\n",
            "epoch: 8354, iter: 37, training_loss: 6.45273e-02\n",
            "epoch: 8355, iter: 37, training_loss: 6.19186e-02\n",
            "epoch: 8356, iter: 37, training_loss: 6.25062e-02\n",
            "epoch: 8357, iter: 37, training_loss: 6.20531e-02\n",
            "epoch: 8358, iter: 37, training_loss: 6.19854e-02\n",
            "epoch: 8359, iter: 37, training_loss: 6.24136e-02\n",
            "epoch: 8360, iter: 37, training_loss: 6.30549e-02\n",
            "epoch: 8361, iter: 37, training_loss: 6.11613e-02\n",
            "epoch: 8362, iter: 37, training_loss: 6.15175e-02\n",
            "epoch: 8363, iter: 37, training_loss: 6.26842e-02\n",
            "epoch: 8364, iter: 37, training_loss: 6.40206e-02\n",
            "epoch: 8365, iter: 37, training_loss: 6.32289e-02\n",
            "epoch: 8366, iter: 37, training_loss: 6.29839e-02\n",
            "epoch: 8367, iter: 37, training_loss: 6.31563e-02\n",
            "epoch: 8368, iter: 37, training_loss: 6.21491e-02\n",
            "epoch: 8369, iter: 37, training_loss: 6.48509e-02\n",
            "epoch: 8370, iter: 37, training_loss: 6.34117e-02\n",
            "epoch: 8371, iter: 37, training_loss: 6.19688e-02\n",
            "epoch: 8372, iter: 37, training_loss: 6.30230e-02\n",
            "epoch: 8373, iter: 37, training_loss: 6.21996e-02\n",
            "epoch: 8374, iter: 37, training_loss: 6.08917e-02\n",
            "epoch: 8375, iter: 37, training_loss: 6.14287e-02\n",
            "epoch: 8376, iter: 37, training_loss: 6.30246e-02\n",
            "epoch: 8377, iter: 37, training_loss: 6.18365e-02\n",
            "epoch: 8378, iter: 37, training_loss: 6.22813e-02\n",
            "epoch: 8379, iter: 37, training_loss: 6.17209e-02\n",
            "epoch: 8380, iter: 37, training_loss: 6.31521e-02\n",
            "epoch: 8381, iter: 37, training_loss: 6.41138e-02\n",
            "epoch: 8382, iter: 37, training_loss: 6.27844e-02\n",
            "epoch: 8383, iter: 37, training_loss: 6.28684e-02\n",
            "epoch: 8384, iter: 37, training_loss: 6.16141e-02\n",
            "epoch: 8385, iter: 37, training_loss: 6.38761e-02\n",
            "epoch: 8386, iter: 37, training_loss: 6.16290e-02\n",
            "epoch: 8387, iter: 37, training_loss: 6.37869e-02\n",
            "epoch: 8388, iter: 37, training_loss: 6.23934e-02\n",
            "epoch: 8389, iter: 37, training_loss: 6.39391e-02\n",
            "epoch: 8390, iter: 37, training_loss: 6.21528e-02\n",
            "epoch: 8391, iter: 37, training_loss: 6.45884e-02\n",
            "epoch: 8392, iter: 37, training_loss: 6.18040e-02\n",
            "epoch: 8393, iter: 37, training_loss: 6.09563e-02\n",
            "epoch: 8394, iter: 37, training_loss: 6.21033e-02\n",
            "epoch: 8395, iter: 37, training_loss: 6.21010e-02\n",
            "epoch: 8396, iter: 37, training_loss: 6.06745e-02\n",
            "epoch: 8397, iter: 37, training_loss: 6.34686e-02\n",
            "epoch: 8398, iter: 37, training_loss: 6.28376e-02\n",
            "epoch: 8399, iter: 37, training_loss: 6.19555e-02\n",
            "epoch: 8400, iter: 37, training_loss: 6.10089e-02\n",
            "epoch: 8401, iter: 37, training_loss: 6.20479e-02\n",
            "epoch: 8402, iter: 37, training_loss: 6.54527e-02\n",
            "epoch: 8403, iter: 37, training_loss: 6.31253e-02\n",
            "epoch: 8404, iter: 37, training_loss: 6.30054e-02\n",
            "epoch: 8405, iter: 37, training_loss: 6.05666e-02\n",
            "epoch: 8406, iter: 37, training_loss: 6.38732e-02\n",
            "epoch: 8407, iter: 37, training_loss: 6.33270e-02\n",
            "epoch: 8408, iter: 37, training_loss: 6.26347e-02\n",
            "epoch: 8409, iter: 37, training_loss: 6.22831e-02\n",
            "epoch: 8410, iter: 37, training_loss: 6.43953e-02\n",
            "epoch: 8411, iter: 37, training_loss: 6.15607e-02\n",
            "epoch: 8412, iter: 37, training_loss: 6.21852e-02\n",
            "epoch: 8413, iter: 37, training_loss: 6.36406e-02\n",
            "epoch: 8414, iter: 37, training_loss: 6.11661e-02\n",
            "epoch: 8415, iter: 37, training_loss: 6.43570e-02\n",
            "epoch: 8416, iter: 37, training_loss: 6.14005e-02\n",
            "epoch: 8417, iter: 37, training_loss: 6.38549e-02\n",
            "epoch: 8418, iter: 37, training_loss: 6.04836e-02\n",
            "epoch: 8419, iter: 37, training_loss: 6.39146e-02\n",
            "epoch: 8420, iter: 37, training_loss: 6.15899e-02\n",
            "epoch: 8421, iter: 37, training_loss: 6.35786e-02\n",
            "epoch: 8422, iter: 37, training_loss: 6.18199e-02\n",
            "epoch: 8423, iter: 37, training_loss: 6.11762e-02\n",
            "epoch: 8424, iter: 37, training_loss: 6.16894e-02\n",
            "epoch: 8425, iter: 37, training_loss: 6.14073e-02\n",
            "epoch: 8426, iter: 37, training_loss: 6.13410e-02\n",
            "epoch: 8427, iter: 37, training_loss: 6.05828e-02\n",
            "epoch: 8428, iter: 37, training_loss: 6.48526e-02\n",
            "epoch: 8429, iter: 37, training_loss: 6.50061e-02\n",
            "epoch: 8430, iter: 37, training_loss: 6.13378e-02\n",
            "epoch: 8431, iter: 37, training_loss: 6.13001e-02\n",
            "epoch: 8432, iter: 37, training_loss: 6.21925e-02\n",
            "epoch: 8433, iter: 37, training_loss: 6.32345e-02\n",
            "epoch: 8434, iter: 37, training_loss: 6.25886e-02\n",
            "epoch: 8435, iter: 37, training_loss: 6.14175e-02\n",
            "epoch: 8436, iter: 37, training_loss: 6.30514e-02\n",
            "epoch: 8437, iter: 37, training_loss: 6.29535e-02\n",
            "epoch: 8438, iter: 37, training_loss: 6.06600e-02\n",
            "epoch: 8439, iter: 37, training_loss: 6.29054e-02\n",
            "epoch: 8440, iter: 37, training_loss: 6.25330e-02\n",
            "epoch: 8441, iter: 37, training_loss: 6.41503e-02\n",
            "epoch: 8442, iter: 37, training_loss: 6.24747e-02\n",
            "epoch: 8443, iter: 37, training_loss: 6.12982e-02\n",
            "epoch: 8444, iter: 37, training_loss: 6.33072e-02\n",
            "epoch: 8445, iter: 37, training_loss: 6.27577e-02\n",
            "epoch: 8446, iter: 37, training_loss: 6.50055e-02\n",
            "epoch: 8447, iter: 37, training_loss: 6.26537e-02\n",
            "epoch: 8448, iter: 37, training_loss: 6.25262e-02\n",
            "epoch: 8449, iter: 37, training_loss: 6.20865e-02\n",
            "epoch: 8450, iter: 37, training_loss: 6.19911e-02\n",
            "epoch: 8451, iter: 37, training_loss: 6.38111e-02\n",
            "epoch: 8452, iter: 37, training_loss: 6.27860e-02\n",
            "epoch: 8453, iter: 37, training_loss: 6.22880e-02\n",
            "epoch: 8454, iter: 37, training_loss: 6.14970e-02\n",
            "epoch: 8455, iter: 37, training_loss: 6.33557e-02\n",
            "epoch: 8456, iter: 37, training_loss: 6.53817e-02\n",
            "epoch: 8457, iter: 37, training_loss: 6.32306e-02\n",
            "epoch: 8458, iter: 37, training_loss: 6.08954e-02\n",
            "epoch: 8459, iter: 37, training_loss: 6.13183e-02\n",
            "epoch: 8460, iter: 37, training_loss: 6.08994e-02\n",
            "epoch: 8461, iter: 37, training_loss: 6.17307e-02\n",
            "epoch: 8462, iter: 37, training_loss: 6.37307e-02\n",
            "epoch: 8463, iter: 37, training_loss: 6.17290e-02\n",
            "epoch: 8464, iter: 37, training_loss: 6.23241e-02\n",
            "epoch: 8465, iter: 37, training_loss: 6.14294e-02\n",
            "epoch: 8466, iter: 37, training_loss: 6.18520e-02\n",
            "epoch: 8467, iter: 37, training_loss: 6.23995e-02\n",
            "epoch: 8468, iter: 37, training_loss: 6.37699e-02\n",
            "epoch: 8469, iter: 37, training_loss: 6.26110e-02\n",
            "epoch: 8470, iter: 37, training_loss: 6.30655e-02\n",
            "epoch: 8471, iter: 37, training_loss: 6.21048e-02\n",
            "epoch: 8472, iter: 37, training_loss: 6.18445e-02\n",
            "epoch: 8473, iter: 37, training_loss: 6.29123e-02\n",
            "epoch: 8474, iter: 37, training_loss: 6.32442e-02\n",
            "epoch: 8475, iter: 37, training_loss: 6.15313e-02\n",
            "epoch: 8476, iter: 37, training_loss: 6.18938e-02\n",
            "epoch: 8477, iter: 37, training_loss: 6.20141e-02\n",
            "epoch: 8478, iter: 37, training_loss: 6.03272e-02\n",
            "epoch: 8479, iter: 37, training_loss: 6.19204e-02\n",
            "epoch: 8480, iter: 37, training_loss: 6.42682e-02\n",
            "epoch: 8481, iter: 37, training_loss: 6.15429e-02\n",
            "epoch: 8482, iter: 37, training_loss: 6.21691e-02\n",
            "epoch: 8483, iter: 37, training_loss: 6.25579e-02\n",
            "epoch: 8484, iter: 37, training_loss: 6.17716e-02\n",
            "epoch: 8485, iter: 37, training_loss: 6.53080e-02\n",
            "epoch: 8486, iter: 37, training_loss: 6.37164e-02\n",
            "epoch: 8487, iter: 37, training_loss: 6.18429e-02\n",
            "epoch: 8488, iter: 37, training_loss: 6.27179e-02\n",
            "epoch: 8489, iter: 37, training_loss: 6.17980e-02\n",
            "epoch: 8490, iter: 37, training_loss: 6.25363e-02\n",
            "epoch: 8491, iter: 37, training_loss: 6.21115e-02\n",
            "epoch: 8492, iter: 37, training_loss: 6.15583e-02\n",
            "epoch: 8493, iter: 37, training_loss: 6.19395e-02\n",
            "epoch: 8494, iter: 37, training_loss: 6.24445e-02\n",
            "epoch: 8495, iter: 37, training_loss: 6.37934e-02\n",
            "epoch: 8496, iter: 37, training_loss: 6.17897e-02\n",
            "epoch: 8497, iter: 37, training_loss: 6.22339e-02\n",
            "epoch: 8498, iter: 37, training_loss: 6.61114e-02\n",
            "epoch: 8499, iter: 37, training_loss: 6.07235e-02\n",
            "epoch: 8500, iter: 37, training_loss: 6.20035e-02\n",
            "epoch: 8501, iter: 37, training_loss: 6.16196e-02\n",
            "epoch: 8502, iter: 37, training_loss: 6.19252e-02\n",
            "epoch: 8503, iter: 37, training_loss: 6.14379e-02\n",
            "epoch: 8504, iter: 37, training_loss: 6.43420e-02\n",
            "epoch: 8505, iter: 37, training_loss: 6.14047e-02\n",
            "epoch: 8506, iter: 37, training_loss: 6.18655e-02\n",
            "epoch: 8507, iter: 37, training_loss: 6.17235e-02\n",
            "epoch: 8508, iter: 37, training_loss: 6.09719e-02\n",
            "epoch: 8509, iter: 37, training_loss: 6.31851e-02\n",
            "epoch: 8510, iter: 37, training_loss: 6.07630e-02\n",
            "epoch: 8511, iter: 37, training_loss: 6.32883e-02\n",
            "epoch: 8512, iter: 37, training_loss: 6.15673e-02\n",
            "epoch: 8513, iter: 37, training_loss: 6.26667e-02\n",
            "epoch: 8514, iter: 37, training_loss: 6.27377e-02\n",
            "epoch: 8515, iter: 37, training_loss: 6.18678e-02\n",
            "epoch: 8516, iter: 37, training_loss: 6.28610e-02\n",
            "epoch: 8517, iter: 37, training_loss: 6.28659e-02\n",
            "epoch: 8518, iter: 37, training_loss: 6.21693e-02\n",
            "epoch: 8519, iter: 37, training_loss: 6.08690e-02\n",
            "epoch: 8520, iter: 37, training_loss: 6.57512e-02\n",
            "epoch: 8521, iter: 37, training_loss: 6.26415e-02\n",
            "epoch: 8522, iter: 37, training_loss: 6.13346e-02\n",
            "epoch: 8523, iter: 37, training_loss: 6.26571e-02\n",
            "epoch: 8524, iter: 37, training_loss: 6.22531e-02\n",
            "epoch: 8525, iter: 37, training_loss: 6.11646e-02\n",
            "epoch: 8526, iter: 37, training_loss: 6.31207e-02\n",
            "epoch: 8527, iter: 37, training_loss: 6.14330e-02\n",
            "epoch: 8528, iter: 37, training_loss: 6.50472e-02\n",
            "epoch: 8529, iter: 37, training_loss: 6.08512e-02\n",
            "epoch: 8530, iter: 37, training_loss: 6.15182e-02\n",
            "epoch: 8531, iter: 37, training_loss: 6.12618e-02\n",
            "epoch: 8532, iter: 37, training_loss: 6.22607e-02\n",
            "epoch: 8533, iter: 37, training_loss: 6.16693e-02\n",
            "epoch: 8534, iter: 37, training_loss: 6.16515e-02\n",
            "epoch: 8535, iter: 37, training_loss: 6.18435e-02\n",
            "epoch: 8536, iter: 37, training_loss: 6.10108e-02\n",
            "epoch: 8537, iter: 37, training_loss: 6.25521e-02\n",
            "epoch: 8538, iter: 37, training_loss: 6.40136e-02\n",
            "epoch: 8539, iter: 37, training_loss: 6.13887e-02\n",
            "epoch: 8540, iter: 37, training_loss: 6.12210e-02\n",
            "epoch: 8541, iter: 37, training_loss: 6.34336e-02\n",
            "epoch: 8542, iter: 37, training_loss: 6.27454e-02\n",
            "epoch: 8543, iter: 37, training_loss: 6.12338e-02\n",
            "epoch: 8544, iter: 37, training_loss: 6.11922e-02\n",
            "epoch: 8545, iter: 37, training_loss: 6.40022e-02\n",
            "epoch: 8546, iter: 37, training_loss: 6.32224e-02\n",
            "epoch: 8547, iter: 37, training_loss: 6.30668e-02\n",
            "epoch: 8548, iter: 37, training_loss: 6.17735e-02\n",
            "epoch: 8549, iter: 37, training_loss: 6.04598e-02\n",
            "epoch: 8550, iter: 37, training_loss: 5.96826e-02\n",
            "epoch: 8551, iter: 37, training_loss: 6.45058e-02\n",
            "epoch: 8552, iter: 37, training_loss: 6.09163e-02\n",
            "epoch: 8553, iter: 37, training_loss: 6.26919e-02\n",
            "epoch: 8554, iter: 37, training_loss: 6.32566e-02\n",
            "epoch: 8555, iter: 37, training_loss: 6.26715e-02\n",
            "epoch: 8556, iter: 37, training_loss: 6.37211e-02\n",
            "epoch: 8557, iter: 37, training_loss: 6.22949e-02\n",
            "epoch: 8558, iter: 37, training_loss: 6.31513e-02\n",
            "epoch: 8559, iter: 37, training_loss: 6.25546e-02\n",
            "epoch: 8560, iter: 37, training_loss: 6.29228e-02\n",
            "epoch: 8561, iter: 37, training_loss: 6.18648e-02\n",
            "epoch: 8562, iter: 37, training_loss: 6.09367e-02\n",
            "epoch: 8563, iter: 37, training_loss: 6.19563e-02\n",
            "epoch: 8564, iter: 37, training_loss: 6.27235e-02\n",
            "epoch: 8565, iter: 37, training_loss: 6.12410e-02\n",
            "epoch: 8566, iter: 37, training_loss: 6.30908e-02\n",
            "epoch: 8567, iter: 37, training_loss: 6.13508e-02\n",
            "epoch: 8568, iter: 37, training_loss: 6.17159e-02\n",
            "epoch: 8569, iter: 37, training_loss: 6.25139e-02\n",
            "epoch: 8570, iter: 37, training_loss: 6.85988e-02\n",
            "epoch: 8571, iter: 37, training_loss: 6.14109e-02\n",
            "epoch: 8572, iter: 37, training_loss: 6.15748e-02\n",
            "epoch: 8573, iter: 37, training_loss: 6.17751e-02\n",
            "epoch: 8574, iter: 37, training_loss: 6.10668e-02\n",
            "epoch: 8575, iter: 37, training_loss: 6.26681e-02\n",
            "epoch: 8576, iter: 37, training_loss: 6.47535e-02\n",
            "epoch: 8577, iter: 37, training_loss: 6.30055e-02\n",
            "epoch: 8578, iter: 37, training_loss: 6.41593e-02\n",
            "epoch: 8579, iter: 37, training_loss: 6.33064e-02\n",
            "epoch: 8580, iter: 37, training_loss: 6.16845e-02\n",
            "epoch: 8581, iter: 37, training_loss: 6.18329e-02\n",
            "epoch: 8582, iter: 37, training_loss: 6.29918e-02\n",
            "epoch: 8583, iter: 37, training_loss: 6.48261e-02\n",
            "epoch: 8584, iter: 37, training_loss: 6.16577e-02\n",
            "epoch: 8585, iter: 37, training_loss: 6.26550e-02\n",
            "epoch: 8586, iter: 37, training_loss: 6.17537e-02\n",
            "epoch: 8587, iter: 37, training_loss: 6.14727e-02\n",
            "epoch: 8588, iter: 37, training_loss: 6.28584e-02\n",
            "epoch: 8589, iter: 37, training_loss: 6.22254e-02\n",
            "epoch: 8590, iter: 37, training_loss: 6.23659e-02\n",
            "epoch: 8591, iter: 37, training_loss: 6.05286e-02\n",
            "epoch: 8592, iter: 37, training_loss: 6.23087e-02\n",
            "epoch: 8593, iter: 37, training_loss: 6.46739e-02\n",
            "epoch: 8594, iter: 37, training_loss: 6.48090e-02\n",
            "epoch: 8595, iter: 37, training_loss: 6.15303e-02\n",
            "epoch: 8596, iter: 37, training_loss: 6.17846e-02\n",
            "epoch: 8597, iter: 37, training_loss: 6.13921e-02\n",
            "epoch: 8598, iter: 37, training_loss: 6.38990e-02\n",
            "epoch: 8599, iter: 37, training_loss: 6.28046e-02\n",
            "epoch: 8600, iter: 37, training_loss: 6.27632e-02\n",
            "epoch: 8601, iter: 37, training_loss: 6.09658e-02\n",
            "epoch: 8602, iter: 37, training_loss: 6.19302e-02\n",
            "epoch: 8603, iter: 37, training_loss: 6.16023e-02\n",
            "epoch: 8604, iter: 37, training_loss: 6.39729e-02\n",
            "epoch: 8605, iter: 37, training_loss: 6.14526e-02\n",
            "epoch: 8606, iter: 37, training_loss: 6.17839e-02\n",
            "epoch: 8607, iter: 37, training_loss: 6.41220e-02\n",
            "epoch: 8608, iter: 37, training_loss: 6.44409e-02\n",
            "epoch: 8609, iter: 37, training_loss: 6.38546e-02\n",
            "epoch: 8610, iter: 37, training_loss: 6.26254e-02\n",
            "epoch: 8611, iter: 37, training_loss: 6.25436e-02\n",
            "epoch: 8612, iter: 37, training_loss: 6.20048e-02\n",
            "epoch: 8613, iter: 37, training_loss: 6.27211e-02\n",
            "epoch: 8614, iter: 37, training_loss: 6.16933e-02\n",
            "epoch: 8615, iter: 37, training_loss: 6.25738e-02\n",
            "epoch: 8616, iter: 37, training_loss: 6.17874e-02\n",
            "epoch: 8617, iter: 37, training_loss: 6.42449e-02\n",
            "epoch: 8618, iter: 37, training_loss: 6.48471e-02\n",
            "epoch: 8619, iter: 37, training_loss: 6.44274e-02\n",
            "epoch: 8620, iter: 37, training_loss: 6.41490e-02\n",
            "epoch: 8621, iter: 37, training_loss: 6.39180e-02\n",
            "epoch: 8622, iter: 37, training_loss: 6.39344e-02\n",
            "epoch: 8623, iter: 37, training_loss: 6.33291e-02\n",
            "epoch: 8624, iter: 37, training_loss: 6.16952e-02\n",
            "epoch: 8625, iter: 37, training_loss: 6.15851e-02\n",
            "epoch: 8626, iter: 37, training_loss: 6.13327e-02\n",
            "epoch: 8627, iter: 37, training_loss: 6.11173e-02\n",
            "epoch: 8628, iter: 37, training_loss: 6.10597e-02\n",
            "epoch: 8629, iter: 37, training_loss: 6.26256e-02\n",
            "epoch: 8630, iter: 37, training_loss: 6.28466e-02\n",
            "epoch: 8631, iter: 37, training_loss: 6.18447e-02\n",
            "epoch: 8632, iter: 37, training_loss: 6.20571e-02\n",
            "epoch: 8633, iter: 37, training_loss: 6.21552e-02\n",
            "epoch: 8634, iter: 37, training_loss: 6.29368e-02\n",
            "epoch: 8635, iter: 37, training_loss: 6.24953e-02\n",
            "epoch: 8636, iter: 37, training_loss: 6.19912e-02\n",
            "epoch: 8637, iter: 37, training_loss: 6.28864e-02\n",
            "epoch: 8638, iter: 37, training_loss: 6.27202e-02\n",
            "epoch: 8639, iter: 37, training_loss: 6.26195e-02\n",
            "epoch: 8640, iter: 37, training_loss: 6.08731e-02\n",
            "epoch: 8641, iter: 37, training_loss: 6.08710e-02\n",
            "epoch: 8642, iter: 37, training_loss: 6.23017e-02\n",
            "epoch: 8643, iter: 37, training_loss: 6.14584e-02\n",
            "epoch: 8644, iter: 37, training_loss: 6.32556e-02\n",
            "epoch: 8645, iter: 37, training_loss: 6.30586e-02\n",
            "epoch: 8646, iter: 37, training_loss: 6.30967e-02\n",
            "epoch: 8647, iter: 37, training_loss: 6.28550e-02\n",
            "epoch: 8648, iter: 37, training_loss: 6.36063e-02\n",
            "epoch: 8649, iter: 37, training_loss: 6.13186e-02\n",
            "epoch: 8650, iter: 37, training_loss: 6.16248e-02\n",
            "epoch: 8651, iter: 37, training_loss: 6.28253e-02\n",
            "epoch: 8652, iter: 37, training_loss: 6.23488e-02\n",
            "epoch: 8653, iter: 37, training_loss: 6.27526e-02\n",
            "epoch: 8654, iter: 37, training_loss: 6.34841e-02\n",
            "epoch: 8655, iter: 37, training_loss: 6.09909e-02\n",
            "epoch: 8656, iter: 37, training_loss: 6.06426e-02\n",
            "epoch: 8657, iter: 37, training_loss: 6.29109e-02\n",
            "epoch: 8658, iter: 37, training_loss: 6.22531e-02\n",
            "epoch: 8659, iter: 37, training_loss: 6.23022e-02\n",
            "epoch: 8660, iter: 37, training_loss: 6.17878e-02\n",
            "epoch: 8661, iter: 37, training_loss: 6.25380e-02\n",
            "epoch: 8662, iter: 37, training_loss: 6.35989e-02\n",
            "epoch: 8663, iter: 37, training_loss: 6.19237e-02\n",
            "epoch: 8664, iter: 37, training_loss: 6.34455e-02\n",
            "epoch: 8665, iter: 37, training_loss: 6.12985e-02\n",
            "epoch: 8666, iter: 37, training_loss: 6.12128e-02\n",
            "epoch: 8667, iter: 37, training_loss: 6.19241e-02\n",
            "epoch: 8668, iter: 37, training_loss: 6.08678e-02\n",
            "epoch: 8669, iter: 37, training_loss: 6.27277e-02\n",
            "epoch: 8670, iter: 37, training_loss: 6.27755e-02\n",
            "epoch: 8671, iter: 37, training_loss: 6.22195e-02\n",
            "epoch: 8672, iter: 37, training_loss: 6.21880e-02\n",
            "epoch: 8673, iter: 37, training_loss: 6.20889e-02\n",
            "epoch: 8674, iter: 37, training_loss: 6.09932e-02\n",
            "epoch: 8675, iter: 37, training_loss: 6.41265e-02\n",
            "epoch: 8676, iter: 37, training_loss: 6.11719e-02\n",
            "epoch: 8677, iter: 37, training_loss: 6.39729e-02\n",
            "epoch: 8678, iter: 37, training_loss: 6.44298e-02\n",
            "epoch: 8679, iter: 37, training_loss: 6.43413e-02\n",
            "epoch: 8680, iter: 37, training_loss: 6.11035e-02\n",
            "epoch: 8681, iter: 37, training_loss: 6.28284e-02\n",
            "epoch: 8682, iter: 37, training_loss: 6.15399e-02\n",
            "epoch: 8683, iter: 37, training_loss: 6.15603e-02\n",
            "epoch: 8684, iter: 37, training_loss: 6.36832e-02\n",
            "epoch: 8685, iter: 37, training_loss: 6.13804e-02\n",
            "epoch: 8686, iter: 37, training_loss: 6.12235e-02\n",
            "epoch: 8687, iter: 37, training_loss: 6.15283e-02\n",
            "epoch: 8688, iter: 37, training_loss: 6.20516e-02\n",
            "epoch: 8689, iter: 37, training_loss: 6.10712e-02\n",
            "epoch: 8690, iter: 37, training_loss: 6.25987e-02\n",
            "epoch: 8691, iter: 37, training_loss: 6.06133e-02\n",
            "epoch: 8692, iter: 37, training_loss: 6.39726e-02\n",
            "epoch: 8693, iter: 37, training_loss: 6.21618e-02\n",
            "epoch: 8694, iter: 37, training_loss: 6.09589e-02\n",
            "epoch: 8695, iter: 37, training_loss: 6.19987e-02\n",
            "epoch: 8696, iter: 37, training_loss: 6.15102e-02\n",
            "epoch: 8697, iter: 37, training_loss: 6.23273e-02\n",
            "epoch: 8698, iter: 37, training_loss: 6.39628e-02\n",
            "epoch: 8699, iter: 37, training_loss: 6.41340e-02\n",
            "epoch: 8700, iter: 37, training_loss: 6.07497e-02\n",
            "epoch: 8701, iter: 37, training_loss: 6.36353e-02\n",
            "epoch: 8702, iter: 37, training_loss: 6.26215e-02\n",
            "epoch: 8703, iter: 37, training_loss: 6.23369e-02\n",
            "epoch: 8704, iter: 37, training_loss: 6.67444e-02\n",
            "epoch: 8705, iter: 37, training_loss: 6.10399e-02\n",
            "epoch: 8706, iter: 37, training_loss: 6.20942e-02\n",
            "epoch: 8707, iter: 37, training_loss: 6.16786e-02\n",
            "epoch: 8708, iter: 37, training_loss: 5.99640e-02\n",
            "epoch: 8709, iter: 37, training_loss: 6.12295e-02\n",
            "epoch: 8710, iter: 37, training_loss: 6.02907e-02\n",
            "epoch: 8711, iter: 37, training_loss: 6.20929e-02\n",
            "epoch: 8712, iter: 37, training_loss: 6.18015e-02\n",
            "epoch: 8713, iter: 37, training_loss: 5.96576e-02\n",
            "epoch: 8714, iter: 37, training_loss: 6.31632e-02\n",
            "epoch: 8715, iter: 37, training_loss: 6.33648e-02\n",
            "epoch: 8716, iter: 37, training_loss: 6.30638e-02\n",
            "epoch: 8717, iter: 37, training_loss: 6.09634e-02\n",
            "epoch: 8718, iter: 37, training_loss: 6.13155e-02\n",
            "epoch: 8719, iter: 37, training_loss: 6.43645e-02\n",
            "epoch: 8720, iter: 37, training_loss: 6.35675e-02\n",
            "epoch: 8721, iter: 37, training_loss: 6.21612e-02\n",
            "epoch: 8722, iter: 37, training_loss: 6.34385e-02\n",
            "epoch: 8723, iter: 37, training_loss: 6.46902e-02\n",
            "epoch: 8724, iter: 37, training_loss: 6.03764e-02\n",
            "epoch: 8725, iter: 37, training_loss: 6.15816e-02\n",
            "epoch: 8726, iter: 37, training_loss: 6.24422e-02\n",
            "epoch: 8727, iter: 37, training_loss: 6.15662e-02\n",
            "epoch: 8728, iter: 37, training_loss: 6.25238e-02\n",
            "epoch: 8729, iter: 37, training_loss: 6.13620e-02\n",
            "epoch: 8730, iter: 37, training_loss: 6.18836e-02\n",
            "epoch: 8731, iter: 37, training_loss: 6.27159e-02\n",
            "epoch: 8732, iter: 37, training_loss: 6.32780e-02\n",
            "epoch: 8733, iter: 37, training_loss: 6.45328e-02\n",
            "epoch: 8734, iter: 37, training_loss: 6.33708e-02\n",
            "epoch: 8735, iter: 37, training_loss: 6.10866e-02\n",
            "epoch: 8736, iter: 37, training_loss: 6.27098e-02\n",
            "epoch: 8737, iter: 37, training_loss: 6.11297e-02\n",
            "epoch: 8738, iter: 37, training_loss: 6.10520e-02\n",
            "epoch: 8739, iter: 37, training_loss: 6.29964e-02\n",
            "epoch: 8740, iter: 37, training_loss: 6.19699e-02\n",
            "epoch: 8741, iter: 37, training_loss: 6.14597e-02\n",
            "epoch: 8742, iter: 37, training_loss: 6.16408e-02\n",
            "epoch: 8743, iter: 37, training_loss: 6.25434e-02\n",
            "epoch: 8744, iter: 37, training_loss: 6.27545e-02\n",
            "epoch: 8745, iter: 37, training_loss: 6.29923e-02\n",
            "epoch: 8746, iter: 37, training_loss: 6.12237e-02\n",
            "epoch: 8747, iter: 37, training_loss: 6.08813e-02\n",
            "epoch: 8748, iter: 37, training_loss: 6.17683e-02\n",
            "epoch: 8749, iter: 37, training_loss: 6.25300e-02\n",
            "epoch: 8750, iter: 37, training_loss: 6.11396e-02\n",
            "epoch: 8751, iter: 37, training_loss: 6.22141e-02\n",
            "epoch: 8752, iter: 37, training_loss: 6.18967e-02\n",
            "epoch: 8753, iter: 37, training_loss: 6.12717e-02\n",
            "epoch: 8754, iter: 37, training_loss: 6.27639e-02\n",
            "epoch: 8755, iter: 37, training_loss: 6.51956e-02\n",
            "epoch: 8756, iter: 37, training_loss: 6.39033e-02\n",
            "epoch: 8757, iter: 37, training_loss: 6.11493e-02\n",
            "epoch: 8758, iter: 37, training_loss: 6.22862e-02\n",
            "epoch: 8759, iter: 37, training_loss: 6.26066e-02\n",
            "epoch: 8760, iter: 37, training_loss: 6.28278e-02\n",
            "epoch: 8761, iter: 37, training_loss: 6.28550e-02\n",
            "epoch: 8762, iter: 37, training_loss: 6.10177e-02\n",
            "epoch: 8763, iter: 37, training_loss: 6.30369e-02\n",
            "epoch: 8764, iter: 37, training_loss: 6.27592e-02\n",
            "epoch: 8765, iter: 37, training_loss: 6.30984e-02\n",
            "epoch: 8766, iter: 37, training_loss: 6.19161e-02\n",
            "epoch: 8767, iter: 37, training_loss: 6.35639e-02\n",
            "epoch: 8768, iter: 37, training_loss: 6.28612e-02\n",
            "epoch: 8769, iter: 37, training_loss: 6.00280e-02\n",
            "epoch: 8770, iter: 37, training_loss: 6.13882e-02\n",
            "epoch: 8771, iter: 37, training_loss: 6.16090e-02\n",
            "epoch: 8772, iter: 37, training_loss: 6.25038e-02\n",
            "epoch: 8773, iter: 37, training_loss: 6.11563e-02\n",
            "epoch: 8774, iter: 37, training_loss: 6.21541e-02\n",
            "epoch: 8775, iter: 37, training_loss: 6.14733e-02\n",
            "epoch: 8776, iter: 37, training_loss: 6.04078e-02\n",
            "epoch: 8777, iter: 37, training_loss: 6.08367e-02\n",
            "epoch: 8778, iter: 37, training_loss: 6.18114e-02\n",
            "epoch: 8779, iter: 37, training_loss: 6.23174e-02\n",
            "epoch: 8780, iter: 37, training_loss: 6.26266e-02\n",
            "epoch: 8781, iter: 37, training_loss: 6.43181e-02\n",
            "epoch: 8782, iter: 37, training_loss: 6.27440e-02\n",
            "epoch: 8783, iter: 37, training_loss: 6.09768e-02\n",
            "epoch: 8784, iter: 37, training_loss: 6.29930e-02\n",
            "epoch: 8785, iter: 37, training_loss: 6.26297e-02\n",
            "epoch: 8786, iter: 37, training_loss: 6.26118e-02\n",
            "epoch: 8787, iter: 37, training_loss: 6.11837e-02\n",
            "epoch: 8788, iter: 37, training_loss: 6.20754e-02\n",
            "epoch: 8789, iter: 37, training_loss: 6.35206e-02\n",
            "epoch: 8790, iter: 37, training_loss: 6.12257e-02\n",
            "epoch: 8791, iter: 37, training_loss: 6.20836e-02\n",
            "epoch: 8792, iter: 37, training_loss: 6.48115e-02\n",
            "epoch: 8793, iter: 37, training_loss: 6.45946e-02\n",
            "epoch: 8794, iter: 37, training_loss: 6.08969e-02\n",
            "epoch: 8795, iter: 37, training_loss: 6.69027e-02\n",
            "epoch: 8796, iter: 37, training_loss: 6.27214e-02\n",
            "epoch: 8797, iter: 37, training_loss: 6.15424e-02\n",
            "epoch: 8798, iter: 37, training_loss: 6.34919e-02\n",
            "epoch: 8799, iter: 37, training_loss: 6.19102e-02\n",
            "epoch: 8800, iter: 37, training_loss: 6.11007e-02\n",
            "epoch: 8801, iter: 37, training_loss: 6.26804e-02\n",
            "epoch: 8802, iter: 37, training_loss: 6.22597e-02\n",
            "epoch: 8803, iter: 37, training_loss: 6.26234e-02\n",
            "epoch: 8804, iter: 37, training_loss: 6.30754e-02\n",
            "epoch: 8805, iter: 37, training_loss: 6.34722e-02\n",
            "epoch: 8806, iter: 37, training_loss: 6.51712e-02\n",
            "epoch: 8807, iter: 37, training_loss: 6.29319e-02\n",
            "epoch: 8808, iter: 37, training_loss: 6.31805e-02\n",
            "epoch: 8809, iter: 37, training_loss: 6.20485e-02\n",
            "epoch: 8810, iter: 37, training_loss: 6.19144e-02\n",
            "epoch: 8811, iter: 37, training_loss: 6.09603e-02\n",
            "epoch: 8812, iter: 37, training_loss: 6.21496e-02\n",
            "epoch: 8813, iter: 37, training_loss: 6.31697e-02\n",
            "epoch: 8814, iter: 37, training_loss: 6.20637e-02\n",
            "epoch: 8815, iter: 37, training_loss: 6.16907e-02\n",
            "epoch: 8816, iter: 37, training_loss: 6.16266e-02\n",
            "epoch: 8817, iter: 37, training_loss: 6.06150e-02\n",
            "epoch: 8818, iter: 37, training_loss: 6.14865e-02\n",
            "epoch: 8819, iter: 37, training_loss: 6.33945e-02\n",
            "epoch: 8820, iter: 37, training_loss: 6.29846e-02\n",
            "epoch: 8821, iter: 37, training_loss: 6.25892e-02\n",
            "epoch: 8822, iter: 37, training_loss: 6.34206e-02\n",
            "epoch: 8823, iter: 37, training_loss: 6.32524e-02\n",
            "epoch: 8824, iter: 37, training_loss: 6.23592e-02\n",
            "epoch: 8825, iter: 37, training_loss: 6.09352e-02\n",
            "epoch: 8826, iter: 37, training_loss: 6.09966e-02\n",
            "epoch: 8827, iter: 37, training_loss: 6.18624e-02\n",
            "epoch: 8828, iter: 37, training_loss: 6.13425e-02\n",
            "epoch: 8829, iter: 37, training_loss: 6.33263e-02\n",
            "epoch: 8830, iter: 37, training_loss: 6.21005e-02\n",
            "epoch: 8831, iter: 37, training_loss: 6.11927e-02\n",
            "epoch: 8832, iter: 37, training_loss: 6.25475e-02\n",
            "epoch: 8833, iter: 37, training_loss: 6.10867e-02\n",
            "epoch: 8834, iter: 37, training_loss: 6.36648e-02\n",
            "epoch: 8835, iter: 37, training_loss: 6.22185e-02\n",
            "epoch: 8836, iter: 37, training_loss: 6.10370e-02\n",
            "epoch: 8837, iter: 37, training_loss: 6.18485e-02\n",
            "epoch: 8838, iter: 37, training_loss: 6.23500e-02\n",
            "epoch: 8839, iter: 37, training_loss: 6.68029e-02\n",
            "epoch: 8840, iter: 37, training_loss: 6.13340e-02\n",
            "epoch: 8841, iter: 37, training_loss: 6.24159e-02\n",
            "epoch: 8842, iter: 37, training_loss: 6.26048e-02\n",
            "epoch: 8843, iter: 37, training_loss: 6.47352e-02\n",
            "epoch: 8844, iter: 37, training_loss: 6.27283e-02\n",
            "epoch: 8845, iter: 37, training_loss: 6.23663e-02\n",
            "epoch: 8846, iter: 37, training_loss: 6.28567e-02\n",
            "epoch: 8847, iter: 37, training_loss: 6.20939e-02\n",
            "epoch: 8848, iter: 37, training_loss: 6.42731e-02\n",
            "epoch: 8849, iter: 37, training_loss: 6.35925e-02\n",
            "epoch: 8850, iter: 37, training_loss: 6.24164e-02\n",
            "epoch: 8851, iter: 37, training_loss: 6.09258e-02\n",
            "epoch: 8852, iter: 37, training_loss: 6.10674e-02\n",
            "epoch: 8853, iter: 37, training_loss: 6.16658e-02\n",
            "epoch: 8854, iter: 37, training_loss: 6.06608e-02\n",
            "epoch: 8855, iter: 37, training_loss: 5.99876e-02\n",
            "epoch: 8856, iter: 37, training_loss: 6.11335e-02\n",
            "epoch: 8857, iter: 37, training_loss: 6.10110e-02\n",
            "epoch: 8858, iter: 37, training_loss: 6.19866e-02\n",
            "epoch: 8859, iter: 37, training_loss: 6.04368e-02\n",
            "epoch: 8860, iter: 37, training_loss: 6.20448e-02\n",
            "epoch: 8861, iter: 37, training_loss: 6.49847e-02\n",
            "epoch: 8862, iter: 37, training_loss: 6.26194e-02\n",
            "epoch: 8863, iter: 37, training_loss: 6.22167e-02\n",
            "epoch: 8864, iter: 37, training_loss: 6.33242e-02\n",
            "epoch: 8865, iter: 37, training_loss: 6.17177e-02\n",
            "epoch: 8866, iter: 37, training_loss: 6.23615e-02\n",
            "epoch: 8867, iter: 37, training_loss: 6.01959e-02\n",
            "epoch: 8868, iter: 37, training_loss: 6.33553e-02\n",
            "epoch: 8869, iter: 37, training_loss: 6.34496e-02\n",
            "epoch: 8870, iter: 37, training_loss: 6.15695e-02\n",
            "epoch: 8871, iter: 37, training_loss: 6.26147e-02\n",
            "epoch: 8872, iter: 37, training_loss: 6.11964e-02\n",
            "epoch: 8873, iter: 37, training_loss: 6.30721e-02\n",
            "epoch: 8874, iter: 37, training_loss: 6.44957e-02\n",
            "epoch: 8875, iter: 37, training_loss: 6.21582e-02\n",
            "epoch: 8876, iter: 37, training_loss: 6.02234e-02\n",
            "epoch: 8877, iter: 37, training_loss: 6.26515e-02\n",
            "epoch: 8878, iter: 37, training_loss: 6.20388e-02\n",
            "epoch: 8879, iter: 37, training_loss: 6.42992e-02\n",
            "epoch: 8880, iter: 37, training_loss: 6.21450e-02\n",
            "epoch: 8881, iter: 37, training_loss: 6.30709e-02\n",
            "epoch: 8882, iter: 37, training_loss: 6.25491e-02\n",
            "epoch: 8883, iter: 37, training_loss: 6.18044e-02\n",
            "epoch: 8884, iter: 37, training_loss: 6.11611e-02\n",
            "epoch: 8885, iter: 37, training_loss: 6.42856e-02\n",
            "epoch: 8886, iter: 37, training_loss: 6.22082e-02\n",
            "epoch: 8887, iter: 37, training_loss: 6.08784e-02\n",
            "epoch: 8888, iter: 37, training_loss: 6.16230e-02\n",
            "epoch: 8889, iter: 37, training_loss: 6.27393e-02\n",
            "epoch: 8890, iter: 37, training_loss: 6.33734e-02\n",
            "epoch: 8891, iter: 37, training_loss: 6.33584e-02\n",
            "epoch: 8892, iter: 37, training_loss: 6.26214e-02\n",
            "epoch: 8893, iter: 37, training_loss: 6.32363e-02\n",
            "epoch: 8894, iter: 37, training_loss: 6.23209e-02\n",
            "epoch: 8895, iter: 37, training_loss: 6.24961e-02\n",
            "epoch: 8896, iter: 37, training_loss: 6.16654e-02\n",
            "epoch: 8897, iter: 37, training_loss: 6.08881e-02\n",
            "epoch: 8898, iter: 37, training_loss: 6.12003e-02\n",
            "epoch: 8899, iter: 37, training_loss: 6.33489e-02\n",
            "epoch: 8900, iter: 37, training_loss: 6.33650e-02\n",
            "epoch: 8901, iter: 37, training_loss: 6.25520e-02\n",
            "epoch: 8902, iter: 37, training_loss: 6.20458e-02\n",
            "epoch: 8903, iter: 37, training_loss: 6.30968e-02\n",
            "epoch: 8904, iter: 37, training_loss: 6.50687e-02\n",
            "epoch: 8905, iter: 37, training_loss: 6.23361e-02\n",
            "epoch: 8906, iter: 37, training_loss: 6.33583e-02\n",
            "epoch: 8907, iter: 37, training_loss: 6.24598e-02\n",
            "epoch: 8908, iter: 37, training_loss: 6.23958e-02\n",
            "epoch: 8909, iter: 37, training_loss: 6.20367e-02\n",
            "epoch: 8910, iter: 37, training_loss: 6.14986e-02\n",
            "epoch: 8911, iter: 37, training_loss: 6.15774e-02\n",
            "epoch: 8912, iter: 37, training_loss: 6.18338e-02\n",
            "epoch: 8913, iter: 37, training_loss: 6.56148e-02\n",
            "epoch: 8914, iter: 37, training_loss: 6.29037e-02\n",
            "epoch: 8915, iter: 37, training_loss: 6.22891e-02\n",
            "epoch: 8916, iter: 37, training_loss: 6.43675e-02\n",
            "epoch: 8917, iter: 37, training_loss: 6.13030e-02\n",
            "epoch: 8918, iter: 37, training_loss: 6.04096e-02\n",
            "epoch: 8919, iter: 37, training_loss: 6.14297e-02\n",
            "epoch: 8920, iter: 37, training_loss: 6.10196e-02\n",
            "epoch: 8921, iter: 37, training_loss: 6.17027e-02\n",
            "epoch: 8922, iter: 37, training_loss: 6.18312e-02\n",
            "epoch: 8923, iter: 37, training_loss: 6.24711e-02\n",
            "epoch: 8924, iter: 37, training_loss: 6.10674e-02\n",
            "epoch: 8925, iter: 37, training_loss: 6.21589e-02\n",
            "epoch: 8926, iter: 37, training_loss: 6.08648e-02\n",
            "epoch: 8927, iter: 37, training_loss: 6.22808e-02\n",
            "epoch: 8928, iter: 37, training_loss: 6.12944e-02\n",
            "epoch: 8929, iter: 37, training_loss: 6.39477e-02\n",
            "epoch: 8930, iter: 37, training_loss: 6.28548e-02\n",
            "epoch: 8931, iter: 37, training_loss: 6.15860e-02\n",
            "epoch: 8932, iter: 37, training_loss: 6.11336e-02\n",
            "epoch: 8933, iter: 37, training_loss: 6.09088e-02\n",
            "epoch: 8934, iter: 37, training_loss: 6.33978e-02\n",
            "epoch: 8935, iter: 37, training_loss: 6.25695e-02\n",
            "epoch: 8936, iter: 37, training_loss: 6.13733e-02\n",
            "epoch: 8937, iter: 37, training_loss: 6.24810e-02\n",
            "epoch: 8938, iter: 37, training_loss: 6.22458e-02\n",
            "epoch: 8939, iter: 37, training_loss: 6.29370e-02\n",
            "epoch: 8940, iter: 37, training_loss: 6.06669e-02\n",
            "epoch: 8941, iter: 37, training_loss: 6.24008e-02\n",
            "epoch: 8942, iter: 37, training_loss: 6.14095e-02\n",
            "epoch: 8943, iter: 37, training_loss: 6.24061e-02\n",
            "epoch: 8944, iter: 37, training_loss: 6.10132e-02\n",
            "epoch: 8945, iter: 37, training_loss: 6.34578e-02\n",
            "epoch: 8946, iter: 37, training_loss: 6.22317e-02\n",
            "epoch: 8947, iter: 37, training_loss: 6.00537e-02\n",
            "epoch: 8948, iter: 37, training_loss: 6.31054e-02\n",
            "epoch: 8949, iter: 37, training_loss: 6.18729e-02\n",
            "epoch: 8950, iter: 37, training_loss: 6.23518e-02\n",
            "epoch: 8951, iter: 37, training_loss: 6.24639e-02\n",
            "epoch: 8952, iter: 37, training_loss: 6.28929e-02\n",
            "epoch: 8953, iter: 37, training_loss: 6.30387e-02\n",
            "epoch: 8954, iter: 37, training_loss: 6.23712e-02\n",
            "epoch: 8955, iter: 37, training_loss: 6.16233e-02\n",
            "epoch: 8956, iter: 37, training_loss: 6.26801e-02\n",
            "epoch: 8957, iter: 37, training_loss: 6.35094e-02\n",
            "epoch: 8958, iter: 37, training_loss: 6.28980e-02\n",
            "epoch: 8959, iter: 37, training_loss: 6.04490e-02\n",
            "epoch: 8960, iter: 37, training_loss: 6.22777e-02\n",
            "epoch: 8961, iter: 37, training_loss: 6.24246e-02\n",
            "epoch: 8962, iter: 37, training_loss: 6.10038e-02\n",
            "epoch: 8963, iter: 37, training_loss: 6.05240e-02\n",
            "epoch: 8964, iter: 37, training_loss: 6.21353e-02\n",
            "epoch: 8965, iter: 37, training_loss: 6.25237e-02\n",
            "epoch: 8966, iter: 37, training_loss: 6.35503e-02\n",
            "epoch: 8967, iter: 37, training_loss: 6.26910e-02\n",
            "epoch: 8968, iter: 37, training_loss: 6.18837e-02\n",
            "epoch: 8969, iter: 37, training_loss: 6.24800e-02\n",
            "epoch: 8970, iter: 37, training_loss: 6.25209e-02\n",
            "epoch: 8971, iter: 37, training_loss: 6.17251e-02\n",
            "epoch: 8972, iter: 37, training_loss: 6.42257e-02\n",
            "epoch: 8973, iter: 37, training_loss: 6.21477e-02\n",
            "epoch: 8974, iter: 37, training_loss: 6.30721e-02\n",
            "epoch: 8975, iter: 37, training_loss: 6.18341e-02\n",
            "epoch: 8976, iter: 37, training_loss: 6.23336e-02\n",
            "epoch: 8977, iter: 37, training_loss: 6.10645e-02\n",
            "epoch: 8978, iter: 37, training_loss: 6.31230e-02\n",
            "epoch: 8979, iter: 37, training_loss: 6.21700e-02\n",
            "epoch: 8980, iter: 37, training_loss: 6.30278e-02\n",
            "epoch: 8981, iter: 37, training_loss: 6.20187e-02\n",
            "epoch: 8982, iter: 37, training_loss: 6.10765e-02\n",
            "epoch: 8983, iter: 37, training_loss: 6.21420e-02\n",
            "epoch: 8984, iter: 37, training_loss: 6.14478e-02\n",
            "epoch: 8985, iter: 37, training_loss: 6.14671e-02\n",
            "epoch: 8986, iter: 37, training_loss: 6.14438e-02\n",
            "epoch: 8987, iter: 37, training_loss: 6.24014e-02\n",
            "epoch: 8988, iter: 37, training_loss: 6.13434e-02\n",
            "epoch: 8989, iter: 37, training_loss: 6.03008e-02\n",
            "epoch: 8990, iter: 37, training_loss: 6.22126e-02\n",
            "epoch: 8991, iter: 37, training_loss: 6.16349e-02\n",
            "epoch: 8992, iter: 37, training_loss: 6.13159e-02\n",
            "epoch: 8993, iter: 37, training_loss: 6.29358e-02\n",
            "epoch: 8994, iter: 37, training_loss: 6.38046e-02\n",
            "epoch: 8995, iter: 37, training_loss: 6.13685e-02\n",
            "epoch: 8996, iter: 37, training_loss: 6.16265e-02\n",
            "epoch: 8997, iter: 37, training_loss: 6.00375e-02\n",
            "epoch: 8998, iter: 37, training_loss: 6.64866e-02\n",
            "epoch: 8999, iter: 37, training_loss: 6.21390e-02\n",
            "epoch: 9000, iter: 37, training_loss: 6.12714e-02\n",
            "epoch: 9001, iter: 37, training_loss: 6.12806e-02\n",
            "epoch: 9002, iter: 37, training_loss: 6.30834e-02\n",
            "epoch: 9003, iter: 37, training_loss: 6.31703e-02\n",
            "epoch: 9004, iter: 37, training_loss: 6.07552e-02\n",
            "epoch: 9005, iter: 37, training_loss: 6.10740e-02\n",
            "epoch: 9006, iter: 37, training_loss: 6.15142e-02\n",
            "epoch: 9007, iter: 37, training_loss: 6.01144e-02\n",
            "epoch: 9008, iter: 37, training_loss: 6.13207e-02\n",
            "epoch: 9009, iter: 37, training_loss: 6.15698e-02\n",
            "epoch: 9010, iter: 37, training_loss: 6.19650e-02\n",
            "epoch: 9011, iter: 37, training_loss: 6.20700e-02\n",
            "epoch: 9012, iter: 37, training_loss: 6.32356e-02\n",
            "epoch: 9013, iter: 37, training_loss: 6.32885e-02\n",
            "epoch: 9014, iter: 37, training_loss: 6.32207e-02\n",
            "epoch: 9015, iter: 37, training_loss: 6.20015e-02\n",
            "epoch: 9016, iter: 37, training_loss: 6.18870e-02\n",
            "epoch: 9017, iter: 37, training_loss: 6.05530e-02\n",
            "epoch: 9018, iter: 37, training_loss: 6.21196e-02\n",
            "epoch: 9019, iter: 37, training_loss: 6.33184e-02\n",
            "epoch: 9020, iter: 37, training_loss: 6.45506e-02\n",
            "epoch: 9021, iter: 37, training_loss: 6.08623e-02\n",
            "epoch: 9022, iter: 37, training_loss: 6.27917e-02\n",
            "epoch: 9023, iter: 37, training_loss: 6.23602e-02\n",
            "epoch: 9024, iter: 37, training_loss: 6.15238e-02\n",
            "epoch: 9025, iter: 37, training_loss: 6.16225e-02\n",
            "epoch: 9026, iter: 37, training_loss: 6.27311e-02\n",
            "epoch: 9027, iter: 37, training_loss: 6.11772e-02\n",
            "epoch: 9028, iter: 37, training_loss: 6.05362e-02\n",
            "epoch: 9029, iter: 37, training_loss: 6.20983e-02\n",
            "epoch: 9030, iter: 37, training_loss: 6.10831e-02\n",
            "epoch: 9031, iter: 37, training_loss: 6.15566e-02\n",
            "epoch: 9032, iter: 37, training_loss: 6.20003e-02\n",
            "epoch: 9033, iter: 37, training_loss: 6.23630e-02\n",
            "epoch: 9034, iter: 37, training_loss: 6.22710e-02\n",
            "epoch: 9035, iter: 37, training_loss: 6.15241e-02\n",
            "epoch: 9036, iter: 37, training_loss: 6.11554e-02\n",
            "epoch: 9037, iter: 37, training_loss: 6.15335e-02\n",
            "epoch: 9038, iter: 37, training_loss: 6.31035e-02\n",
            "epoch: 9039, iter: 37, training_loss: 6.31198e-02\n",
            "epoch: 9040, iter: 37, training_loss: 6.13745e-02\n",
            "epoch: 9041, iter: 37, training_loss: 6.25282e-02\n",
            "epoch: 9042, iter: 37, training_loss: 6.38301e-02\n",
            "epoch: 9043, iter: 37, training_loss: 6.38503e-02\n",
            "epoch: 9044, iter: 37, training_loss: 6.02562e-02\n",
            "epoch: 9045, iter: 37, training_loss: 6.13119e-02\n",
            "epoch: 9046, iter: 37, training_loss: 6.08304e-02\n",
            "epoch: 9047, iter: 37, training_loss: 6.11774e-02\n",
            "epoch: 9048, iter: 37, training_loss: 6.06568e-02\n",
            "epoch: 9049, iter: 37, training_loss: 6.26121e-02\n",
            "epoch: 9050, iter: 37, training_loss: 6.12704e-02\n",
            "epoch: 9051, iter: 37, training_loss: 6.20736e-02\n",
            "epoch: 9052, iter: 37, training_loss: 6.49382e-02\n",
            "epoch: 9053, iter: 37, training_loss: 6.21680e-02\n",
            "epoch: 9054, iter: 37, training_loss: 6.08258e-02\n",
            "epoch: 9055, iter: 37, training_loss: 6.09317e-02\n",
            "epoch: 9056, iter: 37, training_loss: 6.16227e-02\n",
            "epoch: 9057, iter: 37, training_loss: 6.22007e-02\n",
            "epoch: 9058, iter: 37, training_loss: 6.13739e-02\n",
            "epoch: 9059, iter: 37, training_loss: 6.21673e-02\n",
            "epoch: 9060, iter: 37, training_loss: 6.37505e-02\n",
            "epoch: 9061, iter: 37, training_loss: 6.19420e-02\n",
            "epoch: 9062, iter: 37, training_loss: 5.98440e-02\n",
            "epoch: 9063, iter: 37, training_loss: 6.14397e-02\n",
            "epoch: 9064, iter: 37, training_loss: 6.45034e-02\n",
            "epoch: 9065, iter: 37, training_loss: 6.31786e-02\n",
            "epoch: 9066, iter: 37, training_loss: 6.25258e-02\n",
            "epoch: 9067, iter: 37, training_loss: 6.17610e-02\n",
            "epoch: 9068, iter: 37, training_loss: 6.09924e-02\n",
            "epoch: 9069, iter: 37, training_loss: 6.14323e-02\n",
            "epoch: 9070, iter: 37, training_loss: 6.21654e-02\n",
            "epoch: 9071, iter: 37, training_loss: 6.20557e-02\n",
            "epoch: 9072, iter: 37, training_loss: 6.37320e-02\n",
            "epoch: 9073, iter: 37, training_loss: 6.19541e-02\n",
            "epoch: 9074, iter: 37, training_loss: 6.21365e-02\n",
            "epoch: 9075, iter: 37, training_loss: 6.15095e-02\n",
            "epoch: 9076, iter: 37, training_loss: 6.39844e-02\n",
            "epoch: 9077, iter: 37, training_loss: 6.10412e-02\n",
            "epoch: 9078, iter: 37, training_loss: 6.42904e-02\n",
            "epoch: 9079, iter: 37, training_loss: 6.28251e-02\n",
            "epoch: 9080, iter: 37, training_loss: 6.16972e-02\n",
            "epoch: 9081, iter: 37, training_loss: 6.24922e-02\n",
            "epoch: 9082, iter: 37, training_loss: 6.13646e-02\n",
            "epoch: 9083, iter: 37, training_loss: 6.22287e-02\n",
            "epoch: 9084, iter: 37, training_loss: 6.33118e-02\n",
            "epoch: 9085, iter: 37, training_loss: 6.22110e-02\n",
            "epoch: 9086, iter: 37, training_loss: 6.10178e-02\n",
            "epoch: 9087, iter: 37, training_loss: 6.26445e-02\n",
            "epoch: 9088, iter: 37, training_loss: 6.31899e-02\n",
            "epoch: 9089, iter: 37, training_loss: 6.11970e-02\n",
            "epoch: 9090, iter: 37, training_loss: 6.25684e-02\n",
            "epoch: 9091, iter: 37, training_loss: 6.12859e-02\n",
            "epoch: 9092, iter: 37, training_loss: 6.31828e-02\n",
            "epoch: 9093, iter: 37, training_loss: 6.22186e-02\n",
            "epoch: 9094, iter: 37, training_loss: 6.09895e-02\n",
            "epoch: 9095, iter: 37, training_loss: 6.12630e-02\n",
            "epoch: 9096, iter: 37, training_loss: 6.16348e-02\n",
            "epoch: 9097, iter: 37, training_loss: 6.06668e-02\n",
            "epoch: 9098, iter: 37, training_loss: 6.22903e-02\n",
            "epoch: 9099, iter: 37, training_loss: 6.00510e-02\n",
            "epoch: 9100, iter: 37, training_loss: 6.24671e-02\n",
            "epoch: 9101, iter: 37, training_loss: 6.06800e-02\n",
            "epoch: 9102, iter: 37, training_loss: 6.22899e-02\n",
            "epoch: 9103, iter: 37, training_loss: 6.38220e-02\n",
            "epoch: 9104, iter: 37, training_loss: 6.14176e-02\n",
            "epoch: 9105, iter: 37, training_loss: 6.15646e-02\n",
            "epoch: 9106, iter: 37, training_loss: 5.93516e-02\n",
            "epoch: 9107, iter: 37, training_loss: 6.53984e-02\n",
            "epoch: 9108, iter: 37, training_loss: 6.20545e-02\n",
            "epoch: 9109, iter: 37, training_loss: 6.46422e-02\n",
            "epoch: 9110, iter: 37, training_loss: 6.25079e-02\n",
            "epoch: 9111, iter: 37, training_loss: 6.19686e-02\n",
            "epoch: 9112, iter: 37, training_loss: 6.26826e-02\n",
            "epoch: 9113, iter: 37, training_loss: 6.25076e-02\n",
            "epoch: 9114, iter: 37, training_loss: 6.11501e-02\n",
            "epoch: 9115, iter: 37, training_loss: 6.15323e-02\n",
            "epoch: 9116, iter: 37, training_loss: 6.10815e-02\n",
            "epoch: 9117, iter: 37, training_loss: 6.16161e-02\n",
            "epoch: 9118, iter: 37, training_loss: 6.23694e-02\n",
            "epoch: 9119, iter: 37, training_loss: 6.28538e-02\n",
            "epoch: 9120, iter: 37, training_loss: 6.54683e-02\n",
            "epoch: 9121, iter: 37, training_loss: 6.14714e-02\n",
            "epoch: 9122, iter: 37, training_loss: 6.37422e-02\n",
            "epoch: 9123, iter: 37, training_loss: 6.19944e-02\n",
            "epoch: 9124, iter: 37, training_loss: 6.13123e-02\n",
            "epoch: 9125, iter: 37, training_loss: 6.09105e-02\n",
            "epoch: 9126, iter: 37, training_loss: 6.06789e-02\n",
            "epoch: 9127, iter: 37, training_loss: 6.16424e-02\n",
            "epoch: 9128, iter: 37, training_loss: 5.97142e-02\n",
            "epoch: 9129, iter: 37, training_loss: 6.26079e-02\n",
            "epoch: 9130, iter: 37, training_loss: 6.24060e-02\n",
            "epoch: 9131, iter: 37, training_loss: 6.26144e-02\n",
            "epoch: 9132, iter: 37, training_loss: 6.21765e-02\n",
            "epoch: 9133, iter: 37, training_loss: 6.21948e-02\n",
            "epoch: 9134, iter: 37, training_loss: 6.21804e-02\n",
            "epoch: 9135, iter: 37, training_loss: 6.14649e-02\n",
            "epoch: 9136, iter: 37, training_loss: 6.13739e-02\n",
            "epoch: 9137, iter: 37, training_loss: 6.16923e-02\n",
            "epoch: 9138, iter: 37, training_loss: 6.19769e-02\n",
            "epoch: 9139, iter: 37, training_loss: 6.50614e-02\n",
            "epoch: 9140, iter: 37, training_loss: 6.07777e-02\n",
            "epoch: 9141, iter: 37, training_loss: 6.61000e-02\n",
            "epoch: 9142, iter: 37, training_loss: 6.21019e-02\n",
            "epoch: 9143, iter: 37, training_loss: 6.12816e-02\n",
            "epoch: 9144, iter: 37, training_loss: 6.22177e-02\n",
            "epoch: 9145, iter: 37, training_loss: 6.15081e-02\n",
            "epoch: 9146, iter: 37, training_loss: 6.29744e-02\n",
            "epoch: 9147, iter: 37, training_loss: 6.27688e-02\n",
            "epoch: 9148, iter: 37, training_loss: 6.15196e-02\n",
            "epoch: 9149, iter: 37, training_loss: 6.20079e-02\n",
            "epoch: 9150, iter: 37, training_loss: 6.09546e-02\n",
            "epoch: 9151, iter: 37, training_loss: 6.20026e-02\n",
            "epoch: 9152, iter: 37, training_loss: 6.15150e-02\n",
            "epoch: 9153, iter: 37, training_loss: 6.14286e-02\n",
            "epoch: 9154, iter: 37, training_loss: 6.18688e-02\n",
            "epoch: 9155, iter: 37, training_loss: 6.43648e-02\n",
            "epoch: 9156, iter: 37, training_loss: 6.13720e-02\n",
            "epoch: 9157, iter: 37, training_loss: 6.32565e-02\n",
            "epoch: 9158, iter: 37, training_loss: 6.02401e-02\n",
            "epoch: 9159, iter: 37, training_loss: 6.29965e-02\n",
            "epoch: 9160, iter: 37, training_loss: 6.27869e-02\n",
            "epoch: 9161, iter: 37, training_loss: 6.32807e-02\n",
            "epoch: 9162, iter: 37, training_loss: 6.30632e-02\n",
            "epoch: 9163, iter: 37, training_loss: 6.27529e-02\n",
            "epoch: 9164, iter: 37, training_loss: 6.30773e-02\n",
            "epoch: 9165, iter: 37, training_loss: 6.16477e-02\n",
            "epoch: 9166, iter: 37, training_loss: 6.25311e-02\n",
            "epoch: 9167, iter: 37, training_loss: 6.18024e-02\n",
            "epoch: 9168, iter: 37, training_loss: 6.15260e-02\n",
            "epoch: 9169, iter: 37, training_loss: 6.22340e-02\n",
            "epoch: 9170, iter: 37, training_loss: 6.39059e-02\n",
            "epoch: 9171, iter: 37, training_loss: 6.15848e-02\n",
            "epoch: 9172, iter: 37, training_loss: 6.33953e-02\n",
            "epoch: 9173, iter: 37, training_loss: 6.51921e-02\n",
            "epoch: 9174, iter: 37, training_loss: 6.36244e-02\n",
            "epoch: 9175, iter: 37, training_loss: 6.41006e-02\n",
            "epoch: 9176, iter: 37, training_loss: 6.28727e-02\n",
            "epoch: 9177, iter: 37, training_loss: 6.28844e-02\n",
            "epoch: 9178, iter: 37, training_loss: 6.61776e-02\n",
            "epoch: 9179, iter: 37, training_loss: 6.21178e-02\n",
            "epoch: 9180, iter: 37, training_loss: 6.10573e-02\n",
            "epoch: 9181, iter: 37, training_loss: 6.37872e-02\n",
            "epoch: 9182, iter: 37, training_loss: 6.31562e-02\n",
            "epoch: 9183, iter: 37, training_loss: 6.06499e-02\n",
            "epoch: 9184, iter: 37, training_loss: 6.08204e-02\n",
            "epoch: 9185, iter: 37, training_loss: 6.18305e-02\n",
            "epoch: 9186, iter: 37, training_loss: 6.36014e-02\n",
            "epoch: 9187, iter: 37, training_loss: 6.05295e-02\n",
            "epoch: 9188, iter: 37, training_loss: 6.08372e-02\n",
            "epoch: 9189, iter: 37, training_loss: 5.96140e-02\n",
            "epoch: 9190, iter: 37, training_loss: 6.00141e-02\n",
            "epoch: 9191, iter: 37, training_loss: 6.20379e-02\n",
            "epoch: 9192, iter: 37, training_loss: 6.14478e-02\n",
            "epoch: 9193, iter: 37, training_loss: 6.15034e-02\n",
            "epoch: 9194, iter: 37, training_loss: 6.07346e-02\n",
            "epoch: 9195, iter: 37, training_loss: 6.20539e-02\n",
            "epoch: 9196, iter: 37, training_loss: 6.36862e-02\n",
            "epoch: 9197, iter: 37, training_loss: 6.23490e-02\n",
            "epoch: 9198, iter: 37, training_loss: 6.16034e-02\n",
            "epoch: 9199, iter: 37, training_loss: 6.37713e-02\n",
            "epoch: 9200, iter: 37, training_loss: 6.28243e-02\n",
            "epoch: 9201, iter: 37, training_loss: 6.25071e-02\n",
            "epoch: 9202, iter: 37, training_loss: 6.36695e-02\n",
            "epoch: 9203, iter: 37, training_loss: 6.13082e-02\n",
            "epoch: 9204, iter: 37, training_loss: 6.28391e-02\n",
            "epoch: 9205, iter: 37, training_loss: 6.22547e-02\n",
            "epoch: 9206, iter: 37, training_loss: 6.37467e-02\n",
            "epoch: 9207, iter: 37, training_loss: 6.25901e-02\n",
            "epoch: 9208, iter: 37, training_loss: 6.06469e-02\n",
            "epoch: 9209, iter: 37, training_loss: 5.99241e-02\n",
            "epoch: 9210, iter: 37, training_loss: 6.04557e-02\n",
            "epoch: 9211, iter: 37, training_loss: 6.08083e-02\n",
            "epoch: 9212, iter: 37, training_loss: 6.63307e-02\n",
            "epoch: 9213, iter: 37, training_loss: 6.13758e-02\n",
            "epoch: 9214, iter: 37, training_loss: 6.12941e-02\n",
            "epoch: 9215, iter: 37, training_loss: 6.18721e-02\n",
            "epoch: 9216, iter: 37, training_loss: 6.21868e-02\n",
            "epoch: 9217, iter: 37, training_loss: 6.09143e-02\n",
            "epoch: 9218, iter: 37, training_loss: 6.29101e-02\n",
            "epoch: 9219, iter: 37, training_loss: 6.26574e-02\n",
            "epoch: 9220, iter: 37, training_loss: 6.23239e-02\n",
            "epoch: 9221, iter: 37, training_loss: 6.12877e-02\n",
            "epoch: 9222, iter: 37, training_loss: 6.05963e-02\n",
            "epoch: 9223, iter: 37, training_loss: 6.32353e-02\n",
            "epoch: 9224, iter: 37, training_loss: 6.12562e-02\n",
            "epoch: 9225, iter: 37, training_loss: 6.01490e-02\n",
            "epoch: 9226, iter: 37, training_loss: 6.17303e-02\n",
            "epoch: 9227, iter: 37, training_loss: 6.21661e-02\n",
            "epoch: 9228, iter: 37, training_loss: 6.20384e-02\n",
            "epoch: 9229, iter: 37, training_loss: 6.11510e-02\n",
            "epoch: 9230, iter: 37, training_loss: 6.14606e-02\n",
            "epoch: 9231, iter: 37, training_loss: 6.15913e-02\n",
            "epoch: 9232, iter: 37, training_loss: 6.17640e-02\n",
            "epoch: 9233, iter: 37, training_loss: 6.41573e-02\n",
            "epoch: 9234, iter: 37, training_loss: 6.12775e-02\n",
            "epoch: 9235, iter: 37, training_loss: 6.33945e-02\n",
            "epoch: 9236, iter: 37, training_loss: 6.05138e-02\n",
            "epoch: 9237, iter: 37, training_loss: 6.06359e-02\n",
            "epoch: 9238, iter: 37, training_loss: 6.35027e-02\n",
            "epoch: 9239, iter: 37, training_loss: 6.32473e-02\n",
            "epoch: 9240, iter: 37, training_loss: 6.13802e-02\n",
            "epoch: 9241, iter: 37, training_loss: 6.08944e-02\n",
            "epoch: 9242, iter: 37, training_loss: 6.16600e-02\n",
            "epoch: 9243, iter: 37, training_loss: 6.25353e-02\n",
            "epoch: 9244, iter: 37, training_loss: 6.15688e-02\n",
            "epoch: 9245, iter: 37, training_loss: 6.19207e-02\n",
            "epoch: 9246, iter: 37, training_loss: 6.25869e-02\n",
            "epoch: 9247, iter: 37, training_loss: 6.07502e-02\n",
            "epoch: 9248, iter: 37, training_loss: 6.28338e-02\n",
            "epoch: 9249, iter: 37, training_loss: 6.15646e-02\n",
            "epoch: 9250, iter: 37, training_loss: 6.19962e-02\n",
            "epoch: 9251, iter: 37, training_loss: 6.03157e-02\n",
            "epoch: 9252, iter: 37, training_loss: 6.14490e-02\n",
            "epoch: 9253, iter: 37, training_loss: 6.19573e-02\n",
            "epoch: 9254, iter: 37, training_loss: 6.20530e-02\n",
            "epoch: 9255, iter: 37, training_loss: 6.05247e-02\n",
            "epoch: 9256, iter: 37, training_loss: 6.33282e-02\n",
            "epoch: 9257, iter: 37, training_loss: 6.46108e-02\n",
            "epoch: 9258, iter: 37, training_loss: 6.28644e-02\n",
            "epoch: 9259, iter: 37, training_loss: 6.19956e-02\n",
            "epoch: 9260, iter: 37, training_loss: 6.12397e-02\n",
            "epoch: 9261, iter: 37, training_loss: 6.15824e-02\n",
            "epoch: 9262, iter: 37, training_loss: 6.29695e-02\n",
            "epoch: 9263, iter: 37, training_loss: 6.37930e-02\n",
            "epoch: 9264, iter: 37, training_loss: 6.14353e-02\n",
            "epoch: 9265, iter: 37, training_loss: 6.11280e-02\n",
            "epoch: 9266, iter: 37, training_loss: 6.50155e-02\n",
            "epoch: 9267, iter: 37, training_loss: 6.24263e-02\n",
            "epoch: 9268, iter: 37, training_loss: 6.27808e-02\n",
            "epoch: 9269, iter: 37, training_loss: 6.07241e-02\n",
            "epoch: 9270, iter: 37, training_loss: 6.18641e-02\n",
            "epoch: 9271, iter: 37, training_loss: 6.48963e-02\n",
            "epoch: 9272, iter: 37, training_loss: 5.97460e-02\n",
            "epoch: 9273, iter: 37, training_loss: 6.11679e-02\n",
            "epoch: 9274, iter: 37, training_loss: 6.13162e-02\n",
            "epoch: 9275, iter: 37, training_loss: 6.18415e-02\n",
            "epoch: 9276, iter: 37, training_loss: 6.19362e-02\n",
            "epoch: 9277, iter: 37, training_loss: 6.23649e-02\n",
            "epoch: 9278, iter: 37, training_loss: 6.12017e-02\n",
            "epoch: 9279, iter: 37, training_loss: 6.16832e-02\n",
            "epoch: 9280, iter: 37, training_loss: 6.11553e-02\n",
            "epoch: 9281, iter: 37, training_loss: 6.12417e-02\n",
            "epoch: 9282, iter: 37, training_loss: 5.94257e-02\n",
            "epoch: 9283, iter: 37, training_loss: 6.31373e-02\n",
            "epoch: 9284, iter: 37, training_loss: 6.13739e-02\n",
            "epoch: 9285, iter: 37, training_loss: 6.19314e-02\n",
            "epoch: 9286, iter: 37, training_loss: 6.11161e-02\n",
            "epoch: 9287, iter: 37, training_loss: 6.11396e-02\n",
            "epoch: 9288, iter: 37, training_loss: 6.21900e-02\n",
            "epoch: 9289, iter: 37, training_loss: 6.21618e-02\n",
            "epoch: 9290, iter: 37, training_loss: 6.13150e-02\n",
            "epoch: 9291, iter: 37, training_loss: 6.06255e-02\n",
            "epoch: 9292, iter: 37, training_loss: 6.13539e-02\n",
            "epoch: 9293, iter: 37, training_loss: 6.16968e-02\n",
            "epoch: 9294, iter: 37, training_loss: 6.02729e-02\n",
            "epoch: 9295, iter: 37, training_loss: 6.01532e-02\n",
            "epoch: 9296, iter: 37, training_loss: 6.14616e-02\n",
            "epoch: 9297, iter: 37, training_loss: 6.16045e-02\n",
            "epoch: 9298, iter: 37, training_loss: 6.14573e-02\n",
            "epoch: 9299, iter: 37, training_loss: 6.20098e-02\n",
            "epoch: 9300, iter: 37, training_loss: 6.41663e-02\n",
            "epoch: 9301, iter: 37, training_loss: 6.03098e-02\n",
            "epoch: 9302, iter: 37, training_loss: 6.31111e-02\n",
            "epoch: 9303, iter: 37, training_loss: 6.21828e-02\n",
            "epoch: 9304, iter: 37, training_loss: 6.09152e-02\n",
            "epoch: 9305, iter: 37, training_loss: 6.28465e-02\n",
            "epoch: 9306, iter: 37, training_loss: 6.12145e-02\n",
            "epoch: 9307, iter: 37, training_loss: 6.06110e-02\n",
            "epoch: 9308, iter: 37, training_loss: 6.42592e-02\n",
            "epoch: 9309, iter: 37, training_loss: 6.13221e-02\n",
            "epoch: 9310, iter: 37, training_loss: 6.11032e-02\n",
            "epoch: 9311, iter: 37, training_loss: 6.07111e-02\n",
            "epoch: 9312, iter: 37, training_loss: 6.49213e-02\n",
            "epoch: 9313, iter: 37, training_loss: 6.39237e-02\n",
            "epoch: 9314, iter: 37, training_loss: 6.20225e-02\n",
            "epoch: 9315, iter: 37, training_loss: 6.25307e-02\n",
            "epoch: 9316, iter: 37, training_loss: 6.14056e-02\n",
            "epoch: 9317, iter: 37, training_loss: 6.15256e-02\n",
            "epoch: 9318, iter: 37, training_loss: 6.24779e-02\n",
            "epoch: 9319, iter: 37, training_loss: 6.13872e-02\n",
            "epoch: 9320, iter: 37, training_loss: 6.13778e-02\n",
            "epoch: 9321, iter: 37, training_loss: 6.30178e-02\n",
            "epoch: 9322, iter: 37, training_loss: 6.29462e-02\n",
            "epoch: 9323, iter: 37, training_loss: 6.11460e-02\n",
            "epoch: 9324, iter: 37, training_loss: 6.10920e-02\n",
            "epoch: 9325, iter: 37, training_loss: 6.11697e-02\n",
            "epoch: 9326, iter: 37, training_loss: 6.12661e-02\n",
            "epoch: 9327, iter: 37, training_loss: 6.18566e-02\n",
            "epoch: 9328, iter: 37, training_loss: 6.20516e-02\n",
            "epoch: 9329, iter: 37, training_loss: 5.96916e-02\n",
            "epoch: 9330, iter: 37, training_loss: 6.12050e-02\n",
            "epoch: 9331, iter: 37, training_loss: 6.50855e-02\n",
            "epoch: 9332, iter: 37, training_loss: 6.26005e-02\n",
            "epoch: 9333, iter: 37, training_loss: 6.26514e-02\n",
            "epoch: 9334, iter: 37, training_loss: 6.25029e-02\n",
            "epoch: 9335, iter: 37, training_loss: 6.04859e-02\n",
            "epoch: 9336, iter: 37, training_loss: 6.13745e-02\n",
            "epoch: 9337, iter: 37, training_loss: 6.13937e-02\n",
            "epoch: 9338, iter: 37, training_loss: 6.16487e-02\n",
            "epoch: 9339, iter: 37, training_loss: 6.07523e-02\n",
            "epoch: 9340, iter: 37, training_loss: 6.23298e-02\n",
            "epoch: 9341, iter: 37, training_loss: 6.24864e-02\n",
            "epoch: 9342, iter: 37, training_loss: 6.13376e-02\n",
            "epoch: 9343, iter: 37, training_loss: 6.15721e-02\n",
            "epoch: 9344, iter: 37, training_loss: 6.35843e-02\n",
            "epoch: 9345, iter: 37, training_loss: 6.23914e-02\n",
            "epoch: 9346, iter: 37, training_loss: 6.14104e-02\n",
            "epoch: 9347, iter: 37, training_loss: 6.02840e-02\n",
            "epoch: 9348, iter: 37, training_loss: 6.24836e-02\n",
            "epoch: 9349, iter: 37, training_loss: 6.37593e-02\n",
            "epoch: 9350, iter: 37, training_loss: 6.08781e-02\n",
            "epoch: 9351, iter: 37, training_loss: 6.19412e-02\n",
            "epoch: 9352, iter: 37, training_loss: 6.13978e-02\n",
            "epoch: 9353, iter: 37, training_loss: 6.05522e-02\n",
            "epoch: 9354, iter: 37, training_loss: 6.09888e-02\n",
            "epoch: 9355, iter: 37, training_loss: 6.21328e-02\n",
            "epoch: 9356, iter: 37, training_loss: 6.05127e-02\n",
            "epoch: 9357, iter: 37, training_loss: 6.45001e-02\n",
            "epoch: 9358, iter: 37, training_loss: 6.24063e-02\n",
            "epoch: 9359, iter: 37, training_loss: 6.25176e-02\n",
            "epoch: 9360, iter: 37, training_loss: 6.51943e-02\n",
            "epoch: 9361, iter: 37, training_loss: 6.34359e-02\n",
            "epoch: 9362, iter: 37, training_loss: 6.16046e-02\n",
            "epoch: 9363, iter: 37, training_loss: 6.23224e-02\n",
            "epoch: 9364, iter: 37, training_loss: 6.34233e-02\n",
            "epoch: 9365, iter: 37, training_loss: 6.08777e-02\n",
            "epoch: 9366, iter: 37, training_loss: 6.11373e-02\n",
            "epoch: 9367, iter: 37, training_loss: 6.30840e-02\n",
            "epoch: 9368, iter: 37, training_loss: 6.10314e-02\n",
            "epoch: 9369, iter: 37, training_loss: 6.23615e-02\n",
            "epoch: 9370, iter: 37, training_loss: 5.94167e-02\n",
            "epoch: 9371, iter: 37, training_loss: 6.12244e-02\n",
            "epoch: 9372, iter: 37, training_loss: 6.01280e-02\n",
            "epoch: 9373, iter: 37, training_loss: 6.25807e-02\n",
            "epoch: 9374, iter: 37, training_loss: 6.02418e-02\n",
            "epoch: 9375, iter: 37, training_loss: 6.17085e-02\n",
            "epoch: 9376, iter: 37, training_loss: 6.06477e-02\n",
            "epoch: 9377, iter: 37, training_loss: 6.22380e-02\n",
            "epoch: 9378, iter: 37, training_loss: 6.18798e-02\n",
            "epoch: 9379, iter: 37, training_loss: 6.24809e-02\n",
            "epoch: 9380, iter: 37, training_loss: 6.01295e-02\n",
            "epoch: 9381, iter: 37, training_loss: 6.67720e-02\n",
            "epoch: 9382, iter: 37, training_loss: 6.12197e-02\n",
            "epoch: 9383, iter: 37, training_loss: 6.07947e-02\n",
            "epoch: 9384, iter: 37, training_loss: 6.12929e-02\n",
            "epoch: 9385, iter: 37, training_loss: 6.13385e-02\n",
            "epoch: 9386, iter: 37, training_loss: 6.18404e-02\n",
            "epoch: 9387, iter: 37, training_loss: 6.47844e-02\n",
            "epoch: 9388, iter: 37, training_loss: 6.15713e-02\n",
            "epoch: 9389, iter: 37, training_loss: 5.96339e-02\n",
            "epoch: 9390, iter: 37, training_loss: 6.06721e-02\n",
            "epoch: 9391, iter: 37, training_loss: 5.95563e-02\n",
            "epoch: 9392, iter: 37, training_loss: 6.45709e-02\n",
            "epoch: 9393, iter: 37, training_loss: 6.22711e-02\n",
            "epoch: 9394, iter: 37, training_loss: 6.06831e-02\n",
            "epoch: 9395, iter: 37, training_loss: 6.13899e-02\n",
            "epoch: 9396, iter: 37, training_loss: 6.35719e-02\n",
            "epoch: 9397, iter: 37, training_loss: 6.44069e-02\n",
            "epoch: 9398, iter: 37, training_loss: 6.23692e-02\n",
            "epoch: 9399, iter: 37, training_loss: 5.98093e-02\n",
            "epoch: 9400, iter: 37, training_loss: 6.15809e-02\n",
            "epoch: 9401, iter: 37, training_loss: 6.24981e-02\n",
            "epoch: 9402, iter: 37, training_loss: 6.05687e-02\n",
            "epoch: 9403, iter: 37, training_loss: 6.09544e-02\n",
            "epoch: 9404, iter: 37, training_loss: 6.34630e-02\n",
            "epoch: 9405, iter: 37, training_loss: 6.07219e-02\n",
            "epoch: 9406, iter: 37, training_loss: 6.12839e-02\n",
            "epoch: 9407, iter: 37, training_loss: 6.26949e-02\n",
            "epoch: 9408, iter: 37, training_loss: 6.21448e-02\n",
            "epoch: 9409, iter: 37, training_loss: 6.11788e-02\n",
            "epoch: 9410, iter: 37, training_loss: 6.06815e-02\n",
            "epoch: 9411, iter: 37, training_loss: 6.10767e-02\n",
            "epoch: 9412, iter: 37, training_loss: 6.23807e-02\n",
            "epoch: 9413, iter: 37, training_loss: 6.17411e-02\n",
            "epoch: 9414, iter: 37, training_loss: 6.15601e-02\n",
            "epoch: 9415, iter: 37, training_loss: 6.32315e-02\n",
            "epoch: 9416, iter: 37, training_loss: 6.30466e-02\n",
            "epoch: 9417, iter: 37, training_loss: 6.02857e-02\n",
            "epoch: 9418, iter: 37, training_loss: 6.15055e-02\n",
            "epoch: 9419, iter: 37, training_loss: 6.30904e-02\n",
            "epoch: 9420, iter: 37, training_loss: 6.18656e-02\n",
            "epoch: 9421, iter: 37, training_loss: 5.98815e-02\n",
            "epoch: 9422, iter: 37, training_loss: 5.95888e-02\n",
            "epoch: 9423, iter: 37, training_loss: 6.13004e-02\n",
            "epoch: 9424, iter: 37, training_loss: 6.04363e-02\n",
            "epoch: 9425, iter: 37, training_loss: 6.17371e-02\n",
            "epoch: 9426, iter: 37, training_loss: 6.17155e-02\n",
            "epoch: 9427, iter: 37, training_loss: 6.25314e-02\n",
            "epoch: 9428, iter: 37, training_loss: 6.12373e-02\n",
            "epoch: 9429, iter: 37, training_loss: 6.20255e-02\n",
            "epoch: 9430, iter: 37, training_loss: 6.07493e-02\n",
            "epoch: 9431, iter: 37, training_loss: 6.15688e-02\n",
            "epoch: 9432, iter: 37, training_loss: 6.00973e-02\n",
            "epoch: 9433, iter: 37, training_loss: 6.13035e-02\n",
            "epoch: 9434, iter: 37, training_loss: 6.10408e-02\n",
            "epoch: 9435, iter: 37, training_loss: 6.09608e-02\n",
            "epoch: 9436, iter: 37, training_loss: 6.33062e-02\n",
            "epoch: 9437, iter: 37, training_loss: 6.22310e-02\n",
            "epoch: 9438, iter: 37, training_loss: 6.10870e-02\n",
            "epoch: 9439, iter: 37, training_loss: 6.08473e-02\n",
            "epoch: 9440, iter: 37, training_loss: 6.18610e-02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname beijing --method stasy --mode sample --save_path beijing_syn.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qt3WX5N0-3Ax",
        "outputId": "3368b263-82b7-4433-9ade-99d3d0ff7cc3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No NaNs in numerical features, skipping\n",
            "Input dimension: 83\n",
            "NCSNpp(\n",
            "  (act): ELU(alpha=1.0)\n",
            "  (all_modules): ModuleList(\n",
            "    (0): GaussianFourierProjection()\n",
            "    (1): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (3): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=83, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (4): ELU(alpha=1.0)\n",
            "    (5): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=1107, out_features=2048, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=2048, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=2048, bias=True)\n",
            "    )\n",
            "    (6): ELU(alpha=1.0)\n",
            "    (7): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=3155, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (8): ELU(alpha=1.0)\n",
            "    (9): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=4179, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (10): ELU(alpha=1.0)\n",
            "    (11): Linear(in_features=5203, out_features=83, bias=True)\n",
            "  )\n",
            ")\n",
            "the number of parameters 10413436\n",
            "Loading SAVED model at from /content/tabsyn/baselines/stasy/ckpt/beijing/model.pth\n",
            "Start sampling...\n",
            "Sampling time = 42.598732709884644\n",
            "Saving sampled data to beijing_syn.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname adult --method stasy --mode train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hom4WKlGJumn",
        "outputId": "81826600-f022-4544-9a30-1c18f4861d40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No NaNs in numerical features, skipping\n",
            "110\n",
            "NCSNpp(\n",
            "  (act): ELU(alpha=1.0)\n",
            "  (all_modules): ModuleList(\n",
            "    (0): GaussianFourierProjection()\n",
            "    (1): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (3): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=110, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (4): ELU(alpha=1.0)\n",
            "    (5): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=1134, out_features=2048, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=2048, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=2048, bias=True)\n",
            "    )\n",
            "    (6): ELU(alpha=1.0)\n",
            "    (7): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=3182, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (8): ELU(alpha=1.0)\n",
            "    (9): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=4206, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (10): ELU(alpha=1.0)\n",
            "    (11): Linear(in_features=5230, out_features=110, bias=True)\n",
            "  )\n",
            ")\n",
            "the number of parameters 10695154\n",
            "epoch: 0, iter: 32, training_loss: 2.40483e+00\n",
            "epoch: 1, iter: 32, training_loss: 1.34937e+00\n",
            "epoch: 2, iter: 32, training_loss: 1.33356e+00\n",
            "epoch: 3, iter: 32, training_loss: 1.36094e+00\n",
            "epoch: 4, iter: 32, training_loss: 1.32903e+00\n",
            "epoch: 5, iter: 32, training_loss: 1.30020e+00\n",
            "epoch: 6, iter: 32, training_loss: 1.29891e+00\n",
            "epoch: 7, iter: 32, training_loss: 1.27200e+00\n",
            "epoch: 8, iter: 32, training_loss: 1.19428e+00\n",
            "epoch: 9, iter: 32, training_loss: 1.20978e+00\n",
            "epoch: 10, iter: 32, training_loss: 1.18273e+00\n",
            "epoch: 11, iter: 32, training_loss: 1.18273e+00\n",
            "epoch: 12, iter: 32, training_loss: 1.12630e+00\n",
            "epoch: 13, iter: 32, training_loss: 1.14706e+00\n",
            "epoch: 14, iter: 32, training_loss: 1.14139e+00\n",
            "epoch: 15, iter: 32, training_loss: 1.12968e+00\n",
            "epoch: 16, iter: 32, training_loss: 1.05103e+00\n",
            "epoch: 17, iter: 32, training_loss: 1.05976e+00\n",
            "epoch: 18, iter: 32, training_loss: 1.05734e+00\n",
            "epoch: 19, iter: 32, training_loss: 1.10674e+00\n",
            "epoch: 20, iter: 32, training_loss: 1.17228e+00\n",
            "epoch: 21, iter: 32, training_loss: 1.10165e+00\n",
            "epoch: 22, iter: 32, training_loss: 1.08856e+00\n",
            "epoch: 23, iter: 32, training_loss: 1.10263e+00\n",
            "epoch: 24, iter: 32, training_loss: 1.13453e+00\n",
            "epoch: 25, iter: 32, training_loss: 1.11402e+00\n",
            "epoch: 26, iter: 32, training_loss: 1.11063e+00\n",
            "epoch: 27, iter: 32, training_loss: 1.14799e+00\n",
            "epoch: 28, iter: 32, training_loss: 1.25180e+00\n",
            "epoch: 29, iter: 32, training_loss: 1.23784e+00\n",
            "epoch: 30, iter: 32, training_loss: 1.16961e+00\n",
            "epoch: 31, iter: 32, training_loss: 1.21687e+00\n",
            "epoch: 32, iter: 32, training_loss: 1.30334e+00\n",
            "epoch: 33, iter: 32, training_loss: 1.25877e+00\n",
            "epoch: 34, iter: 32, training_loss: 1.29926e+00\n",
            "epoch: 35, iter: 32, training_loss: 1.30057e+00\n",
            "epoch: 36, iter: 32, training_loss: 1.35971e+00\n",
            "epoch: 37, iter: 32, training_loss: 1.47066e+00\n",
            "epoch: 38, iter: 32, training_loss: 1.37041e+00\n",
            "epoch: 39, iter: 32, training_loss: 1.43727e+00\n",
            "epoch: 40, iter: 32, training_loss: 1.38743e+00\n",
            "epoch: 41, iter: 32, training_loss: 1.30151e+00\n",
            "epoch: 42, iter: 32, training_loss: 1.48619e+00\n",
            "epoch: 43, iter: 32, training_loss: 1.56480e+00\n",
            "epoch: 44, iter: 32, training_loss: 1.45857e+00\n",
            "epoch: 45, iter: 32, training_loss: 1.50135e+00\n",
            "epoch: 46, iter: 32, training_loss: 1.64077e+00\n",
            "epoch: 47, iter: 32, training_loss: 1.59159e+00\n",
            "epoch: 48, iter: 32, training_loss: 1.50403e+00\n",
            "epoch: 49, iter: 32, training_loss: 1.75175e+00\n",
            "epoch: 50, iter: 32, training_loss: 1.52024e+00\n",
            "epoch: 51, iter: 32, training_loss: 1.58734e+00\n",
            "epoch: 52, iter: 32, training_loss: 1.56328e+00\n",
            "epoch: 53, iter: 32, training_loss: 1.91090e+00\n",
            "epoch: 54, iter: 32, training_loss: 1.86642e+00\n",
            "epoch: 55, iter: 32, training_loss: 1.98866e+00\n",
            "epoch: 56, iter: 32, training_loss: 2.05846e+00\n",
            "epoch: 57, iter: 32, training_loss: 1.86741e+00\n",
            "epoch: 58, iter: 32, training_loss: 1.70147e+00\n",
            "epoch: 59, iter: 32, training_loss: 1.72288e+00\n",
            "epoch: 60, iter: 32, training_loss: 1.70914e+00\n",
            "epoch: 61, iter: 32, training_loss: 1.79582e+00\n",
            "epoch: 62, iter: 32, training_loss: 1.85400e+00\n",
            "epoch: 63, iter: 32, training_loss: 1.90432e+00\n",
            "epoch: 64, iter: 32, training_loss: 2.01751e+00\n",
            "epoch: 65, iter: 32, training_loss: 2.13403e+00\n",
            "epoch: 66, iter: 32, training_loss: 1.97676e+00\n",
            "epoch: 67, iter: 32, training_loss: 2.11443e+00\n",
            "epoch: 68, iter: 32, training_loss: 2.12287e+00\n",
            "epoch: 69, iter: 32, training_loss: 2.22535e+00\n",
            "epoch: 70, iter: 32, training_loss: 1.93592e+00\n",
            "epoch: 71, iter: 32, training_loss: 1.96339e+00\n",
            "epoch: 72, iter: 32, training_loss: 2.30972e+00\n",
            "epoch: 73, iter: 32, training_loss: 2.13651e+00\n",
            "epoch: 74, iter: 32, training_loss: 1.91722e+00\n",
            "epoch: 75, iter: 32, training_loss: 2.06379e+00\n",
            "epoch: 76, iter: 32, training_loss: 2.52825e+00\n",
            "epoch: 77, iter: 32, training_loss: 2.35337e+00\n",
            "epoch: 78, iter: 32, training_loss: 2.48469e+00\n",
            "epoch: 79, iter: 32, training_loss: 3.05060e+00\n",
            "epoch: 80, iter: 32, training_loss: 2.95761e+00\n",
            "epoch: 81, iter: 32, training_loss: 2.84291e+00\n",
            "epoch: 82, iter: 32, training_loss: 2.36255e+00\n",
            "epoch: 83, iter: 32, training_loss: 2.50982e+00\n",
            "epoch: 84, iter: 32, training_loss: 2.63192e+00\n",
            "epoch: 85, iter: 32, training_loss: 2.88176e+00\n",
            "epoch: 86, iter: 32, training_loss: 2.67030e+00\n",
            "epoch: 87, iter: 32, training_loss: 2.83854e+00\n",
            "epoch: 88, iter: 32, training_loss: 2.78164e+00\n",
            "epoch: 89, iter: 32, training_loss: 2.53126e+00\n",
            "epoch: 90, iter: 32, training_loss: 2.87311e+00\n",
            "epoch: 91, iter: 32, training_loss: 2.91209e+00\n",
            "epoch: 92, iter: 32, training_loss: 2.83997e+00\n",
            "epoch: 93, iter: 32, training_loss: 2.09497e+00\n",
            "epoch: 94, iter: 32, training_loss: 2.50010e+00\n",
            "epoch: 95, iter: 32, training_loss: 3.07559e+00\n",
            "epoch: 96, iter: 32, training_loss: 2.93735e+00\n",
            "epoch: 97, iter: 32, training_loss: 2.66331e+00\n",
            "epoch: 98, iter: 32, training_loss: 2.67774e+00\n",
            "epoch: 99, iter: 32, training_loss: 3.02809e+00\n",
            "epoch: 100, iter: 32, training_loss: 2.92540e+00\n",
            "epoch: 101, iter: 32, training_loss: 2.75044e+00\n",
            "epoch: 102, iter: 32, training_loss: 2.95993e+00\n",
            "epoch: 103, iter: 32, training_loss: 3.05957e+00\n",
            "epoch: 104, iter: 32, training_loss: 3.30330e+00\n",
            "epoch: 105, iter: 32, training_loss: 3.16195e+00\n",
            "epoch: 106, iter: 32, training_loss: 3.28951e+00\n",
            "epoch: 107, iter: 32, training_loss: 3.54925e+00\n",
            "epoch: 108, iter: 32, training_loss: 3.40774e+00\n",
            "epoch: 109, iter: 32, training_loss: 3.21910e+00\n",
            "epoch: 110, iter: 32, training_loss: 3.14910e+00\n",
            "epoch: 111, iter: 32, training_loss: 3.18317e+00\n",
            "epoch: 112, iter: 32, training_loss: 3.42235e+00\n",
            "epoch: 113, iter: 32, training_loss: 3.14260e+00\n",
            "epoch: 114, iter: 32, training_loss: 3.06632e+00\n",
            "epoch: 115, iter: 32, training_loss: 3.65230e+00\n",
            "epoch: 116, iter: 32, training_loss: 3.55241e+00\n",
            "epoch: 117, iter: 32, training_loss: 3.40179e+00\n",
            "epoch: 118, iter: 32, training_loss: 3.12321e+00\n",
            "epoch: 119, iter: 32, training_loss: 3.56289e+00\n",
            "epoch: 120, iter: 32, training_loss: 3.22176e+00\n",
            "epoch: 121, iter: 32, training_loss: 3.49344e+00\n",
            "epoch: 122, iter: 32, training_loss: 3.68268e+00\n",
            "epoch: 123, iter: 32, training_loss: 3.75088e+00\n",
            "epoch: 124, iter: 32, training_loss: 3.50789e+00\n",
            "epoch: 125, iter: 32, training_loss: 3.21779e+00\n",
            "epoch: 126, iter: 32, training_loss: 3.54107e+00\n",
            "epoch: 127, iter: 32, training_loss: 3.65388e+00\n",
            "epoch: 128, iter: 32, training_loss: 3.98772e+00\n",
            "epoch: 129, iter: 32, training_loss: 4.43602e+00\n",
            "epoch: 130, iter: 32, training_loss: 3.95917e+00\n",
            "epoch: 131, iter: 32, training_loss: 3.60472e+00\n",
            "epoch: 132, iter: 32, training_loss: 3.65164e+00\n",
            "epoch: 133, iter: 32, training_loss: 3.63616e+00\n",
            "epoch: 134, iter: 32, training_loss: 3.52918e+00\n",
            "epoch: 135, iter: 32, training_loss: 3.91750e+00\n",
            "epoch: 136, iter: 32, training_loss: 3.91081e+00\n",
            "epoch: 137, iter: 32, training_loss: 3.69752e+00\n",
            "epoch: 138, iter: 32, training_loss: 3.85781e+00\n",
            "epoch: 139, iter: 32, training_loss: 3.67759e+00\n",
            "epoch: 140, iter: 32, training_loss: 3.96035e+00\n",
            "epoch: 141, iter: 32, training_loss: 3.69055e+00\n",
            "epoch: 142, iter: 32, training_loss: 3.30398e+00\n",
            "epoch: 143, iter: 32, training_loss: 3.37705e+00\n",
            "epoch: 144, iter: 32, training_loss: 3.81065e+00\n",
            "epoch: 145, iter: 32, training_loss: 3.41057e+00\n",
            "epoch: 146, iter: 32, training_loss: 3.64129e+00\n",
            "epoch: 147, iter: 32, training_loss: 4.05517e+00\n",
            "epoch: 148, iter: 32, training_loss: 3.20270e+00\n",
            "epoch: 149, iter: 32, training_loss: 3.26357e+00\n",
            "epoch: 150, iter: 32, training_loss: 3.59809e+00\n",
            "epoch: 151, iter: 32, training_loss: 3.80140e+00\n",
            "epoch: 152, iter: 32, training_loss: 3.65574e+00\n",
            "epoch: 153, iter: 32, training_loss: 3.11234e+00\n",
            "epoch: 154, iter: 32, training_loss: 3.19119e+00\n",
            "epoch: 155, iter: 32, training_loss: 3.33097e+00\n",
            "epoch: 156, iter: 32, training_loss: 3.33656e+00\n",
            "epoch: 157, iter: 32, training_loss: 3.96422e+00\n",
            "epoch: 158, iter: 32, training_loss: 3.49903e+00\n",
            "epoch: 159, iter: 32, training_loss: 3.16749e+00\n",
            "epoch: 160, iter: 32, training_loss: 3.27544e+00\n",
            "epoch: 161, iter: 32, training_loss: 3.53531e+00\n",
            "epoch: 162, iter: 32, training_loss: 2.83705e+00\n",
            "epoch: 163, iter: 32, training_loss: 2.95688e+00\n",
            "epoch: 164, iter: 32, training_loss: 2.67014e+00\n",
            "epoch: 165, iter: 32, training_loss: 2.55156e+00\n",
            "epoch: 166, iter: 32, training_loss: 2.74753e+00\n",
            "epoch: 167, iter: 32, training_loss: 3.20551e+00\n",
            "epoch: 168, iter: 32, training_loss: 2.40515e+00\n",
            "epoch: 169, iter: 32, training_loss: 2.58850e+00\n",
            "epoch: 170, iter: 32, training_loss: 2.16574e+00\n",
            "epoch: 171, iter: 32, training_loss: 2.07573e+00\n",
            "epoch: 172, iter: 32, training_loss: 2.20848e+00\n",
            "epoch: 173, iter: 32, training_loss: 2.26371e+00\n",
            "epoch: 174, iter: 32, training_loss: 1.91309e+00\n",
            "epoch: 175, iter: 32, training_loss: 1.94398e+00\n",
            "epoch: 176, iter: 32, training_loss: 2.00225e+00\n",
            "epoch: 177, iter: 32, training_loss: 1.56682e+00\n",
            "epoch: 178, iter: 32, training_loss: 1.56662e+00\n",
            "epoch: 179, iter: 32, training_loss: 1.63758e+00\n",
            "epoch: 180, iter: 32, training_loss: 1.53806e+00\n",
            "epoch: 181, iter: 32, training_loss: 1.33898e+00\n",
            "epoch: 182, iter: 32, training_loss: 1.03086e+00\n",
            "epoch: 183, iter: 32, training_loss: 1.01530e+00\n",
            "epoch: 184, iter: 32, training_loss: 9.63980e-01\n",
            "epoch: 185, iter: 32, training_loss: 8.95495e-01\n",
            "epoch: 186, iter: 32, training_loss: 8.95256e-01\n",
            "epoch: 187, iter: 32, training_loss: 8.61771e-01\n",
            "epoch: 188, iter: 32, training_loss: 8.52562e-01\n",
            "epoch: 189, iter: 32, training_loss: 1.33069e+00\n",
            "epoch: 190, iter: 32, training_loss: 9.74962e-01\n",
            "epoch: 191, iter: 32, training_loss: 9.77257e-01\n",
            "epoch: 192, iter: 32, training_loss: 9.26430e-01\n",
            "epoch: 193, iter: 32, training_loss: 8.72222e-01\n",
            "epoch: 194, iter: 32, training_loss: 8.87671e-01\n",
            "epoch: 195, iter: 32, training_loss: 9.45898e-01\n",
            "epoch: 196, iter: 32, training_loss: 8.41893e-01\n",
            "epoch: 197, iter: 32, training_loss: 8.93534e-01\n",
            "epoch: 198, iter: 32, training_loss: 8.84363e-01\n",
            "epoch: 199, iter: 32, training_loss: 1.11560e+00\n",
            "epoch: 200, iter: 32, training_loss: 8.35537e-01\n",
            "epoch: 201, iter: 32, training_loss: 9.08960e-01\n",
            "epoch: 202, iter: 32, training_loss: 9.43835e-01\n",
            "epoch: 203, iter: 32, training_loss: 1.05171e+00\n",
            "epoch: 204, iter: 32, training_loss: 8.74272e-01\n",
            "epoch: 205, iter: 32, training_loss: 8.73908e-01\n",
            "epoch: 206, iter: 32, training_loss: 8.15585e-01\n",
            "epoch: 207, iter: 32, training_loss: 9.41294e-01\n",
            "epoch: 208, iter: 32, training_loss: 9.06605e-01\n",
            "epoch: 209, iter: 32, training_loss: 8.96135e-01\n",
            "epoch: 210, iter: 32, training_loss: 9.18350e-01\n",
            "epoch: 211, iter: 32, training_loss: 1.01494e+00\n",
            "epoch: 212, iter: 32, training_loss: 9.84267e-01\n",
            "epoch: 213, iter: 32, training_loss: 8.75018e-01\n",
            "epoch: 214, iter: 32, training_loss: 8.83852e-01\n",
            "epoch: 215, iter: 32, training_loss: 9.57342e-01\n",
            "epoch: 216, iter: 32, training_loss: 8.95539e-01\n",
            "epoch: 217, iter: 32, training_loss: 1.02816e+00\n",
            "epoch: 218, iter: 32, training_loss: 7.75941e-01\n",
            "epoch: 219, iter: 32, training_loss: 8.01860e-01\n",
            "epoch: 220, iter: 32, training_loss: 7.12147e-01\n",
            "epoch: 221, iter: 32, training_loss: 8.16508e-01\n",
            "epoch: 222, iter: 32, training_loss: 6.89794e-01\n",
            "epoch: 223, iter: 32, training_loss: 7.30893e-01\n",
            "epoch: 224, iter: 32, training_loss: 7.68277e-01\n",
            "epoch: 225, iter: 32, training_loss: 7.38167e-01\n",
            "epoch: 226, iter: 32, training_loss: 8.09960e-01\n",
            "epoch: 227, iter: 32, training_loss: 7.25697e-01\n",
            "epoch: 228, iter: 32, training_loss: 7.62583e-01\n",
            "epoch: 229, iter: 32, training_loss: 7.84075e-01\n",
            "epoch: 230, iter: 32, training_loss: 7.73727e-01\n",
            "epoch: 231, iter: 32, training_loss: 7.84056e-01\n",
            "epoch: 232, iter: 32, training_loss: 7.23671e-01\n",
            "epoch: 233, iter: 32, training_loss: 7.40406e-01\n",
            "epoch: 234, iter: 32, training_loss: 7.65283e-01\n",
            "epoch: 235, iter: 32, training_loss: 7.18908e-01\n",
            "epoch: 236, iter: 32, training_loss: 7.31411e-01\n",
            "epoch: 237, iter: 32, training_loss: 7.26345e-01\n",
            "epoch: 238, iter: 32, training_loss: 6.90525e-01\n",
            "epoch: 239, iter: 32, training_loss: 7.15747e-01\n",
            "epoch: 240, iter: 32, training_loss: 6.88773e-01\n",
            "epoch: 241, iter: 32, training_loss: 6.71223e-01\n",
            "epoch: 242, iter: 32, training_loss: 7.86908e-01\n",
            "epoch: 243, iter: 32, training_loss: 6.66829e-01\n",
            "epoch: 244, iter: 32, training_loss: 6.45086e-01\n",
            "epoch: 245, iter: 32, training_loss: 6.22617e-01\n",
            "epoch: 246, iter: 32, training_loss: 9.26353e-01\n",
            "epoch: 247, iter: 32, training_loss: 8.49010e-01\n",
            "epoch: 248, iter: 32, training_loss: 6.16591e-01\n",
            "epoch: 249, iter: 32, training_loss: 5.82338e-01\n",
            "epoch: 250, iter: 32, training_loss: 6.13912e-01\n",
            "epoch: 251, iter: 32, training_loss: 6.60016e-01\n",
            "epoch: 252, iter: 32, training_loss: 5.95332e-01\n",
            "epoch: 253, iter: 32, training_loss: 6.61381e-01\n",
            "epoch: 254, iter: 32, training_loss: 5.93367e-01\n",
            "epoch: 255, iter: 32, training_loss: 4.60075e-01\n",
            "epoch: 256, iter: 32, training_loss: 4.92265e-01\n",
            "epoch: 257, iter: 32, training_loss: 5.05331e-01\n",
            "epoch: 258, iter: 32, training_loss: 4.25681e-01\n",
            "epoch: 259, iter: 32, training_loss: 4.89638e-01\n",
            "epoch: 260, iter: 32, training_loss: 5.00407e-01\n",
            "epoch: 261, iter: 32, training_loss: 4.86655e-01\n",
            "epoch: 262, iter: 32, training_loss: 4.54101e-01\n",
            "epoch: 263, iter: 32, training_loss: 4.80986e-01\n",
            "epoch: 264, iter: 32, training_loss: 4.58682e-01\n",
            "epoch: 265, iter: 32, training_loss: 4.03547e-01\n",
            "epoch: 266, iter: 32, training_loss: 3.79826e-01\n",
            "epoch: 267, iter: 32, training_loss: 5.21285e-01\n",
            "epoch: 268, iter: 32, training_loss: 4.40052e-01\n",
            "epoch: 269, iter: 32, training_loss: 4.61559e-01\n",
            "epoch: 270, iter: 32, training_loss: 4.43121e-01\n",
            "epoch: 271, iter: 32, training_loss: 3.89238e-01\n",
            "epoch: 272, iter: 32, training_loss: 3.80616e-01\n",
            "epoch: 273, iter: 32, training_loss: 4.61930e-01\n",
            "epoch: 274, iter: 32, training_loss: 4.57210e-01\n",
            "epoch: 275, iter: 32, training_loss: 4.05741e-01\n",
            "epoch: 276, iter: 32, training_loss: 3.65338e-01\n",
            "epoch: 277, iter: 32, training_loss: 5.23084e-01\n",
            "epoch: 278, iter: 32, training_loss: 4.64109e-01\n",
            "epoch: 279, iter: 32, training_loss: 4.39238e-01\n",
            "epoch: 280, iter: 32, training_loss: 4.13081e-01\n",
            "epoch: 281, iter: 32, training_loss: 3.81507e-01\n",
            "epoch: 282, iter: 32, training_loss: 3.89381e-01\n",
            "epoch: 283, iter: 32, training_loss: 4.77992e-01\n",
            "epoch: 284, iter: 32, training_loss: 4.35894e-01\n",
            "epoch: 285, iter: 32, training_loss: 4.48672e-01\n",
            "epoch: 286, iter: 32, training_loss: 4.53128e-01\n",
            "epoch: 287, iter: 32, training_loss: 5.36128e-01\n",
            "epoch: 288, iter: 32, training_loss: 4.47057e-01\n",
            "epoch: 289, iter: 32, training_loss: 3.81277e-01\n",
            "epoch: 290, iter: 32, training_loss: 4.37636e-01\n",
            "epoch: 291, iter: 32, training_loss: 3.76466e-01\n",
            "epoch: 292, iter: 32, training_loss: 4.09821e-01\n",
            "epoch: 293, iter: 32, training_loss: 3.83433e-01\n",
            "epoch: 294, iter: 32, training_loss: 3.82556e-01\n",
            "epoch: 295, iter: 32, training_loss: 3.99752e-01\n",
            "epoch: 296, iter: 32, training_loss: 3.79117e-01\n",
            "epoch: 297, iter: 32, training_loss: 3.86124e-01\n",
            "epoch: 298, iter: 32, training_loss: 3.78739e-01\n",
            "epoch: 299, iter: 32, training_loss: 3.58694e-01\n",
            "epoch: 300, iter: 32, training_loss: 3.39869e-01\n",
            "epoch: 301, iter: 32, training_loss: 3.82918e-01\n",
            "epoch: 302, iter: 32, training_loss: 4.00932e-01\n",
            "epoch: 303, iter: 32, training_loss: 4.12743e-01\n",
            "epoch: 304, iter: 32, training_loss: 3.97254e-01\n",
            "epoch: 305, iter: 32, training_loss: 4.52680e-01\n",
            "epoch: 306, iter: 32, training_loss: 3.65912e-01\n",
            "epoch: 307, iter: 32, training_loss: 3.41003e-01\n",
            "epoch: 308, iter: 32, training_loss: 3.26751e-01\n",
            "epoch: 309, iter: 32, training_loss: 3.13823e-01\n",
            "epoch: 310, iter: 32, training_loss: 2.97968e-01\n",
            "epoch: 311, iter: 32, training_loss: 3.09025e-01\n",
            "epoch: 312, iter: 32, training_loss: 3.59139e-01\n",
            "epoch: 313, iter: 32, training_loss: 4.33438e-01\n",
            "epoch: 314, iter: 32, training_loss: 3.87784e-01\n",
            "epoch: 315, iter: 32, training_loss: 4.14727e-01\n",
            "epoch: 316, iter: 32, training_loss: 3.96307e-01\n",
            "epoch: 317, iter: 32, training_loss: 3.37927e-01\n",
            "epoch: 318, iter: 32, training_loss: 3.22760e-01\n",
            "epoch: 319, iter: 32, training_loss: 3.00752e-01\n",
            "epoch: 320, iter: 32, training_loss: 3.22618e-01\n",
            "epoch: 321, iter: 32, training_loss: 3.62545e-01\n",
            "epoch: 322, iter: 32, training_loss: 2.94627e-01\n",
            "epoch: 323, iter: 32, training_loss: 3.76977e-01\n",
            "epoch: 324, iter: 32, training_loss: 3.94005e-01\n",
            "epoch: 325, iter: 32, training_loss: 3.92385e-01\n",
            "epoch: 326, iter: 32, training_loss: 3.61324e-01\n",
            "epoch: 327, iter: 32, training_loss: 3.21271e-01\n",
            "epoch: 328, iter: 32, training_loss: 2.83272e-01\n",
            "epoch: 329, iter: 32, training_loss: 3.52392e-01\n",
            "epoch: 330, iter: 32, training_loss: 4.42985e-01\n",
            "epoch: 331, iter: 32, training_loss: 4.01663e-01\n",
            "epoch: 332, iter: 32, training_loss: 3.76970e-01\n",
            "epoch: 333, iter: 32, training_loss: 3.48558e-01\n",
            "epoch: 334, iter: 32, training_loss: 3.07605e-01\n",
            "epoch: 335, iter: 32, training_loss: 2.86089e-01\n",
            "epoch: 336, iter: 32, training_loss: 3.06600e-01\n",
            "epoch: 337, iter: 32, training_loss: 3.39052e-01\n",
            "epoch: 338, iter: 32, training_loss: 3.11206e-01\n",
            "epoch: 339, iter: 32, training_loss: 2.73982e-01\n",
            "epoch: 340, iter: 32, training_loss: 3.22173e-01\n",
            "epoch: 341, iter: 32, training_loss: 4.32459e-01\n",
            "epoch: 342, iter: 32, training_loss: 3.28077e-01\n",
            "epoch: 343, iter: 32, training_loss: 2.99212e-01\n",
            "epoch: 344, iter: 32, training_loss: 2.66396e-01\n",
            "epoch: 345, iter: 32, training_loss: 3.73685e-01\n",
            "epoch: 346, iter: 32, training_loss: 2.97459e-01\n",
            "epoch: 347, iter: 32, training_loss: 3.27930e-01\n",
            "epoch: 348, iter: 32, training_loss: 3.58051e-01\n",
            "epoch: 349, iter: 32, training_loss: 3.23459e-01\n",
            "epoch: 350, iter: 32, training_loss: 3.63160e-01\n",
            "epoch: 351, iter: 32, training_loss: 3.22429e-01\n",
            "epoch: 352, iter: 32, training_loss: 2.81181e-01\n",
            "epoch: 353, iter: 32, training_loss: 2.55295e-01\n",
            "epoch: 354, iter: 32, training_loss: 3.59243e-01\n",
            "epoch: 355, iter: 32, training_loss: 4.04501e-01\n",
            "epoch: 356, iter: 32, training_loss: 3.15191e-01\n",
            "epoch: 357, iter: 32, training_loss: 2.68614e-01\n",
            "epoch: 358, iter: 32, training_loss: 2.63354e-01\n",
            "epoch: 359, iter: 32, training_loss: 2.62509e-01\n",
            "epoch: 360, iter: 32, training_loss: 3.39561e-01\n",
            "epoch: 361, iter: 32, training_loss: 3.18012e-01\n",
            "epoch: 362, iter: 32, training_loss: 3.16196e-01\n",
            "epoch: 363, iter: 32, training_loss: 3.43440e-01\n",
            "epoch: 364, iter: 32, training_loss: 3.37849e-01\n",
            "epoch: 365, iter: 32, training_loss: 3.06316e-01\n",
            "epoch: 366, iter: 32, training_loss: 3.15990e-01\n",
            "epoch: 367, iter: 32, training_loss: 4.52168e-01\n",
            "epoch: 368, iter: 32, training_loss: 3.59267e-01\n",
            "epoch: 369, iter: 32, training_loss: 3.31510e-01\n",
            "epoch: 370, iter: 32, training_loss: 3.19902e-01\n",
            "epoch: 371, iter: 32, training_loss: 2.93948e-01\n",
            "epoch: 372, iter: 32, training_loss: 2.72893e-01\n",
            "epoch: 373, iter: 32, training_loss: 2.68466e-01\n",
            "epoch: 374, iter: 32, training_loss: 3.21003e-01\n",
            "epoch: 375, iter: 32, training_loss: 3.33573e-01\n",
            "epoch: 376, iter: 32, training_loss: 3.69572e-01\n",
            "epoch: 377, iter: 32, training_loss: 3.29101e-01\n",
            "epoch: 378, iter: 32, training_loss: 2.89034e-01\n",
            "epoch: 379, iter: 32, training_loss: 3.10036e-01\n",
            "epoch: 380, iter: 32, training_loss: 2.53308e-01\n",
            "epoch: 381, iter: 32, training_loss: 2.48869e-01\n",
            "epoch: 382, iter: 32, training_loss: 3.02553e-01\n",
            "epoch: 383, iter: 32, training_loss: 3.04146e-01\n",
            "epoch: 384, iter: 32, training_loss: 2.75228e-01\n",
            "epoch: 385, iter: 32, training_loss: 2.34842e-01\n",
            "epoch: 386, iter: 32, training_loss: 2.86684e-01\n",
            "epoch: 387, iter: 32, training_loss: 3.36696e-01\n",
            "epoch: 388, iter: 32, training_loss: 2.59383e-01\n",
            "epoch: 389, iter: 32, training_loss: 2.34681e-01\n",
            "epoch: 390, iter: 32, training_loss: 3.23406e-01\n",
            "epoch: 391, iter: 32, training_loss: 2.58126e-01\n",
            "epoch: 392, iter: 32, training_loss: 2.55367e-01\n",
            "epoch: 393, iter: 32, training_loss: 2.57302e-01\n",
            "epoch: 394, iter: 32, training_loss: 3.13719e-01\n",
            "epoch: 395, iter: 32, training_loss: 3.11066e-01\n",
            "epoch: 396, iter: 32, training_loss: 2.61992e-01\n",
            "epoch: 397, iter: 32, training_loss: 3.50911e-01\n",
            "epoch: 398, iter: 32, training_loss: 3.06324e-01\n",
            "epoch: 399, iter: 32, training_loss: 2.61768e-01\n",
            "epoch: 400, iter: 32, training_loss: 3.72217e-01\n",
            "epoch: 401, iter: 32, training_loss: 3.18865e-01\n",
            "epoch: 402, iter: 32, training_loss: 2.89260e-01\n",
            "epoch: 403, iter: 32, training_loss: 2.96434e-01\n",
            "epoch: 404, iter: 32, training_loss: 2.41559e-01\n",
            "epoch: 405, iter: 32, training_loss: 2.41578e-01\n",
            "epoch: 406, iter: 32, training_loss: 2.38889e-01\n",
            "epoch: 407, iter: 32, training_loss: 2.53100e-01\n",
            "epoch: 408, iter: 32, training_loss: 2.37220e-01\n",
            "epoch: 409, iter: 32, training_loss: 2.36102e-01\n",
            "epoch: 410, iter: 32, training_loss: 2.30067e-01\n",
            "epoch: 411, iter: 32, training_loss: 2.19379e-01\n",
            "epoch: 412, iter: 32, training_loss: 2.27338e-01\n",
            "epoch: 413, iter: 32, training_loss: 2.19737e-01\n",
            "epoch: 414, iter: 32, training_loss: 2.16880e-01\n",
            "epoch: 415, iter: 32, training_loss: 2.30964e-01\n",
            "epoch: 416, iter: 32, training_loss: 2.32051e-01\n",
            "epoch: 417, iter: 32, training_loss: 2.27794e-01\n",
            "epoch: 418, iter: 32, training_loss: 2.20898e-01\n",
            "epoch: 419, iter: 32, training_loss: 2.07935e-01\n",
            "epoch: 420, iter: 32, training_loss: 2.13409e-01\n",
            "epoch: 421, iter: 32, training_loss: 2.71420e-01\n",
            "epoch: 422, iter: 32, training_loss: 2.64484e-01\n",
            "epoch: 423, iter: 32, training_loss: 2.45640e-01\n",
            "epoch: 424, iter: 32, training_loss: 2.69656e-01\n",
            "epoch: 425, iter: 32, training_loss: 2.74480e-01\n",
            "epoch: 426, iter: 32, training_loss: 2.67290e-01\n",
            "epoch: 427, iter: 32, training_loss: 3.38316e-01\n",
            "epoch: 428, iter: 32, training_loss: 2.31779e-01\n",
            "epoch: 429, iter: 32, training_loss: 2.13976e-01\n",
            "epoch: 430, iter: 32, training_loss: 3.13783e-01\n",
            "epoch: 431, iter: 32, training_loss: 2.52811e-01\n",
            "epoch: 432, iter: 32, training_loss: 2.87481e-01\n",
            "epoch: 433, iter: 32, training_loss: 3.61428e-01\n",
            "epoch: 434, iter: 32, training_loss: 2.71647e-01\n",
            "epoch: 435, iter: 32, training_loss: 2.31279e-01\n",
            "epoch: 436, iter: 32, training_loss: 2.86483e-01\n",
            "epoch: 437, iter: 32, training_loss: 4.34538e-01\n",
            "epoch: 438, iter: 32, training_loss: 3.04583e-01\n",
            "epoch: 439, iter: 32, training_loss: 2.77080e-01\n",
            "epoch: 440, iter: 32, training_loss: 3.19241e-01\n",
            "epoch: 441, iter: 32, training_loss: 2.62000e-01\n",
            "epoch: 442, iter: 32, training_loss: 2.84748e-01\n",
            "epoch: 443, iter: 32, training_loss: 2.52485e-01\n",
            "epoch: 444, iter: 32, training_loss: 2.20971e-01\n",
            "epoch: 445, iter: 32, training_loss: 2.20966e-01\n",
            "epoch: 446, iter: 32, training_loss: 2.18765e-01\n",
            "epoch: 447, iter: 32, training_loss: 2.62404e-01\n",
            "epoch: 448, iter: 32, training_loss: 2.14642e-01\n",
            "epoch: 449, iter: 32, training_loss: 2.47612e-01\n",
            "epoch: 450, iter: 32, training_loss: 2.60282e-01\n",
            "epoch: 451, iter: 32, training_loss: 2.11152e-01\n",
            "epoch: 452, iter: 32, training_loss: 2.04815e-01\n",
            "epoch: 453, iter: 32, training_loss: 2.15001e-01\n",
            "epoch: 454, iter: 32, training_loss: 2.00939e-01\n",
            "epoch: 455, iter: 32, training_loss: 3.41408e-01\n",
            "epoch: 456, iter: 32, training_loss: 2.52647e-01\n",
            "epoch: 457, iter: 32, training_loss: 2.17013e-01\n",
            "epoch: 458, iter: 32, training_loss: 2.44754e-01\n",
            "epoch: 459, iter: 32, training_loss: 2.52056e-01\n",
            "epoch: 460, iter: 32, training_loss: 2.32256e-01\n",
            "epoch: 461, iter: 32, training_loss: 2.09503e-01\n",
            "epoch: 462, iter: 32, training_loss: 2.09385e-01\n",
            "epoch: 463, iter: 32, training_loss: 2.17781e-01\n",
            "epoch: 464, iter: 32, training_loss: 2.76470e-01\n",
            "epoch: 465, iter: 32, training_loss: 2.20847e-01\n",
            "epoch: 466, iter: 32, training_loss: 3.15057e-01\n",
            "epoch: 467, iter: 32, training_loss: 3.78527e-01\n",
            "epoch: 468, iter: 32, training_loss: 2.28803e-01\n",
            "epoch: 469, iter: 32, training_loss: 2.22632e-01\n",
            "epoch: 470, iter: 32, training_loss: 2.90929e-01\n",
            "epoch: 471, iter: 32, training_loss: 2.78907e-01\n",
            "epoch: 472, iter: 32, training_loss: 2.12964e-01\n",
            "epoch: 473, iter: 32, training_loss: 2.10212e-01\n",
            "epoch: 474, iter: 32, training_loss: 2.52156e-01\n",
            "epoch: 475, iter: 32, training_loss: 2.32208e-01\n",
            "epoch: 476, iter: 32, training_loss: 1.95866e-01\n",
            "epoch: 477, iter: 32, training_loss: 2.50115e-01\n",
            "epoch: 478, iter: 32, training_loss: 2.53843e-01\n",
            "epoch: 479, iter: 32, training_loss: 2.70887e-01\n",
            "epoch: 480, iter: 32, training_loss: 2.65723e-01\n",
            "epoch: 481, iter: 32, training_loss: 2.35474e-01\n",
            "epoch: 482, iter: 32, training_loss: 3.00090e-01\n",
            "epoch: 483, iter: 32, training_loss: 2.60880e-01\n",
            "epoch: 484, iter: 32, training_loss: 2.16980e-01\n",
            "epoch: 485, iter: 32, training_loss: 1.99383e-01\n",
            "epoch: 486, iter: 32, training_loss: 2.04659e-01\n",
            "epoch: 487, iter: 32, training_loss: 3.32432e-01\n",
            "epoch: 488, iter: 32, training_loss: 2.69940e-01\n",
            "epoch: 489, iter: 32, training_loss: 2.35702e-01\n",
            "epoch: 490, iter: 32, training_loss: 2.38105e-01\n",
            "epoch: 491, iter: 32, training_loss: 2.06644e-01\n",
            "epoch: 492, iter: 32, training_loss: 2.31251e-01\n",
            "epoch: 493, iter: 32, training_loss: 2.56329e-01\n",
            "epoch: 494, iter: 32, training_loss: 2.24307e-01\n",
            "epoch: 495, iter: 32, training_loss: 2.67319e-01\n",
            "epoch: 496, iter: 32, training_loss: 2.96461e-01\n",
            "epoch: 497, iter: 32, training_loss: 2.58064e-01\n",
            "epoch: 498, iter: 32, training_loss: 2.87393e-01\n",
            "epoch: 499, iter: 32, training_loss: 2.84146e-01\n",
            "epoch: 500, iter: 32, training_loss: 2.19295e-01\n",
            "epoch: 501, iter: 32, training_loss: 2.72670e-01\n",
            "epoch: 502, iter: 32, training_loss: 2.66803e-01\n",
            "epoch: 503, iter: 32, training_loss: 2.33755e-01\n",
            "epoch: 504, iter: 32, training_loss: 2.56445e-01\n",
            "epoch: 505, iter: 32, training_loss: 2.07491e-01\n",
            "epoch: 506, iter: 32, training_loss: 2.11923e-01\n",
            "epoch: 507, iter: 32, training_loss: 2.11431e-01\n",
            "epoch: 508, iter: 32, training_loss: 1.95633e-01\n",
            "epoch: 509, iter: 32, training_loss: 2.77136e-01\n",
            "epoch: 510, iter: 32, training_loss: 2.63704e-01\n",
            "epoch: 511, iter: 32, training_loss: 2.86296e-01\n",
            "epoch: 512, iter: 32, training_loss: 2.25531e-01\n",
            "epoch: 513, iter: 32, training_loss: 1.91613e-01\n",
            "epoch: 514, iter: 32, training_loss: 1.87984e-01\n",
            "epoch: 515, iter: 32, training_loss: 2.00868e-01\n",
            "epoch: 516, iter: 32, training_loss: 2.17025e-01\n",
            "epoch: 517, iter: 32, training_loss: 2.21479e-01\n",
            "epoch: 518, iter: 32, training_loss: 2.07230e-01\n",
            "epoch: 519, iter: 32, training_loss: 2.04312e-01\n",
            "epoch: 520, iter: 32, training_loss: 2.24682e-01\n",
            "epoch: 521, iter: 32, training_loss: 2.26677e-01\n",
            "epoch: 522, iter: 32, training_loss: 2.46857e-01\n",
            "epoch: 523, iter: 32, training_loss: 2.36576e-01\n",
            "epoch: 524, iter: 32, training_loss: 2.45902e-01\n",
            "epoch: 525, iter: 32, training_loss: 2.47038e-01\n",
            "epoch: 526, iter: 32, training_loss: 2.20164e-01\n",
            "epoch: 527, iter: 32, training_loss: 2.10871e-01\n",
            "epoch: 528, iter: 32, training_loss: 2.12966e-01\n",
            "epoch: 529, iter: 32, training_loss: 2.21797e-01\n",
            "epoch: 530, iter: 32, training_loss: 2.30115e-01\n",
            "epoch: 531, iter: 32, training_loss: 1.86905e-01\n",
            "epoch: 532, iter: 32, training_loss: 2.03046e-01\n",
            "epoch: 533, iter: 32, training_loss: 2.70220e-01\n",
            "epoch: 534, iter: 32, training_loss: 2.12735e-01\n",
            "epoch: 535, iter: 32, training_loss: 1.91193e-01\n",
            "epoch: 536, iter: 32, training_loss: 2.32618e-01\n",
            "epoch: 537, iter: 32, training_loss: 1.76978e-01\n",
            "epoch: 538, iter: 32, training_loss: 2.00283e-01\n",
            "epoch: 539, iter: 32, training_loss: 2.39036e-01\n",
            "epoch: 540, iter: 32, training_loss: 2.45373e-01\n",
            "epoch: 541, iter: 32, training_loss: 2.73948e-01\n",
            "epoch: 542, iter: 32, training_loss: 2.41927e-01\n",
            "epoch: 543, iter: 32, training_loss: 1.82912e-01\n",
            "epoch: 544, iter: 32, training_loss: 1.90820e-01\n",
            "epoch: 545, iter: 32, training_loss: 1.74155e-01\n",
            "epoch: 546, iter: 32, training_loss: 2.68609e-01\n",
            "epoch: 547, iter: 32, training_loss: 2.32459e-01\n",
            "epoch: 548, iter: 32, training_loss: 1.90538e-01\n",
            "epoch: 549, iter: 32, training_loss: 1.98587e-01\n",
            "epoch: 550, iter: 32, training_loss: 2.45572e-01\n",
            "epoch: 551, iter: 32, training_loss: 1.92996e-01\n",
            "epoch: 552, iter: 32, training_loss: 1.75849e-01\n",
            "epoch: 553, iter: 32, training_loss: 1.96344e-01\n",
            "epoch: 554, iter: 32, training_loss: 2.16494e-01\n",
            "epoch: 555, iter: 32, training_loss: 2.01765e-01\n",
            "epoch: 556, iter: 32, training_loss: 2.27199e-01\n",
            "epoch: 557, iter: 32, training_loss: 2.29599e-01\n",
            "epoch: 558, iter: 32, training_loss: 1.79167e-01\n",
            "epoch: 559, iter: 32, training_loss: 2.58580e-01\n",
            "epoch: 560, iter: 32, training_loss: 3.35218e-01\n",
            "epoch: 561, iter: 32, training_loss: 2.42203e-01\n",
            "epoch: 562, iter: 32, training_loss: 2.26686e-01\n",
            "epoch: 563, iter: 32, training_loss: 2.20407e-01\n",
            "epoch: 564, iter: 32, training_loss: 2.69877e-01\n",
            "epoch: 565, iter: 32, training_loss: 2.05891e-01\n",
            "epoch: 566, iter: 32, training_loss: 2.59765e-01\n",
            "epoch: 567, iter: 32, training_loss: 1.94122e-01\n",
            "epoch: 568, iter: 32, training_loss: 2.01869e-01\n",
            "epoch: 569, iter: 32, training_loss: 2.01271e-01\n",
            "epoch: 570, iter: 32, training_loss: 1.97872e-01\n",
            "epoch: 571, iter: 32, training_loss: 2.27924e-01\n",
            "epoch: 572, iter: 32, training_loss: 2.19743e-01\n",
            "epoch: 573, iter: 32, training_loss: 2.31514e-01\n",
            "epoch: 574, iter: 32, training_loss: 2.17813e-01\n",
            "epoch: 575, iter: 32, training_loss: 2.05185e-01\n",
            "epoch: 576, iter: 32, training_loss: 1.92249e-01\n",
            "epoch: 577, iter: 32, training_loss: 1.79869e-01\n",
            "epoch: 578, iter: 32, training_loss: 2.36181e-01\n",
            "epoch: 579, iter: 32, training_loss: 2.26320e-01\n",
            "epoch: 580, iter: 32, training_loss: 1.94600e-01\n",
            "epoch: 581, iter: 32, training_loss: 2.48782e-01\n",
            "epoch: 582, iter: 32, training_loss: 2.14865e-01\n",
            "epoch: 583, iter: 32, training_loss: 2.13764e-01\n",
            "epoch: 584, iter: 32, training_loss: 3.04111e-01\n",
            "epoch: 585, iter: 32, training_loss: 2.25196e-01\n",
            "epoch: 586, iter: 32, training_loss: 2.58639e-01\n",
            "epoch: 587, iter: 32, training_loss: 2.12289e-01\n",
            "epoch: 588, iter: 32, training_loss: 1.83986e-01\n",
            "epoch: 589, iter: 32, training_loss: 1.77047e-01\n",
            "epoch: 590, iter: 32, training_loss: 1.76876e-01\n",
            "epoch: 591, iter: 32, training_loss: 2.35312e-01\n",
            "epoch: 592, iter: 32, training_loss: 2.43668e-01\n",
            "epoch: 593, iter: 32, training_loss: 2.69883e-01\n",
            "epoch: 594, iter: 32, training_loss: 2.38512e-01\n",
            "epoch: 595, iter: 32, training_loss: 2.05520e-01\n",
            "epoch: 596, iter: 32, training_loss: 1.87328e-01\n",
            "epoch: 597, iter: 32, training_loss: 1.87349e-01\n",
            "epoch: 598, iter: 32, training_loss: 2.14880e-01\n",
            "epoch: 599, iter: 32, training_loss: 2.17679e-01\n",
            "epoch: 600, iter: 32, training_loss: 2.29770e-01\n",
            "epoch: 601, iter: 32, training_loss: 2.32882e-01\n",
            "epoch: 602, iter: 32, training_loss: 2.00652e-01\n",
            "epoch: 603, iter: 32, training_loss: 2.15190e-01\n",
            "epoch: 604, iter: 32, training_loss: 2.30210e-01\n",
            "epoch: 605, iter: 32, training_loss: 1.97279e-01\n",
            "epoch: 606, iter: 32, training_loss: 1.71790e-01\n",
            "epoch: 607, iter: 32, training_loss: 2.95893e-01\n",
            "epoch: 608, iter: 32, training_loss: 2.21145e-01\n",
            "epoch: 609, iter: 32, training_loss: 1.67626e-01\n",
            "epoch: 610, iter: 32, training_loss: 2.59786e-01\n",
            "epoch: 611, iter: 32, training_loss: 2.17298e-01\n",
            "epoch: 612, iter: 32, training_loss: 2.08692e-01\n",
            "epoch: 613, iter: 32, training_loss: 2.10021e-01\n",
            "epoch: 614, iter: 32, training_loss: 2.20482e-01\n",
            "epoch: 615, iter: 32, training_loss: 2.14161e-01\n",
            "epoch: 616, iter: 32, training_loss: 1.83889e-01\n",
            "epoch: 617, iter: 32, training_loss: 2.10897e-01\n",
            "epoch: 618, iter: 32, training_loss: 2.09387e-01\n",
            "epoch: 619, iter: 32, training_loss: 1.84892e-01\n",
            "epoch: 620, iter: 32, training_loss: 1.71207e-01\n",
            "epoch: 621, iter: 32, training_loss: 2.52098e-01\n",
            "epoch: 622, iter: 32, training_loss: 1.73528e-01\n",
            "epoch: 623, iter: 32, training_loss: 1.76647e-01\n",
            "epoch: 624, iter: 32, training_loss: 2.09970e-01\n",
            "epoch: 625, iter: 32, training_loss: 2.16756e-01\n",
            "epoch: 626, iter: 32, training_loss: 2.07740e-01\n",
            "epoch: 627, iter: 32, training_loss: 2.29798e-01\n",
            "epoch: 628, iter: 32, training_loss: 1.83138e-01\n",
            "epoch: 629, iter: 32, training_loss: 1.83454e-01\n",
            "epoch: 630, iter: 32, training_loss: 1.86049e-01\n",
            "epoch: 631, iter: 32, training_loss: 1.88118e-01\n",
            "epoch: 632, iter: 32, training_loss: 2.08913e-01\n",
            "epoch: 633, iter: 32, training_loss: 2.21147e-01\n",
            "epoch: 634, iter: 32, training_loss: 2.12081e-01\n",
            "epoch: 635, iter: 32, training_loss: 1.63836e-01\n",
            "epoch: 636, iter: 32, training_loss: 1.77004e-01\n",
            "epoch: 637, iter: 32, training_loss: 1.70622e-01\n",
            "epoch: 638, iter: 32, training_loss: 1.60240e-01\n",
            "epoch: 639, iter: 32, training_loss: 2.81978e-01\n",
            "epoch: 640, iter: 32, training_loss: 2.56580e-01\n",
            "epoch: 641, iter: 32, training_loss: 2.16743e-01\n",
            "epoch: 642, iter: 32, training_loss: 2.12869e-01\n",
            "epoch: 643, iter: 32, training_loss: 2.17695e-01\n",
            "epoch: 644, iter: 32, training_loss: 1.82960e-01\n",
            "epoch: 645, iter: 32, training_loss: 1.67495e-01\n",
            "epoch: 646, iter: 32, training_loss: 1.60847e-01\n",
            "epoch: 647, iter: 32, training_loss: 1.55477e-01\n",
            "epoch: 648, iter: 32, training_loss: 1.56969e-01\n",
            "epoch: 649, iter: 32, training_loss: 1.72550e-01\n",
            "epoch: 650, iter: 32, training_loss: 1.88086e-01\n",
            "epoch: 651, iter: 32, training_loss: 1.58772e-01\n",
            "epoch: 652, iter: 32, training_loss: 1.59919e-01\n",
            "epoch: 653, iter: 32, training_loss: 2.14256e-01\n",
            "epoch: 654, iter: 32, training_loss: 1.94044e-01\n",
            "epoch: 655, iter: 32, training_loss: 2.06041e-01\n",
            "epoch: 656, iter: 32, training_loss: 1.96792e-01\n",
            "epoch: 657, iter: 32, training_loss: 2.12665e-01\n",
            "epoch: 658, iter: 32, training_loss: 1.80195e-01\n",
            "epoch: 659, iter: 32, training_loss: 2.13392e-01\n",
            "epoch: 660, iter: 32, training_loss: 2.28564e-01\n",
            "epoch: 661, iter: 32, training_loss: 1.93335e-01\n",
            "epoch: 662, iter: 32, training_loss: 2.10310e-01\n",
            "epoch: 663, iter: 32, training_loss: 1.80194e-01\n",
            "epoch: 664, iter: 32, training_loss: 2.73361e-01\n",
            "epoch: 665, iter: 32, training_loss: 2.67112e-01\n",
            "epoch: 666, iter: 32, training_loss: 2.33441e-01\n",
            "epoch: 667, iter: 32, training_loss: 2.00638e-01\n",
            "epoch: 668, iter: 32, training_loss: 1.85463e-01\n",
            "epoch: 669, iter: 32, training_loss: 1.80168e-01\n",
            "epoch: 670, iter: 32, training_loss: 1.87451e-01\n",
            "epoch: 671, iter: 32, training_loss: 1.62321e-01\n",
            "epoch: 672, iter: 32, training_loss: 1.54926e-01\n",
            "epoch: 673, iter: 32, training_loss: 1.66936e-01\n",
            "epoch: 674, iter: 32, training_loss: 2.58134e-01\n",
            "epoch: 675, iter: 32, training_loss: 1.93162e-01\n",
            "epoch: 676, iter: 32, training_loss: 1.79075e-01\n",
            "epoch: 677, iter: 32, training_loss: 2.14279e-01\n",
            "epoch: 678, iter: 32, training_loss: 1.73241e-01\n",
            "epoch: 679, iter: 32, training_loss: 2.00116e-01\n",
            "epoch: 680, iter: 32, training_loss: 2.38922e-01\n",
            "epoch: 681, iter: 32, training_loss: 2.16108e-01\n",
            "epoch: 682, iter: 32, training_loss: 2.02480e-01\n",
            "epoch: 683, iter: 32, training_loss: 1.77187e-01\n",
            "epoch: 684, iter: 32, training_loss: 1.91514e-01\n",
            "epoch: 685, iter: 32, training_loss: 2.28187e-01\n",
            "epoch: 686, iter: 32, training_loss: 2.08868e-01\n",
            "epoch: 687, iter: 32, training_loss: 1.79386e-01\n",
            "epoch: 688, iter: 32, training_loss: 1.83983e-01\n",
            "epoch: 689, iter: 32, training_loss: 2.07121e-01\n",
            "epoch: 690, iter: 32, training_loss: 2.13431e-01\n",
            "epoch: 691, iter: 32, training_loss: 1.62189e-01\n",
            "epoch: 692, iter: 32, training_loss: 1.77316e-01\n",
            "epoch: 693, iter: 32, training_loss: 1.63511e-01\n",
            "epoch: 694, iter: 32, training_loss: 2.00334e-01\n",
            "epoch: 695, iter: 32, training_loss: 1.57184e-01\n",
            "epoch: 696, iter: 32, training_loss: 1.87095e-01\n",
            "epoch: 697, iter: 32, training_loss: 1.99237e-01\n",
            "epoch: 698, iter: 32, training_loss: 1.76958e-01\n",
            "epoch: 699, iter: 32, training_loss: 1.49338e-01\n",
            "epoch: 700, iter: 32, training_loss: 1.89910e-01\n",
            "epoch: 701, iter: 32, training_loss: 1.64749e-01\n",
            "epoch: 702, iter: 32, training_loss: 1.46606e-01\n",
            "epoch: 703, iter: 32, training_loss: 1.49260e-01\n",
            "epoch: 704, iter: 32, training_loss: 1.46413e-01\n",
            "epoch: 705, iter: 32, training_loss: 1.84748e-01\n",
            "epoch: 706, iter: 32, training_loss: 2.02135e-01\n",
            "epoch: 707, iter: 32, training_loss: 1.52588e-01\n",
            "epoch: 708, iter: 32, training_loss: 2.36360e-01\n",
            "epoch: 709, iter: 32, training_loss: 1.65156e-01\n",
            "epoch: 710, iter: 32, training_loss: 1.62633e-01\n",
            "epoch: 711, iter: 32, training_loss: 1.48956e-01\n",
            "epoch: 712, iter: 32, training_loss: 1.78503e-01\n",
            "epoch: 713, iter: 32, training_loss: 2.06411e-01\n",
            "epoch: 714, iter: 32, training_loss: 1.94658e-01\n",
            "epoch: 715, iter: 32, training_loss: 1.60216e-01\n",
            "epoch: 716, iter: 32, training_loss: 1.53803e-01\n",
            "epoch: 717, iter: 32, training_loss: 1.59734e-01\n",
            "epoch: 718, iter: 32, training_loss: 1.49642e-01\n",
            "epoch: 719, iter: 32, training_loss: 1.60382e-01\n",
            "epoch: 720, iter: 32, training_loss: 1.89769e-01\n",
            "epoch: 721, iter: 32, training_loss: 1.87052e-01\n",
            "epoch: 722, iter: 32, training_loss: 1.58317e-01\n",
            "epoch: 723, iter: 32, training_loss: 1.54849e-01\n",
            "epoch: 724, iter: 32, training_loss: 1.80185e-01\n",
            "epoch: 725, iter: 32, training_loss: 2.33620e-01\n",
            "epoch: 726, iter: 32, training_loss: 1.79626e-01\n",
            "epoch: 727, iter: 32, training_loss: 1.64861e-01\n",
            "epoch: 728, iter: 32, training_loss: 2.85420e-01\n",
            "epoch: 729, iter: 32, training_loss: 2.33229e-01\n",
            "epoch: 730, iter: 32, training_loss: 1.61412e-01\n",
            "epoch: 731, iter: 32, training_loss: 1.52952e-01\n",
            "epoch: 732, iter: 32, training_loss: 2.03723e-01\n",
            "epoch: 733, iter: 32, training_loss: 1.68450e-01\n",
            "epoch: 734, iter: 32, training_loss: 1.47982e-01\n",
            "epoch: 735, iter: 32, training_loss: 1.75545e-01\n",
            "epoch: 736, iter: 32, training_loss: 1.70543e-01\n",
            "epoch: 737, iter: 32, training_loss: 1.74322e-01\n",
            "epoch: 738, iter: 32, training_loss: 1.45366e-01\n",
            "epoch: 739, iter: 32, training_loss: 1.94764e-01\n",
            "epoch: 740, iter: 32, training_loss: 2.51088e-01\n",
            "epoch: 741, iter: 32, training_loss: 2.00864e-01\n",
            "epoch: 742, iter: 32, training_loss: 1.66091e-01\n",
            "epoch: 743, iter: 32, training_loss: 1.47898e-01\n",
            "epoch: 744, iter: 32, training_loss: 1.45136e-01\n",
            "epoch: 745, iter: 32, training_loss: 1.72575e-01\n",
            "epoch: 746, iter: 32, training_loss: 1.58704e-01\n",
            "epoch: 747, iter: 32, training_loss: 1.67618e-01\n",
            "epoch: 748, iter: 32, training_loss: 1.74913e-01\n",
            "epoch: 749, iter: 32, training_loss: 2.00642e-01\n",
            "epoch: 750, iter: 32, training_loss: 1.48503e-01\n",
            "epoch: 751, iter: 32, training_loss: 1.44143e-01\n",
            "epoch: 752, iter: 32, training_loss: 1.45381e-01\n",
            "epoch: 753, iter: 32, training_loss: 2.11086e-01\n",
            "epoch: 754, iter: 32, training_loss: 1.47064e-01\n",
            "epoch: 755, iter: 32, training_loss: 2.29291e-01\n",
            "epoch: 756, iter: 32, training_loss: 1.94227e-01\n",
            "epoch: 757, iter: 32, training_loss: 2.25789e-01\n",
            "epoch: 758, iter: 32, training_loss: 2.05127e-01\n",
            "epoch: 759, iter: 32, training_loss: 2.17604e-01\n",
            "epoch: 760, iter: 32, training_loss: 1.62250e-01\n",
            "epoch: 761, iter: 32, training_loss: 2.05955e-01\n",
            "epoch: 762, iter: 32, training_loss: 1.73045e-01\n",
            "epoch: 763, iter: 32, training_loss: 1.64734e-01\n",
            "epoch: 764, iter: 32, training_loss: 1.54349e-01\n",
            "epoch: 765, iter: 32, training_loss: 1.45893e-01\n",
            "epoch: 766, iter: 32, training_loss: 1.90203e-01\n",
            "epoch: 767, iter: 32, training_loss: 1.45555e-01\n",
            "epoch: 768, iter: 32, training_loss: 1.52485e-01\n",
            "epoch: 769, iter: 32, training_loss: 1.44082e-01\n",
            "epoch: 770, iter: 32, training_loss: 1.54074e-01\n",
            "epoch: 771, iter: 32, training_loss: 1.65938e-01\n",
            "epoch: 772, iter: 32, training_loss: 1.90425e-01\n",
            "epoch: 773, iter: 32, training_loss: 2.02454e-01\n",
            "epoch: 774, iter: 32, training_loss: 1.84115e-01\n",
            "epoch: 775, iter: 32, training_loss: 1.69053e-01\n",
            "epoch: 776, iter: 32, training_loss: 1.76624e-01\n",
            "epoch: 777, iter: 32, training_loss: 2.09693e-01\n",
            "epoch: 778, iter: 32, training_loss: 1.87231e-01\n",
            "epoch: 779, iter: 32, training_loss: 2.55452e-01\n",
            "epoch: 780, iter: 32, training_loss: 2.08425e-01\n",
            "epoch: 781, iter: 32, training_loss: 1.86378e-01\n",
            "epoch: 782, iter: 32, training_loss: 1.56621e-01\n",
            "epoch: 783, iter: 32, training_loss: 1.52183e-01\n",
            "epoch: 784, iter: 32, training_loss: 1.64800e-01\n",
            "epoch: 785, iter: 32, training_loss: 1.78591e-01\n",
            "epoch: 786, iter: 32, training_loss: 1.51497e-01\n",
            "epoch: 787, iter: 32, training_loss: 1.40058e-01\n",
            "epoch: 788, iter: 32, training_loss: 1.85007e-01\n",
            "epoch: 789, iter: 32, training_loss: 1.83690e-01\n",
            "epoch: 790, iter: 32, training_loss: 1.56022e-01\n",
            "epoch: 791, iter: 32, training_loss: 1.78875e-01\n",
            "epoch: 792, iter: 32, training_loss: 1.79021e-01\n",
            "epoch: 793, iter: 32, training_loss: 1.83847e-01\n",
            "epoch: 794, iter: 32, training_loss: 1.48779e-01\n",
            "epoch: 795, iter: 32, training_loss: 1.56041e-01\n",
            "epoch: 796, iter: 32, training_loss: 1.93850e-01\n",
            "epoch: 797, iter: 32, training_loss: 1.47102e-01\n",
            "epoch: 798, iter: 32, training_loss: 1.38163e-01\n",
            "epoch: 799, iter: 32, training_loss: 1.79355e-01\n",
            "epoch: 800, iter: 32, training_loss: 1.51693e-01\n",
            "epoch: 801, iter: 32, training_loss: 1.49789e-01\n",
            "epoch: 802, iter: 32, training_loss: 1.74973e-01\n",
            "epoch: 803, iter: 32, training_loss: 1.56672e-01\n",
            "epoch: 804, iter: 32, training_loss: 1.41669e-01\n",
            "epoch: 805, iter: 32, training_loss: 1.29612e-01\n",
            "epoch: 806, iter: 32, training_loss: 2.28807e-01\n",
            "epoch: 807, iter: 32, training_loss: 2.22179e-01\n",
            "epoch: 808, iter: 32, training_loss: 1.47440e-01\n",
            "epoch: 809, iter: 32, training_loss: 1.27334e-01\n",
            "epoch: 810, iter: 32, training_loss: 1.44441e-01\n",
            "epoch: 811, iter: 32, training_loss: 1.66861e-01\n",
            "epoch: 812, iter: 32, training_loss: 1.62429e-01\n",
            "epoch: 813, iter: 32, training_loss: 1.40108e-01\n",
            "epoch: 814, iter: 32, training_loss: 1.30351e-01\n",
            "epoch: 815, iter: 32, training_loss: 1.28960e-01\n",
            "epoch: 816, iter: 32, training_loss: 1.49084e-01\n",
            "epoch: 817, iter: 32, training_loss: 1.69515e-01\n",
            "epoch: 818, iter: 32, training_loss: 1.37690e-01\n",
            "epoch: 819, iter: 32, training_loss: 1.89084e-01\n",
            "epoch: 820, iter: 32, training_loss: 2.26145e-01\n",
            "epoch: 821, iter: 32, training_loss: 1.50412e-01\n",
            "epoch: 822, iter: 32, training_loss: 1.33765e-01\n",
            "epoch: 823, iter: 32, training_loss: 1.32703e-01\n",
            "epoch: 824, iter: 32, training_loss: 1.81655e-01\n",
            "epoch: 825, iter: 32, training_loss: 1.71153e-01\n",
            "epoch: 826, iter: 32, training_loss: 1.57039e-01\n",
            "epoch: 827, iter: 32, training_loss: 1.40980e-01\n",
            "epoch: 828, iter: 32, training_loss: 1.34169e-01\n",
            "epoch: 829, iter: 32, training_loss: 1.29257e-01\n",
            "epoch: 830, iter: 32, training_loss: 1.52058e-01\n",
            "epoch: 831, iter: 32, training_loss: 1.44075e-01\n",
            "epoch: 832, iter: 32, training_loss: 1.90133e-01\n",
            "epoch: 833, iter: 32, training_loss: 1.79342e-01\n",
            "epoch: 834, iter: 32, training_loss: 1.58366e-01\n",
            "epoch: 835, iter: 32, training_loss: 1.31075e-01\n",
            "epoch: 836, iter: 32, training_loss: 1.60186e-01\n",
            "epoch: 837, iter: 32, training_loss: 2.04613e-01\n",
            "epoch: 838, iter: 32, training_loss: 1.71084e-01\n",
            "epoch: 839, iter: 32, training_loss: 1.43111e-01\n",
            "epoch: 840, iter: 32, training_loss: 1.52030e-01\n",
            "epoch: 841, iter: 32, training_loss: 1.73752e-01\n",
            "epoch: 842, iter: 32, training_loss: 1.62249e-01\n",
            "epoch: 843, iter: 32, training_loss: 2.17586e-01\n",
            "epoch: 844, iter: 32, training_loss: 1.77860e-01\n",
            "epoch: 845, iter: 32, training_loss: 1.64057e-01\n",
            "epoch: 846, iter: 32, training_loss: 1.51247e-01\n",
            "epoch: 847, iter: 32, training_loss: 1.36237e-01\n",
            "epoch: 848, iter: 32, training_loss: 1.39381e-01\n",
            "epoch: 849, iter: 32, training_loss: 1.29127e-01\n",
            "epoch: 850, iter: 32, training_loss: 1.74555e-01\n",
            "epoch: 851, iter: 32, training_loss: 1.57418e-01\n",
            "epoch: 852, iter: 32, training_loss: 1.44081e-01\n",
            "epoch: 853, iter: 32, training_loss: 1.48546e-01\n",
            "epoch: 854, iter: 32, training_loss: 1.42525e-01\n",
            "epoch: 855, iter: 32, training_loss: 1.39657e-01\n",
            "epoch: 856, iter: 32, training_loss: 1.33843e-01\n",
            "epoch: 857, iter: 32, training_loss: 1.22573e-01\n",
            "epoch: 858, iter: 32, training_loss: 1.40345e-01\n",
            "epoch: 859, iter: 32, training_loss: 1.91265e-01\n",
            "epoch: 860, iter: 32, training_loss: 1.40762e-01\n",
            "epoch: 861, iter: 32, training_loss: 1.45362e-01\n",
            "epoch: 862, iter: 32, training_loss: 1.45452e-01\n",
            "epoch: 863, iter: 32, training_loss: 1.29675e-01\n",
            "epoch: 864, iter: 32, training_loss: 1.30366e-01\n",
            "epoch: 865, iter: 32, training_loss: 1.62300e-01\n",
            "epoch: 866, iter: 32, training_loss: 1.36609e-01\n",
            "epoch: 867, iter: 32, training_loss: 1.50745e-01\n",
            "epoch: 868, iter: 32, training_loss: 1.33808e-01\n",
            "epoch: 869, iter: 32, training_loss: 1.27269e-01\n",
            "epoch: 870, iter: 32, training_loss: 1.36471e-01\n",
            "epoch: 871, iter: 32, training_loss: 2.32229e-01\n",
            "epoch: 872, iter: 32, training_loss: 1.91140e-01\n",
            "epoch: 873, iter: 32, training_loss: 1.94374e-01\n",
            "epoch: 874, iter: 32, training_loss: 1.59073e-01\n",
            "epoch: 875, iter: 32, training_loss: 1.81916e-01\n",
            "epoch: 876, iter: 32, training_loss: 1.47178e-01\n",
            "epoch: 877, iter: 32, training_loss: 1.31828e-01\n",
            "epoch: 878, iter: 32, training_loss: 1.29107e-01\n",
            "epoch: 879, iter: 32, training_loss: 1.31356e-01\n",
            "epoch: 880, iter: 32, training_loss: 1.59358e-01\n",
            "epoch: 881, iter: 32, training_loss: 1.44254e-01\n",
            "epoch: 882, iter: 32, training_loss: 1.77337e-01\n",
            "epoch: 883, iter: 32, training_loss: 1.78735e-01\n",
            "epoch: 884, iter: 32, training_loss: 1.31300e-01\n",
            "epoch: 885, iter: 32, training_loss: 1.30934e-01\n",
            "epoch: 886, iter: 32, training_loss: 1.79304e-01\n",
            "epoch: 887, iter: 32, training_loss: 1.55979e-01\n",
            "epoch: 888, iter: 32, training_loss: 1.39583e-01\n",
            "epoch: 889, iter: 32, training_loss: 1.36849e-01\n",
            "epoch: 890, iter: 32, training_loss: 1.68836e-01\n",
            "epoch: 891, iter: 32, training_loss: 1.58729e-01\n",
            "epoch: 892, iter: 32, training_loss: 1.59274e-01\n",
            "epoch: 893, iter: 32, training_loss: 1.63263e-01\n",
            "epoch: 894, iter: 32, training_loss: 1.31440e-01\n",
            "epoch: 895, iter: 32, training_loss: 2.77204e-01\n",
            "epoch: 896, iter: 32, training_loss: 1.92474e-01\n",
            "epoch: 897, iter: 32, training_loss: 2.22231e-01\n",
            "epoch: 898, iter: 32, training_loss: 1.51961e-01\n",
            "epoch: 899, iter: 32, training_loss: 1.36507e-01\n",
            "epoch: 900, iter: 32, training_loss: 2.02325e-01\n",
            "epoch: 901, iter: 32, training_loss: 1.55981e-01\n",
            "epoch: 902, iter: 32, training_loss: 1.56000e-01\n",
            "epoch: 903, iter: 32, training_loss: 1.48118e-01\n",
            "epoch: 904, iter: 32, training_loss: 1.93287e-01\n",
            "epoch: 905, iter: 32, training_loss: 1.68755e-01\n",
            "epoch: 906, iter: 32, training_loss: 1.56437e-01\n",
            "epoch: 907, iter: 32, training_loss: 1.40321e-01\n",
            "epoch: 908, iter: 32, training_loss: 1.63547e-01\n",
            "epoch: 909, iter: 32, training_loss: 1.40249e-01\n",
            "epoch: 910, iter: 32, training_loss: 1.30570e-01\n",
            "epoch: 911, iter: 32, training_loss: 1.37337e-01\n",
            "epoch: 912, iter: 32, training_loss: 1.26337e-01\n",
            "epoch: 913, iter: 32, training_loss: 1.71290e-01\n",
            "epoch: 914, iter: 32, training_loss: 1.93896e-01\n",
            "epoch: 915, iter: 32, training_loss: 1.79211e-01\n",
            "epoch: 916, iter: 32, training_loss: 1.33169e-01\n",
            "epoch: 917, iter: 32, training_loss: 1.30144e-01\n",
            "epoch: 918, iter: 32, training_loss: 1.23179e-01\n",
            "epoch: 919, iter: 32, training_loss: 1.79475e-01\n",
            "epoch: 920, iter: 32, training_loss: 1.41439e-01\n",
            "epoch: 921, iter: 32, training_loss: 1.29321e-01\n",
            "epoch: 922, iter: 32, training_loss: 1.42433e-01\n",
            "epoch: 923, iter: 32, training_loss: 1.47539e-01\n",
            "epoch: 924, iter: 32, training_loss: 1.66017e-01\n",
            "epoch: 925, iter: 32, training_loss: 1.41850e-01\n",
            "epoch: 926, iter: 32, training_loss: 1.37697e-01\n",
            "epoch: 927, iter: 32, training_loss: 1.48086e-01\n",
            "epoch: 928, iter: 32, training_loss: 1.45545e-01\n",
            "epoch: 929, iter: 32, training_loss: 1.31467e-01\n",
            "epoch: 930, iter: 32, training_loss: 1.29147e-01\n",
            "epoch: 931, iter: 32, training_loss: 1.74507e-01\n",
            "epoch: 932, iter: 32, training_loss: 1.57089e-01\n",
            "epoch: 933, iter: 32, training_loss: 1.28000e-01\n",
            "epoch: 934, iter: 32, training_loss: 1.75813e-01\n",
            "epoch: 935, iter: 32, training_loss: 1.86830e-01\n",
            "epoch: 936, iter: 32, training_loss: 1.67404e-01\n",
            "epoch: 937, iter: 32, training_loss: 1.42393e-01\n",
            "epoch: 938, iter: 32, training_loss: 1.40409e-01\n",
            "epoch: 939, iter: 32, training_loss: 1.29097e-01\n",
            "epoch: 940, iter: 32, training_loss: 1.22406e-01\n",
            "epoch: 941, iter: 32, training_loss: 1.47050e-01\n",
            "epoch: 942, iter: 32, training_loss: 1.42401e-01\n",
            "epoch: 943, iter: 32, training_loss: 1.37083e-01\n",
            "epoch: 944, iter: 32, training_loss: 1.87844e-01\n",
            "epoch: 945, iter: 32, training_loss: 1.71558e-01\n",
            "epoch: 946, iter: 32, training_loss: 1.44639e-01\n",
            "epoch: 947, iter: 32, training_loss: 1.23700e-01\n",
            "epoch: 948, iter: 32, training_loss: 1.67515e-01\n",
            "epoch: 949, iter: 32, training_loss: 1.48669e-01\n",
            "epoch: 950, iter: 32, training_loss: 1.58835e-01\n",
            "epoch: 951, iter: 32, training_loss: 1.27019e-01\n",
            "epoch: 952, iter: 32, training_loss: 1.59551e-01\n",
            "epoch: 953, iter: 32, training_loss: 1.61023e-01\n",
            "epoch: 954, iter: 32, training_loss: 1.47407e-01\n",
            "epoch: 955, iter: 32, training_loss: 1.36754e-01\n",
            "epoch: 956, iter: 32, training_loss: 1.31940e-01\n",
            "epoch: 957, iter: 32, training_loss: 1.32061e-01\n",
            "epoch: 958, iter: 32, training_loss: 1.40494e-01\n",
            "epoch: 959, iter: 32, training_loss: 1.28294e-01\n",
            "epoch: 960, iter: 32, training_loss: 1.21679e-01\n",
            "epoch: 961, iter: 32, training_loss: 1.49558e-01\n",
            "epoch: 962, iter: 32, training_loss: 1.63976e-01\n",
            "epoch: 963, iter: 32, training_loss: 1.40841e-01\n",
            "epoch: 964, iter: 32, training_loss: 1.39804e-01\n",
            "epoch: 965, iter: 32, training_loss: 1.18414e-01\n",
            "epoch: 966, iter: 32, training_loss: 1.56184e-01\n",
            "epoch: 967, iter: 32, training_loss: 1.46661e-01\n",
            "epoch: 968, iter: 32, training_loss: 1.20057e-01\n",
            "epoch: 969, iter: 32, training_loss: 1.21170e-01\n",
            "epoch: 970, iter: 32, training_loss: 1.23605e-01\n",
            "epoch: 971, iter: 32, training_loss: 1.47288e-01\n",
            "epoch: 972, iter: 32, training_loss: 1.24719e-01\n",
            "epoch: 973, iter: 32, training_loss: 1.10800e-01\n",
            "epoch: 974, iter: 32, training_loss: 1.72437e-01\n",
            "epoch: 975, iter: 32, training_loss: 1.46239e-01\n",
            "epoch: 976, iter: 32, training_loss: 1.55705e-01\n",
            "epoch: 977, iter: 32, training_loss: 1.58336e-01\n",
            "epoch: 978, iter: 32, training_loss: 1.32835e-01\n",
            "epoch: 979, iter: 32, training_loss: 1.35187e-01\n",
            "epoch: 980, iter: 32, training_loss: 1.27247e-01\n",
            "epoch: 981, iter: 32, training_loss: 1.33271e-01\n",
            "epoch: 982, iter: 32, training_loss: 1.19177e-01\n",
            "epoch: 983, iter: 32, training_loss: 1.53537e-01\n",
            "epoch: 984, iter: 32, training_loss: 1.71010e-01\n",
            "epoch: 985, iter: 32, training_loss: 1.26335e-01\n",
            "epoch: 986, iter: 32, training_loss: 1.44492e-01\n",
            "epoch: 987, iter: 32, training_loss: 1.38707e-01\n",
            "epoch: 988, iter: 32, training_loss: 1.35530e-01\n",
            "epoch: 989, iter: 32, training_loss: 1.43253e-01\n",
            "epoch: 990, iter: 32, training_loss: 1.28909e-01\n",
            "epoch: 991, iter: 32, training_loss: 1.21983e-01\n",
            "epoch: 992, iter: 32, training_loss: 1.43863e-01\n",
            "epoch: 993, iter: 32, training_loss: 1.60144e-01\n",
            "epoch: 994, iter: 32, training_loss: 1.48769e-01\n",
            "epoch: 995, iter: 32, training_loss: 1.42192e-01\n",
            "epoch: 996, iter: 32, training_loss: 1.57906e-01\n",
            "epoch: 997, iter: 32, training_loss: 1.45148e-01\n",
            "epoch: 998, iter: 32, training_loss: 1.74185e-01\n",
            "epoch: 999, iter: 32, training_loss: 1.36232e-01\n",
            "epoch: 1000, iter: 32, training_loss: 1.42582e-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname adult --method stasy --mode sample --save_path adult_syn.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2uH7t8_UYeg",
        "outputId": "23e41d4b-2e15-4f30-f46d-6e50b7fbd5e0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No NaNs in numerical features, skipping\n",
            "Input dimension: 110\n",
            "NCSNpp(\n",
            "  (act): ELU(alpha=1.0)\n",
            "  (all_modules): ModuleList(\n",
            "    (0): GaussianFourierProjection()\n",
            "    (1): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (3): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=110, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (4): ELU(alpha=1.0)\n",
            "    (5): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=1134, out_features=2048, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=2048, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=2048, bias=True)\n",
            "    )\n",
            "    (6): ELU(alpha=1.0)\n",
            "    (7): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=3182, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (8): ELU(alpha=1.0)\n",
            "    (9): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=4206, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (10): ELU(alpha=1.0)\n",
            "    (11): Linear(in_features=5230, out_features=110, bias=True)\n",
            "  )\n",
            ")\n",
            "the number of parameters 10695154\n",
            "Loading SAVED model at from /content/tabsyn/baselines/stasy/ckpt/adult/model.pth\n",
            "Start sampling...\n",
            "(32561, 9)\n",
            "Sampling time = 38.70943093299866\n",
            "Saving sampled data to adult_syn.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname magic --method stasy --mode train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-_mux8C-4xN",
        "outputId": "0b76ca7f-2c4c-4ac3-8377-057d4e673df2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No NaNs in numerical features, skipping\n",
            "12\n",
            "NCSNpp(\n",
            "  (act): ELU(alpha=1.0)\n",
            "  (all_modules): ModuleList(\n",
            "    (0): GaussianFourierProjection()\n",
            "    (1): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (3): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=12, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (4): ELU(alpha=1.0)\n",
            "    (5): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=1036, out_features=2048, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=2048, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=2048, bias=True)\n",
            "    )\n",
            "    (6): ELU(alpha=1.0)\n",
            "    (7): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=3084, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (8): ELU(alpha=1.0)\n",
            "    (9): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=4108, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (10): ELU(alpha=1.0)\n",
            "    (11): Linear(in_features=5132, out_features=12, bias=True)\n",
            "  )\n",
            ")\n",
            "the number of parameters 9679580\n",
            "epoch: 0, iter: 17, training_loss: 2.98496e+00\n",
            "epoch: 1, iter: 17, training_loss: 1.19238e+00\n",
            "epoch: 2, iter: 17, training_loss: 1.06764e+00\n",
            "epoch: 3, iter: 17, training_loss: 1.01781e+00\n",
            "epoch: 4, iter: 17, training_loss: 9.30309e-01\n",
            "epoch: 5, iter: 17, training_loss: 8.86004e-01\n",
            "epoch: 6, iter: 17, training_loss: 8.36056e-01\n",
            "epoch: 7, iter: 17, training_loss: 9.02443e-01\n",
            "epoch: 8, iter: 17, training_loss: 8.81824e-01\n",
            "epoch: 9, iter: 17, training_loss: 8.89109e-01\n",
            "epoch: 10, iter: 17, training_loss: 9.23137e-01\n",
            "epoch: 11, iter: 17, training_loss: 8.92498e-01\n",
            "epoch: 12, iter: 17, training_loss: 9.85869e-01\n",
            "epoch: 13, iter: 17, training_loss: 1.01547e+00\n",
            "epoch: 14, iter: 17, training_loss: 1.04378e+00\n",
            "epoch: 15, iter: 17, training_loss: 1.15113e+00\n",
            "epoch: 16, iter: 17, training_loss: 1.23489e+00\n",
            "epoch: 17, iter: 17, training_loss: 1.03259e+00\n",
            "epoch: 18, iter: 17, training_loss: 9.99357e-01\n",
            "epoch: 19, iter: 17, training_loss: 9.49625e-01\n",
            "epoch: 20, iter: 17, training_loss: 1.08361e+00\n",
            "epoch: 21, iter: 17, training_loss: 1.07912e+00\n",
            "epoch: 22, iter: 17, training_loss: 1.47499e+00\n",
            "epoch: 23, iter: 17, training_loss: 1.15331e+00\n",
            "epoch: 24, iter: 17, training_loss: 1.03223e+00\n",
            "epoch: 25, iter: 17, training_loss: 1.21411e+00\n",
            "epoch: 26, iter: 17, training_loss: 1.43867e+00\n",
            "epoch: 27, iter: 17, training_loss: 1.20020e+00\n",
            "epoch: 28, iter: 17, training_loss: 1.19474e+00\n",
            "epoch: 29, iter: 17, training_loss: 1.20464e+00\n",
            "epoch: 30, iter: 17, training_loss: 1.25415e+00\n",
            "epoch: 31, iter: 17, training_loss: 1.36146e+00\n",
            "epoch: 32, iter: 17, training_loss: 1.26653e+00\n",
            "epoch: 33, iter: 17, training_loss: 1.11257e+00\n",
            "epoch: 34, iter: 17, training_loss: 9.12066e-01\n",
            "epoch: 35, iter: 17, training_loss: 1.06170e+00\n",
            "epoch: 36, iter: 17, training_loss: 1.38565e+00\n",
            "epoch: 37, iter: 17, training_loss: 1.08540e+00\n",
            "epoch: 38, iter: 17, training_loss: 1.20562e+00\n",
            "epoch: 39, iter: 17, training_loss: 1.35516e+00\n",
            "epoch: 40, iter: 17, training_loss: 1.28241e+00\n",
            "epoch: 41, iter: 17, training_loss: 1.16978e+00\n",
            "epoch: 42, iter: 17, training_loss: 1.28579e+00\n",
            "epoch: 43, iter: 17, training_loss: 1.36284e+00\n",
            "epoch: 44, iter: 17, training_loss: 1.42640e+00\n",
            "epoch: 45, iter: 17, training_loss: 1.17996e+00\n",
            "epoch: 46, iter: 17, training_loss: 1.17401e+00\n",
            "epoch: 47, iter: 17, training_loss: 1.08684e+00\n",
            "epoch: 48, iter: 17, training_loss: 1.13631e+00\n",
            "epoch: 49, iter: 17, training_loss: 1.16271e+00\n",
            "epoch: 50, iter: 17, training_loss: 1.22355e+00\n",
            "epoch: 51, iter: 17, training_loss: 1.11728e+00\n",
            "epoch: 52, iter: 17, training_loss: 1.22413e+00\n",
            "epoch: 53, iter: 17, training_loss: 1.45977e+00\n",
            "epoch: 54, iter: 17, training_loss: 1.40942e+00\n",
            "epoch: 55, iter: 17, training_loss: 1.01166e+00\n",
            "epoch: 56, iter: 17, training_loss: 1.12434e+00\n",
            "epoch: 57, iter: 17, training_loss: 1.24039e+00\n",
            "epoch: 58, iter: 17, training_loss: 1.10955e+00\n",
            "epoch: 59, iter: 17, training_loss: 1.33056e+00\n",
            "epoch: 60, iter: 17, training_loss: 1.48328e+00\n",
            "epoch: 61, iter: 17, training_loss: 1.49674e+00\n",
            "epoch: 62, iter: 17, training_loss: 1.32983e+00\n",
            "epoch: 63, iter: 17, training_loss: 1.45279e+00\n",
            "epoch: 64, iter: 17, training_loss: 1.32667e+00\n",
            "epoch: 65, iter: 17, training_loss: 1.43418e+00\n",
            "epoch: 66, iter: 17, training_loss: 1.14672e+00\n",
            "epoch: 67, iter: 17, training_loss: 1.16161e+00\n",
            "epoch: 68, iter: 17, training_loss: 1.50653e+00\n",
            "epoch: 69, iter: 17, training_loss: 1.80919e+00\n",
            "epoch: 70, iter: 17, training_loss: 1.17722e+00\n",
            "epoch: 71, iter: 17, training_loss: 1.32331e+00\n",
            "epoch: 72, iter: 17, training_loss: 1.58998e+00\n",
            "epoch: 73, iter: 17, training_loss: 1.64033e+00\n",
            "epoch: 74, iter: 17, training_loss: 1.70812e+00\n",
            "epoch: 75, iter: 17, training_loss: 1.34099e+00\n",
            "epoch: 76, iter: 17, training_loss: 1.45862e+00\n",
            "epoch: 77, iter: 17, training_loss: 1.53111e+00\n",
            "epoch: 78, iter: 17, training_loss: 2.88849e+00\n",
            "epoch: 79, iter: 17, training_loss: 2.56149e+00\n",
            "epoch: 80, iter: 17, training_loss: 1.64654e+00\n",
            "epoch: 81, iter: 17, training_loss: 1.36703e+00\n",
            "epoch: 82, iter: 17, training_loss: 1.70403e+00\n",
            "epoch: 83, iter: 17, training_loss: 1.95972e+00\n",
            "epoch: 84, iter: 17, training_loss: 1.61818e+00\n",
            "epoch: 85, iter: 17, training_loss: 1.48520e+00\n",
            "epoch: 86, iter: 17, training_loss: 1.57174e+00\n",
            "epoch: 87, iter: 17, training_loss: 1.64235e+00\n",
            "epoch: 88, iter: 17, training_loss: 1.59778e+00\n",
            "epoch: 89, iter: 17, training_loss: 1.35624e+00\n",
            "epoch: 90, iter: 17, training_loss: 1.18619e+00\n",
            "epoch: 91, iter: 17, training_loss: 1.48734e+00\n",
            "epoch: 92, iter: 17, training_loss: 1.45192e+00\n",
            "epoch: 93, iter: 17, training_loss: 2.12397e+00\n",
            "epoch: 94, iter: 17, training_loss: 1.90887e+00\n",
            "epoch: 95, iter: 17, training_loss: 1.71957e+00\n",
            "epoch: 96, iter: 17, training_loss: 1.80077e+00\n",
            "epoch: 97, iter: 17, training_loss: 1.52946e+00\n",
            "epoch: 98, iter: 17, training_loss: 3.49140e+00\n",
            "epoch: 99, iter: 17, training_loss: 3.59004e+00\n",
            "epoch: 100, iter: 17, training_loss: 2.67667e+00\n",
            "epoch: 101, iter: 17, training_loss: 1.70692e+00\n",
            "epoch: 102, iter: 17, training_loss: 1.73024e+00\n",
            "epoch: 103, iter: 17, training_loss: 2.00765e+00\n",
            "epoch: 104, iter: 17, training_loss: 2.91040e+00\n",
            "epoch: 105, iter: 17, training_loss: 1.91068e+00\n",
            "epoch: 106, iter: 17, training_loss: 3.14145e+00\n",
            "epoch: 107, iter: 17, training_loss: 3.30543e+00\n",
            "epoch: 108, iter: 17, training_loss: 1.74528e+00\n",
            "epoch: 109, iter: 17, training_loss: 1.69182e+00\n",
            "epoch: 110, iter: 17, training_loss: 1.82674e+00\n",
            "epoch: 111, iter: 17, training_loss: 1.39042e+00\n",
            "epoch: 112, iter: 17, training_loss: 1.69042e+00\n",
            "epoch: 113, iter: 17, training_loss: 1.80623e+00\n",
            "epoch: 114, iter: 17, training_loss: 1.94456e+00\n",
            "epoch: 115, iter: 17, training_loss: 2.67348e+00\n",
            "epoch: 116, iter: 17, training_loss: 1.58718e+00\n",
            "epoch: 117, iter: 17, training_loss: 1.71921e+00\n",
            "epoch: 118, iter: 17, training_loss: 1.35513e+00\n",
            "epoch: 119, iter: 17, training_loss: 1.88553e+00\n",
            "epoch: 120, iter: 17, training_loss: 1.83867e+00\n",
            "epoch: 121, iter: 17, training_loss: 2.02362e+00\n",
            "epoch: 122, iter: 17, training_loss: 2.11291e+00\n",
            "epoch: 123, iter: 17, training_loss: 2.48994e+00\n",
            "epoch: 124, iter: 17, training_loss: 2.47646e+00\n",
            "epoch: 125, iter: 17, training_loss: 2.92037e+00\n",
            "epoch: 126, iter: 17, training_loss: 2.02980e+00\n",
            "epoch: 127, iter: 17, training_loss: 1.82728e+00\n",
            "epoch: 128, iter: 17, training_loss: 1.99064e+00\n",
            "epoch: 129, iter: 17, training_loss: 1.88923e+00\n",
            "epoch: 130, iter: 17, training_loss: 1.72656e+00\n",
            "epoch: 131, iter: 17, training_loss: 1.66243e+00\n",
            "epoch: 132, iter: 17, training_loss: 2.02419e+00\n",
            "epoch: 133, iter: 17, training_loss: 2.60313e+00\n",
            "epoch: 134, iter: 17, training_loss: 2.05287e+00\n",
            "epoch: 135, iter: 17, training_loss: 3.30499e+00\n",
            "epoch: 136, iter: 17, training_loss: 3.23386e+00\n",
            "epoch: 137, iter: 17, training_loss: 3.39168e+00\n",
            "epoch: 138, iter: 17, training_loss: 1.87776e+00\n",
            "epoch: 139, iter: 17, training_loss: 2.12219e+00\n",
            "epoch: 140, iter: 17, training_loss: 2.23547e+00\n",
            "epoch: 141, iter: 17, training_loss: 3.08250e+00\n",
            "epoch: 142, iter: 17, training_loss: 2.41171e+00\n",
            "epoch: 143, iter: 17, training_loss: 3.08033e+00\n",
            "epoch: 144, iter: 17, training_loss: 3.05206e+00\n",
            "epoch: 145, iter: 17, training_loss: 2.52789e+00\n",
            "epoch: 146, iter: 17, training_loss: 2.44503e+00\n",
            "epoch: 147, iter: 17, training_loss: 2.07218e+00\n",
            "epoch: 148, iter: 17, training_loss: 1.87372e+00\n",
            "epoch: 149, iter: 17, training_loss: 3.15233e+00\n",
            "epoch: 150, iter: 17, training_loss: 3.81334e+00\n",
            "epoch: 151, iter: 17, training_loss: 1.65718e+00\n",
            "epoch: 152, iter: 17, training_loss: 1.69137e+00\n",
            "epoch: 153, iter: 17, training_loss: 1.92676e+00\n",
            "epoch: 154, iter: 17, training_loss: 2.02721e+00\n",
            "epoch: 155, iter: 17, training_loss: 1.79402e+00\n",
            "epoch: 156, iter: 17, training_loss: 1.93409e+00\n",
            "epoch: 157, iter: 17, training_loss: 2.28602e+00\n",
            "epoch: 158, iter: 17, training_loss: 1.72987e+00\n",
            "epoch: 159, iter: 17, training_loss: 2.26676e+00\n",
            "epoch: 160, iter: 17, training_loss: 2.41374e+00\n",
            "epoch: 161, iter: 17, training_loss: 2.32802e+00\n",
            "epoch: 162, iter: 17, training_loss: 2.32626e+00\n",
            "epoch: 163, iter: 17, training_loss: 2.19400e+00\n",
            "epoch: 164, iter: 17, training_loss: 4.03381e+00\n",
            "epoch: 165, iter: 17, training_loss: 3.35954e+00\n",
            "epoch: 166, iter: 17, training_loss: 2.19024e+00\n",
            "epoch: 167, iter: 17, training_loss: 1.93480e+00\n",
            "epoch: 168, iter: 17, training_loss: 2.72694e+00\n",
            "epoch: 169, iter: 17, training_loss: 2.67744e+00\n",
            "epoch: 170, iter: 17, training_loss: 2.07017e+00\n",
            "epoch: 171, iter: 17, training_loss: 3.36885e+00\n",
            "epoch: 172, iter: 17, training_loss: 3.02445e+00\n",
            "epoch: 173, iter: 17, training_loss: 1.94741e+00\n",
            "epoch: 174, iter: 17, training_loss: 2.43701e+00\n",
            "epoch: 175, iter: 17, training_loss: 1.76538e+00\n",
            "epoch: 176, iter: 17, training_loss: 1.97247e+00\n",
            "epoch: 177, iter: 17, training_loss: 3.55822e+00\n",
            "epoch: 178, iter: 17, training_loss: 4.28892e+00\n",
            "epoch: 179, iter: 17, training_loss: 2.31672e+00\n",
            "epoch: 180, iter: 17, training_loss: 2.38131e+00\n",
            "epoch: 181, iter: 17, training_loss: 3.78648e+00\n",
            "epoch: 182, iter: 17, training_loss: 2.45352e+00\n",
            "epoch: 183, iter: 17, training_loss: 2.91044e+00\n",
            "epoch: 184, iter: 17, training_loss: 1.98415e+00\n",
            "epoch: 185, iter: 17, training_loss: 2.63828e+00\n",
            "epoch: 186, iter: 17, training_loss: 2.16924e+00\n",
            "epoch: 187, iter: 17, training_loss: 2.22900e+00\n",
            "epoch: 188, iter: 17, training_loss: 2.10739e+00\n",
            "epoch: 189, iter: 17, training_loss: 1.89301e+00\n",
            "epoch: 190, iter: 17, training_loss: 2.27840e+00\n",
            "epoch: 191, iter: 17, training_loss: 2.20501e+00\n",
            "epoch: 192, iter: 17, training_loss: 1.76407e+00\n",
            "epoch: 193, iter: 17, training_loss: 2.23363e+00\n",
            "epoch: 194, iter: 17, training_loss: 2.83263e+00\n",
            "epoch: 195, iter: 17, training_loss: 2.19649e+00\n",
            "epoch: 196, iter: 17, training_loss: 1.81616e+00\n",
            "epoch: 197, iter: 17, training_loss: 2.21588e+00\n",
            "epoch: 198, iter: 17, training_loss: 2.00709e+00\n",
            "epoch: 199, iter: 17, training_loss: 1.96153e+00\n",
            "epoch: 200, iter: 17, training_loss: 2.01590e+00\n",
            "epoch: 201, iter: 17, training_loss: 1.77482e+00\n",
            "epoch: 202, iter: 17, training_loss: 1.58149e+00\n",
            "epoch: 203, iter: 17, training_loss: 1.73156e+00\n",
            "epoch: 204, iter: 17, training_loss: 2.10036e+00\n",
            "epoch: 205, iter: 17, training_loss: 2.61526e+00\n",
            "epoch: 206, iter: 17, training_loss: 1.91221e+00\n",
            "epoch: 207, iter: 17, training_loss: 3.55575e+00\n",
            "epoch: 208, iter: 17, training_loss: 3.35729e+00\n",
            "epoch: 209, iter: 17, training_loss: 2.07388e+00\n",
            "epoch: 210, iter: 17, training_loss: 2.07036e+00\n",
            "epoch: 211, iter: 17, training_loss: 1.41968e+00\n",
            "epoch: 212, iter: 17, training_loss: 1.46694e+00\n",
            "epoch: 213, iter: 17, training_loss: 2.39529e+00\n",
            "epoch: 214, iter: 17, training_loss: 1.69903e+00\n",
            "epoch: 215, iter: 17, training_loss: 2.36948e+00\n",
            "epoch: 216, iter: 17, training_loss: 3.46606e+00\n",
            "epoch: 217, iter: 17, training_loss: 2.05107e+00\n",
            "epoch: 218, iter: 17, training_loss: 1.99731e+00\n",
            "epoch: 219, iter: 17, training_loss: 1.63932e+00\n",
            "epoch: 220, iter: 17, training_loss: 1.93314e+00\n",
            "epoch: 221, iter: 17, training_loss: 1.94725e+00\n",
            "epoch: 222, iter: 17, training_loss: 1.78205e+00\n",
            "epoch: 223, iter: 17, training_loss: 2.25881e+00\n",
            "epoch: 224, iter: 17, training_loss: 2.17091e+00\n",
            "epoch: 225, iter: 17, training_loss: 2.20630e+00\n",
            "epoch: 226, iter: 17, training_loss: 1.63376e+00\n",
            "epoch: 227, iter: 17, training_loss: 1.51383e+00\n",
            "epoch: 228, iter: 17, training_loss: 1.65115e+00\n",
            "epoch: 229, iter: 17, training_loss: 1.39233e+00\n",
            "epoch: 230, iter: 17, training_loss: 2.16827e+00\n",
            "epoch: 231, iter: 17, training_loss: 1.49355e+00\n",
            "epoch: 232, iter: 17, training_loss: 1.81634e+00\n",
            "epoch: 233, iter: 17, training_loss: 2.21401e+00\n",
            "epoch: 234, iter: 17, training_loss: 1.67008e+00\n",
            "epoch: 235, iter: 17, training_loss: 1.41849e+00\n",
            "epoch: 236, iter: 17, training_loss: 1.96760e+00\n",
            "epoch: 237, iter: 17, training_loss: 1.63238e+00\n",
            "epoch: 238, iter: 17, training_loss: 1.67326e+00\n",
            "epoch: 239, iter: 17, training_loss: 1.46596e+00\n",
            "epoch: 240, iter: 17, training_loss: 1.64333e+00\n",
            "epoch: 241, iter: 17, training_loss: 2.22383e+00\n",
            "epoch: 242, iter: 17, training_loss: 1.98094e+00\n",
            "epoch: 243, iter: 17, training_loss: 1.70560e+00\n",
            "epoch: 244, iter: 17, training_loss: 1.81086e+00\n",
            "epoch: 245, iter: 17, training_loss: 1.76886e+00\n",
            "epoch: 246, iter: 17, training_loss: 1.74652e+00\n",
            "epoch: 247, iter: 17, training_loss: 1.71519e+00\n",
            "epoch: 248, iter: 17, training_loss: 1.59617e+00\n",
            "epoch: 249, iter: 17, training_loss: 1.46844e+00\n",
            "epoch: 250, iter: 17, training_loss: 1.43195e+00\n",
            "epoch: 251, iter: 17, training_loss: 1.73935e+00\n",
            "epoch: 252, iter: 17, training_loss: 2.06409e+00\n",
            "epoch: 253, iter: 17, training_loss: 1.70180e+00\n",
            "epoch: 254, iter: 17, training_loss: 1.57434e+00\n",
            "epoch: 255, iter: 17, training_loss: 1.55305e+00\n",
            "epoch: 256, iter: 17, training_loss: 1.45957e+00\n",
            "epoch: 257, iter: 17, training_loss: 1.59329e+00\n",
            "epoch: 258, iter: 17, training_loss: 1.68824e+00\n",
            "epoch: 259, iter: 17, training_loss: 1.64061e+00\n",
            "epoch: 260, iter: 17, training_loss: 1.44994e+00\n",
            "epoch: 261, iter: 17, training_loss: 2.33634e+00\n",
            "epoch: 262, iter: 17, training_loss: 1.99484e+00\n",
            "epoch: 263, iter: 17, training_loss: 1.82010e+00\n",
            "epoch: 264, iter: 17, training_loss: 2.45746e+00\n",
            "epoch: 265, iter: 17, training_loss: 1.88152e+00\n",
            "epoch: 266, iter: 17, training_loss: 1.48554e+00\n",
            "epoch: 267, iter: 17, training_loss: 1.72668e+00\n",
            "epoch: 268, iter: 17, training_loss: 1.47540e+00\n",
            "epoch: 269, iter: 17, training_loss: 1.81061e+00\n",
            "epoch: 270, iter: 17, training_loss: 1.79186e+00\n",
            "epoch: 271, iter: 17, training_loss: 2.31273e+00\n",
            "epoch: 272, iter: 17, training_loss: 1.91190e+00\n",
            "epoch: 273, iter: 17, training_loss: 1.62242e+00\n",
            "epoch: 274, iter: 17, training_loss: 1.52947e+00\n",
            "epoch: 275, iter: 17, training_loss: 1.44372e+00\n",
            "epoch: 276, iter: 17, training_loss: 1.47524e+00\n",
            "epoch: 277, iter: 17, training_loss: 1.16329e+00\n",
            "epoch: 278, iter: 17, training_loss: 1.28810e+00\n",
            "epoch: 279, iter: 17, training_loss: 1.21322e+00\n",
            "epoch: 280, iter: 17, training_loss: 1.70578e+00\n",
            "epoch: 281, iter: 17, training_loss: 1.81317e+00\n",
            "epoch: 282, iter: 17, training_loss: 1.90635e+00\n",
            "epoch: 283, iter: 17, training_loss: 1.95747e+00\n",
            "epoch: 284, iter: 17, training_loss: 1.52115e+00\n",
            "epoch: 285, iter: 17, training_loss: 1.29720e+00\n",
            "epoch: 286, iter: 17, training_loss: 1.59427e+00\n",
            "epoch: 287, iter: 17, training_loss: 1.65341e+00\n",
            "epoch: 288, iter: 17, training_loss: 2.10369e+00\n",
            "epoch: 289, iter: 17, training_loss: 1.85551e+00\n",
            "epoch: 290, iter: 17, training_loss: 1.31779e+00\n",
            "epoch: 291, iter: 17, training_loss: 1.28187e+00\n",
            "epoch: 292, iter: 17, training_loss: 1.35777e+00\n",
            "epoch: 293, iter: 17, training_loss: 1.85175e+00\n",
            "epoch: 294, iter: 17, training_loss: 1.70000e+00\n",
            "epoch: 295, iter: 17, training_loss: 2.03981e+00\n",
            "epoch: 296, iter: 17, training_loss: 2.14596e+00\n",
            "epoch: 297, iter: 17, training_loss: 2.45102e+00\n",
            "epoch: 298, iter: 17, training_loss: 1.43812e+00\n",
            "epoch: 299, iter: 17, training_loss: 1.75229e+00\n",
            "epoch: 300, iter: 17, training_loss: 1.17434e+00\n",
            "epoch: 301, iter: 17, training_loss: 1.25352e+00\n",
            "epoch: 302, iter: 17, training_loss: 1.78372e+00\n",
            "epoch: 303, iter: 17, training_loss: 1.71523e+00\n",
            "epoch: 304, iter: 17, training_loss: 1.30328e+00\n",
            "epoch: 305, iter: 17, training_loss: 1.82091e+00\n",
            "epoch: 306, iter: 17, training_loss: 1.14829e+00\n",
            "epoch: 307, iter: 17, training_loss: 1.16255e+00\n",
            "epoch: 308, iter: 17, training_loss: 1.48377e+00\n",
            "epoch: 309, iter: 17, training_loss: 1.96745e+00\n",
            "epoch: 310, iter: 17, training_loss: 1.27894e+00\n",
            "epoch: 311, iter: 17, training_loss: 1.60514e+00\n",
            "epoch: 312, iter: 17, training_loss: 1.43386e+00\n",
            "epoch: 313, iter: 17, training_loss: 1.85268e+00\n",
            "epoch: 314, iter: 17, training_loss: 1.70741e+00\n",
            "epoch: 315, iter: 17, training_loss: 1.82898e+00\n",
            "epoch: 316, iter: 17, training_loss: 1.28516e+00\n",
            "epoch: 317, iter: 17, training_loss: 1.34734e+00\n",
            "epoch: 318, iter: 17, training_loss: 1.19832e+00\n",
            "epoch: 319, iter: 17, training_loss: 1.07604e+00\n",
            "epoch: 320, iter: 17, training_loss: 1.27280e+00\n",
            "epoch: 321, iter: 17, training_loss: 1.04934e+00\n",
            "epoch: 322, iter: 17, training_loss: 1.26022e+00\n",
            "epoch: 323, iter: 17, training_loss: 1.27518e+00\n",
            "epoch: 324, iter: 17, training_loss: 1.67097e+00\n",
            "epoch: 325, iter: 17, training_loss: 1.29588e+00\n",
            "epoch: 326, iter: 17, training_loss: 1.59646e+00\n",
            "epoch: 327, iter: 17, training_loss: 1.06209e+00\n",
            "epoch: 328, iter: 17, training_loss: 1.13760e+00\n",
            "epoch: 329, iter: 17, training_loss: 1.30651e+00\n",
            "epoch: 330, iter: 17, training_loss: 1.35867e+00\n",
            "epoch: 331, iter: 17, training_loss: 1.11447e+00\n",
            "epoch: 332, iter: 17, training_loss: 9.80990e-01\n",
            "epoch: 333, iter: 17, training_loss: 8.81259e-01\n",
            "epoch: 334, iter: 17, training_loss: 1.00150e+00\n",
            "epoch: 335, iter: 17, training_loss: 9.42278e-01\n",
            "epoch: 336, iter: 17, training_loss: 1.55253e+00\n",
            "epoch: 337, iter: 17, training_loss: 1.11629e+00\n",
            "epoch: 338, iter: 17, training_loss: 9.13836e-01\n",
            "epoch: 339, iter: 17, training_loss: 9.92734e-01\n",
            "epoch: 340, iter: 17, training_loss: 9.19119e-01\n",
            "epoch: 341, iter: 17, training_loss: 9.02946e-01\n",
            "epoch: 342, iter: 17, training_loss: 9.11667e-01\n",
            "epoch: 343, iter: 17, training_loss: 1.42993e+00\n",
            "epoch: 344, iter: 17, training_loss: 1.11174e+00\n",
            "epoch: 345, iter: 17, training_loss: 1.00705e+00\n",
            "epoch: 346, iter: 17, training_loss: 9.03487e-01\n",
            "epoch: 347, iter: 17, training_loss: 1.15640e+00\n",
            "epoch: 348, iter: 17, training_loss: 1.09424e+00\n",
            "epoch: 349, iter: 17, training_loss: 1.45407e+00\n",
            "epoch: 350, iter: 17, training_loss: 9.65762e-01\n",
            "epoch: 351, iter: 17, training_loss: 9.01132e-01\n",
            "epoch: 352, iter: 17, training_loss: 8.51006e-01\n",
            "epoch: 353, iter: 17, training_loss: 8.80234e-01\n",
            "epoch: 354, iter: 17, training_loss: 1.17716e+00\n",
            "epoch: 355, iter: 17, training_loss: 9.02515e-01\n",
            "epoch: 356, iter: 17, training_loss: 1.12915e+00\n",
            "epoch: 357, iter: 17, training_loss: 1.20043e+00\n",
            "epoch: 358, iter: 17, training_loss: 9.53812e-01\n",
            "epoch: 359, iter: 17, training_loss: 1.12131e+00\n",
            "epoch: 360, iter: 17, training_loss: 9.95464e-01\n",
            "epoch: 361, iter: 17, training_loss: 9.43983e-01\n",
            "epoch: 362, iter: 17, training_loss: 8.54477e-01\n",
            "epoch: 363, iter: 17, training_loss: 9.17550e-01\n",
            "epoch: 364, iter: 17, training_loss: 1.34888e+00\n",
            "epoch: 365, iter: 17, training_loss: 1.26979e+00\n",
            "epoch: 366, iter: 17, training_loss: 1.24645e+00\n",
            "epoch: 367, iter: 17, training_loss: 1.32014e+00\n",
            "epoch: 368, iter: 17, training_loss: 1.03717e+00\n",
            "epoch: 369, iter: 17, training_loss: 1.10358e+00\n",
            "epoch: 370, iter: 17, training_loss: 1.00702e+00\n",
            "epoch: 371, iter: 17, training_loss: 1.09261e+00\n",
            "epoch: 372, iter: 17, training_loss: 9.09332e-01\n",
            "epoch: 373, iter: 17, training_loss: 8.87803e-01\n",
            "epoch: 374, iter: 17, training_loss: 1.07646e+00\n",
            "epoch: 375, iter: 17, training_loss: 1.10552e+00\n",
            "epoch: 376, iter: 17, training_loss: 1.16466e+00\n",
            "epoch: 377, iter: 17, training_loss: 8.85146e-01\n",
            "epoch: 378, iter: 17, training_loss: 8.90378e-01\n",
            "epoch: 379, iter: 17, training_loss: 9.31359e-01\n",
            "epoch: 380, iter: 17, training_loss: 8.99858e-01\n",
            "epoch: 381, iter: 17, training_loss: 9.82251e-01\n",
            "epoch: 382, iter: 17, training_loss: 9.36104e-01\n",
            "epoch: 383, iter: 17, training_loss: 8.79513e-01\n",
            "epoch: 384, iter: 17, training_loss: 9.28235e-01\n",
            "epoch: 385, iter: 17, training_loss: 9.48722e-01\n",
            "epoch: 386, iter: 17, training_loss: 8.65006e-01\n",
            "epoch: 387, iter: 17, training_loss: 9.31177e-01\n",
            "epoch: 388, iter: 17, training_loss: 1.36816e+00\n",
            "epoch: 389, iter: 17, training_loss: 1.03273e+00\n",
            "epoch: 390, iter: 17, training_loss: 1.13532e+00\n",
            "epoch: 391, iter: 17, training_loss: 8.95907e-01\n",
            "epoch: 392, iter: 17, training_loss: 8.57313e-01\n",
            "epoch: 393, iter: 17, training_loss: 9.00130e-01\n",
            "epoch: 394, iter: 17, training_loss: 8.51805e-01\n",
            "epoch: 395, iter: 17, training_loss: 8.64876e-01\n",
            "epoch: 396, iter: 17, training_loss: 8.12470e-01\n",
            "epoch: 397, iter: 17, training_loss: 8.29998e-01\n",
            "epoch: 398, iter: 17, training_loss: 8.51073e-01\n",
            "epoch: 399, iter: 17, training_loss: 8.55620e-01\n",
            "epoch: 400, iter: 17, training_loss: 9.15348e-01\n",
            "epoch: 401, iter: 17, training_loss: 1.20764e+00\n",
            "epoch: 402, iter: 17, training_loss: 1.72156e+00\n",
            "epoch: 403, iter: 17, training_loss: 1.10547e+00\n",
            "epoch: 404, iter: 17, training_loss: 1.51918e+00\n",
            "epoch: 405, iter: 17, training_loss: 1.32343e+00\n",
            "epoch: 406, iter: 17, training_loss: 1.61917e+00\n",
            "epoch: 407, iter: 17, training_loss: 1.12540e+00\n",
            "epoch: 408, iter: 17, training_loss: 1.04850e+00\n",
            "epoch: 409, iter: 17, training_loss: 9.04752e-01\n",
            "epoch: 410, iter: 17, training_loss: 1.41453e+00\n",
            "epoch: 411, iter: 17, training_loss: 8.78379e-01\n",
            "epoch: 412, iter: 17, training_loss: 8.87388e-01\n",
            "epoch: 413, iter: 17, training_loss: 8.61107e-01\n",
            "epoch: 414, iter: 17, training_loss: 8.30851e-01\n",
            "epoch: 415, iter: 17, training_loss: 8.54626e-01\n",
            "epoch: 416, iter: 17, training_loss: 8.98593e-01\n",
            "epoch: 417, iter: 17, training_loss: 1.00125e+00\n",
            "epoch: 418, iter: 17, training_loss: 1.00856e+00\n",
            "epoch: 419, iter: 17, training_loss: 9.83144e-01\n",
            "epoch: 420, iter: 17, training_loss: 1.07880e+00\n",
            "epoch: 421, iter: 17, training_loss: 9.56772e-01\n",
            "epoch: 422, iter: 17, training_loss: 8.29741e-01\n",
            "epoch: 423, iter: 17, training_loss: 8.83474e-01\n",
            "epoch: 424, iter: 17, training_loss: 8.39067e-01\n",
            "epoch: 425, iter: 17, training_loss: 9.10825e-01\n",
            "epoch: 426, iter: 17, training_loss: 8.36780e-01\n",
            "epoch: 427, iter: 17, training_loss: 8.31981e-01\n",
            "epoch: 428, iter: 17, training_loss: 8.76544e-01\n",
            "epoch: 429, iter: 17, training_loss: 7.96141e-01\n",
            "epoch: 430, iter: 17, training_loss: 1.24869e+00\n",
            "epoch: 431, iter: 17, training_loss: 7.76032e-01\n",
            "epoch: 432, iter: 17, training_loss: 9.08996e-01\n",
            "epoch: 433, iter: 17, training_loss: 9.99354e-01\n",
            "epoch: 434, iter: 17, training_loss: 8.19932e-01\n",
            "epoch: 435, iter: 17, training_loss: 8.38750e-01\n",
            "epoch: 436, iter: 17, training_loss: 8.05764e-01\n",
            "epoch: 437, iter: 17, training_loss: 9.92570e-01\n",
            "epoch: 438, iter: 17, training_loss: 9.65929e-01\n",
            "epoch: 439, iter: 17, training_loss: 8.26976e-01\n",
            "epoch: 440, iter: 17, training_loss: 8.62060e-01\n",
            "epoch: 441, iter: 17, training_loss: 1.02128e+00\n",
            "epoch: 442, iter: 17, training_loss: 8.77695e-01\n",
            "epoch: 443, iter: 17, training_loss: 1.00125e+00\n",
            "epoch: 444, iter: 17, training_loss: 8.60627e-01\n",
            "epoch: 445, iter: 17, training_loss: 8.40797e-01\n",
            "epoch: 446, iter: 17, training_loss: 8.21810e-01\n",
            "epoch: 447, iter: 17, training_loss: 8.33247e-01\n",
            "epoch: 448, iter: 17, training_loss: 7.87946e-01\n",
            "epoch: 449, iter: 17, training_loss: 8.09462e-01\n",
            "epoch: 450, iter: 17, training_loss: 8.41266e-01\n",
            "epoch: 451, iter: 17, training_loss: 8.88321e-01\n",
            "epoch: 452, iter: 17, training_loss: 8.14182e-01\n",
            "epoch: 453, iter: 17, training_loss: 7.39206e-01\n",
            "epoch: 454, iter: 17, training_loss: 7.15504e-01\n",
            "epoch: 455, iter: 17, training_loss: 6.93821e-01\n",
            "epoch: 456, iter: 17, training_loss: 7.77532e-01\n",
            "epoch: 457, iter: 17, training_loss: 6.88647e-01\n",
            "epoch: 458, iter: 17, training_loss: 7.73993e-01\n",
            "epoch: 459, iter: 17, training_loss: 8.36526e-01\n",
            "epoch: 460, iter: 17, training_loss: 7.86402e-01\n",
            "epoch: 461, iter: 17, training_loss: 7.07010e-01\n",
            "epoch: 462, iter: 17, training_loss: 8.63082e-01\n",
            "epoch: 463, iter: 17, training_loss: 8.03796e-01\n",
            "epoch: 464, iter: 17, training_loss: 8.46823e-01\n",
            "epoch: 465, iter: 17, training_loss: 7.27681e-01\n",
            "epoch: 466, iter: 17, training_loss: 8.06359e-01\n",
            "epoch: 467, iter: 17, training_loss: 7.55467e-01\n",
            "epoch: 468, iter: 17, training_loss: 6.82572e-01\n",
            "epoch: 469, iter: 17, training_loss: 6.68278e-01\n",
            "epoch: 470, iter: 17, training_loss: 7.47648e-01\n",
            "epoch: 471, iter: 17, training_loss: 6.99550e-01\n",
            "epoch: 472, iter: 17, training_loss: 7.13756e-01\n",
            "epoch: 473, iter: 17, training_loss: 8.17676e-01\n",
            "epoch: 474, iter: 17, training_loss: 7.41388e-01\n",
            "epoch: 475, iter: 17, training_loss: 6.71433e-01\n",
            "epoch: 476, iter: 17, training_loss: 6.59412e-01\n",
            "epoch: 477, iter: 17, training_loss: 7.59794e-01\n",
            "epoch: 478, iter: 17, training_loss: 9.11397e-01\n",
            "epoch: 479, iter: 17, training_loss: 7.67094e-01\n",
            "epoch: 480, iter: 17, training_loss: 7.16775e-01\n",
            "epoch: 481, iter: 17, training_loss: 7.69435e-01\n",
            "epoch: 482, iter: 17, training_loss: 6.91557e-01\n",
            "epoch: 483, iter: 17, training_loss: 6.82900e-01\n",
            "epoch: 484, iter: 17, training_loss: 8.56700e-01\n",
            "epoch: 485, iter: 17, training_loss: 7.59795e-01\n",
            "epoch: 486, iter: 17, training_loss: 7.73900e-01\n",
            "epoch: 487, iter: 17, training_loss: 9.29167e-01\n",
            "epoch: 488, iter: 17, training_loss: 8.11547e-01\n",
            "epoch: 489, iter: 17, training_loss: 7.57686e-01\n",
            "epoch: 490, iter: 17, training_loss: 9.14138e-01\n",
            "epoch: 491, iter: 17, training_loss: 1.04185e+00\n",
            "epoch: 492, iter: 17, training_loss: 1.11072e+00\n",
            "epoch: 493, iter: 17, training_loss: 9.19894e-01\n",
            "epoch: 494, iter: 17, training_loss: 8.47648e-01\n",
            "epoch: 495, iter: 17, training_loss: 8.18768e-01\n",
            "epoch: 496, iter: 17, training_loss: 8.60892e-01\n",
            "epoch: 497, iter: 17, training_loss: 8.39618e-01\n",
            "epoch: 498, iter: 17, training_loss: 7.97379e-01\n",
            "epoch: 499, iter: 17, training_loss: 7.19181e-01\n",
            "epoch: 500, iter: 17, training_loss: 6.96402e-01\n",
            "epoch: 501, iter: 17, training_loss: 8.37371e-01\n",
            "epoch: 502, iter: 17, training_loss: 8.08810e-01\n",
            "epoch: 503, iter: 17, training_loss: 7.00459e-01\n",
            "epoch: 504, iter: 17, training_loss: 7.09528e-01\n",
            "epoch: 505, iter: 17, training_loss: 7.42798e-01\n",
            "epoch: 506, iter: 17, training_loss: 7.23733e-01\n",
            "epoch: 507, iter: 17, training_loss: 6.71921e-01\n",
            "epoch: 508, iter: 17, training_loss: 7.18794e-01\n",
            "epoch: 509, iter: 17, training_loss: 7.18400e-01\n",
            "epoch: 510, iter: 17, training_loss: 7.05696e-01\n",
            "epoch: 511, iter: 17, training_loss: 7.83261e-01\n",
            "epoch: 512, iter: 17, training_loss: 9.35441e-01\n",
            "epoch: 513, iter: 17, training_loss: 7.80374e-01\n",
            "epoch: 514, iter: 17, training_loss: 7.41220e-01\n",
            "epoch: 515, iter: 17, training_loss: 7.16029e-01\n",
            "epoch: 516, iter: 17, training_loss: 1.16227e+00\n",
            "epoch: 517, iter: 17, training_loss: 7.97568e-01\n",
            "epoch: 518, iter: 17, training_loss: 6.94360e-01\n",
            "epoch: 519, iter: 17, training_loss: 9.77584e-01\n",
            "epoch: 520, iter: 17, training_loss: 7.46304e-01\n",
            "epoch: 521, iter: 17, training_loss: 9.52493e-01\n",
            "epoch: 522, iter: 17, training_loss: 6.83148e-01\n",
            "epoch: 523, iter: 17, training_loss: 8.53042e-01\n",
            "epoch: 524, iter: 17, training_loss: 8.86876e-01\n",
            "epoch: 525, iter: 17, training_loss: 6.92654e-01\n",
            "epoch: 526, iter: 17, training_loss: 6.92583e-01\n",
            "epoch: 527, iter: 17, training_loss: 8.28541e-01\n",
            "epoch: 528, iter: 17, training_loss: 1.01425e+00\n",
            "epoch: 529, iter: 17, training_loss: 1.04685e+00\n",
            "epoch: 530, iter: 17, training_loss: 7.14103e-01\n",
            "epoch: 531, iter: 17, training_loss: 7.45618e-01\n",
            "epoch: 532, iter: 17, training_loss: 7.09952e-01\n",
            "epoch: 533, iter: 17, training_loss: 6.68111e-01\n",
            "epoch: 534, iter: 17, training_loss: 6.35232e-01\n",
            "epoch: 535, iter: 17, training_loss: 6.04028e-01\n",
            "epoch: 536, iter: 17, training_loss: 6.53888e-01\n",
            "epoch: 537, iter: 17, training_loss: 1.02033e+00\n",
            "epoch: 538, iter: 17, training_loss: 7.26824e-01\n",
            "epoch: 539, iter: 17, training_loss: 6.99431e-01\n",
            "epoch: 540, iter: 17, training_loss: 6.74334e-01\n",
            "epoch: 541, iter: 17, training_loss: 6.44517e-01\n",
            "epoch: 542, iter: 17, training_loss: 6.25172e-01\n",
            "epoch: 543, iter: 17, training_loss: 6.12832e-01\n",
            "epoch: 544, iter: 17, training_loss: 5.98615e-01\n",
            "epoch: 545, iter: 17, training_loss: 8.43171e-01\n",
            "epoch: 546, iter: 17, training_loss: 1.04143e+00\n",
            "epoch: 547, iter: 17, training_loss: 7.13534e-01\n",
            "epoch: 548, iter: 17, training_loss: 6.73610e-01\n",
            "epoch: 549, iter: 17, training_loss: 6.66206e-01\n",
            "epoch: 550, iter: 17, training_loss: 6.62917e-01\n",
            "epoch: 551, iter: 17, training_loss: 6.68750e-01\n",
            "epoch: 552, iter: 17, training_loss: 6.22187e-01\n",
            "epoch: 553, iter: 17, training_loss: 6.14915e-01\n",
            "epoch: 554, iter: 17, training_loss: 6.08756e-01\n",
            "epoch: 555, iter: 17, training_loss: 6.31540e-01\n",
            "epoch: 556, iter: 17, training_loss: 6.98740e-01\n",
            "epoch: 557, iter: 17, training_loss: 7.10269e-01\n",
            "epoch: 558, iter: 17, training_loss: 6.68894e-01\n",
            "epoch: 559, iter: 17, training_loss: 6.56609e-01\n",
            "epoch: 560, iter: 17, training_loss: 6.21868e-01\n",
            "epoch: 561, iter: 17, training_loss: 6.08248e-01\n",
            "epoch: 562, iter: 17, training_loss: 7.33246e-01\n",
            "epoch: 563, iter: 17, training_loss: 6.75708e-01\n",
            "epoch: 564, iter: 17, training_loss: 5.97180e-01\n",
            "epoch: 565, iter: 17, training_loss: 6.48082e-01\n",
            "epoch: 566, iter: 17, training_loss: 6.10602e-01\n",
            "epoch: 567, iter: 17, training_loss: 7.37180e-01\n",
            "epoch: 568, iter: 17, training_loss: 7.25171e-01\n",
            "epoch: 569, iter: 17, training_loss: 6.74270e-01\n",
            "epoch: 570, iter: 17, training_loss: 7.03518e-01\n",
            "epoch: 571, iter: 17, training_loss: 6.58697e-01\n",
            "epoch: 572, iter: 17, training_loss: 6.63528e-01\n",
            "epoch: 573, iter: 17, training_loss: 7.42886e-01\n",
            "epoch: 574, iter: 17, training_loss: 1.13342e+00\n",
            "epoch: 575, iter: 17, training_loss: 8.88518e-01\n",
            "epoch: 576, iter: 17, training_loss: 7.10347e-01\n",
            "epoch: 577, iter: 17, training_loss: 6.57006e-01\n",
            "epoch: 578, iter: 17, training_loss: 6.42034e-01\n",
            "epoch: 579, iter: 17, training_loss: 6.60705e-01\n",
            "epoch: 580, iter: 17, training_loss: 6.97789e-01\n",
            "epoch: 581, iter: 17, training_loss: 6.68508e-01\n",
            "epoch: 582, iter: 17, training_loss: 6.66127e-01\n",
            "epoch: 583, iter: 17, training_loss: 6.54655e-01\n",
            "epoch: 584, iter: 17, training_loss: 6.11200e-01\n",
            "epoch: 585, iter: 17, training_loss: 6.12288e-01\n",
            "epoch: 586, iter: 17, training_loss: 7.48759e-01\n",
            "epoch: 587, iter: 17, training_loss: 8.37793e-01\n",
            "epoch: 588, iter: 17, training_loss: 6.17000e-01\n",
            "epoch: 589, iter: 17, training_loss: 6.92916e-01\n",
            "epoch: 590, iter: 17, training_loss: 6.87809e-01\n",
            "epoch: 591, iter: 17, training_loss: 6.20439e-01\n",
            "epoch: 592, iter: 17, training_loss: 6.28276e-01\n",
            "epoch: 593, iter: 17, training_loss: 6.49601e-01\n",
            "epoch: 594, iter: 17, training_loss: 6.26915e-01\n",
            "epoch: 595, iter: 17, training_loss: 6.44958e-01\n",
            "epoch: 596, iter: 17, training_loss: 6.83013e-01\n",
            "epoch: 597, iter: 17, training_loss: 6.61924e-01\n",
            "epoch: 598, iter: 17, training_loss: 9.32782e-01\n",
            "epoch: 599, iter: 17, training_loss: 1.00514e+00\n",
            "epoch: 600, iter: 17, training_loss: 9.68982e-01\n",
            "epoch: 601, iter: 17, training_loss: 9.42091e-01\n",
            "epoch: 602, iter: 17, training_loss: 8.48985e-01\n",
            "epoch: 603, iter: 17, training_loss: 8.30516e-01\n",
            "epoch: 604, iter: 17, training_loss: 7.05904e-01\n",
            "epoch: 605, iter: 17, training_loss: 6.43353e-01\n",
            "epoch: 606, iter: 17, training_loss: 6.43848e-01\n",
            "epoch: 607, iter: 17, training_loss: 7.50630e-01\n",
            "epoch: 608, iter: 17, training_loss: 7.20306e-01\n",
            "epoch: 609, iter: 17, training_loss: 6.05901e-01\n",
            "epoch: 610, iter: 17, training_loss: 6.14500e-01\n",
            "epoch: 611, iter: 17, training_loss: 6.56657e-01\n",
            "epoch: 612, iter: 17, training_loss: 6.54609e-01\n",
            "epoch: 613, iter: 17, training_loss: 6.34629e-01\n",
            "epoch: 614, iter: 17, training_loss: 7.23931e-01\n",
            "epoch: 615, iter: 17, training_loss: 6.33401e-01\n",
            "epoch: 616, iter: 17, training_loss: 6.15777e-01\n",
            "epoch: 617, iter: 17, training_loss: 6.70426e-01\n",
            "epoch: 618, iter: 17, training_loss: 6.40839e-01\n",
            "epoch: 619, iter: 17, training_loss: 6.71050e-01\n",
            "epoch: 620, iter: 17, training_loss: 6.80420e-01\n",
            "epoch: 621, iter: 17, training_loss: 6.97143e-01\n",
            "epoch: 622, iter: 17, training_loss: 1.21050e+00\n",
            "epoch: 623, iter: 17, training_loss: 9.06259e-01\n",
            "epoch: 624, iter: 17, training_loss: 7.77283e-01\n",
            "epoch: 625, iter: 17, training_loss: 6.92659e-01\n",
            "epoch: 626, iter: 17, training_loss: 6.32496e-01\n",
            "epoch: 627, iter: 17, training_loss: 5.98873e-01\n",
            "epoch: 628, iter: 17, training_loss: 6.36401e-01\n",
            "epoch: 629, iter: 17, training_loss: 6.33109e-01\n",
            "epoch: 630, iter: 17, training_loss: 7.09531e-01\n",
            "epoch: 631, iter: 17, training_loss: 6.60061e-01\n",
            "epoch: 632, iter: 17, training_loss: 6.43640e-01\n",
            "epoch: 633, iter: 17, training_loss: 6.34146e-01\n",
            "epoch: 634, iter: 17, training_loss: 6.42542e-01\n",
            "epoch: 635, iter: 17, training_loss: 6.70817e-01\n",
            "epoch: 636, iter: 17, training_loss: 6.94392e-01\n",
            "epoch: 637, iter: 17, training_loss: 7.06573e-01\n",
            "epoch: 638, iter: 17, training_loss: 6.89299e-01\n",
            "epoch: 639, iter: 17, training_loss: 6.55389e-01\n",
            "epoch: 640, iter: 17, training_loss: 6.23055e-01\n",
            "epoch: 641, iter: 17, training_loss: 6.04310e-01\n",
            "epoch: 642, iter: 17, training_loss: 6.65575e-01\n",
            "epoch: 643, iter: 17, training_loss: 7.20788e-01\n",
            "epoch: 644, iter: 17, training_loss: 6.81987e-01\n",
            "epoch: 645, iter: 17, training_loss: 6.89046e-01\n",
            "epoch: 646, iter: 17, training_loss: 7.68283e-01\n",
            "epoch: 647, iter: 17, training_loss: 6.40322e-01\n",
            "epoch: 648, iter: 17, training_loss: 6.18918e-01\n",
            "epoch: 649, iter: 17, training_loss: 6.43111e-01\n",
            "epoch: 650, iter: 17, training_loss: 6.64739e-01\n",
            "epoch: 651, iter: 17, training_loss: 6.30160e-01\n",
            "epoch: 652, iter: 17, training_loss: 6.59990e-01\n",
            "epoch: 653, iter: 17, training_loss: 6.41608e-01\n",
            "epoch: 654, iter: 17, training_loss: 6.19183e-01\n",
            "epoch: 655, iter: 17, training_loss: 5.94232e-01\n",
            "epoch: 656, iter: 17, training_loss: 5.83353e-01\n",
            "epoch: 657, iter: 17, training_loss: 6.54841e-01\n",
            "epoch: 658, iter: 17, training_loss: 6.84621e-01\n",
            "epoch: 659, iter: 17, training_loss: 6.44976e-01\n",
            "epoch: 660, iter: 17, training_loss: 6.14110e-01\n",
            "epoch: 661, iter: 17, training_loss: 5.97311e-01\n",
            "epoch: 662, iter: 17, training_loss: 5.87036e-01\n",
            "epoch: 663, iter: 17, training_loss: 7.01223e-01\n",
            "epoch: 664, iter: 17, training_loss: 6.52610e-01\n",
            "epoch: 665, iter: 17, training_loss: 6.32182e-01\n",
            "epoch: 666, iter: 17, training_loss: 6.07309e-01\n",
            "epoch: 667, iter: 17, training_loss: 8.89608e-01\n",
            "epoch: 668, iter: 17, training_loss: 7.74802e-01\n",
            "epoch: 669, iter: 17, training_loss: 6.56874e-01\n",
            "epoch: 670, iter: 17, training_loss: 6.37448e-01\n",
            "epoch: 671, iter: 17, training_loss: 1.01896e+00\n",
            "epoch: 672, iter: 17, training_loss: 6.94924e-01\n",
            "epoch: 673, iter: 17, training_loss: 6.80219e-01\n",
            "epoch: 674, iter: 17, training_loss: 8.79059e-01\n",
            "epoch: 675, iter: 17, training_loss: 6.74853e-01\n",
            "epoch: 676, iter: 17, training_loss: 8.22146e-01\n",
            "epoch: 677, iter: 17, training_loss: 8.69898e-01\n",
            "epoch: 678, iter: 17, training_loss: 8.45545e-01\n",
            "epoch: 679, iter: 17, training_loss: 8.51180e-01\n",
            "epoch: 680, iter: 17, training_loss: 7.61203e-01\n",
            "epoch: 681, iter: 17, training_loss: 7.49108e-01\n",
            "epoch: 682, iter: 17, training_loss: 7.01668e-01\n",
            "epoch: 683, iter: 17, training_loss: 6.18128e-01\n",
            "epoch: 684, iter: 17, training_loss: 6.79637e-01\n",
            "epoch: 685, iter: 17, training_loss: 6.09715e-01\n",
            "epoch: 686, iter: 17, training_loss: 6.56218e-01\n",
            "epoch: 687, iter: 17, training_loss: 6.67600e-01\n",
            "epoch: 688, iter: 17, training_loss: 6.30521e-01\n",
            "epoch: 689, iter: 17, training_loss: 6.28936e-01\n",
            "epoch: 690, iter: 17, training_loss: 6.17144e-01\n",
            "epoch: 691, iter: 17, training_loss: 6.95755e-01\n",
            "epoch: 692, iter: 17, training_loss: 7.82826e-01\n",
            "epoch: 693, iter: 17, training_loss: 6.20422e-01\n",
            "epoch: 694, iter: 17, training_loss: 5.75650e-01\n",
            "epoch: 695, iter: 17, training_loss: 6.71474e-01\n",
            "epoch: 696, iter: 17, training_loss: 6.44843e-01\n",
            "epoch: 697, iter: 17, training_loss: 6.80156e-01\n",
            "epoch: 698, iter: 17, training_loss: 6.41276e-01\n",
            "epoch: 699, iter: 17, training_loss: 6.40270e-01\n",
            "epoch: 700, iter: 17, training_loss: 6.33179e-01\n",
            "epoch: 701, iter: 17, training_loss: 6.13065e-01\n",
            "epoch: 702, iter: 17, training_loss: 5.89499e-01\n",
            "epoch: 703, iter: 17, training_loss: 5.95122e-01\n",
            "epoch: 704, iter: 17, training_loss: 5.80464e-01\n",
            "epoch: 705, iter: 17, training_loss: 5.63865e-01\n",
            "epoch: 706, iter: 17, training_loss: 5.63696e-01\n",
            "epoch: 707, iter: 17, training_loss: 6.41634e-01\n",
            "epoch: 708, iter: 17, training_loss: 6.67580e-01\n",
            "epoch: 709, iter: 17, training_loss: 6.80972e-01\n",
            "epoch: 710, iter: 17, training_loss: 6.85227e-01\n",
            "epoch: 711, iter: 17, training_loss: 6.20531e-01\n",
            "epoch: 712, iter: 17, training_loss: 6.05354e-01\n",
            "epoch: 713, iter: 17, training_loss: 5.87744e-01\n",
            "epoch: 714, iter: 17, training_loss: 6.24068e-01\n",
            "epoch: 715, iter: 17, training_loss: 6.36120e-01\n",
            "epoch: 716, iter: 17, training_loss: 6.46577e-01\n",
            "epoch: 717, iter: 17, training_loss: 6.04740e-01\n",
            "epoch: 718, iter: 17, training_loss: 5.90053e-01\n",
            "epoch: 719, iter: 17, training_loss: 5.87900e-01\n",
            "epoch: 720, iter: 17, training_loss: 6.60419e-01\n",
            "epoch: 721, iter: 17, training_loss: 6.43430e-01\n",
            "epoch: 722, iter: 17, training_loss: 5.97205e-01\n",
            "epoch: 723, iter: 17, training_loss: 6.61103e-01\n",
            "epoch: 724, iter: 17, training_loss: 6.47981e-01\n",
            "epoch: 725, iter: 17, training_loss: 6.58985e-01\n",
            "epoch: 726, iter: 17, training_loss: 5.96439e-01\n",
            "epoch: 727, iter: 17, training_loss: 7.91554e-01\n",
            "epoch: 728, iter: 17, training_loss: 1.17269e+00\n",
            "epoch: 729, iter: 17, training_loss: 1.13203e+00\n",
            "epoch: 730, iter: 17, training_loss: 9.17414e-01\n",
            "epoch: 731, iter: 17, training_loss: 8.83644e-01\n",
            "epoch: 732, iter: 17, training_loss: 7.84023e-01\n",
            "epoch: 733, iter: 17, training_loss: 7.63309e-01\n",
            "epoch: 734, iter: 17, training_loss: 7.32241e-01\n",
            "epoch: 735, iter: 17, training_loss: 7.43795e-01\n",
            "epoch: 736, iter: 17, training_loss: 6.94669e-01\n",
            "epoch: 737, iter: 17, training_loss: 6.63136e-01\n",
            "epoch: 738, iter: 17, training_loss: 6.28200e-01\n",
            "epoch: 739, iter: 17, training_loss: 6.14828e-01\n",
            "epoch: 740, iter: 17, training_loss: 6.28110e-01\n",
            "epoch: 741, iter: 17, training_loss: 6.51051e-01\n",
            "epoch: 742, iter: 17, training_loss: 6.21339e-01\n",
            "epoch: 743, iter: 17, training_loss: 5.86835e-01\n",
            "epoch: 744, iter: 17, training_loss: 6.46230e-01\n",
            "epoch: 745, iter: 17, training_loss: 6.72148e-01\n",
            "epoch: 746, iter: 17, training_loss: 6.87727e-01\n",
            "epoch: 747, iter: 17, training_loss: 6.62157e-01\n",
            "epoch: 748, iter: 17, training_loss: 6.34751e-01\n",
            "epoch: 749, iter: 17, training_loss: 6.68064e-01\n",
            "epoch: 750, iter: 17, training_loss: 6.71506e-01\n",
            "epoch: 751, iter: 17, training_loss: 6.40735e-01\n",
            "epoch: 752, iter: 17, training_loss: 6.58635e-01\n",
            "epoch: 753, iter: 17, training_loss: 7.58322e-01\n",
            "epoch: 754, iter: 17, training_loss: 7.16401e-01\n",
            "epoch: 755, iter: 17, training_loss: 5.92040e-01\n",
            "epoch: 756, iter: 17, training_loss: 5.96091e-01\n",
            "epoch: 757, iter: 17, training_loss: 6.60805e-01\n",
            "epoch: 758, iter: 17, training_loss: 5.97965e-01\n",
            "epoch: 759, iter: 17, training_loss: 6.00295e-01\n",
            "epoch: 760, iter: 17, training_loss: 5.94646e-01\n",
            "epoch: 761, iter: 17, training_loss: 6.12285e-01\n",
            "epoch: 762, iter: 17, training_loss: 7.61391e-01\n",
            "epoch: 763, iter: 17, training_loss: 7.18424e-01\n",
            "epoch: 764, iter: 17, training_loss: 6.48470e-01\n",
            "epoch: 765, iter: 17, training_loss: 6.51045e-01\n",
            "epoch: 766, iter: 17, training_loss: 6.08327e-01\n",
            "epoch: 767, iter: 17, training_loss: 6.06135e-01\n",
            "epoch: 768, iter: 17, training_loss: 6.02403e-01\n",
            "epoch: 769, iter: 17, training_loss: 7.78471e-01\n",
            "epoch: 770, iter: 17, training_loss: 6.11219e-01\n",
            "epoch: 771, iter: 17, training_loss: 6.33425e-01\n",
            "epoch: 772, iter: 17, training_loss: 6.21123e-01\n",
            "epoch: 773, iter: 17, training_loss: 6.25992e-01\n",
            "epoch: 774, iter: 17, training_loss: 6.33544e-01\n",
            "epoch: 775, iter: 17, training_loss: 6.50339e-01\n",
            "epoch: 776, iter: 17, training_loss: 6.54063e-01\n",
            "epoch: 777, iter: 17, training_loss: 6.38535e-01\n",
            "epoch: 778, iter: 17, training_loss: 6.16968e-01\n",
            "epoch: 779, iter: 17, training_loss: 5.86393e-01\n",
            "epoch: 780, iter: 17, training_loss: 7.76293e-01\n",
            "epoch: 781, iter: 17, training_loss: 8.90733e-01\n",
            "epoch: 782, iter: 17, training_loss: 6.03243e-01\n",
            "epoch: 783, iter: 17, training_loss: 6.10748e-01\n",
            "epoch: 784, iter: 17, training_loss: 5.82001e-01\n",
            "epoch: 785, iter: 17, training_loss: 5.76443e-01\n",
            "epoch: 786, iter: 17, training_loss: 5.83907e-01\n",
            "epoch: 787, iter: 17, training_loss: 6.40191e-01\n",
            "epoch: 788, iter: 17, training_loss: 6.10722e-01\n",
            "epoch: 789, iter: 17, training_loss: 6.61709e-01\n",
            "epoch: 790, iter: 17, training_loss: 6.39823e-01\n",
            "epoch: 791, iter: 17, training_loss: 6.16726e-01\n",
            "epoch: 792, iter: 17, training_loss: 5.95486e-01\n",
            "epoch: 793, iter: 17, training_loss: 6.58658e-01\n",
            "epoch: 794, iter: 17, training_loss: 6.22175e-01\n",
            "epoch: 795, iter: 17, training_loss: 6.07431e-01\n",
            "epoch: 796, iter: 17, training_loss: 5.83348e-01\n",
            "epoch: 797, iter: 17, training_loss: 6.22410e-01\n",
            "epoch: 798, iter: 17, training_loss: 6.37782e-01\n",
            "epoch: 799, iter: 17, training_loss: 6.31691e-01\n",
            "epoch: 800, iter: 17, training_loss: 5.99042e-01\n",
            "epoch: 801, iter: 17, training_loss: 5.94448e-01\n",
            "epoch: 802, iter: 17, training_loss: 5.73031e-01\n",
            "epoch: 803, iter: 17, training_loss: 5.74589e-01\n",
            "epoch: 804, iter: 17, training_loss: 6.72597e-01\n",
            "epoch: 805, iter: 17, training_loss: 5.93785e-01\n",
            "epoch: 806, iter: 17, training_loss: 5.91168e-01\n",
            "epoch: 807, iter: 17, training_loss: 6.41296e-01\n",
            "epoch: 808, iter: 17, training_loss: 6.01930e-01\n",
            "epoch: 809, iter: 17, training_loss: 6.23849e-01\n",
            "epoch: 810, iter: 17, training_loss: 6.15417e-01\n",
            "epoch: 811, iter: 17, training_loss: 5.85973e-01\n",
            "epoch: 812, iter: 17, training_loss: 5.79351e-01\n",
            "epoch: 813, iter: 17, training_loss: 5.76811e-01\n",
            "epoch: 814, iter: 17, training_loss: 5.73615e-01\n",
            "epoch: 815, iter: 17, training_loss: 6.22624e-01\n",
            "epoch: 816, iter: 17, training_loss: 6.83820e-01\n",
            "epoch: 817, iter: 17, training_loss: 6.05593e-01\n",
            "epoch: 818, iter: 17, training_loss: 6.91112e-01\n",
            "epoch: 819, iter: 17, training_loss: 9.60786e-01\n",
            "epoch: 820, iter: 17, training_loss: 1.13981e+00\n",
            "epoch: 821, iter: 17, training_loss: 8.00015e-01\n",
            "epoch: 822, iter: 17, training_loss: 7.77394e-01\n",
            "epoch: 823, iter: 17, training_loss: 7.16745e-01\n",
            "epoch: 824, iter: 17, training_loss: 6.47600e-01\n",
            "epoch: 825, iter: 17, training_loss: 6.19351e-01\n",
            "epoch: 826, iter: 17, training_loss: 6.04173e-01\n",
            "epoch: 827, iter: 17, training_loss: 6.21591e-01\n",
            "epoch: 828, iter: 17, training_loss: 6.11981e-01\n",
            "epoch: 829, iter: 17, training_loss: 5.81338e-01\n",
            "epoch: 830, iter: 17, training_loss: 5.68950e-01\n",
            "epoch: 831, iter: 17, training_loss: 6.00773e-01\n",
            "epoch: 832, iter: 17, training_loss: 5.85955e-01\n",
            "epoch: 833, iter: 17, training_loss: 6.08822e-01\n",
            "epoch: 834, iter: 17, training_loss: 6.32982e-01\n",
            "epoch: 835, iter: 17, training_loss: 6.38845e-01\n",
            "epoch: 836, iter: 17, training_loss: 6.06473e-01\n",
            "epoch: 837, iter: 17, training_loss: 6.05461e-01\n",
            "epoch: 838, iter: 17, training_loss: 5.78650e-01\n",
            "epoch: 839, iter: 17, training_loss: 6.48043e-01\n",
            "epoch: 840, iter: 17, training_loss: 6.15024e-01\n",
            "epoch: 841, iter: 17, training_loss: 6.16949e-01\n",
            "epoch: 842, iter: 17, training_loss: 6.01684e-01\n",
            "epoch: 843, iter: 17, training_loss: 5.78142e-01\n",
            "epoch: 844, iter: 17, training_loss: 5.97466e-01\n",
            "epoch: 845, iter: 17, training_loss: 6.24287e-01\n",
            "epoch: 846, iter: 17, training_loss: 6.09856e-01\n",
            "epoch: 847, iter: 17, training_loss: 5.92602e-01\n",
            "epoch: 848, iter: 17, training_loss: 6.01760e-01\n",
            "epoch: 849, iter: 17, training_loss: 6.09188e-01\n",
            "epoch: 850, iter: 17, training_loss: 5.97854e-01\n",
            "epoch: 851, iter: 17, training_loss: 5.82394e-01\n",
            "epoch: 852, iter: 17, training_loss: 6.15559e-01\n",
            "epoch: 853, iter: 17, training_loss: 6.61911e-01\n",
            "epoch: 854, iter: 17, training_loss: 5.94697e-01\n",
            "epoch: 855, iter: 17, training_loss: 5.89936e-01\n",
            "epoch: 856, iter: 17, training_loss: 5.95023e-01\n",
            "epoch: 857, iter: 17, training_loss: 6.01175e-01\n",
            "epoch: 858, iter: 17, training_loss: 6.45733e-01\n",
            "epoch: 859, iter: 17, training_loss: 9.11327e-01\n",
            "epoch: 860, iter: 17, training_loss: 7.50643e-01\n",
            "epoch: 861, iter: 17, training_loss: 6.63186e-01\n",
            "epoch: 862, iter: 17, training_loss: 6.02892e-01\n",
            "epoch: 863, iter: 17, training_loss: 6.10605e-01\n",
            "epoch: 864, iter: 17, training_loss: 6.04095e-01\n",
            "epoch: 865, iter: 17, training_loss: 5.80105e-01\n",
            "epoch: 866, iter: 17, training_loss: 5.72608e-01\n",
            "epoch: 867, iter: 17, training_loss: 7.59021e-01\n",
            "epoch: 868, iter: 17, training_loss: 6.68698e-01\n",
            "epoch: 869, iter: 17, training_loss: 7.18240e-01\n",
            "epoch: 870, iter: 17, training_loss: 8.10976e-01\n",
            "epoch: 871, iter: 17, training_loss: 7.91386e-01\n",
            "epoch: 872, iter: 17, training_loss: 7.32763e-01\n",
            "epoch: 873, iter: 17, training_loss: 6.27528e-01\n",
            "epoch: 874, iter: 17, training_loss: 5.55814e-01\n",
            "epoch: 875, iter: 17, training_loss: 6.00727e-01\n",
            "epoch: 876, iter: 17, training_loss: 6.11330e-01\n",
            "epoch: 877, iter: 17, training_loss: 5.69140e-01\n",
            "epoch: 878, iter: 17, training_loss: 5.83865e-01\n",
            "epoch: 879, iter: 17, training_loss: 5.59376e-01\n",
            "epoch: 880, iter: 17, training_loss: 5.72178e-01\n",
            "epoch: 881, iter: 17, training_loss: 5.97995e-01\n",
            "epoch: 882, iter: 17, training_loss: 6.42780e-01\n",
            "epoch: 883, iter: 17, training_loss: 6.16856e-01\n",
            "epoch: 884, iter: 17, training_loss: 5.91187e-01\n",
            "epoch: 885, iter: 17, training_loss: 7.99856e-01\n",
            "epoch: 886, iter: 17, training_loss: 6.10414e-01\n",
            "epoch: 887, iter: 17, training_loss: 7.79754e-01\n",
            "epoch: 888, iter: 17, training_loss: 5.93904e-01\n",
            "epoch: 889, iter: 17, training_loss: 5.87962e-01\n",
            "epoch: 890, iter: 17, training_loss: 6.05038e-01\n",
            "epoch: 891, iter: 17, training_loss: 6.11434e-01\n",
            "epoch: 892, iter: 17, training_loss: 5.91473e-01\n",
            "epoch: 893, iter: 17, training_loss: 6.26667e-01\n",
            "epoch: 894, iter: 17, training_loss: 5.96222e-01\n",
            "epoch: 895, iter: 17, training_loss: 7.47171e-01\n",
            "epoch: 896, iter: 17, training_loss: 6.18478e-01\n",
            "epoch: 897, iter: 17, training_loss: 6.29260e-01\n",
            "epoch: 898, iter: 17, training_loss: 6.09610e-01\n",
            "epoch: 899, iter: 17, training_loss: 6.23991e-01\n",
            "epoch: 900, iter: 17, training_loss: 6.24098e-01\n",
            "epoch: 901, iter: 17, training_loss: 6.02716e-01\n",
            "epoch: 902, iter: 17, training_loss: 5.84255e-01\n",
            "epoch: 903, iter: 17, training_loss: 5.76109e-01\n",
            "epoch: 904, iter: 17, training_loss: 5.67936e-01\n",
            "epoch: 905, iter: 17, training_loss: 5.59728e-01\n",
            "epoch: 906, iter: 17, training_loss: 5.96599e-01\n",
            "epoch: 907, iter: 17, training_loss: 5.43383e-01\n",
            "epoch: 908, iter: 17, training_loss: 6.70071e-01\n",
            "epoch: 909, iter: 17, training_loss: 6.70235e-01\n",
            "epoch: 910, iter: 17, training_loss: 5.58434e-01\n",
            "epoch: 911, iter: 17, training_loss: 6.12689e-01\n",
            "epoch: 912, iter: 17, training_loss: 6.02675e-01\n",
            "epoch: 913, iter: 17, training_loss: 5.90561e-01\n",
            "epoch: 914, iter: 17, training_loss: 5.88390e-01\n",
            "epoch: 915, iter: 17, training_loss: 5.98229e-01\n",
            "epoch: 916, iter: 17, training_loss: 5.93469e-01\n",
            "epoch: 917, iter: 17, training_loss: 8.56046e-01\n",
            "epoch: 918, iter: 17, training_loss: 6.24505e-01\n",
            "epoch: 919, iter: 17, training_loss: 5.96455e-01\n",
            "epoch: 920, iter: 17, training_loss: 5.84597e-01\n",
            "epoch: 921, iter: 17, training_loss: 5.95617e-01\n",
            "epoch: 922, iter: 17, training_loss: 5.62108e-01\n",
            "epoch: 923, iter: 17, training_loss: 6.04349e-01\n",
            "epoch: 924, iter: 17, training_loss: 5.71005e-01\n",
            "epoch: 925, iter: 17, training_loss: 5.78160e-01\n",
            "epoch: 926, iter: 17, training_loss: 6.01988e-01\n",
            "epoch: 927, iter: 17, training_loss: 7.07417e-01\n",
            "epoch: 928, iter: 17, training_loss: 7.17954e-01\n",
            "epoch: 929, iter: 17, training_loss: 6.64522e-01\n",
            "epoch: 930, iter: 17, training_loss: 6.44748e-01\n",
            "epoch: 931, iter: 17, training_loss: 6.39709e-01\n",
            "epoch: 932, iter: 17, training_loss: 6.47983e-01\n",
            "epoch: 933, iter: 17, training_loss: 6.25177e-01\n",
            "epoch: 934, iter: 17, training_loss: 6.31351e-01\n",
            "epoch: 935, iter: 17, training_loss: 6.29026e-01\n",
            "epoch: 936, iter: 17, training_loss: 6.11752e-01\n",
            "epoch: 937, iter: 17, training_loss: 6.13048e-01\n",
            "epoch: 938, iter: 17, training_loss: 6.01552e-01\n",
            "epoch: 939, iter: 17, training_loss: 5.80520e-01\n",
            "epoch: 940, iter: 17, training_loss: 5.70832e-01\n",
            "epoch: 941, iter: 17, training_loss: 6.10514e-01\n",
            "epoch: 942, iter: 17, training_loss: 7.67122e-01\n",
            "epoch: 943, iter: 17, training_loss: 9.43886e-01\n",
            "epoch: 944, iter: 17, training_loss: 7.32690e-01\n",
            "epoch: 945, iter: 17, training_loss: 6.67706e-01\n",
            "epoch: 946, iter: 17, training_loss: 6.32501e-01\n",
            "epoch: 947, iter: 17, training_loss: 5.85874e-01\n",
            "epoch: 948, iter: 17, training_loss: 5.75154e-01\n",
            "epoch: 949, iter: 17, training_loss: 5.76114e-01\n",
            "epoch: 950, iter: 17, training_loss: 6.03526e-01\n",
            "epoch: 951, iter: 17, training_loss: 6.09786e-01\n",
            "epoch: 952, iter: 17, training_loss: 7.86990e-01\n",
            "epoch: 953, iter: 17, training_loss: 6.13121e-01\n",
            "epoch: 954, iter: 17, training_loss: 5.93043e-01\n",
            "epoch: 955, iter: 17, training_loss: 5.86267e-01\n",
            "epoch: 956, iter: 17, training_loss: 5.84580e-01\n",
            "epoch: 957, iter: 17, training_loss: 5.77587e-01\n",
            "epoch: 958, iter: 17, training_loss: 5.62433e-01\n",
            "epoch: 959, iter: 17, training_loss: 5.65201e-01\n",
            "epoch: 960, iter: 17, training_loss: 5.85524e-01\n",
            "epoch: 961, iter: 17, training_loss: 5.76642e-01\n",
            "epoch: 962, iter: 17, training_loss: 6.34561e-01\n",
            "epoch: 963, iter: 17, training_loss: 5.95126e-01\n",
            "epoch: 964, iter: 17, training_loss: 5.90834e-01\n",
            "epoch: 965, iter: 17, training_loss: 5.67425e-01\n",
            "epoch: 966, iter: 17, training_loss: 6.08098e-01\n",
            "epoch: 967, iter: 17, training_loss: 5.78447e-01\n",
            "epoch: 968, iter: 17, training_loss: 5.71428e-01\n",
            "epoch: 969, iter: 17, training_loss: 7.49471e-01\n",
            "epoch: 970, iter: 17, training_loss: 6.11219e-01\n",
            "epoch: 971, iter: 17, training_loss: 5.65754e-01\n",
            "epoch: 972, iter: 17, training_loss: 5.55406e-01\n",
            "epoch: 973, iter: 17, training_loss: 5.51395e-01\n",
            "epoch: 974, iter: 17, training_loss: 5.44697e-01\n",
            "epoch: 975, iter: 17, training_loss: 5.81726e-01\n",
            "epoch: 976, iter: 17, training_loss: 6.10597e-01\n",
            "epoch: 977, iter: 17, training_loss: 6.23585e-01\n",
            "epoch: 978, iter: 17, training_loss: 5.73415e-01\n",
            "epoch: 979, iter: 17, training_loss: 5.94546e-01\n",
            "epoch: 980, iter: 17, training_loss: 5.88674e-01\n",
            "epoch: 981, iter: 17, training_loss: 5.76497e-01\n",
            "epoch: 982, iter: 17, training_loss: 5.99621e-01\n",
            "epoch: 983, iter: 17, training_loss: 5.96801e-01\n",
            "epoch: 984, iter: 17, training_loss: 5.93374e-01\n",
            "epoch: 985, iter: 17, training_loss: 5.58931e-01\n",
            "epoch: 986, iter: 17, training_loss: 5.39149e-01\n",
            "epoch: 987, iter: 17, training_loss: 5.49439e-01\n",
            "epoch: 988, iter: 17, training_loss: 6.20337e-01\n",
            "epoch: 989, iter: 17, training_loss: 6.05217e-01\n",
            "epoch: 990, iter: 17, training_loss: 6.41791e-01\n",
            "epoch: 991, iter: 17, training_loss: 6.92805e-01\n",
            "epoch: 992, iter: 17, training_loss: 5.88999e-01\n",
            "epoch: 993, iter: 17, training_loss: 6.06153e-01\n",
            "epoch: 994, iter: 17, training_loss: 5.90305e-01\n",
            "epoch: 995, iter: 17, training_loss: 7.35694e-01\n",
            "epoch: 996, iter: 17, training_loss: 6.06393e-01\n",
            "epoch: 997, iter: 17, training_loss: 5.89036e-01\n",
            "epoch: 998, iter: 17, training_loss: 5.67677e-01\n",
            "epoch: 999, iter: 17, training_loss: 6.58989e-01\n",
            "epoch: 1000, iter: 17, training_loss: 6.18346e-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname magic --method stasy --mode sample --save_path magic_syn.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llBUvqtguDir",
        "outputId": "6cf27c9e-48ed-4336-e51c-b96b6793f434"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No NaNs in numerical features, skipping\n",
            "Input dimension: 12\n",
            "NCSNpp(\n",
            "  (act): ELU(alpha=1.0)\n",
            "  (all_modules): ModuleList(\n",
            "    (0): GaussianFourierProjection()\n",
            "    (1): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (3): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=12, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (4): ELU(alpha=1.0)\n",
            "    (5): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=1036, out_features=2048, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=2048, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=2048, bias=True)\n",
            "    )\n",
            "    (6): ELU(alpha=1.0)\n",
            "    (7): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=3084, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (8): ELU(alpha=1.0)\n",
            "    (9): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=4108, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (10): ELU(alpha=1.0)\n",
            "    (11): Linear(in_features=5132, out_features=12, bias=True)\n",
            "  )\n",
            ")\n",
            "the number of parameters 9679580\n",
            "Loading SAVED model at from /content/tabsyn/baselines/stasy/ckpt/magic/model.pth\n",
            "Start sampling...\n",
            "(17117, 1)\n",
            "Sampling time = 14.712437868118286\n",
            "Saving sampled data to magic_syn.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname default --method stasy --mode train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ay5QX31CDrI3",
        "outputId": "fc243487-d0a4-4bce-82d7-163b32a5c73e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No NaNs in numerical features, skipping\n",
            "93\n",
            "NCSNpp(\n",
            "  (act): ELU(alpha=1.0)\n",
            "  (all_modules): ModuleList(\n",
            "    (0): GaussianFourierProjection()\n",
            "    (1): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (3): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=93, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (4): ELU(alpha=1.0)\n",
            "    (5): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=1117, out_features=2048, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=2048, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=2048, bias=True)\n",
            "    )\n",
            "    (6): ELU(alpha=1.0)\n",
            "    (7): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=3165, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (8): ELU(alpha=1.0)\n",
            "    (9): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=4189, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (10): ELU(alpha=1.0)\n",
            "    (11): Linear(in_features=5213, out_features=93, bias=True)\n",
            "  )\n",
            ")\n",
            "the number of parameters 10517606\n",
            "epoch: 0, iter: 26, training_loss: 2.52606e+00\n",
            "epoch: 1, iter: 26, training_loss: 1.32406e+00\n",
            "epoch: 2, iter: 26, training_loss: 1.26913e+00\n",
            "epoch: 3, iter: 26, training_loss: 1.29834e+00\n",
            "epoch: 4, iter: 26, training_loss: 1.31338e+00\n",
            "epoch: 5, iter: 26, training_loss: 1.27468e+00\n",
            "epoch: 6, iter: 26, training_loss: 1.27379e+00\n",
            "epoch: 7, iter: 26, training_loss: 1.19454e+00\n",
            "epoch: 8, iter: 26, training_loss: 1.24568e+00\n",
            "epoch: 9, iter: 26, training_loss: 1.15910e+00\n",
            "epoch: 10, iter: 26, training_loss: 1.17010e+00\n",
            "epoch: 11, iter: 26, training_loss: 1.10463e+00\n",
            "epoch: 12, iter: 26, training_loss: 1.08888e+00\n",
            "epoch: 13, iter: 26, training_loss: 1.11604e+00\n",
            "epoch: 14, iter: 26, training_loss: 1.05954e+00\n",
            "epoch: 15, iter: 26, training_loss: 1.09152e+00\n",
            "epoch: 16, iter: 26, training_loss: 1.02861e+00\n",
            "epoch: 17, iter: 26, training_loss: 1.07497e+00\n",
            "epoch: 18, iter: 26, training_loss: 1.06139e+00\n",
            "epoch: 19, iter: 26, training_loss: 1.10746e+00\n",
            "epoch: 20, iter: 26, training_loss: 1.12905e+00\n",
            "epoch: 21, iter: 26, training_loss: 1.09677e+00\n",
            "epoch: 22, iter: 26, training_loss: 1.04139e+00\n",
            "epoch: 23, iter: 26, training_loss: 1.08169e+00\n",
            "epoch: 24, iter: 26, training_loss: 1.06147e+00\n",
            "epoch: 25, iter: 26, training_loss: 1.07182e+00\n",
            "epoch: 26, iter: 26, training_loss: 1.13838e+00\n",
            "epoch: 27, iter: 26, training_loss: 1.10362e+00\n",
            "epoch: 28, iter: 26, training_loss: 1.04740e+00\n",
            "epoch: 29, iter: 26, training_loss: 1.05448e+00\n",
            "epoch: 30, iter: 26, training_loss: 1.04321e+00\n",
            "epoch: 31, iter: 26, training_loss: 1.07399e+00\n",
            "epoch: 32, iter: 26, training_loss: 1.13447e+00\n",
            "epoch: 33, iter: 26, training_loss: 1.10814e+00\n",
            "epoch: 34, iter: 26, training_loss: 1.15363e+00\n",
            "epoch: 35, iter: 26, training_loss: 1.16220e+00\n",
            "epoch: 36, iter: 26, training_loss: 1.18205e+00\n",
            "epoch: 37, iter: 26, training_loss: 1.28691e+00\n",
            "epoch: 38, iter: 26, training_loss: 1.17423e+00\n",
            "epoch: 39, iter: 26, training_loss: 1.26707e+00\n",
            "epoch: 40, iter: 26, training_loss: 1.20556e+00\n",
            "epoch: 41, iter: 26, training_loss: 1.22152e+00\n",
            "epoch: 42, iter: 26, training_loss: 1.25798e+00\n",
            "epoch: 43, iter: 26, training_loss: 1.24126e+00\n",
            "epoch: 44, iter: 26, training_loss: 1.26211e+00\n",
            "epoch: 45, iter: 26, training_loss: 1.41857e+00\n",
            "epoch: 46, iter: 26, training_loss: 1.43970e+00\n",
            "epoch: 47, iter: 26, training_loss: 1.43798e+00\n",
            "epoch: 48, iter: 26, training_loss: 1.54808e+00\n",
            "epoch: 49, iter: 26, training_loss: 1.34574e+00\n",
            "epoch: 50, iter: 26, training_loss: 1.60504e+00\n",
            "epoch: 51, iter: 26, training_loss: 1.37477e+00\n",
            "epoch: 52, iter: 26, training_loss: 1.45203e+00\n",
            "epoch: 53, iter: 26, training_loss: 1.62804e+00\n",
            "epoch: 54, iter: 26, training_loss: 1.49549e+00\n",
            "epoch: 55, iter: 26, training_loss: 1.44702e+00\n",
            "epoch: 56, iter: 26, training_loss: 1.45616e+00\n",
            "epoch: 57, iter: 26, training_loss: 1.64378e+00\n",
            "epoch: 58, iter: 26, training_loss: 1.53083e+00\n",
            "epoch: 59, iter: 26, training_loss: 1.52164e+00\n",
            "epoch: 60, iter: 26, training_loss: 1.53960e+00\n",
            "epoch: 61, iter: 26, training_loss: 1.70342e+00\n",
            "epoch: 62, iter: 26, training_loss: 1.59483e+00\n",
            "epoch: 63, iter: 26, training_loss: 1.73244e+00\n",
            "epoch: 64, iter: 26, training_loss: 1.67402e+00\n",
            "epoch: 65, iter: 26, training_loss: 1.53095e+00\n",
            "epoch: 66, iter: 26, training_loss: 1.62347e+00\n",
            "epoch: 67, iter: 26, training_loss: 1.54702e+00\n",
            "epoch: 68, iter: 26, training_loss: 1.66908e+00\n",
            "epoch: 69, iter: 26, training_loss: 1.60149e+00\n",
            "epoch: 70, iter: 26, training_loss: 1.83917e+00\n",
            "epoch: 71, iter: 26, training_loss: 1.74166e+00\n",
            "epoch: 72, iter: 26, training_loss: 1.59693e+00\n",
            "epoch: 73, iter: 26, training_loss: 1.64322e+00\n",
            "epoch: 74, iter: 26, training_loss: 1.85066e+00\n",
            "epoch: 75, iter: 26, training_loss: 1.80902e+00\n",
            "epoch: 76, iter: 26, training_loss: 1.65891e+00\n",
            "epoch: 77, iter: 26, training_loss: 1.75720e+00\n",
            "epoch: 78, iter: 26, training_loss: 1.84632e+00\n",
            "epoch: 79, iter: 26, training_loss: 1.90300e+00\n",
            "epoch: 80, iter: 26, training_loss: 1.81073e+00\n",
            "epoch: 81, iter: 26, training_loss: 1.73236e+00\n",
            "epoch: 82, iter: 26, training_loss: 2.01106e+00\n",
            "epoch: 83, iter: 26, training_loss: 1.73113e+00\n",
            "epoch: 84, iter: 26, training_loss: 1.91817e+00\n",
            "epoch: 85, iter: 26, training_loss: 1.87049e+00\n",
            "epoch: 86, iter: 26, training_loss: 1.94552e+00\n",
            "epoch: 87, iter: 26, training_loss: 1.82480e+00\n",
            "epoch: 88, iter: 26, training_loss: 1.73348e+00\n",
            "epoch: 89, iter: 26, training_loss: 1.76170e+00\n",
            "epoch: 90, iter: 26, training_loss: 1.84599e+00\n",
            "epoch: 91, iter: 26, training_loss: 1.78669e+00\n",
            "epoch: 92, iter: 26, training_loss: 1.86088e+00\n",
            "epoch: 93, iter: 26, training_loss: 2.03637e+00\n",
            "epoch: 94, iter: 26, training_loss: 1.96672e+00\n",
            "epoch: 95, iter: 26, training_loss: 2.12031e+00\n",
            "epoch: 96, iter: 26, training_loss: 1.86668e+00\n",
            "epoch: 97, iter: 26, training_loss: 2.14467e+00\n",
            "epoch: 98, iter: 26, training_loss: 1.94336e+00\n",
            "epoch: 99, iter: 26, training_loss: 2.05462e+00\n",
            "epoch: 100, iter: 26, training_loss: 1.96526e+00\n",
            "epoch: 101, iter: 26, training_loss: 2.17097e+00\n",
            "epoch: 102, iter: 26, training_loss: 1.99733e+00\n",
            "epoch: 103, iter: 26, training_loss: 2.68055e+00\n",
            "epoch: 104, iter: 26, training_loss: 2.01925e+00\n",
            "epoch: 105, iter: 26, training_loss: 2.26109e+00\n",
            "epoch: 106, iter: 26, training_loss: 2.53792e+00\n",
            "epoch: 107, iter: 26, training_loss: 2.46794e+00\n",
            "epoch: 108, iter: 26, training_loss: 2.32929e+00\n",
            "epoch: 109, iter: 26, training_loss: 2.27867e+00\n",
            "epoch: 110, iter: 26, training_loss: 2.42606e+00\n",
            "epoch: 111, iter: 26, training_loss: 2.52590e+00\n",
            "epoch: 112, iter: 26, training_loss: 2.38202e+00\n",
            "epoch: 113, iter: 26, training_loss: 2.47915e+00\n",
            "epoch: 114, iter: 26, training_loss: 2.73155e+00\n",
            "epoch: 115, iter: 26, training_loss: 2.63483e+00\n",
            "epoch: 116, iter: 26, training_loss: 2.64443e+00\n",
            "epoch: 117, iter: 26, training_loss: 2.48086e+00\n",
            "epoch: 118, iter: 26, training_loss: 2.79368e+00\n",
            "epoch: 119, iter: 26, training_loss: 2.80267e+00\n",
            "epoch: 120, iter: 26, training_loss: 2.56919e+00\n",
            "epoch: 121, iter: 26, training_loss: 3.02774e+00\n",
            "epoch: 122, iter: 26, training_loss: 3.20084e+00\n",
            "epoch: 123, iter: 26, training_loss: 2.93651e+00\n",
            "epoch: 124, iter: 26, training_loss: 3.04433e+00\n",
            "epoch: 125, iter: 26, training_loss: 3.07003e+00\n",
            "epoch: 126, iter: 26, training_loss: 3.03389e+00\n",
            "epoch: 127, iter: 26, training_loss: 3.14829e+00\n",
            "epoch: 128, iter: 26, training_loss: 3.11974e+00\n",
            "epoch: 129, iter: 26, training_loss: 3.31132e+00\n",
            "epoch: 130, iter: 26, training_loss: 2.92032e+00\n",
            "epoch: 131, iter: 26, training_loss: 3.30171e+00\n",
            "epoch: 132, iter: 26, training_loss: 3.44842e+00\n",
            "epoch: 133, iter: 26, training_loss: 3.60673e+00\n",
            "epoch: 134, iter: 26, training_loss: 2.91781e+00\n",
            "epoch: 135, iter: 26, training_loss: 3.65587e+00\n",
            "epoch: 136, iter: 26, training_loss: 2.94829e+00\n",
            "epoch: 137, iter: 26, training_loss: 2.72907e+00\n",
            "epoch: 138, iter: 26, training_loss: 3.76053e+00\n",
            "epoch: 139, iter: 26, training_loss: 3.46715e+00\n",
            "epoch: 140, iter: 26, training_loss: 3.76040e+00\n",
            "epoch: 141, iter: 26, training_loss: 3.53520e+00\n",
            "epoch: 142, iter: 26, training_loss: 3.54253e+00\n",
            "epoch: 143, iter: 26, training_loss: 3.30667e+00\n",
            "epoch: 144, iter: 26, training_loss: 3.58962e+00\n",
            "epoch: 145, iter: 26, training_loss: 3.45304e+00\n",
            "epoch: 146, iter: 26, training_loss: 3.15803e+00\n",
            "epoch: 147, iter: 26, training_loss: 3.05527e+00\n",
            "epoch: 148, iter: 26, training_loss: 3.57678e+00\n",
            "epoch: 149, iter: 26, training_loss: 3.22943e+00\n",
            "epoch: 150, iter: 26, training_loss: 3.11412e+00\n",
            "epoch: 151, iter: 26, training_loss: 2.85264e+00\n",
            "epoch: 152, iter: 26, training_loss: 3.32645e+00\n",
            "epoch: 153, iter: 26, training_loss: 3.70667e+00\n",
            "epoch: 154, iter: 26, training_loss: 3.09421e+00\n",
            "epoch: 155, iter: 26, training_loss: 3.40979e+00\n",
            "epoch: 156, iter: 26, training_loss: 3.65596e+00\n",
            "epoch: 157, iter: 26, training_loss: 3.13052e+00\n",
            "epoch: 158, iter: 26, training_loss: 3.35456e+00\n",
            "epoch: 159, iter: 26, training_loss: 3.38675e+00\n",
            "epoch: 160, iter: 26, training_loss: 3.33015e+00\n",
            "epoch: 161, iter: 26, training_loss: 3.38570e+00\n",
            "epoch: 162, iter: 26, training_loss: 2.97959e+00\n",
            "epoch: 163, iter: 26, training_loss: 3.03720e+00\n",
            "epoch: 164, iter: 26, training_loss: 3.07191e+00\n",
            "epoch: 165, iter: 26, training_loss: 3.16595e+00\n",
            "epoch: 166, iter: 26, training_loss: 3.42138e+00\n",
            "epoch: 167, iter: 26, training_loss: 3.29859e+00\n",
            "epoch: 168, iter: 26, training_loss: 3.91547e+00\n",
            "epoch: 169, iter: 26, training_loss: 3.05033e+00\n",
            "epoch: 170, iter: 26, training_loss: 3.06384e+00\n",
            "epoch: 171, iter: 26, training_loss: 3.13594e+00\n",
            "epoch: 172, iter: 26, training_loss: 3.20904e+00\n",
            "epoch: 173, iter: 26, training_loss: 3.37474e+00\n",
            "epoch: 174, iter: 26, training_loss: 3.18010e+00\n",
            "epoch: 175, iter: 26, training_loss: 3.29033e+00\n",
            "epoch: 176, iter: 26, training_loss: 3.17109e+00\n",
            "epoch: 177, iter: 26, training_loss: 3.76261e+00\n",
            "epoch: 178, iter: 26, training_loss: 2.76069e+00\n",
            "epoch: 179, iter: 26, training_loss: 3.13275e+00\n",
            "epoch: 180, iter: 26, training_loss: 2.92684e+00\n",
            "epoch: 181, iter: 26, training_loss: 2.93541e+00\n",
            "epoch: 182, iter: 26, training_loss: 3.90644e+00\n",
            "epoch: 183, iter: 26, training_loss: 3.46937e+00\n",
            "epoch: 184, iter: 26, training_loss: 3.10361e+00\n",
            "epoch: 185, iter: 26, training_loss: 3.03718e+00\n",
            "epoch: 186, iter: 26, training_loss: 3.05318e+00\n",
            "epoch: 187, iter: 26, training_loss: 3.02481e+00\n",
            "epoch: 188, iter: 26, training_loss: 3.43402e+00\n",
            "epoch: 189, iter: 26, training_loss: 2.92540e+00\n",
            "epoch: 190, iter: 26, training_loss: 3.18883e+00\n",
            "epoch: 191, iter: 26, training_loss: 2.79050e+00\n",
            "epoch: 192, iter: 26, training_loss: 2.95862e+00\n",
            "epoch: 193, iter: 26, training_loss: 2.98326e+00\n",
            "epoch: 194, iter: 26, training_loss: 2.77843e+00\n",
            "epoch: 195, iter: 26, training_loss: 2.48728e+00\n",
            "epoch: 196, iter: 26, training_loss: 2.57297e+00\n",
            "epoch: 197, iter: 26, training_loss: 2.74023e+00\n",
            "epoch: 198, iter: 26, training_loss: 2.45798e+00\n",
            "epoch: 199, iter: 26, training_loss: 3.42238e+00\n",
            "epoch: 200, iter: 26, training_loss: 2.75792e+00\n",
            "epoch: 201, iter: 26, training_loss: 2.93819e+00\n",
            "epoch: 202, iter: 26, training_loss: 2.39723e+00\n",
            "epoch: 203, iter: 26, training_loss: 2.60118e+00\n",
            "epoch: 204, iter: 26, training_loss: 2.47010e+00\n",
            "epoch: 205, iter: 26, training_loss: 2.49791e+00\n",
            "epoch: 206, iter: 26, training_loss: 1.89778e+00\n",
            "epoch: 207, iter: 26, training_loss: 1.92120e+00\n",
            "epoch: 208, iter: 26, training_loss: 2.33507e+00\n",
            "epoch: 209, iter: 26, training_loss: 1.80176e+00\n",
            "epoch: 210, iter: 26, training_loss: 1.96318e+00\n",
            "epoch: 211, iter: 26, training_loss: 1.87366e+00\n",
            "epoch: 212, iter: 26, training_loss: 2.16431e+00\n",
            "epoch: 213, iter: 26, training_loss: 1.49831e+00\n",
            "epoch: 214, iter: 26, training_loss: 1.47529e+00\n",
            "epoch: 215, iter: 26, training_loss: 1.86774e+00\n",
            "epoch: 216, iter: 26, training_loss: 1.96737e+00\n",
            "epoch: 217, iter: 26, training_loss: 1.40894e+00\n",
            "epoch: 218, iter: 26, training_loss: 1.23294e+00\n",
            "epoch: 219, iter: 26, training_loss: 1.29842e+00\n",
            "epoch: 220, iter: 26, training_loss: 1.15207e+00\n",
            "epoch: 221, iter: 26, training_loss: 1.14716e+00\n",
            "epoch: 222, iter: 26, training_loss: 1.00785e+00\n",
            "epoch: 223, iter: 26, training_loss: 1.11598e+00\n",
            "epoch: 224, iter: 26, training_loss: 1.23013e+00\n",
            "epoch: 225, iter: 26, training_loss: 1.25963e+00\n",
            "epoch: 226, iter: 26, training_loss: 8.69503e-01\n",
            "epoch: 227, iter: 26, training_loss: 9.41433e-01\n",
            "epoch: 228, iter: 26, training_loss: 8.34531e-01\n",
            "epoch: 229, iter: 26, training_loss: 8.85211e-01\n",
            "epoch: 230, iter: 26, training_loss: 1.18226e+00\n",
            "epoch: 231, iter: 26, training_loss: 9.26039e-01\n",
            "epoch: 232, iter: 26, training_loss: 1.14379e+00\n",
            "epoch: 233, iter: 26, training_loss: 1.01556e+00\n",
            "epoch: 234, iter: 26, training_loss: 9.56986e-01\n",
            "epoch: 235, iter: 26, training_loss: 8.61988e-01\n",
            "epoch: 236, iter: 26, training_loss: 8.25668e-01\n",
            "epoch: 237, iter: 26, training_loss: 8.90894e-01\n",
            "epoch: 238, iter: 26, training_loss: 8.46051e-01\n",
            "epoch: 239, iter: 26, training_loss: 8.45654e-01\n",
            "epoch: 240, iter: 26, training_loss: 8.06778e-01\n",
            "epoch: 241, iter: 26, training_loss: 7.51847e-01\n",
            "epoch: 242, iter: 26, training_loss: 9.57407e-01\n",
            "epoch: 243, iter: 26, training_loss: 8.50742e-01\n",
            "epoch: 244, iter: 26, training_loss: 9.89894e-01\n",
            "epoch: 245, iter: 26, training_loss: 8.79297e-01\n",
            "epoch: 246, iter: 26, training_loss: 8.50717e-01\n",
            "epoch: 247, iter: 26, training_loss: 8.72722e-01\n",
            "epoch: 248, iter: 26, training_loss: 1.00365e+00\n",
            "epoch: 249, iter: 26, training_loss: 8.20229e-01\n",
            "epoch: 250, iter: 26, training_loss: 7.06012e-01\n",
            "epoch: 251, iter: 26, training_loss: 7.90530e-01\n",
            "epoch: 252, iter: 26, training_loss: 7.64425e-01\n",
            "epoch: 253, iter: 26, training_loss: 8.76942e-01\n",
            "epoch: 254, iter: 26, training_loss: 8.70893e-01\n",
            "epoch: 255, iter: 26, training_loss: 9.64128e-01\n",
            "epoch: 256, iter: 26, training_loss: 7.09322e-01\n",
            "epoch: 257, iter: 26, training_loss: 8.51499e-01\n",
            "epoch: 258, iter: 26, training_loss: 7.62934e-01\n",
            "epoch: 259, iter: 26, training_loss: 7.30528e-01\n",
            "epoch: 260, iter: 26, training_loss: 7.34719e-01\n",
            "epoch: 261, iter: 26, training_loss: 7.90429e-01\n",
            "epoch: 262, iter: 26, training_loss: 7.60893e-01\n",
            "epoch: 263, iter: 26, training_loss: 7.47110e-01\n",
            "epoch: 264, iter: 26, training_loss: 8.94242e-01\n",
            "epoch: 265, iter: 26, training_loss: 7.46744e-01\n",
            "epoch: 266, iter: 26, training_loss: 7.44010e-01\n",
            "epoch: 267, iter: 26, training_loss: 7.68562e-01\n",
            "epoch: 268, iter: 26, training_loss: 7.89229e-01\n",
            "epoch: 269, iter: 26, training_loss: 7.86999e-01\n",
            "epoch: 270, iter: 26, training_loss: 7.38704e-01\n",
            "epoch: 271, iter: 26, training_loss: 7.70235e-01\n",
            "epoch: 272, iter: 26, training_loss: 7.45248e-01\n",
            "epoch: 273, iter: 26, training_loss: 7.14807e-01\n",
            "epoch: 274, iter: 26, training_loss: 7.46270e-01\n",
            "epoch: 275, iter: 26, training_loss: 6.84899e-01\n",
            "epoch: 276, iter: 26, training_loss: 6.81442e-01\n",
            "epoch: 277, iter: 26, training_loss: 6.69408e-01\n",
            "epoch: 278, iter: 26, training_loss: 7.04095e-01\n",
            "epoch: 279, iter: 26, training_loss: 6.55237e-01\n",
            "epoch: 280, iter: 26, training_loss: 6.79815e-01\n",
            "epoch: 281, iter: 26, training_loss: 7.02031e-01\n",
            "epoch: 282, iter: 26, training_loss: 6.42616e-01\n",
            "epoch: 283, iter: 26, training_loss: 6.55836e-01\n",
            "epoch: 284, iter: 26, training_loss: 6.84319e-01\n",
            "epoch: 285, iter: 26, training_loss: 6.45800e-01\n",
            "epoch: 286, iter: 26, training_loss: 6.18001e-01\n",
            "epoch: 287, iter: 26, training_loss: 7.01827e-01\n",
            "epoch: 288, iter: 26, training_loss: 6.73831e-01\n",
            "epoch: 289, iter: 26, training_loss: 6.43859e-01\n",
            "epoch: 290, iter: 26, training_loss: 5.28472e-01\n",
            "epoch: 291, iter: 26, training_loss: 6.22201e-01\n",
            "epoch: 292, iter: 26, training_loss: 6.30141e-01\n",
            "epoch: 293, iter: 26, training_loss: 6.48697e-01\n",
            "epoch: 294, iter: 26, training_loss: 6.95998e-01\n",
            "epoch: 295, iter: 26, training_loss: 6.40255e-01\n",
            "epoch: 296, iter: 26, training_loss: 9.68317e-01\n",
            "epoch: 297, iter: 26, training_loss: 6.55880e-01\n",
            "epoch: 298, iter: 26, training_loss: 6.10766e-01\n",
            "epoch: 299, iter: 26, training_loss: 5.91303e-01\n",
            "epoch: 300, iter: 26, training_loss: 6.02535e-01\n",
            "epoch: 301, iter: 26, training_loss: 6.64759e-01\n",
            "epoch: 302, iter: 26, training_loss: 6.35113e-01\n",
            "epoch: 303, iter: 26, training_loss: 6.09301e-01\n",
            "epoch: 304, iter: 26, training_loss: 6.10586e-01\n",
            "epoch: 305, iter: 26, training_loss: 6.34943e-01\n",
            "epoch: 306, iter: 26, training_loss: 6.13780e-01\n",
            "epoch: 307, iter: 26, training_loss: 5.87238e-01\n",
            "epoch: 308, iter: 26, training_loss: 7.58787e-01\n",
            "epoch: 309, iter: 26, training_loss: 5.12869e-01\n",
            "epoch: 310, iter: 26, training_loss: 7.18140e-01\n",
            "epoch: 311, iter: 26, training_loss: 9.43856e-01\n",
            "epoch: 312, iter: 26, training_loss: 5.09421e-01\n",
            "epoch: 313, iter: 26, training_loss: 4.54620e-01\n",
            "epoch: 314, iter: 26, training_loss: 5.19097e-01\n",
            "epoch: 315, iter: 26, training_loss: 5.10597e-01\n",
            "epoch: 316, iter: 26, training_loss: 5.31773e-01\n",
            "epoch: 317, iter: 26, training_loss: 4.83431e-01\n",
            "epoch: 318, iter: 26, training_loss: 4.37269e-01\n",
            "epoch: 319, iter: 26, training_loss: 3.85891e-01\n",
            "epoch: 320, iter: 26, training_loss: 3.77642e-01\n",
            "epoch: 321, iter: 26, training_loss: 3.70873e-01\n",
            "epoch: 322, iter: 26, training_loss: 4.17466e-01\n",
            "epoch: 323, iter: 26, training_loss: 4.50235e-01\n",
            "epoch: 324, iter: 26, training_loss: 4.48073e-01\n",
            "epoch: 325, iter: 26, training_loss: 4.02193e-01\n",
            "epoch: 326, iter: 26, training_loss: 4.01413e-01\n",
            "epoch: 327, iter: 26, training_loss: 3.97115e-01\n",
            "epoch: 328, iter: 26, training_loss: 4.02033e-01\n",
            "epoch: 329, iter: 26, training_loss: 3.75426e-01\n",
            "epoch: 330, iter: 26, training_loss: 4.41443e-01\n",
            "epoch: 331, iter: 26, training_loss: 3.85734e-01\n",
            "epoch: 332, iter: 26, training_loss: 3.98325e-01\n",
            "epoch: 333, iter: 26, training_loss: 3.63256e-01\n",
            "epoch: 334, iter: 26, training_loss: 3.76837e-01\n",
            "epoch: 335, iter: 26, training_loss: 3.89752e-01\n",
            "epoch: 336, iter: 26, training_loss: 4.10147e-01\n",
            "epoch: 337, iter: 26, training_loss: 4.09865e-01\n",
            "epoch: 338, iter: 26, training_loss: 3.57380e-01\n",
            "epoch: 339, iter: 26, training_loss: 3.50117e-01\n",
            "epoch: 340, iter: 26, training_loss: 3.41788e-01\n",
            "epoch: 341, iter: 26, training_loss: 3.41725e-01\n",
            "epoch: 342, iter: 26, training_loss: 4.29312e-01\n",
            "epoch: 343, iter: 26, training_loss: 4.40953e-01\n",
            "epoch: 344, iter: 26, training_loss: 4.06807e-01\n",
            "epoch: 345, iter: 26, training_loss: 4.41279e-01\n",
            "epoch: 346, iter: 26, training_loss: 4.48820e-01\n",
            "epoch: 347, iter: 26, training_loss: 4.23635e-01\n",
            "epoch: 348, iter: 26, training_loss: 4.71505e-01\n",
            "epoch: 349, iter: 26, training_loss: 3.77110e-01\n",
            "epoch: 350, iter: 26, training_loss: 3.48367e-01\n",
            "epoch: 351, iter: 26, training_loss: 5.31783e-01\n",
            "epoch: 352, iter: 26, training_loss: 4.53997e-01\n",
            "epoch: 353, iter: 26, training_loss: 4.12644e-01\n",
            "epoch: 354, iter: 26, training_loss: 4.71715e-01\n",
            "epoch: 355, iter: 26, training_loss: 4.64630e-01\n",
            "epoch: 356, iter: 26, training_loss: 4.04424e-01\n",
            "epoch: 357, iter: 26, training_loss: 3.43838e-01\n",
            "epoch: 358, iter: 26, training_loss: 4.14625e-01\n",
            "epoch: 359, iter: 26, training_loss: 4.60633e-01\n",
            "epoch: 360, iter: 26, training_loss: 3.65487e-01\n",
            "epoch: 361, iter: 26, training_loss: 4.91908e-01\n",
            "epoch: 362, iter: 26, training_loss: 4.30592e-01\n",
            "epoch: 363, iter: 26, training_loss: 4.04270e-01\n",
            "epoch: 364, iter: 26, training_loss: 3.93269e-01\n",
            "epoch: 365, iter: 26, training_loss: 3.98640e-01\n",
            "epoch: 366, iter: 26, training_loss: 4.49641e-01\n",
            "epoch: 367, iter: 26, training_loss: 4.03292e-01\n",
            "epoch: 368, iter: 26, training_loss: 3.56683e-01\n",
            "epoch: 369, iter: 26, training_loss: 4.60693e-01\n",
            "epoch: 370, iter: 26, training_loss: 3.98259e-01\n",
            "epoch: 371, iter: 26, training_loss: 4.42254e-01\n",
            "epoch: 372, iter: 26, training_loss: 4.37316e-01\n",
            "epoch: 373, iter: 26, training_loss: 4.29463e-01\n",
            "epoch: 374, iter: 26, training_loss: 4.18672e-01\n",
            "epoch: 375, iter: 26, training_loss: 4.25852e-01\n",
            "epoch: 376, iter: 26, training_loss: 4.23730e-01\n",
            "epoch: 377, iter: 26, training_loss: 4.50837e-01\n",
            "epoch: 378, iter: 26, training_loss: 4.65922e-01\n",
            "epoch: 379, iter: 26, training_loss: 4.18645e-01\n",
            "epoch: 380, iter: 26, training_loss: 3.38556e-01\n",
            "epoch: 381, iter: 26, training_loss: 4.55179e-01\n",
            "epoch: 382, iter: 26, training_loss: 4.31201e-01\n",
            "epoch: 383, iter: 26, training_loss: 3.92426e-01\n",
            "epoch: 384, iter: 26, training_loss: 3.98259e-01\n",
            "epoch: 385, iter: 26, training_loss: 3.89335e-01\n",
            "epoch: 386, iter: 26, training_loss: 3.71578e-01\n",
            "epoch: 387, iter: 26, training_loss: 3.57964e-01\n",
            "epoch: 388, iter: 26, training_loss: 3.70702e-01\n",
            "epoch: 389, iter: 26, training_loss: 3.77606e-01\n",
            "epoch: 390, iter: 26, training_loss: 3.32203e-01\n",
            "epoch: 391, iter: 26, training_loss: 3.48556e-01\n",
            "epoch: 392, iter: 26, training_loss: 3.88695e-01\n",
            "epoch: 393, iter: 26, training_loss: 3.78662e-01\n",
            "epoch: 394, iter: 26, training_loss: 3.46961e-01\n",
            "epoch: 395, iter: 26, training_loss: 3.37689e-01\n",
            "epoch: 396, iter: 26, training_loss: 3.63633e-01\n",
            "epoch: 397, iter: 26, training_loss: 3.41574e-01\n",
            "epoch: 398, iter: 26, training_loss: 3.44223e-01\n",
            "epoch: 399, iter: 26, training_loss: 3.19374e-01\n",
            "epoch: 400, iter: 26, training_loss: 4.20771e-01\n",
            "epoch: 401, iter: 26, training_loss: 4.10815e-01\n",
            "epoch: 402, iter: 26, training_loss: 3.63748e-01\n",
            "epoch: 403, iter: 26, training_loss: 4.02068e-01\n",
            "epoch: 404, iter: 26, training_loss: 3.94615e-01\n",
            "epoch: 405, iter: 26, training_loss: 3.37406e-01\n",
            "epoch: 406, iter: 26, training_loss: 4.29652e-01\n",
            "epoch: 407, iter: 26, training_loss: 3.70224e-01\n",
            "epoch: 408, iter: 26, training_loss: 3.47596e-01\n",
            "epoch: 409, iter: 26, training_loss: 3.91461e-01\n",
            "epoch: 410, iter: 26, training_loss: 4.13904e-01\n",
            "epoch: 411, iter: 26, training_loss: 3.68649e-01\n",
            "epoch: 412, iter: 26, training_loss: 3.42986e-01\n",
            "epoch: 413, iter: 26, training_loss: 3.21679e-01\n",
            "epoch: 414, iter: 26, training_loss: 3.39397e-01\n",
            "epoch: 415, iter: 26, training_loss: 3.99384e-01\n",
            "epoch: 416, iter: 26, training_loss: 3.42835e-01\n",
            "epoch: 417, iter: 26, training_loss: 3.38940e-01\n",
            "epoch: 418, iter: 26, training_loss: 3.18357e-01\n",
            "epoch: 419, iter: 26, training_loss: 3.15740e-01\n",
            "epoch: 420, iter: 26, training_loss: 3.21558e-01\n",
            "epoch: 421, iter: 26, training_loss: 3.76492e-01\n",
            "epoch: 422, iter: 26, training_loss: 3.31759e-01\n",
            "epoch: 423, iter: 26, training_loss: 4.46380e-01\n",
            "epoch: 424, iter: 26, training_loss: 3.68531e-01\n",
            "epoch: 425, iter: 26, training_loss: 3.43891e-01\n",
            "epoch: 426, iter: 26, training_loss: 3.58550e-01\n",
            "epoch: 427, iter: 26, training_loss: 3.73024e-01\n",
            "epoch: 428, iter: 26, training_loss: 3.46330e-01\n",
            "epoch: 429, iter: 26, training_loss: 3.21479e-01\n",
            "epoch: 430, iter: 26, training_loss: 2.96912e-01\n",
            "epoch: 431, iter: 26, training_loss: 3.05791e-01\n",
            "epoch: 432, iter: 26, training_loss: 2.97666e-01\n",
            "epoch: 433, iter: 26, training_loss: 3.09676e-01\n",
            "epoch: 434, iter: 26, training_loss: 4.02051e-01\n",
            "epoch: 435, iter: 26, training_loss: 3.40959e-01\n",
            "epoch: 436, iter: 26, training_loss: 3.18570e-01\n",
            "epoch: 437, iter: 26, training_loss: 2.95432e-01\n",
            "epoch: 438, iter: 26, training_loss: 3.00921e-01\n",
            "epoch: 439, iter: 26, training_loss: 2.94004e-01\n",
            "epoch: 440, iter: 26, training_loss: 3.45097e-01\n",
            "epoch: 441, iter: 26, training_loss: 3.28933e-01\n",
            "epoch: 442, iter: 26, training_loss: 3.28468e-01\n",
            "epoch: 443, iter: 26, training_loss: 4.44624e-01\n",
            "epoch: 444, iter: 26, training_loss: 3.35130e-01\n",
            "epoch: 445, iter: 26, training_loss: 2.99405e-01\n",
            "epoch: 446, iter: 26, training_loss: 2.86101e-01\n",
            "epoch: 447, iter: 26, training_loss: 2.81308e-01\n",
            "epoch: 448, iter: 26, training_loss: 3.10938e-01\n",
            "epoch: 449, iter: 26, training_loss: 2.96371e-01\n",
            "epoch: 450, iter: 26, training_loss: 3.02363e-01\n",
            "epoch: 451, iter: 26, training_loss: 2.90930e-01\n",
            "epoch: 452, iter: 26, training_loss: 2.85875e-01\n",
            "epoch: 453, iter: 26, training_loss: 4.03216e-01\n",
            "epoch: 454, iter: 26, training_loss: 3.20926e-01\n",
            "epoch: 455, iter: 26, training_loss: 2.96096e-01\n",
            "epoch: 456, iter: 26, training_loss: 3.27893e-01\n",
            "epoch: 457, iter: 26, training_loss: 3.27375e-01\n",
            "epoch: 458, iter: 26, training_loss: 3.27405e-01\n",
            "epoch: 459, iter: 26, training_loss: 2.83568e-01\n",
            "epoch: 460, iter: 26, training_loss: 2.91767e-01\n",
            "epoch: 461, iter: 26, training_loss: 3.90499e-01\n",
            "epoch: 462, iter: 26, training_loss: 3.29434e-01\n",
            "epoch: 463, iter: 26, training_loss: 3.14822e-01\n",
            "epoch: 464, iter: 26, training_loss: 2.92761e-01\n",
            "epoch: 465, iter: 26, training_loss: 3.80064e-01\n",
            "epoch: 466, iter: 26, training_loss: 3.29542e-01\n",
            "epoch: 467, iter: 26, training_loss: 3.18245e-01\n",
            "epoch: 468, iter: 26, training_loss: 2.89830e-01\n",
            "epoch: 469, iter: 26, training_loss: 2.95661e-01\n",
            "epoch: 470, iter: 26, training_loss: 3.27853e-01\n",
            "epoch: 471, iter: 26, training_loss: 2.93378e-01\n",
            "epoch: 472, iter: 26, training_loss: 2.86021e-01\n",
            "epoch: 473, iter: 26, training_loss: 3.26132e-01\n",
            "epoch: 474, iter: 26, training_loss: 3.39339e-01\n",
            "epoch: 475, iter: 26, training_loss: 2.94031e-01\n",
            "epoch: 476, iter: 26, training_loss: 2.87557e-01\n",
            "epoch: 477, iter: 26, training_loss: 2.79596e-01\n",
            "epoch: 478, iter: 26, training_loss: 3.18779e-01\n",
            "epoch: 479, iter: 26, training_loss: 5.03809e-01\n",
            "epoch: 480, iter: 26, training_loss: 3.64062e-01\n",
            "epoch: 481, iter: 26, training_loss: 3.73966e-01\n",
            "epoch: 482, iter: 26, training_loss: 3.21854e-01\n",
            "epoch: 483, iter: 26, training_loss: 3.12383e-01\n",
            "epoch: 484, iter: 26, training_loss: 3.11211e-01\n",
            "epoch: 485, iter: 26, training_loss: 4.15316e-01\n",
            "epoch: 486, iter: 26, training_loss: 3.30559e-01\n",
            "epoch: 487, iter: 26, training_loss: 2.88774e-01\n",
            "epoch: 488, iter: 26, training_loss: 3.43920e-01\n",
            "epoch: 489, iter: 26, training_loss: 2.97815e-01\n",
            "epoch: 490, iter: 26, training_loss: 3.62351e-01\n",
            "epoch: 491, iter: 26, training_loss: 3.31510e-01\n",
            "epoch: 492, iter: 26, training_loss: 2.79542e-01\n",
            "epoch: 493, iter: 26, training_loss: 2.83883e-01\n",
            "epoch: 494, iter: 26, training_loss: 3.32372e-01\n",
            "epoch: 495, iter: 26, training_loss: 2.72090e-01\n",
            "epoch: 496, iter: 26, training_loss: 3.75234e-01\n",
            "epoch: 497, iter: 26, training_loss: 3.67478e-01\n",
            "epoch: 498, iter: 26, training_loss: 3.88846e-01\n",
            "epoch: 499, iter: 26, training_loss: 3.23489e-01\n",
            "epoch: 500, iter: 26, training_loss: 3.04103e-01\n",
            "epoch: 501, iter: 26, training_loss: 3.15243e-01\n",
            "epoch: 502, iter: 26, training_loss: 2.95896e-01\n",
            "epoch: 503, iter: 26, training_loss: 2.69774e-01\n",
            "epoch: 504, iter: 26, training_loss: 3.14953e-01\n",
            "epoch: 505, iter: 26, training_loss: 3.51712e-01\n",
            "epoch: 506, iter: 26, training_loss: 3.17349e-01\n",
            "epoch: 507, iter: 26, training_loss: 3.15008e-01\n",
            "epoch: 508, iter: 26, training_loss: 2.95538e-01\n",
            "epoch: 509, iter: 26, training_loss: 2.71530e-01\n",
            "epoch: 510, iter: 26, training_loss: 2.69463e-01\n",
            "epoch: 511, iter: 26, training_loss: 2.66274e-01\n",
            "epoch: 512, iter: 26, training_loss: 3.49537e-01\n",
            "epoch: 513, iter: 26, training_loss: 4.15108e-01\n",
            "epoch: 514, iter: 26, training_loss: 3.82712e-01\n",
            "epoch: 515, iter: 26, training_loss: 3.33653e-01\n",
            "epoch: 516, iter: 26, training_loss: 3.27020e-01\n",
            "epoch: 517, iter: 26, training_loss: 3.77098e-01\n",
            "epoch: 518, iter: 26, training_loss: 3.66297e-01\n",
            "epoch: 519, iter: 26, training_loss: 3.10463e-01\n",
            "epoch: 520, iter: 26, training_loss: 3.14113e-01\n",
            "epoch: 521, iter: 26, training_loss: 3.04937e-01\n",
            "epoch: 522, iter: 26, training_loss: 3.16329e-01\n",
            "epoch: 523, iter: 26, training_loss: 3.73249e-01\n",
            "epoch: 524, iter: 26, training_loss: 3.33058e-01\n",
            "epoch: 525, iter: 26, training_loss: 2.84823e-01\n",
            "epoch: 526, iter: 26, training_loss: 2.65650e-01\n",
            "epoch: 527, iter: 26, training_loss: 3.43990e-01\n",
            "epoch: 528, iter: 26, training_loss: 2.99676e-01\n",
            "epoch: 529, iter: 26, training_loss: 3.16674e-01\n",
            "epoch: 530, iter: 26, training_loss: 3.19422e-01\n",
            "epoch: 531, iter: 26, training_loss: 3.22558e-01\n",
            "epoch: 532, iter: 26, training_loss: 3.45172e-01\n",
            "epoch: 533, iter: 26, training_loss: 3.37505e-01\n",
            "epoch: 534, iter: 26, training_loss: 3.74194e-01\n",
            "epoch: 535, iter: 26, training_loss: 2.92260e-01\n",
            "epoch: 536, iter: 26, training_loss: 3.40005e-01\n",
            "epoch: 537, iter: 26, training_loss: 3.37967e-01\n",
            "epoch: 538, iter: 26, training_loss: 3.01661e-01\n",
            "epoch: 539, iter: 26, training_loss: 2.61144e-01\n",
            "epoch: 540, iter: 26, training_loss: 2.50989e-01\n",
            "epoch: 541, iter: 26, training_loss: 2.48488e-01\n",
            "epoch: 542, iter: 26, training_loss: 2.42398e-01\n",
            "epoch: 543, iter: 26, training_loss: 3.53680e-01\n",
            "epoch: 544, iter: 26, training_loss: 2.89486e-01\n",
            "epoch: 545, iter: 26, training_loss: 3.11734e-01\n",
            "epoch: 546, iter: 26, training_loss: 2.81328e-01\n",
            "epoch: 547, iter: 26, training_loss: 2.57931e-01\n",
            "epoch: 548, iter: 26, training_loss: 2.44612e-01\n",
            "epoch: 549, iter: 26, training_loss: 2.81100e-01\n",
            "epoch: 550, iter: 26, training_loss: 2.70256e-01\n",
            "epoch: 551, iter: 26, training_loss: 4.09818e-01\n",
            "epoch: 552, iter: 26, training_loss: 4.04152e-01\n",
            "epoch: 553, iter: 26, training_loss: 3.32358e-01\n",
            "epoch: 554, iter: 26, training_loss: 2.78801e-01\n",
            "epoch: 555, iter: 26, training_loss: 3.10439e-01\n",
            "epoch: 556, iter: 26, training_loss: 2.94659e-01\n",
            "epoch: 557, iter: 26, training_loss: 3.23094e-01\n",
            "epoch: 558, iter: 26, training_loss: 2.67377e-01\n",
            "epoch: 559, iter: 26, training_loss: 2.71496e-01\n",
            "epoch: 560, iter: 26, training_loss: 2.76449e-01\n",
            "epoch: 561, iter: 26, training_loss: 2.62250e-01\n",
            "epoch: 562, iter: 26, training_loss: 2.66033e-01\n",
            "epoch: 563, iter: 26, training_loss: 2.53334e-01\n",
            "epoch: 564, iter: 26, training_loss: 2.88401e-01\n",
            "epoch: 565, iter: 26, training_loss: 3.26745e-01\n",
            "epoch: 566, iter: 26, training_loss: 3.18783e-01\n",
            "epoch: 567, iter: 26, training_loss: 3.23569e-01\n",
            "epoch: 568, iter: 26, training_loss: 2.92836e-01\n",
            "epoch: 569, iter: 26, training_loss: 3.47443e-01\n",
            "epoch: 570, iter: 26, training_loss: 3.54987e-01\n",
            "epoch: 571, iter: 26, training_loss: 2.97482e-01\n",
            "epoch: 572, iter: 26, training_loss: 2.58891e-01\n",
            "epoch: 573, iter: 26, training_loss: 2.77243e-01\n",
            "epoch: 574, iter: 26, training_loss: 2.91000e-01\n",
            "epoch: 575, iter: 26, training_loss: 2.76759e-01\n",
            "epoch: 576, iter: 26, training_loss: 2.57470e-01\n",
            "epoch: 577, iter: 26, training_loss: 2.66886e-01\n",
            "epoch: 578, iter: 26, training_loss: 2.56329e-01\n",
            "epoch: 579, iter: 26, training_loss: 3.22928e-01\n",
            "epoch: 580, iter: 26, training_loss: 3.12549e-01\n",
            "epoch: 581, iter: 26, training_loss: 3.07680e-01\n",
            "epoch: 582, iter: 26, training_loss: 2.58391e-01\n",
            "epoch: 583, iter: 26, training_loss: 3.15567e-01\n",
            "epoch: 584, iter: 26, training_loss: 3.35918e-01\n",
            "epoch: 585, iter: 26, training_loss: 2.98846e-01\n",
            "epoch: 586, iter: 26, training_loss: 3.05632e-01\n",
            "epoch: 587, iter: 26, training_loss: 2.77809e-01\n",
            "epoch: 588, iter: 26, training_loss: 2.50051e-01\n",
            "epoch: 589, iter: 26, training_loss: 2.58731e-01\n",
            "epoch: 590, iter: 26, training_loss: 2.64316e-01\n",
            "epoch: 591, iter: 26, training_loss: 2.98884e-01\n",
            "epoch: 592, iter: 26, training_loss: 2.81312e-01\n",
            "epoch: 593, iter: 26, training_loss: 2.43965e-01\n",
            "epoch: 594, iter: 26, training_loss: 2.85399e-01\n",
            "epoch: 595, iter: 26, training_loss: 2.82921e-01\n",
            "epoch: 596, iter: 26, training_loss: 2.51456e-01\n",
            "epoch: 597, iter: 26, training_loss: 2.99307e-01\n",
            "epoch: 598, iter: 26, training_loss: 2.97439e-01\n",
            "epoch: 599, iter: 26, training_loss: 2.74708e-01\n",
            "epoch: 600, iter: 26, training_loss: 2.47963e-01\n",
            "epoch: 601, iter: 26, training_loss: 2.33347e-01\n",
            "epoch: 602, iter: 26, training_loss: 2.97089e-01\n",
            "epoch: 603, iter: 26, training_loss: 3.71612e-01\n",
            "epoch: 604, iter: 26, training_loss: 3.12753e-01\n",
            "epoch: 605, iter: 26, training_loss: 2.86198e-01\n",
            "epoch: 606, iter: 26, training_loss: 2.45350e-01\n",
            "epoch: 607, iter: 26, training_loss: 2.45963e-01\n",
            "epoch: 608, iter: 26, training_loss: 2.98682e-01\n",
            "epoch: 609, iter: 26, training_loss: 3.21576e-01\n",
            "epoch: 610, iter: 26, training_loss: 2.89356e-01\n",
            "epoch: 611, iter: 26, training_loss: 2.49013e-01\n",
            "epoch: 612, iter: 26, training_loss: 2.28757e-01\n",
            "epoch: 613, iter: 26, training_loss: 3.01055e-01\n",
            "epoch: 614, iter: 26, training_loss: 2.92378e-01\n",
            "epoch: 615, iter: 26, training_loss: 2.73228e-01\n",
            "epoch: 616, iter: 26, training_loss: 3.14552e-01\n",
            "epoch: 617, iter: 26, training_loss: 2.92552e-01\n",
            "epoch: 618, iter: 26, training_loss: 2.93085e-01\n",
            "epoch: 619, iter: 26, training_loss: 2.88978e-01\n",
            "epoch: 620, iter: 26, training_loss: 2.67883e-01\n",
            "epoch: 621, iter: 26, training_loss: 2.60422e-01\n",
            "epoch: 622, iter: 26, training_loss: 2.81955e-01\n",
            "epoch: 623, iter: 26, training_loss: 2.53027e-01\n",
            "epoch: 624, iter: 26, training_loss: 2.83068e-01\n",
            "epoch: 625, iter: 26, training_loss: 3.38161e-01\n",
            "epoch: 626, iter: 26, training_loss: 3.11658e-01\n",
            "epoch: 627, iter: 26, training_loss: 2.64860e-01\n",
            "epoch: 628, iter: 26, training_loss: 2.36510e-01\n",
            "epoch: 629, iter: 26, training_loss: 3.05740e-01\n",
            "epoch: 630, iter: 26, training_loss: 2.83854e-01\n",
            "epoch: 631, iter: 26, training_loss: 2.75950e-01\n",
            "epoch: 632, iter: 26, training_loss: 2.58363e-01\n",
            "epoch: 633, iter: 26, training_loss: 2.37373e-01\n",
            "epoch: 634, iter: 26, training_loss: 2.55854e-01\n",
            "epoch: 635, iter: 26, training_loss: 2.61662e-01\n",
            "epoch: 636, iter: 26, training_loss: 2.40165e-01\n",
            "epoch: 637, iter: 26, training_loss: 2.35876e-01\n",
            "epoch: 638, iter: 26, training_loss: 2.20641e-01\n",
            "epoch: 639, iter: 26, training_loss: 2.17692e-01\n",
            "epoch: 640, iter: 26, training_loss: 3.22159e-01\n",
            "epoch: 641, iter: 26, training_loss: 2.88690e-01\n",
            "epoch: 642, iter: 26, training_loss: 2.39831e-01\n",
            "epoch: 643, iter: 26, training_loss: 2.44103e-01\n",
            "epoch: 644, iter: 26, training_loss: 2.77825e-01\n",
            "epoch: 645, iter: 26, training_loss: 2.87896e-01\n",
            "epoch: 646, iter: 26, training_loss: 2.64665e-01\n",
            "epoch: 647, iter: 26, training_loss: 2.61412e-01\n",
            "epoch: 648, iter: 26, training_loss: 2.45574e-01\n",
            "epoch: 649, iter: 26, training_loss: 2.65414e-01\n",
            "epoch: 650, iter: 26, training_loss: 2.65708e-01\n",
            "epoch: 651, iter: 26, training_loss: 2.57895e-01\n",
            "epoch: 652, iter: 26, training_loss: 2.33584e-01\n",
            "epoch: 653, iter: 26, training_loss: 2.29761e-01\n",
            "epoch: 654, iter: 26, training_loss: 2.37187e-01\n",
            "epoch: 655, iter: 26, training_loss: 2.18078e-01\n",
            "epoch: 656, iter: 26, training_loss: 2.15868e-01\n",
            "epoch: 657, iter: 26, training_loss: 2.24786e-01\n",
            "epoch: 658, iter: 26, training_loss: 2.20834e-01\n",
            "epoch: 659, iter: 26, training_loss: 2.48957e-01\n",
            "epoch: 660, iter: 26, training_loss: 3.30908e-01\n",
            "epoch: 661, iter: 26, training_loss: 2.71890e-01\n",
            "epoch: 662, iter: 26, training_loss: 2.31278e-01\n",
            "epoch: 663, iter: 26, training_loss: 2.27069e-01\n",
            "epoch: 664, iter: 26, training_loss: 2.24301e-01\n",
            "epoch: 665, iter: 26, training_loss: 2.25058e-01\n",
            "epoch: 666, iter: 26, training_loss: 2.43193e-01\n",
            "epoch: 667, iter: 26, training_loss: 2.56678e-01\n",
            "epoch: 668, iter: 26, training_loss: 2.28369e-01\n",
            "epoch: 669, iter: 26, training_loss: 2.12537e-01\n",
            "epoch: 670, iter: 26, training_loss: 2.36945e-01\n",
            "epoch: 671, iter: 26, training_loss: 2.52356e-01\n",
            "epoch: 672, iter: 26, training_loss: 2.71004e-01\n",
            "epoch: 673, iter: 26, training_loss: 2.52940e-01\n",
            "epoch: 674, iter: 26, training_loss: 2.26334e-01\n",
            "epoch: 675, iter: 26, training_loss: 2.25993e-01\n",
            "epoch: 676, iter: 26, training_loss: 2.49860e-01\n",
            "epoch: 677, iter: 26, training_loss: 2.64851e-01\n",
            "epoch: 678, iter: 26, training_loss: 2.50887e-01\n",
            "epoch: 679, iter: 26, training_loss: 2.46282e-01\n",
            "epoch: 680, iter: 26, training_loss: 2.45084e-01\n",
            "epoch: 681, iter: 26, training_loss: 2.12651e-01\n",
            "epoch: 682, iter: 26, training_loss: 2.46163e-01\n",
            "epoch: 683, iter: 26, training_loss: 3.51627e-01\n",
            "epoch: 684, iter: 26, training_loss: 2.43794e-01\n",
            "epoch: 685, iter: 26, training_loss: 2.37464e-01\n",
            "epoch: 686, iter: 26, training_loss: 2.65615e-01\n",
            "epoch: 687, iter: 26, training_loss: 2.57494e-01\n",
            "epoch: 688, iter: 26, training_loss: 2.11555e-01\n",
            "epoch: 689, iter: 26, training_loss: 2.31654e-01\n",
            "epoch: 690, iter: 26, training_loss: 2.59076e-01\n",
            "epoch: 691, iter: 26, training_loss: 2.89517e-01\n",
            "epoch: 692, iter: 26, training_loss: 3.42331e-01\n",
            "epoch: 693, iter: 26, training_loss: 3.11775e-01\n",
            "epoch: 694, iter: 26, training_loss: 2.84326e-01\n",
            "epoch: 695, iter: 26, training_loss: 2.85757e-01\n",
            "epoch: 696, iter: 26, training_loss: 2.50025e-01\n",
            "epoch: 697, iter: 26, training_loss: 2.30689e-01\n",
            "epoch: 698, iter: 26, training_loss: 2.33289e-01\n",
            "epoch: 699, iter: 26, training_loss: 2.19598e-01\n",
            "epoch: 700, iter: 26, training_loss: 2.09295e-01\n",
            "epoch: 701, iter: 26, training_loss: 2.93254e-01\n",
            "epoch: 702, iter: 26, training_loss: 2.76882e-01\n",
            "epoch: 703, iter: 26, training_loss: 2.27663e-01\n",
            "epoch: 704, iter: 26, training_loss: 2.76074e-01\n",
            "epoch: 705, iter: 26, training_loss: 2.88386e-01\n",
            "epoch: 706, iter: 26, training_loss: 2.32292e-01\n",
            "epoch: 707, iter: 26, training_loss: 2.18515e-01\n",
            "epoch: 708, iter: 26, training_loss: 2.15324e-01\n",
            "epoch: 709, iter: 26, training_loss: 2.72928e-01\n",
            "epoch: 710, iter: 26, training_loss: 3.00179e-01\n",
            "epoch: 711, iter: 26, training_loss: 2.51520e-01\n",
            "epoch: 712, iter: 26, training_loss: 2.46635e-01\n",
            "epoch: 713, iter: 26, training_loss: 2.49968e-01\n",
            "epoch: 714, iter: 26, training_loss: 2.52433e-01\n",
            "epoch: 715, iter: 26, training_loss: 2.19345e-01\n",
            "epoch: 716, iter: 26, training_loss: 3.16093e-01\n",
            "epoch: 717, iter: 26, training_loss: 2.53570e-01\n",
            "epoch: 718, iter: 26, training_loss: 2.56302e-01\n",
            "epoch: 719, iter: 26, training_loss: 2.46380e-01\n",
            "epoch: 720, iter: 26, training_loss: 2.63205e-01\n",
            "epoch: 721, iter: 26, training_loss: 2.42167e-01\n",
            "epoch: 722, iter: 26, training_loss: 2.16526e-01\n",
            "epoch: 723, iter: 26, training_loss: 2.13991e-01\n",
            "epoch: 724, iter: 26, training_loss: 2.29740e-01\n",
            "epoch: 725, iter: 26, training_loss: 2.34950e-01\n",
            "epoch: 726, iter: 26, training_loss: 2.54227e-01\n",
            "epoch: 727, iter: 26, training_loss: 2.34046e-01\n",
            "epoch: 728, iter: 26, training_loss: 2.22648e-01\n",
            "epoch: 729, iter: 26, training_loss: 2.04037e-01\n",
            "epoch: 730, iter: 26, training_loss: 2.35182e-01\n",
            "epoch: 731, iter: 26, training_loss: 2.41927e-01\n",
            "epoch: 732, iter: 26, training_loss: 2.47199e-01\n",
            "epoch: 733, iter: 26, training_loss: 2.23594e-01\n",
            "epoch: 734, iter: 26, training_loss: 2.01285e-01\n",
            "epoch: 735, iter: 26, training_loss: 2.08938e-01\n",
            "epoch: 736, iter: 26, training_loss: 3.45507e-01\n",
            "epoch: 737, iter: 26, training_loss: 2.66542e-01\n",
            "epoch: 738, iter: 26, training_loss: 2.55107e-01\n",
            "epoch: 739, iter: 26, training_loss: 2.44525e-01\n",
            "epoch: 740, iter: 26, training_loss: 2.71876e-01\n",
            "epoch: 741, iter: 26, training_loss: 2.27905e-01\n",
            "epoch: 742, iter: 26, training_loss: 2.53887e-01\n",
            "epoch: 743, iter: 26, training_loss: 2.59472e-01\n",
            "epoch: 744, iter: 26, training_loss: 3.23825e-01\n",
            "epoch: 745, iter: 26, training_loss: 2.40004e-01\n",
            "epoch: 746, iter: 26, training_loss: 2.74114e-01\n",
            "epoch: 747, iter: 26, training_loss: 2.40266e-01\n",
            "epoch: 748, iter: 26, training_loss: 2.22101e-01\n",
            "epoch: 749, iter: 26, training_loss: 2.18277e-01\n",
            "epoch: 750, iter: 26, training_loss: 2.18057e-01\n",
            "epoch: 751, iter: 26, training_loss: 2.63386e-01\n",
            "epoch: 752, iter: 26, training_loss: 2.66775e-01\n",
            "epoch: 753, iter: 26, training_loss: 2.93244e-01\n",
            "epoch: 754, iter: 26, training_loss: 2.31576e-01\n",
            "epoch: 755, iter: 26, training_loss: 2.54961e-01\n",
            "epoch: 756, iter: 26, training_loss: 2.19884e-01\n",
            "epoch: 757, iter: 26, training_loss: 2.01933e-01\n",
            "epoch: 758, iter: 26, training_loss: 2.16932e-01\n",
            "epoch: 759, iter: 26, training_loss: 2.07814e-01\n",
            "epoch: 760, iter: 26, training_loss: 2.24284e-01\n",
            "epoch: 761, iter: 26, training_loss: 2.76824e-01\n",
            "epoch: 762, iter: 26, training_loss: 2.28192e-01\n",
            "epoch: 763, iter: 26, training_loss: 2.15155e-01\n",
            "epoch: 764, iter: 26, training_loss: 2.39902e-01\n",
            "epoch: 765, iter: 26, training_loss: 2.27049e-01\n",
            "epoch: 766, iter: 26, training_loss: 2.60909e-01\n",
            "epoch: 767, iter: 26, training_loss: 2.44599e-01\n",
            "epoch: 768, iter: 26, training_loss: 2.61527e-01\n",
            "epoch: 769, iter: 26, training_loss: 2.26531e-01\n",
            "epoch: 770, iter: 26, training_loss: 2.04857e-01\n",
            "epoch: 771, iter: 26, training_loss: 2.61559e-01\n",
            "epoch: 772, iter: 26, training_loss: 2.42297e-01\n",
            "epoch: 773, iter: 26, training_loss: 2.10400e-01\n",
            "epoch: 774, iter: 26, training_loss: 2.35365e-01\n",
            "epoch: 775, iter: 26, training_loss: 2.60321e-01\n",
            "epoch: 776, iter: 26, training_loss: 2.11688e-01\n",
            "epoch: 777, iter: 26, training_loss: 2.04128e-01\n",
            "epoch: 778, iter: 26, training_loss: 2.11370e-01\n",
            "epoch: 779, iter: 26, training_loss: 2.28910e-01\n",
            "epoch: 780, iter: 26, training_loss: 2.64187e-01\n",
            "epoch: 781, iter: 26, training_loss: 2.56220e-01\n",
            "epoch: 782, iter: 26, training_loss: 2.11533e-01\n",
            "epoch: 783, iter: 26, training_loss: 1.99806e-01\n",
            "epoch: 784, iter: 26, training_loss: 2.14533e-01\n",
            "epoch: 785, iter: 26, training_loss: 2.24412e-01\n",
            "epoch: 786, iter: 26, training_loss: 2.54136e-01\n",
            "epoch: 787, iter: 26, training_loss: 2.28023e-01\n",
            "epoch: 788, iter: 26, training_loss: 2.11128e-01\n",
            "epoch: 789, iter: 26, training_loss: 2.01857e-01\n",
            "epoch: 790, iter: 26, training_loss: 2.01530e-01\n",
            "epoch: 791, iter: 26, training_loss: 2.46282e-01\n",
            "epoch: 792, iter: 26, training_loss: 2.27783e-01\n",
            "epoch: 793, iter: 26, training_loss: 2.87679e-01\n",
            "epoch: 794, iter: 26, training_loss: 2.80015e-01\n",
            "epoch: 795, iter: 26, training_loss: 2.26580e-01\n",
            "epoch: 796, iter: 26, training_loss: 2.07779e-01\n",
            "epoch: 797, iter: 26, training_loss: 2.03179e-01\n",
            "epoch: 798, iter: 26, training_loss: 2.26854e-01\n",
            "epoch: 799, iter: 26, training_loss: 2.43548e-01\n",
            "epoch: 800, iter: 26, training_loss: 2.29823e-01\n",
            "epoch: 801, iter: 26, training_loss: 2.13665e-01\n",
            "epoch: 802, iter: 26, training_loss: 2.37453e-01\n",
            "epoch: 803, iter: 26, training_loss: 2.39713e-01\n",
            "epoch: 804, iter: 26, training_loss: 2.51082e-01\n",
            "epoch: 805, iter: 26, training_loss: 2.45001e-01\n",
            "epoch: 806, iter: 26, training_loss: 2.30655e-01\n",
            "epoch: 807, iter: 26, training_loss: 2.27679e-01\n",
            "epoch: 808, iter: 26, training_loss: 2.15458e-01\n",
            "epoch: 809, iter: 26, training_loss: 2.93428e-01\n",
            "epoch: 810, iter: 26, training_loss: 2.46070e-01\n",
            "epoch: 811, iter: 26, training_loss: 2.16813e-01\n",
            "epoch: 812, iter: 26, training_loss: 2.21293e-01\n",
            "epoch: 813, iter: 26, training_loss: 2.05491e-01\n",
            "epoch: 814, iter: 26, training_loss: 2.67440e-01\n",
            "epoch: 815, iter: 26, training_loss: 2.76053e-01\n",
            "epoch: 816, iter: 26, training_loss: 2.23562e-01\n",
            "epoch: 817, iter: 26, training_loss: 1.98739e-01\n",
            "epoch: 818, iter: 26, training_loss: 1.98151e-01\n",
            "epoch: 819, iter: 26, training_loss: 2.74657e-01\n",
            "epoch: 820, iter: 26, training_loss: 2.11209e-01\n",
            "epoch: 821, iter: 26, training_loss: 2.00091e-01\n",
            "epoch: 822, iter: 26, training_loss: 1.98381e-01\n",
            "epoch: 823, iter: 26, training_loss: 2.34734e-01\n",
            "epoch: 824, iter: 26, training_loss: 2.30669e-01\n",
            "epoch: 825, iter: 26, training_loss: 2.37882e-01\n",
            "epoch: 826, iter: 26, training_loss: 2.12682e-01\n",
            "epoch: 827, iter: 26, training_loss: 2.31238e-01\n",
            "epoch: 828, iter: 26, training_loss: 2.32068e-01\n",
            "epoch: 829, iter: 26, training_loss: 2.44711e-01\n",
            "epoch: 830, iter: 26, training_loss: 2.02551e-01\n",
            "epoch: 831, iter: 26, training_loss: 2.50925e-01\n",
            "epoch: 832, iter: 26, training_loss: 2.10304e-01\n",
            "epoch: 833, iter: 26, training_loss: 1.97343e-01\n",
            "epoch: 834, iter: 26, training_loss: 1.88600e-01\n",
            "epoch: 835, iter: 26, training_loss: 2.29543e-01\n",
            "epoch: 836, iter: 26, training_loss: 2.12716e-01\n",
            "epoch: 837, iter: 26, training_loss: 1.93403e-01\n",
            "epoch: 838, iter: 26, training_loss: 2.09382e-01\n",
            "epoch: 839, iter: 26, training_loss: 2.61809e-01\n",
            "epoch: 840, iter: 26, training_loss: 2.23213e-01\n",
            "epoch: 841, iter: 26, training_loss: 1.87502e-01\n",
            "epoch: 842, iter: 26, training_loss: 2.16529e-01\n",
            "epoch: 843, iter: 26, training_loss: 1.92031e-01\n",
            "epoch: 844, iter: 26, training_loss: 1.85979e-01\n",
            "epoch: 845, iter: 26, training_loss: 2.19002e-01\n",
            "epoch: 846, iter: 26, training_loss: 3.16622e-01\n",
            "epoch: 847, iter: 26, training_loss: 2.69891e-01\n",
            "epoch: 848, iter: 26, training_loss: 2.06548e-01\n",
            "epoch: 849, iter: 26, training_loss: 1.93722e-01\n",
            "epoch: 850, iter: 26, training_loss: 2.11009e-01\n",
            "epoch: 851, iter: 26, training_loss: 2.05263e-01\n",
            "epoch: 852, iter: 26, training_loss: 2.38168e-01\n",
            "epoch: 853, iter: 26, training_loss: 2.65793e-01\n",
            "epoch: 854, iter: 26, training_loss: 2.13006e-01\n",
            "epoch: 855, iter: 26, training_loss: 1.91836e-01\n",
            "epoch: 856, iter: 26, training_loss: 2.07753e-01\n",
            "epoch: 857, iter: 26, training_loss: 2.28754e-01\n",
            "epoch: 858, iter: 26, training_loss: 2.00298e-01\n",
            "epoch: 859, iter: 26, training_loss: 2.12944e-01\n",
            "epoch: 860, iter: 26, training_loss: 2.22259e-01\n",
            "epoch: 861, iter: 26, training_loss: 1.95445e-01\n",
            "epoch: 862, iter: 26, training_loss: 1.90404e-01\n",
            "epoch: 863, iter: 26, training_loss: 1.84231e-01\n",
            "epoch: 864, iter: 26, training_loss: 2.23221e-01\n",
            "epoch: 865, iter: 26, training_loss: 2.04287e-01\n",
            "epoch: 866, iter: 26, training_loss: 2.25619e-01\n",
            "epoch: 867, iter: 26, training_loss: 2.09716e-01\n",
            "epoch: 868, iter: 26, training_loss: 2.14694e-01\n",
            "epoch: 869, iter: 26, training_loss: 2.01153e-01\n",
            "epoch: 870, iter: 26, training_loss: 2.02507e-01\n",
            "epoch: 871, iter: 26, training_loss: 2.27952e-01\n",
            "epoch: 872, iter: 26, training_loss: 2.14255e-01\n",
            "epoch: 873, iter: 26, training_loss: 2.35131e-01\n",
            "epoch: 874, iter: 26, training_loss: 1.97091e-01\n",
            "epoch: 875, iter: 26, training_loss: 1.93145e-01\n",
            "epoch: 876, iter: 26, training_loss: 2.30664e-01\n",
            "epoch: 877, iter: 26, training_loss: 2.16001e-01\n",
            "epoch: 878, iter: 26, training_loss: 2.19004e-01\n",
            "epoch: 879, iter: 26, training_loss: 2.09690e-01\n",
            "epoch: 880, iter: 26, training_loss: 2.50679e-01\n",
            "epoch: 881, iter: 26, training_loss: 2.18050e-01\n",
            "epoch: 882, iter: 26, training_loss: 1.95844e-01\n",
            "epoch: 883, iter: 26, training_loss: 1.93383e-01\n",
            "epoch: 884, iter: 26, training_loss: 2.21437e-01\n",
            "epoch: 885, iter: 26, training_loss: 2.01292e-01\n",
            "epoch: 886, iter: 26, training_loss: 1.91614e-01\n",
            "epoch: 887, iter: 26, training_loss: 2.37322e-01\n",
            "epoch: 888, iter: 26, training_loss: 2.16255e-01\n",
            "epoch: 889, iter: 26, training_loss: 1.96533e-01\n",
            "epoch: 890, iter: 26, training_loss: 2.21382e-01\n",
            "epoch: 891, iter: 26, training_loss: 2.53694e-01\n",
            "epoch: 892, iter: 26, training_loss: 2.07129e-01\n",
            "epoch: 893, iter: 26, training_loss: 2.21435e-01\n",
            "epoch: 894, iter: 26, training_loss: 1.84203e-01\n",
            "epoch: 895, iter: 26, training_loss: 2.04124e-01\n",
            "epoch: 896, iter: 26, training_loss: 1.98882e-01\n",
            "epoch: 897, iter: 26, training_loss: 1.80971e-01\n",
            "epoch: 898, iter: 26, training_loss: 1.82677e-01\n",
            "epoch: 899, iter: 26, training_loss: 2.12854e-01\n",
            "epoch: 900, iter: 26, training_loss: 2.18491e-01\n",
            "epoch: 901, iter: 26, training_loss: 1.97661e-01\n",
            "epoch: 902, iter: 26, training_loss: 1.83765e-01\n",
            "epoch: 903, iter: 26, training_loss: 2.18923e-01\n",
            "epoch: 904, iter: 26, training_loss: 2.03698e-01\n",
            "epoch: 905, iter: 26, training_loss: 1.78910e-01\n",
            "epoch: 906, iter: 26, training_loss: 2.25388e-01\n",
            "epoch: 907, iter: 26, training_loss: 2.28066e-01\n",
            "epoch: 908, iter: 26, training_loss: 2.12445e-01\n",
            "epoch: 909, iter: 26, training_loss: 2.47154e-01\n",
            "epoch: 910, iter: 26, training_loss: 2.05174e-01\n",
            "epoch: 911, iter: 26, training_loss: 1.84185e-01\n",
            "epoch: 912, iter: 26, training_loss: 2.35793e-01\n",
            "epoch: 913, iter: 26, training_loss: 2.80769e-01\n",
            "epoch: 914, iter: 26, training_loss: 2.14752e-01\n",
            "epoch: 915, iter: 26, training_loss: 2.20634e-01\n",
            "epoch: 916, iter: 26, training_loss: 2.59424e-01\n",
            "epoch: 917, iter: 26, training_loss: 1.99863e-01\n",
            "epoch: 918, iter: 26, training_loss: 2.14921e-01\n",
            "epoch: 919, iter: 26, training_loss: 2.16196e-01\n",
            "epoch: 920, iter: 26, training_loss: 2.08450e-01\n",
            "epoch: 921, iter: 26, training_loss: 2.09961e-01\n",
            "epoch: 922, iter: 26, training_loss: 2.01769e-01\n",
            "epoch: 923, iter: 26, training_loss: 2.03665e-01\n",
            "epoch: 924, iter: 26, training_loss: 1.99987e-01\n",
            "epoch: 925, iter: 26, training_loss: 2.05037e-01\n",
            "epoch: 926, iter: 26, training_loss: 1.89804e-01\n",
            "epoch: 927, iter: 26, training_loss: 1.87756e-01\n",
            "epoch: 928, iter: 26, training_loss: 1.96898e-01\n",
            "epoch: 929, iter: 26, training_loss: 2.38685e-01\n",
            "epoch: 930, iter: 26, training_loss: 1.93197e-01\n",
            "epoch: 931, iter: 26, training_loss: 1.81263e-01\n",
            "epoch: 932, iter: 26, training_loss: 2.06209e-01\n",
            "epoch: 933, iter: 26, training_loss: 2.22027e-01\n",
            "epoch: 934, iter: 26, training_loss: 2.02150e-01\n",
            "epoch: 935, iter: 26, training_loss: 2.14364e-01\n",
            "epoch: 936, iter: 26, training_loss: 2.09179e-01\n",
            "epoch: 937, iter: 26, training_loss: 2.09094e-01\n",
            "epoch: 938, iter: 26, training_loss: 1.85730e-01\n",
            "epoch: 939, iter: 26, training_loss: 2.00757e-01\n",
            "epoch: 940, iter: 26, training_loss: 2.83216e-01\n",
            "epoch: 941, iter: 26, training_loss: 2.11078e-01\n",
            "epoch: 942, iter: 26, training_loss: 2.18455e-01\n",
            "epoch: 943, iter: 26, training_loss: 2.35693e-01\n",
            "epoch: 944, iter: 26, training_loss: 1.97917e-01\n",
            "epoch: 945, iter: 26, training_loss: 2.32866e-01\n",
            "epoch: 946, iter: 26, training_loss: 2.05726e-01\n",
            "epoch: 947, iter: 26, training_loss: 2.99217e-01\n",
            "epoch: 948, iter: 26, training_loss: 2.10927e-01\n",
            "epoch: 949, iter: 26, training_loss: 1.92945e-01\n",
            "epoch: 950, iter: 26, training_loss: 2.26621e-01\n",
            "epoch: 951, iter: 26, training_loss: 1.95243e-01\n",
            "epoch: 952, iter: 26, training_loss: 1.78047e-01\n",
            "epoch: 953, iter: 26, training_loss: 2.16823e-01\n",
            "epoch: 954, iter: 26, training_loss: 2.24107e-01\n",
            "epoch: 955, iter: 26, training_loss: 2.04209e-01\n",
            "epoch: 956, iter: 26, training_loss: 2.00510e-01\n",
            "epoch: 957, iter: 26, training_loss: 1.76929e-01\n",
            "epoch: 958, iter: 26, training_loss: 1.74190e-01\n",
            "epoch: 959, iter: 26, training_loss: 1.85261e-01\n",
            "epoch: 960, iter: 26, training_loss: 2.63479e-01\n",
            "epoch: 961, iter: 26, training_loss: 2.05904e-01\n",
            "epoch: 962, iter: 26, training_loss: 2.16299e-01\n",
            "epoch: 963, iter: 26, training_loss: 2.30207e-01\n",
            "epoch: 964, iter: 26, training_loss: 2.01427e-01\n",
            "epoch: 965, iter: 26, training_loss: 2.04233e-01\n",
            "epoch: 966, iter: 26, training_loss: 1.81247e-01\n",
            "epoch: 967, iter: 26, training_loss: 1.82392e-01\n",
            "epoch: 968, iter: 26, training_loss: 1.72346e-01\n",
            "epoch: 969, iter: 26, training_loss: 2.00874e-01\n",
            "epoch: 970, iter: 26, training_loss: 2.00711e-01\n",
            "epoch: 971, iter: 26, training_loss: 1.77541e-01\n",
            "epoch: 972, iter: 26, training_loss: 1.84533e-01\n",
            "epoch: 973, iter: 26, training_loss: 2.16464e-01\n",
            "epoch: 974, iter: 26, training_loss: 1.79730e-01\n",
            "epoch: 975, iter: 26, training_loss: 1.71739e-01\n",
            "epoch: 976, iter: 26, training_loss: 2.21302e-01\n",
            "epoch: 977, iter: 26, training_loss: 2.11720e-01\n",
            "epoch: 978, iter: 26, training_loss: 1.89290e-01\n",
            "epoch: 979, iter: 26, training_loss: 1.90046e-01\n",
            "epoch: 980, iter: 26, training_loss: 1.89063e-01\n",
            "epoch: 981, iter: 26, training_loss: 1.97890e-01\n",
            "epoch: 982, iter: 26, training_loss: 1.72912e-01\n",
            "epoch: 983, iter: 26, training_loss: 2.50450e-01\n",
            "epoch: 984, iter: 26, training_loss: 2.41798e-01\n",
            "epoch: 985, iter: 26, training_loss: 2.00137e-01\n",
            "epoch: 986, iter: 26, training_loss: 1.71488e-01\n",
            "epoch: 987, iter: 26, training_loss: 2.01380e-01\n",
            "epoch: 988, iter: 26, training_loss: 1.76132e-01\n",
            "epoch: 989, iter: 26, training_loss: 2.37646e-01\n",
            "epoch: 990, iter: 26, training_loss: 1.91287e-01\n",
            "epoch: 991, iter: 26, training_loss: 1.73314e-01\n",
            "epoch: 992, iter: 26, training_loss: 1.75304e-01\n",
            "epoch: 993, iter: 26, training_loss: 1.85013e-01\n",
            "epoch: 994, iter: 26, training_loss: 1.90253e-01\n",
            "epoch: 995, iter: 26, training_loss: 1.82550e-01\n",
            "epoch: 996, iter: 26, training_loss: 1.91160e-01\n",
            "epoch: 997, iter: 26, training_loss: 2.01808e-01\n",
            "epoch: 998, iter: 26, training_loss: 2.18387e-01\n",
            "epoch: 999, iter: 26, training_loss: 2.27417e-01\n",
            "epoch: 1000, iter: 26, training_loss: 2.03223e-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname default --method stasy --mode sample --save_path default_syn.csv"
      ],
      "metadata": {
        "id": "Iq6bmOW1uzvq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edff66c8-e881-46b2-9bc2-4e6039eee527"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No NaNs in numerical features, skipping\n",
            "Input dimension: 93\n",
            "NCSNpp(\n",
            "  (act): ELU(alpha=1.0)\n",
            "  (all_modules): ModuleList(\n",
            "    (0): GaussianFourierProjection()\n",
            "    (1): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (3): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=93, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (4): ELU(alpha=1.0)\n",
            "    (5): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=1117, out_features=2048, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=2048, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=2048, bias=True)\n",
            "    )\n",
            "    (6): ELU(alpha=1.0)\n",
            "    (7): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=3165, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (8): ELU(alpha=1.0)\n",
            "    (9): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=4189, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (10): ELU(alpha=1.0)\n",
            "    (11): Linear(in_features=5213, out_features=93, bias=True)\n",
            "  )\n",
            ")\n",
            "the number of parameters 10517606\n",
            "Loading SAVED model at from /content/tabsyn/baselines/stasy/ckpt/default/model.pth\n",
            "Start sampling...\n",
            "(27000, 10)\n",
            "Sampling time = 27.812456369400024\n",
            "Saving sampled data to default_syn.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname shoppers --method stasy --mode train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIV5D1YmDu2C",
        "outputId": "396fcc80-d1e0-4592-a0d4-7d9e16194df6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No NaNs in numerical features, skipping\n",
            "77\n",
            "NCSNpp(\n",
            "  (act): ELU(alpha=1.0)\n",
            "  (all_modules): ModuleList(\n",
            "    (0): GaussianFourierProjection()\n",
            "    (1): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (3): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=77, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (4): ELU(alpha=1.0)\n",
            "    (5): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=1101, out_features=2048, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=2048, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=2048, bias=True)\n",
            "    )\n",
            "    (6): ELU(alpha=1.0)\n",
            "    (7): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=3149, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (8): ELU(alpha=1.0)\n",
            "    (9): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=4173, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (10): ELU(alpha=1.0)\n",
            "    (11): Linear(in_features=5197, out_features=77, bias=True)\n",
            "  )\n",
            ")\n",
            "the number of parameters 10351030\n",
            "epoch: 0, iter: 11, training_loss: 3.65814e+00\n",
            "epoch: 1, iter: 11, training_loss: 2.09271e+00\n",
            "epoch: 2, iter: 11, training_loss: 1.31195e+00\n",
            "epoch: 3, iter: 11, training_loss: 1.35203e+00\n",
            "epoch: 4, iter: 11, training_loss: 1.26142e+00\n",
            "epoch: 5, iter: 11, training_loss: 1.34207e+00\n",
            "epoch: 6, iter: 11, training_loss: 1.23606e+00\n",
            "epoch: 7, iter: 11, training_loss: 1.28056e+00\n",
            "epoch: 8, iter: 11, training_loss: 1.22472e+00\n",
            "epoch: 9, iter: 11, training_loss: 1.23089e+00\n",
            "epoch: 10, iter: 11, training_loss: 1.28502e+00\n",
            "epoch: 11, iter: 11, training_loss: 1.25668e+00\n",
            "epoch: 12, iter: 11, training_loss: 1.22448e+00\n",
            "epoch: 13, iter: 11, training_loss: 1.28053e+00\n",
            "epoch: 14, iter: 11, training_loss: 1.22222e+00\n",
            "epoch: 15, iter: 11, training_loss: 1.22799e+00\n",
            "epoch: 16, iter: 11, training_loss: 1.19519e+00\n",
            "epoch: 17, iter: 11, training_loss: 1.17584e+00\n",
            "epoch: 18, iter: 11, training_loss: 1.20252e+00\n",
            "epoch: 19, iter: 11, training_loss: 1.12785e+00\n",
            "epoch: 20, iter: 11, training_loss: 1.17803e+00\n",
            "epoch: 21, iter: 11, training_loss: 1.21321e+00\n",
            "epoch: 22, iter: 11, training_loss: 1.09396e+00\n",
            "epoch: 23, iter: 11, training_loss: 1.16327e+00\n",
            "epoch: 24, iter: 11, training_loss: 1.15639e+00\n",
            "epoch: 25, iter: 11, training_loss: 1.12393e+00\n",
            "epoch: 26, iter: 11, training_loss: 1.07974e+00\n",
            "epoch: 27, iter: 11, training_loss: 1.05793e+00\n",
            "epoch: 28, iter: 11, training_loss: 1.14771e+00\n",
            "epoch: 29, iter: 11, training_loss: 1.10671e+00\n",
            "epoch: 30, iter: 11, training_loss: 1.07732e+00\n",
            "epoch: 31, iter: 11, training_loss: 1.08982e+00\n",
            "epoch: 32, iter: 11, training_loss: 1.06787e+00\n",
            "epoch: 33, iter: 11, training_loss: 1.07827e+00\n",
            "epoch: 34, iter: 11, training_loss: 1.09529e+00\n",
            "epoch: 35, iter: 11, training_loss: 1.01651e+00\n",
            "epoch: 36, iter: 11, training_loss: 1.08694e+00\n",
            "epoch: 37, iter: 11, training_loss: 1.03045e+00\n",
            "epoch: 38, iter: 11, training_loss: 1.04469e+00\n",
            "epoch: 39, iter: 11, training_loss: 1.03063e+00\n",
            "epoch: 40, iter: 11, training_loss: 1.06508e+00\n",
            "epoch: 41, iter: 11, training_loss: 1.13441e+00\n",
            "epoch: 42, iter: 11, training_loss: 1.03559e+00\n",
            "epoch: 43, iter: 11, training_loss: 1.10073e+00\n",
            "epoch: 44, iter: 11, training_loss: 1.10620e+00\n",
            "epoch: 45, iter: 11, training_loss: 1.07500e+00\n",
            "epoch: 46, iter: 11, training_loss: 1.02989e+00\n",
            "epoch: 47, iter: 11, training_loss: 1.01156e+00\n",
            "epoch: 48, iter: 11, training_loss: 1.05098e+00\n",
            "epoch: 49, iter: 11, training_loss: 1.02204e+00\n",
            "epoch: 50, iter: 11, training_loss: 1.02754e+00\n",
            "epoch: 51, iter: 11, training_loss: 1.08200e+00\n",
            "epoch: 52, iter: 11, training_loss: 1.11008e+00\n",
            "epoch: 53, iter: 11, training_loss: 1.04296e+00\n",
            "epoch: 54, iter: 11, training_loss: 1.10004e+00\n",
            "epoch: 55, iter: 11, training_loss: 1.13749e+00\n",
            "epoch: 56, iter: 11, training_loss: 1.12610e+00\n",
            "epoch: 57, iter: 11, training_loss: 1.10429e+00\n",
            "epoch: 58, iter: 11, training_loss: 1.05664e+00\n",
            "epoch: 59, iter: 11, training_loss: 1.18699e+00\n",
            "epoch: 60, iter: 11, training_loss: 1.08605e+00\n",
            "epoch: 61, iter: 11, training_loss: 1.22728e+00\n",
            "epoch: 62, iter: 11, training_loss: 1.18712e+00\n",
            "epoch: 63, iter: 11, training_loss: 1.06694e+00\n",
            "epoch: 64, iter: 11, training_loss: 1.12555e+00\n",
            "epoch: 65, iter: 11, training_loss: 1.08488e+00\n",
            "epoch: 66, iter: 11, training_loss: 1.06126e+00\n",
            "epoch: 67, iter: 11, training_loss: 1.13009e+00\n",
            "epoch: 68, iter: 11, training_loss: 1.10389e+00\n",
            "epoch: 69, iter: 11, training_loss: 1.15925e+00\n",
            "epoch: 70, iter: 11, training_loss: 1.08907e+00\n",
            "epoch: 71, iter: 11, training_loss: 1.07443e+00\n",
            "epoch: 72, iter: 11, training_loss: 1.13227e+00\n",
            "epoch: 73, iter: 11, training_loss: 1.12326e+00\n",
            "epoch: 74, iter: 11, training_loss: 1.15404e+00\n",
            "epoch: 75, iter: 11, training_loss: 1.12425e+00\n",
            "epoch: 76, iter: 11, training_loss: 1.43228e+00\n",
            "epoch: 77, iter: 11, training_loss: 1.50306e+00\n",
            "epoch: 78, iter: 11, training_loss: 1.22481e+00\n",
            "epoch: 79, iter: 11, training_loss: 1.06139e+00\n",
            "epoch: 80, iter: 11, training_loss: 1.27451e+00\n",
            "epoch: 81, iter: 11, training_loss: 1.14629e+00\n",
            "epoch: 82, iter: 11, training_loss: 1.13785e+00\n",
            "epoch: 83, iter: 11, training_loss: 1.22838e+00\n",
            "epoch: 84, iter: 11, training_loss: 1.08111e+00\n",
            "epoch: 85, iter: 11, training_loss: 1.05906e+00\n",
            "epoch: 86, iter: 11, training_loss: 1.43509e+00\n",
            "epoch: 87, iter: 11, training_loss: 1.15461e+00\n",
            "epoch: 88, iter: 11, training_loss: 1.20143e+00\n",
            "epoch: 89, iter: 11, training_loss: 1.28992e+00\n",
            "epoch: 90, iter: 11, training_loss: 1.33124e+00\n",
            "epoch: 91, iter: 11, training_loss: 1.23999e+00\n",
            "epoch: 92, iter: 11, training_loss: 1.41208e+00\n",
            "epoch: 93, iter: 11, training_loss: 1.45213e+00\n",
            "epoch: 94, iter: 11, training_loss: 1.37209e+00\n",
            "epoch: 95, iter: 11, training_loss: 1.32224e+00\n",
            "epoch: 96, iter: 11, training_loss: 1.30676e+00\n",
            "epoch: 97, iter: 11, training_loss: 1.31341e+00\n",
            "epoch: 98, iter: 11, training_loss: 1.66485e+00\n",
            "epoch: 99, iter: 11, training_loss: 1.53746e+00\n",
            "epoch: 100, iter: 11, training_loss: 1.26792e+00\n",
            "epoch: 101, iter: 11, training_loss: 1.18036e+00\n",
            "epoch: 102, iter: 11, training_loss: 1.36773e+00\n",
            "epoch: 103, iter: 11, training_loss: 1.29297e+00\n",
            "epoch: 104, iter: 11, training_loss: 1.25867e+00\n",
            "epoch: 105, iter: 11, training_loss: 1.37804e+00\n",
            "epoch: 106, iter: 11, training_loss: 1.20066e+00\n",
            "epoch: 107, iter: 11, training_loss: 1.35945e+00\n",
            "epoch: 108, iter: 11, training_loss: 1.44600e+00\n",
            "epoch: 109, iter: 11, training_loss: 1.56326e+00\n",
            "epoch: 110, iter: 11, training_loss: 1.48644e+00\n",
            "epoch: 111, iter: 11, training_loss: 1.45197e+00\n",
            "epoch: 112, iter: 11, training_loss: 1.39998e+00\n",
            "epoch: 113, iter: 11, training_loss: 1.33521e+00\n",
            "epoch: 114, iter: 11, training_loss: 1.27813e+00\n",
            "epoch: 115, iter: 11, training_loss: 1.29836e+00\n",
            "epoch: 116, iter: 11, training_loss: 1.22664e+00\n",
            "epoch: 117, iter: 11, training_loss: 1.70967e+00\n",
            "epoch: 118, iter: 11, training_loss: 1.41796e+00\n",
            "epoch: 119, iter: 11, training_loss: 1.40683e+00\n",
            "epoch: 120, iter: 11, training_loss: 1.25730e+00\n",
            "epoch: 121, iter: 11, training_loss: 1.58799e+00\n",
            "epoch: 122, iter: 11, training_loss: 1.49549e+00\n",
            "epoch: 123, iter: 11, training_loss: 1.64911e+00\n",
            "epoch: 124, iter: 11, training_loss: 1.40653e+00\n",
            "epoch: 125, iter: 11, training_loss: 1.61358e+00\n",
            "epoch: 126, iter: 11, training_loss: 1.37082e+00\n",
            "epoch: 127, iter: 11, training_loss: 1.71186e+00\n",
            "epoch: 128, iter: 11, training_loss: 1.49458e+00\n",
            "epoch: 129, iter: 11, training_loss: 1.73153e+00\n",
            "epoch: 130, iter: 11, training_loss: 1.75619e+00\n",
            "epoch: 131, iter: 11, training_loss: 1.59971e+00\n",
            "epoch: 132, iter: 11, training_loss: 1.59986e+00\n",
            "epoch: 133, iter: 11, training_loss: 1.76413e+00\n",
            "epoch: 134, iter: 11, training_loss: 1.85898e+00\n",
            "epoch: 135, iter: 11, training_loss: 1.53162e+00\n",
            "epoch: 136, iter: 11, training_loss: 1.49543e+00\n",
            "epoch: 137, iter: 11, training_loss: 1.60850e+00\n",
            "epoch: 138, iter: 11, training_loss: 1.52588e+00\n",
            "epoch: 139, iter: 11, training_loss: 1.68891e+00\n",
            "epoch: 140, iter: 11, training_loss: 1.66725e+00\n",
            "epoch: 141, iter: 11, training_loss: 1.57242e+00\n",
            "epoch: 142, iter: 11, training_loss: 1.73686e+00\n",
            "epoch: 143, iter: 11, training_loss: 1.35795e+00\n",
            "epoch: 144, iter: 11, training_loss: 1.57321e+00\n",
            "epoch: 145, iter: 11, training_loss: 1.54999e+00\n",
            "epoch: 146, iter: 11, training_loss: 1.71192e+00\n",
            "epoch: 147, iter: 11, training_loss: 1.61527e+00\n",
            "epoch: 148, iter: 11, training_loss: 2.31803e+00\n",
            "epoch: 149, iter: 11, training_loss: 1.59617e+00\n",
            "epoch: 150, iter: 11, training_loss: 1.43820e+00\n",
            "epoch: 151, iter: 11, training_loss: 1.69761e+00\n",
            "epoch: 152, iter: 11, training_loss: 1.80420e+00\n",
            "epoch: 153, iter: 11, training_loss: 1.70100e+00\n",
            "epoch: 154, iter: 11, training_loss: 1.75766e+00\n",
            "epoch: 155, iter: 11, training_loss: 1.92442e+00\n",
            "epoch: 156, iter: 11, training_loss: 1.71555e+00\n",
            "epoch: 157, iter: 11, training_loss: 1.92230e+00\n",
            "epoch: 158, iter: 11, training_loss: 1.68559e+00\n",
            "epoch: 159, iter: 11, training_loss: 1.75440e+00\n",
            "epoch: 160, iter: 11, training_loss: 1.49030e+00\n",
            "epoch: 161, iter: 11, training_loss: 1.55319e+00\n",
            "epoch: 162, iter: 11, training_loss: 1.56559e+00\n",
            "epoch: 163, iter: 11, training_loss: 1.45104e+00\n",
            "epoch: 164, iter: 11, training_loss: 1.66568e+00\n",
            "epoch: 165, iter: 11, training_loss: 1.65877e+00\n",
            "epoch: 166, iter: 11, training_loss: 1.61159e+00\n",
            "epoch: 167, iter: 11, training_loss: 1.78649e+00\n",
            "epoch: 168, iter: 11, training_loss: 2.14577e+00\n",
            "epoch: 169, iter: 11, training_loss: 2.18761e+00\n",
            "epoch: 170, iter: 11, training_loss: 1.90858e+00\n",
            "epoch: 171, iter: 11, training_loss: 2.56344e+00\n",
            "epoch: 172, iter: 11, training_loss: 2.00240e+00\n",
            "epoch: 173, iter: 11, training_loss: 1.93915e+00\n",
            "epoch: 174, iter: 11, training_loss: 1.91124e+00\n",
            "epoch: 175, iter: 11, training_loss: 1.96605e+00\n",
            "epoch: 176, iter: 11, training_loss: 2.34849e+00\n",
            "epoch: 177, iter: 11, training_loss: 1.92328e+00\n",
            "epoch: 178, iter: 11, training_loss: 1.96332e+00\n",
            "epoch: 179, iter: 11, training_loss: 1.74406e+00\n",
            "epoch: 180, iter: 11, training_loss: 3.15547e+00\n",
            "epoch: 181, iter: 11, training_loss: 2.36975e+00\n",
            "epoch: 182, iter: 11, training_loss: 2.04665e+00\n",
            "epoch: 183, iter: 11, training_loss: 2.30974e+00\n",
            "epoch: 184, iter: 11, training_loss: 2.18653e+00\n",
            "epoch: 185, iter: 11, training_loss: 2.49917e+00\n",
            "epoch: 186, iter: 11, training_loss: 2.18545e+00\n",
            "epoch: 187, iter: 11, training_loss: 2.54785e+00\n",
            "epoch: 188, iter: 11, training_loss: 2.71400e+00\n",
            "epoch: 189, iter: 11, training_loss: 2.23145e+00\n",
            "epoch: 190, iter: 11, training_loss: 2.69460e+00\n",
            "epoch: 191, iter: 11, training_loss: 2.23835e+00\n",
            "epoch: 192, iter: 11, training_loss: 2.04732e+00\n",
            "epoch: 193, iter: 11, training_loss: 2.46668e+00\n",
            "epoch: 194, iter: 11, training_loss: 2.04639e+00\n",
            "epoch: 195, iter: 11, training_loss: 1.85010e+00\n",
            "epoch: 196, iter: 11, training_loss: 2.23924e+00\n",
            "epoch: 197, iter: 11, training_loss: 1.81702e+00\n",
            "epoch: 198, iter: 11, training_loss: 2.31345e+00\n",
            "epoch: 199, iter: 11, training_loss: 2.00049e+00\n",
            "epoch: 200, iter: 11, training_loss: 1.88177e+00\n",
            "epoch: 201, iter: 11, training_loss: 2.33865e+00\n",
            "epoch: 202, iter: 11, training_loss: 2.82856e+00\n",
            "epoch: 203, iter: 11, training_loss: 1.92003e+00\n",
            "epoch: 204, iter: 11, training_loss: 1.86856e+00\n",
            "epoch: 205, iter: 11, training_loss: 1.95892e+00\n",
            "epoch: 206, iter: 11, training_loss: 1.73868e+00\n",
            "epoch: 207, iter: 11, training_loss: 2.05667e+00\n",
            "epoch: 208, iter: 11, training_loss: 2.13846e+00\n",
            "epoch: 209, iter: 11, training_loss: 2.24547e+00\n",
            "epoch: 210, iter: 11, training_loss: 1.71778e+00\n",
            "epoch: 211, iter: 11, training_loss: 1.87264e+00\n",
            "epoch: 212, iter: 11, training_loss: 1.85573e+00\n",
            "epoch: 213, iter: 11, training_loss: 1.78958e+00\n",
            "epoch: 214, iter: 11, training_loss: 1.88296e+00\n",
            "epoch: 215, iter: 11, training_loss: 1.78622e+00\n",
            "epoch: 216, iter: 11, training_loss: 2.26283e+00\n",
            "epoch: 217, iter: 11, training_loss: 2.16915e+00\n",
            "epoch: 218, iter: 11, training_loss: 2.49653e+00\n",
            "epoch: 219, iter: 11, training_loss: 2.23970e+00\n",
            "epoch: 220, iter: 11, training_loss: 2.88990e+00\n",
            "epoch: 221, iter: 11, training_loss: 2.10597e+00\n",
            "epoch: 222, iter: 11, training_loss: 2.03859e+00\n",
            "epoch: 223, iter: 11, training_loss: 1.74769e+00\n",
            "epoch: 224, iter: 11, training_loss: 2.25698e+00\n",
            "epoch: 225, iter: 11, training_loss: 2.44872e+00\n",
            "epoch: 226, iter: 11, training_loss: 2.73475e+00\n",
            "epoch: 227, iter: 11, training_loss: 2.63125e+00\n",
            "epoch: 228, iter: 11, training_loss: 2.26198e+00\n",
            "epoch: 229, iter: 11, training_loss: 2.07724e+00\n",
            "epoch: 230, iter: 11, training_loss: 2.45303e+00\n",
            "epoch: 231, iter: 11, training_loss: 2.66015e+00\n",
            "epoch: 232, iter: 11, training_loss: 2.53297e+00\n",
            "epoch: 233, iter: 11, training_loss: 2.13938e+00\n",
            "epoch: 234, iter: 11, training_loss: 1.84634e+00\n",
            "epoch: 235, iter: 11, training_loss: 2.75600e+00\n",
            "epoch: 236, iter: 11, training_loss: 2.17212e+00\n",
            "epoch: 237, iter: 11, training_loss: 2.78202e+00\n",
            "epoch: 238, iter: 11, training_loss: 2.35663e+00\n",
            "epoch: 239, iter: 11, training_loss: 2.54635e+00\n",
            "epoch: 240, iter: 11, training_loss: 2.17241e+00\n",
            "epoch: 241, iter: 11, training_loss: 2.19703e+00\n",
            "epoch: 242, iter: 11, training_loss: 2.19159e+00\n",
            "epoch: 243, iter: 11, training_loss: 1.99112e+00\n",
            "epoch: 244, iter: 11, training_loss: 1.99801e+00\n",
            "epoch: 245, iter: 11, training_loss: 2.55437e+00\n",
            "epoch: 246, iter: 11, training_loss: 2.03483e+00\n",
            "epoch: 247, iter: 11, training_loss: 2.02906e+00\n",
            "epoch: 248, iter: 11, training_loss: 2.08193e+00\n",
            "epoch: 249, iter: 11, training_loss: 2.34998e+00\n",
            "epoch: 250, iter: 11, training_loss: 2.06663e+00\n",
            "epoch: 251, iter: 11, training_loss: 2.29922e+00\n",
            "epoch: 252, iter: 11, training_loss: 2.40044e+00\n",
            "epoch: 253, iter: 11, training_loss: 3.02007e+00\n",
            "epoch: 254, iter: 11, training_loss: 2.96560e+00\n",
            "epoch: 255, iter: 11, training_loss: 2.55740e+00\n",
            "epoch: 256, iter: 11, training_loss: 2.66942e+00\n",
            "epoch: 257, iter: 11, training_loss: 2.40735e+00\n",
            "epoch: 258, iter: 11, training_loss: 2.39086e+00\n",
            "epoch: 259, iter: 11, training_loss: 2.80587e+00\n",
            "epoch: 260, iter: 11, training_loss: 2.33291e+00\n",
            "epoch: 261, iter: 11, training_loss: 2.82438e+00\n",
            "epoch: 262, iter: 11, training_loss: 2.65762e+00\n",
            "epoch: 263, iter: 11, training_loss: 2.23805e+00\n",
            "epoch: 264, iter: 11, training_loss: 2.78382e+00\n",
            "epoch: 265, iter: 11, training_loss: 2.55600e+00\n",
            "epoch: 266, iter: 11, training_loss: 2.48240e+00\n",
            "epoch: 267, iter: 11, training_loss: 2.85236e+00\n",
            "epoch: 268, iter: 11, training_loss: 3.20245e+00\n",
            "epoch: 269, iter: 11, training_loss: 2.81384e+00\n",
            "epoch: 270, iter: 11, training_loss: 2.59804e+00\n",
            "epoch: 271, iter: 11, training_loss: 2.75100e+00\n",
            "epoch: 272, iter: 11, training_loss: 2.63902e+00\n",
            "epoch: 273, iter: 11, training_loss: 2.94302e+00\n",
            "epoch: 274, iter: 11, training_loss: 2.66262e+00\n",
            "epoch: 275, iter: 11, training_loss: 3.32724e+00\n",
            "epoch: 276, iter: 11, training_loss: 2.35318e+00\n",
            "epoch: 277, iter: 11, training_loss: 2.81531e+00\n",
            "epoch: 278, iter: 11, training_loss: 2.85983e+00\n",
            "epoch: 279, iter: 11, training_loss: 3.02566e+00\n",
            "epoch: 280, iter: 11, training_loss: 2.61064e+00\n",
            "epoch: 281, iter: 11, training_loss: 3.01715e+00\n",
            "epoch: 282, iter: 11, training_loss: 3.46794e+00\n",
            "epoch: 283, iter: 11, training_loss: 3.58511e+00\n",
            "epoch: 284, iter: 11, training_loss: 2.99193e+00\n",
            "epoch: 285, iter: 11, training_loss: 3.70266e+00\n",
            "epoch: 286, iter: 11, training_loss: 2.31654e+00\n",
            "epoch: 287, iter: 11, training_loss: 2.65496e+00\n",
            "epoch: 288, iter: 11, training_loss: 2.34321e+00\n",
            "epoch: 289, iter: 11, training_loss: 2.50444e+00\n",
            "epoch: 290, iter: 11, training_loss: 2.41457e+00\n",
            "epoch: 291, iter: 11, training_loss: 2.81262e+00\n",
            "epoch: 292, iter: 11, training_loss: 3.56964e+00\n",
            "epoch: 293, iter: 11, training_loss: 2.80619e+00\n",
            "epoch: 294, iter: 11, training_loss: 2.95714e+00\n",
            "epoch: 295, iter: 11, training_loss: 2.65542e+00\n",
            "epoch: 296, iter: 11, training_loss: 2.82060e+00\n",
            "epoch: 297, iter: 11, training_loss: 3.20341e+00\n",
            "epoch: 298, iter: 11, training_loss: 2.67465e+00\n",
            "epoch: 299, iter: 11, training_loss: 3.11046e+00\n",
            "epoch: 300, iter: 11, training_loss: 3.03924e+00\n",
            "epoch: 301, iter: 11, training_loss: 2.44309e+00\n",
            "epoch: 302, iter: 11, training_loss: 2.50066e+00\n",
            "epoch: 303, iter: 11, training_loss: 3.06513e+00\n",
            "epoch: 304, iter: 11, training_loss: 2.84823e+00\n",
            "epoch: 305, iter: 11, training_loss: 2.73305e+00\n",
            "epoch: 306, iter: 11, training_loss: 2.71165e+00\n",
            "epoch: 307, iter: 11, training_loss: 3.59593e+00\n",
            "epoch: 308, iter: 11, training_loss: 3.17516e+00\n",
            "epoch: 309, iter: 11, training_loss: 2.79639e+00\n",
            "epoch: 310, iter: 11, training_loss: 2.66502e+00\n",
            "epoch: 311, iter: 11, training_loss: 2.68473e+00\n",
            "epoch: 312, iter: 11, training_loss: 2.36770e+00\n",
            "epoch: 313, iter: 11, training_loss: 2.49626e+00\n",
            "epoch: 314, iter: 11, training_loss: 2.75944e+00\n",
            "epoch: 315, iter: 11, training_loss: 2.76092e+00\n",
            "epoch: 316, iter: 11, training_loss: 2.66365e+00\n",
            "epoch: 317, iter: 11, training_loss: 2.69574e+00\n",
            "epoch: 318, iter: 11, training_loss: 2.60239e+00\n",
            "epoch: 319, iter: 11, training_loss: 3.20569e+00\n",
            "epoch: 320, iter: 11, training_loss: 2.87551e+00\n",
            "epoch: 321, iter: 11, training_loss: 2.63800e+00\n",
            "epoch: 322, iter: 11, training_loss: 2.75049e+00\n",
            "epoch: 323, iter: 11, training_loss: 3.01606e+00\n",
            "epoch: 324, iter: 11, training_loss: 2.47607e+00\n",
            "epoch: 325, iter: 11, training_loss: 2.58786e+00\n",
            "epoch: 326, iter: 11, training_loss: 2.45760e+00\n",
            "epoch: 327, iter: 11, training_loss: 3.23203e+00\n",
            "epoch: 328, iter: 11, training_loss: 2.38346e+00\n",
            "epoch: 329, iter: 11, training_loss: 3.25665e+00\n",
            "epoch: 330, iter: 11, training_loss: 2.17297e+00\n",
            "epoch: 331, iter: 11, training_loss: 2.68888e+00\n",
            "epoch: 332, iter: 11, training_loss: 2.75067e+00\n",
            "epoch: 333, iter: 11, training_loss: 3.21336e+00\n",
            "epoch: 334, iter: 11, training_loss: 2.51969e+00\n",
            "epoch: 335, iter: 11, training_loss: 2.58350e+00\n",
            "epoch: 336, iter: 11, training_loss: 2.65318e+00\n",
            "epoch: 337, iter: 11, training_loss: 2.84095e+00\n",
            "epoch: 338, iter: 11, training_loss: 2.86505e+00\n",
            "epoch: 339, iter: 11, training_loss: 2.87507e+00\n",
            "epoch: 340, iter: 11, training_loss: 3.09328e+00\n",
            "epoch: 341, iter: 11, training_loss: 2.91140e+00\n",
            "epoch: 342, iter: 11, training_loss: 2.29496e+00\n",
            "epoch: 343, iter: 11, training_loss: 2.90133e+00\n",
            "epoch: 344, iter: 11, training_loss: 3.24310e+00\n",
            "epoch: 345, iter: 11, training_loss: 2.83445e+00\n",
            "epoch: 346, iter: 11, training_loss: 2.93464e+00\n",
            "epoch: 347, iter: 11, training_loss: 3.54619e+00\n",
            "epoch: 348, iter: 11, training_loss: 2.98108e+00\n",
            "epoch: 349, iter: 11, training_loss: 2.64304e+00\n",
            "epoch: 350, iter: 11, training_loss: 2.36258e+00\n",
            "epoch: 351, iter: 11, training_loss: 2.40084e+00\n",
            "epoch: 352, iter: 11, training_loss: 2.70420e+00\n",
            "epoch: 353, iter: 11, training_loss: 3.02834e+00\n",
            "epoch: 354, iter: 11, training_loss: 3.68667e+00\n",
            "epoch: 355, iter: 11, training_loss: 2.85796e+00\n",
            "epoch: 356, iter: 11, training_loss: 3.07416e+00\n",
            "epoch: 357, iter: 11, training_loss: 2.93739e+00\n",
            "epoch: 358, iter: 11, training_loss: 3.17391e+00\n",
            "epoch: 359, iter: 11, training_loss: 2.74206e+00\n",
            "epoch: 360, iter: 11, training_loss: 3.16043e+00\n",
            "epoch: 361, iter: 11, training_loss: 2.82041e+00\n",
            "epoch: 362, iter: 11, training_loss: 2.74349e+00\n",
            "epoch: 363, iter: 11, training_loss: 3.52303e+00\n",
            "epoch: 364, iter: 11, training_loss: 4.13345e+00\n",
            "epoch: 365, iter: 11, training_loss: 4.17726e+00\n",
            "epoch: 366, iter: 11, training_loss: 2.96716e+00\n",
            "epoch: 367, iter: 11, training_loss: 2.73550e+00\n",
            "epoch: 368, iter: 11, training_loss: 3.30630e+00\n",
            "epoch: 369, iter: 11, training_loss: 3.11225e+00\n",
            "epoch: 370, iter: 11, training_loss: 3.33431e+00\n",
            "epoch: 371, iter: 11, training_loss: 2.52004e+00\n",
            "epoch: 372, iter: 11, training_loss: 2.51482e+00\n",
            "epoch: 373, iter: 11, training_loss: 2.59520e+00\n",
            "epoch: 374, iter: 11, training_loss: 2.92826e+00\n",
            "epoch: 375, iter: 11, training_loss: 2.68527e+00\n",
            "epoch: 376, iter: 11, training_loss: 2.50689e+00\n",
            "epoch: 377, iter: 11, training_loss: 2.36553e+00\n",
            "epoch: 378, iter: 11, training_loss: 2.80476e+00\n",
            "epoch: 379, iter: 11, training_loss: 2.68802e+00\n",
            "epoch: 380, iter: 11, training_loss: 3.06928e+00\n",
            "epoch: 381, iter: 11, training_loss: 3.14398e+00\n",
            "epoch: 382, iter: 11, training_loss: 2.77005e+00\n",
            "epoch: 383, iter: 11, training_loss: 2.31450e+00\n",
            "epoch: 384, iter: 11, training_loss: 2.86915e+00\n",
            "epoch: 385, iter: 11, training_loss: 3.35320e+00\n",
            "epoch: 386, iter: 11, training_loss: 2.70986e+00\n",
            "epoch: 387, iter: 11, training_loss: 2.37970e+00\n",
            "epoch: 388, iter: 11, training_loss: 2.66031e+00\n",
            "epoch: 389, iter: 11, training_loss: 3.33958e+00\n",
            "epoch: 390, iter: 11, training_loss: 2.92589e+00\n",
            "epoch: 391, iter: 11, training_loss: 3.82159e+00\n",
            "epoch: 392, iter: 11, training_loss: 2.74220e+00\n",
            "epoch: 393, iter: 11, training_loss: 2.72730e+00\n",
            "epoch: 394, iter: 11, training_loss: 3.48193e+00\n",
            "epoch: 395, iter: 11, training_loss: 3.18260e+00\n",
            "epoch: 396, iter: 11, training_loss: 3.32221e+00\n",
            "epoch: 397, iter: 11, training_loss: 2.88290e+00\n",
            "epoch: 398, iter: 11, training_loss: 3.06374e+00\n",
            "epoch: 399, iter: 11, training_loss: 2.59113e+00\n",
            "epoch: 400, iter: 11, training_loss: 2.86091e+00\n",
            "epoch: 401, iter: 11, training_loss: 3.30355e+00\n",
            "epoch: 402, iter: 11, training_loss: 2.74874e+00\n",
            "epoch: 403, iter: 11, training_loss: 3.30170e+00\n",
            "epoch: 404, iter: 11, training_loss: 3.41239e+00\n",
            "epoch: 405, iter: 11, training_loss: 4.26082e+00\n",
            "epoch: 406, iter: 11, training_loss: 3.20417e+00\n",
            "epoch: 407, iter: 11, training_loss: 3.17842e+00\n",
            "epoch: 408, iter: 11, training_loss: 4.08457e+00\n",
            "epoch: 409, iter: 11, training_loss: 2.48010e+00\n",
            "epoch: 410, iter: 11, training_loss: 3.17121e+00\n",
            "epoch: 411, iter: 11, training_loss: 2.83836e+00\n",
            "epoch: 412, iter: 11, training_loss: 2.37152e+00\n",
            "epoch: 413, iter: 11, training_loss: 2.83609e+00\n",
            "epoch: 414, iter: 11, training_loss: 2.22377e+00\n",
            "epoch: 415, iter: 11, training_loss: 2.09555e+00\n",
            "epoch: 416, iter: 11, training_loss: 2.49733e+00\n",
            "epoch: 417, iter: 11, training_loss: 2.38018e+00\n",
            "epoch: 418, iter: 11, training_loss: 2.46323e+00\n",
            "epoch: 419, iter: 11, training_loss: 3.39540e+00\n",
            "epoch: 420, iter: 11, training_loss: 2.70464e+00\n",
            "epoch: 421, iter: 11, training_loss: 2.30227e+00\n",
            "epoch: 422, iter: 11, training_loss: 3.05165e+00\n",
            "epoch: 423, iter: 11, training_loss: 2.22694e+00\n",
            "epoch: 424, iter: 11, training_loss: 2.84983e+00\n",
            "epoch: 425, iter: 11, training_loss: 2.76943e+00\n",
            "epoch: 426, iter: 11, training_loss: 2.94246e+00\n",
            "epoch: 427, iter: 11, training_loss: 2.90288e+00\n",
            "epoch: 428, iter: 11, training_loss: 2.88033e+00\n",
            "epoch: 429, iter: 11, training_loss: 2.74751e+00\n",
            "epoch: 430, iter: 11, training_loss: 2.85721e+00\n",
            "epoch: 431, iter: 11, training_loss: 3.15954e+00\n",
            "epoch: 432, iter: 11, training_loss: 2.92967e+00\n",
            "epoch: 433, iter: 11, training_loss: 2.81386e+00\n",
            "epoch: 434, iter: 11, training_loss: 2.52743e+00\n",
            "epoch: 435, iter: 11, training_loss: 2.61181e+00\n",
            "epoch: 436, iter: 11, training_loss: 2.69685e+00\n",
            "epoch: 437, iter: 11, training_loss: 2.30574e+00\n",
            "epoch: 438, iter: 11, training_loss: 2.01467e+00\n",
            "epoch: 439, iter: 11, training_loss: 2.40289e+00\n",
            "epoch: 440, iter: 11, training_loss: 2.33072e+00\n",
            "epoch: 441, iter: 11, training_loss: 2.99514e+00\n",
            "epoch: 442, iter: 11, training_loss: 3.32620e+00\n",
            "epoch: 443, iter: 11, training_loss: 2.61411e+00\n",
            "epoch: 444, iter: 11, training_loss: 2.33606e+00\n",
            "epoch: 445, iter: 11, training_loss: 1.96676e+00\n",
            "epoch: 446, iter: 11, training_loss: 2.60205e+00\n",
            "epoch: 447, iter: 11, training_loss: 2.73062e+00\n",
            "epoch: 448, iter: 11, training_loss: 2.75042e+00\n",
            "epoch: 449, iter: 11, training_loss: 2.26926e+00\n",
            "epoch: 450, iter: 11, training_loss: 2.17750e+00\n",
            "epoch: 451, iter: 11, training_loss: 2.03187e+00\n",
            "epoch: 452, iter: 11, training_loss: 2.17386e+00\n",
            "epoch: 453, iter: 11, training_loss: 2.88102e+00\n",
            "epoch: 454, iter: 11, training_loss: 2.09476e+00\n",
            "epoch: 455, iter: 11, training_loss: 1.93065e+00\n",
            "epoch: 456, iter: 11, training_loss: 2.32616e+00\n",
            "epoch: 457, iter: 11, training_loss: 2.61731e+00\n",
            "epoch: 458, iter: 11, training_loss: 1.85228e+00\n",
            "epoch: 459, iter: 11, training_loss: 2.17018e+00\n",
            "epoch: 460, iter: 11, training_loss: 1.83169e+00\n",
            "epoch: 461, iter: 11, training_loss: 1.66203e+00\n",
            "epoch: 462, iter: 11, training_loss: 1.96962e+00\n",
            "epoch: 463, iter: 11, training_loss: 2.22030e+00\n",
            "epoch: 464, iter: 11, training_loss: 2.16951e+00\n",
            "epoch: 465, iter: 11, training_loss: 2.56398e+00\n",
            "epoch: 466, iter: 11, training_loss: 2.12107e+00\n",
            "epoch: 467, iter: 11, training_loss: 2.07438e+00\n",
            "epoch: 468, iter: 11, training_loss: 1.72604e+00\n",
            "epoch: 469, iter: 11, training_loss: 1.82535e+00\n",
            "epoch: 470, iter: 11, training_loss: 2.17347e+00\n",
            "epoch: 471, iter: 11, training_loss: 2.87115e+00\n",
            "epoch: 472, iter: 11, training_loss: 1.94695e+00\n",
            "epoch: 473, iter: 11, training_loss: 1.90677e+00\n",
            "epoch: 474, iter: 11, training_loss: 1.54539e+00\n",
            "epoch: 475, iter: 11, training_loss: 1.57101e+00\n",
            "epoch: 476, iter: 11, training_loss: 1.62213e+00\n",
            "epoch: 477, iter: 11, training_loss: 1.53169e+00\n",
            "epoch: 478, iter: 11, training_loss: 1.62544e+00\n",
            "epoch: 479, iter: 11, training_loss: 1.63952e+00\n",
            "epoch: 480, iter: 11, training_loss: 1.55111e+00\n",
            "epoch: 481, iter: 11, training_loss: 1.63936e+00\n",
            "epoch: 482, iter: 11, training_loss: 1.82621e+00\n",
            "epoch: 483, iter: 11, training_loss: 1.94370e+00\n",
            "epoch: 484, iter: 11, training_loss: 2.29421e+00\n",
            "epoch: 485, iter: 11, training_loss: 1.92093e+00\n",
            "epoch: 486, iter: 11, training_loss: 1.64810e+00\n",
            "epoch: 487, iter: 11, training_loss: 1.55439e+00\n",
            "epoch: 488, iter: 11, training_loss: 1.41290e+00\n",
            "epoch: 489, iter: 11, training_loss: 1.52927e+00\n",
            "epoch: 490, iter: 11, training_loss: 1.43576e+00\n",
            "epoch: 491, iter: 11, training_loss: 1.27955e+00\n",
            "epoch: 492, iter: 11, training_loss: 1.57743e+00\n",
            "epoch: 493, iter: 11, training_loss: 1.41683e+00\n",
            "epoch: 494, iter: 11, training_loss: 1.32201e+00\n",
            "epoch: 495, iter: 11, training_loss: 1.29992e+00\n",
            "epoch: 496, iter: 11, training_loss: 1.80468e+00\n",
            "epoch: 497, iter: 11, training_loss: 1.65134e+00\n",
            "epoch: 498, iter: 11, training_loss: 1.40787e+00\n",
            "epoch: 499, iter: 11, training_loss: 1.28405e+00\n",
            "epoch: 500, iter: 11, training_loss: 1.10216e+00\n",
            "epoch: 501, iter: 11, training_loss: 1.32328e+00\n",
            "epoch: 502, iter: 11, training_loss: 1.48537e+00\n",
            "epoch: 503, iter: 11, training_loss: 1.18926e+00\n",
            "epoch: 504, iter: 11, training_loss: 1.43731e+00\n",
            "epoch: 505, iter: 11, training_loss: 1.30842e+00\n",
            "epoch: 506, iter: 11, training_loss: 1.01341e+00\n",
            "epoch: 507, iter: 11, training_loss: 9.98216e-01\n",
            "epoch: 508, iter: 11, training_loss: 1.13208e+00\n",
            "epoch: 509, iter: 11, training_loss: 2.08612e+00\n",
            "epoch: 510, iter: 11, training_loss: 1.42111e+00\n",
            "epoch: 511, iter: 11, training_loss: 1.16467e+00\n",
            "epoch: 512, iter: 11, training_loss: 9.94969e-01\n",
            "epoch: 513, iter: 11, training_loss: 1.04490e+00\n",
            "epoch: 514, iter: 11, training_loss: 9.21271e-01\n",
            "epoch: 515, iter: 11, training_loss: 1.03735e+00\n",
            "epoch: 516, iter: 11, training_loss: 1.01061e+00\n",
            "epoch: 517, iter: 11, training_loss: 9.15973e-01\n",
            "epoch: 518, iter: 11, training_loss: 9.81277e-01\n",
            "epoch: 519, iter: 11, training_loss: 1.00308e+00\n",
            "epoch: 520, iter: 11, training_loss: 9.86141e-01\n",
            "epoch: 521, iter: 11, training_loss: 9.96060e-01\n",
            "epoch: 522, iter: 11, training_loss: 1.20905e+00\n",
            "epoch: 523, iter: 11, training_loss: 1.02397e+00\n",
            "epoch: 524, iter: 11, training_loss: 9.29873e-01\n",
            "epoch: 525, iter: 11, training_loss: 9.69819e-01\n",
            "epoch: 526, iter: 11, training_loss: 8.75835e-01\n",
            "epoch: 527, iter: 11, training_loss: 1.17429e+00\n",
            "epoch: 528, iter: 11, training_loss: 1.00709e+00\n",
            "epoch: 529, iter: 11, training_loss: 8.84024e-01\n",
            "epoch: 530, iter: 11, training_loss: 8.71616e-01\n",
            "epoch: 531, iter: 11, training_loss: 1.10830e+00\n",
            "epoch: 532, iter: 11, training_loss: 1.06998e+00\n",
            "epoch: 533, iter: 11, training_loss: 8.65819e-01\n",
            "epoch: 534, iter: 11, training_loss: 8.78049e-01\n",
            "epoch: 535, iter: 11, training_loss: 8.99104e-01\n",
            "epoch: 536, iter: 11, training_loss: 1.04481e+00\n",
            "epoch: 537, iter: 11, training_loss: 1.05741e+00\n",
            "epoch: 538, iter: 11, training_loss: 1.09812e+00\n",
            "epoch: 539, iter: 11, training_loss: 1.23793e+00\n",
            "epoch: 540, iter: 11, training_loss: 9.71044e-01\n",
            "epoch: 541, iter: 11, training_loss: 8.67250e-01\n",
            "epoch: 542, iter: 11, training_loss: 8.30916e-01\n",
            "epoch: 543, iter: 11, training_loss: 8.69173e-01\n",
            "epoch: 544, iter: 11, training_loss: 8.91928e-01\n",
            "epoch: 545, iter: 11, training_loss: 9.01201e-01\n",
            "epoch: 546, iter: 11, training_loss: 8.74392e-01\n",
            "epoch: 547, iter: 11, training_loss: 1.08643e+00\n",
            "epoch: 548, iter: 11, training_loss: 1.11683e+00\n",
            "epoch: 549, iter: 11, training_loss: 8.12119e-01\n",
            "epoch: 550, iter: 11, training_loss: 7.83414e-01\n",
            "epoch: 551, iter: 11, training_loss: 8.81313e-01\n",
            "epoch: 552, iter: 11, training_loss: 8.53796e-01\n",
            "epoch: 553, iter: 11, training_loss: 1.28327e+00\n",
            "epoch: 554, iter: 11, training_loss: 1.29094e+00\n",
            "epoch: 555, iter: 11, training_loss: 1.16525e+00\n",
            "epoch: 556, iter: 11, training_loss: 9.43796e-01\n",
            "epoch: 557, iter: 11, training_loss: 8.91425e-01\n",
            "epoch: 558, iter: 11, training_loss: 8.01585e-01\n",
            "epoch: 559, iter: 11, training_loss: 7.74574e-01\n",
            "epoch: 560, iter: 11, training_loss: 8.50193e-01\n",
            "epoch: 561, iter: 11, training_loss: 8.26014e-01\n",
            "epoch: 562, iter: 11, training_loss: 8.66336e-01\n",
            "epoch: 563, iter: 11, training_loss: 8.05381e-01\n",
            "epoch: 564, iter: 11, training_loss: 9.45719e-01\n",
            "epoch: 565, iter: 11, training_loss: 1.15035e+00\n",
            "epoch: 566, iter: 11, training_loss: 9.88809e-01\n",
            "epoch: 567, iter: 11, training_loss: 8.21109e-01\n",
            "epoch: 568, iter: 11, training_loss: 8.54201e-01\n",
            "epoch: 569, iter: 11, training_loss: 7.82656e-01\n",
            "epoch: 570, iter: 11, training_loss: 8.48553e-01\n",
            "epoch: 571, iter: 11, training_loss: 7.52196e-01\n",
            "epoch: 572, iter: 11, training_loss: 9.03914e-01\n",
            "epoch: 573, iter: 11, training_loss: 8.71387e-01\n",
            "epoch: 574, iter: 11, training_loss: 7.50307e-01\n",
            "epoch: 575, iter: 11, training_loss: 9.32293e-01\n",
            "epoch: 576, iter: 11, training_loss: 7.23203e-01\n",
            "epoch: 577, iter: 11, training_loss: 7.73833e-01\n",
            "epoch: 578, iter: 11, training_loss: 8.26291e-01\n",
            "epoch: 579, iter: 11, training_loss: 8.06424e-01\n",
            "epoch: 580, iter: 11, training_loss: 1.08944e+00\n",
            "epoch: 581, iter: 11, training_loss: 8.29994e-01\n",
            "epoch: 582, iter: 11, training_loss: 8.04754e-01\n",
            "epoch: 583, iter: 11, training_loss: 8.02121e-01\n",
            "epoch: 584, iter: 11, training_loss: 1.13652e+00\n",
            "epoch: 585, iter: 11, training_loss: 1.20601e+00\n",
            "epoch: 586, iter: 11, training_loss: 9.10769e-01\n",
            "epoch: 587, iter: 11, training_loss: 8.20997e-01\n",
            "epoch: 588, iter: 11, training_loss: 7.59785e-01\n",
            "epoch: 589, iter: 11, training_loss: 7.85836e-01\n",
            "epoch: 590, iter: 11, training_loss: 8.33192e-01\n",
            "epoch: 591, iter: 11, training_loss: 7.07205e-01\n",
            "epoch: 592, iter: 11, training_loss: 1.17986e+00\n",
            "epoch: 593, iter: 11, training_loss: 1.17876e+00\n",
            "epoch: 594, iter: 11, training_loss: 8.73501e-01\n",
            "epoch: 595, iter: 11, training_loss: 7.23562e-01\n",
            "epoch: 596, iter: 11, training_loss: 7.21640e-01\n",
            "epoch: 597, iter: 11, training_loss: 6.97231e-01\n",
            "epoch: 598, iter: 11, training_loss: 7.41551e-01\n",
            "epoch: 599, iter: 11, training_loss: 8.13346e-01\n",
            "epoch: 600, iter: 11, training_loss: 7.22696e-01\n",
            "epoch: 601, iter: 11, training_loss: 6.83732e-01\n",
            "epoch: 602, iter: 11, training_loss: 7.85938e-01\n",
            "epoch: 603, iter: 11, training_loss: 7.28769e-01\n",
            "epoch: 604, iter: 11, training_loss: 7.58544e-01\n",
            "epoch: 605, iter: 11, training_loss: 6.22497e-01\n",
            "epoch: 606, iter: 11, training_loss: 6.76405e-01\n",
            "epoch: 607, iter: 11, training_loss: 8.63092e-01\n",
            "epoch: 608, iter: 11, training_loss: 7.81277e-01\n",
            "epoch: 609, iter: 11, training_loss: 7.82945e-01\n",
            "epoch: 610, iter: 11, training_loss: 7.70237e-01\n",
            "epoch: 611, iter: 11, training_loss: 7.74976e-01\n",
            "epoch: 612, iter: 11, training_loss: 7.22584e-01\n",
            "epoch: 613, iter: 11, training_loss: 6.65162e-01\n",
            "epoch: 614, iter: 11, training_loss: 7.24485e-01\n",
            "epoch: 615, iter: 11, training_loss: 7.30583e-01\n",
            "epoch: 616, iter: 11, training_loss: 6.85015e-01\n",
            "epoch: 617, iter: 11, training_loss: 7.52200e-01\n",
            "epoch: 618, iter: 11, training_loss: 9.59575e-01\n",
            "epoch: 619, iter: 11, training_loss: 8.63466e-01\n",
            "epoch: 620, iter: 11, training_loss: 7.94663e-01\n",
            "epoch: 621, iter: 11, training_loss: 8.11953e-01\n",
            "epoch: 622, iter: 11, training_loss: 1.12238e+00\n",
            "epoch: 623, iter: 11, training_loss: 8.72146e-01\n",
            "epoch: 624, iter: 11, training_loss: 8.86397e-01\n",
            "epoch: 625, iter: 11, training_loss: 7.57067e-01\n",
            "epoch: 626, iter: 11, training_loss: 7.92154e-01\n",
            "epoch: 627, iter: 11, training_loss: 8.24500e-01\n",
            "epoch: 628, iter: 11, training_loss: 9.68425e-01\n",
            "epoch: 629, iter: 11, training_loss: 9.42565e-01\n",
            "epoch: 630, iter: 11, training_loss: 1.13288e+00\n",
            "epoch: 631, iter: 11, training_loss: 7.66757e-01\n",
            "epoch: 632, iter: 11, training_loss: 7.12794e-01\n",
            "epoch: 633, iter: 11, training_loss: 6.79654e-01\n",
            "epoch: 634, iter: 11, training_loss: 7.49334e-01\n",
            "epoch: 635, iter: 11, training_loss: 6.85789e-01\n",
            "epoch: 636, iter: 11, training_loss: 6.98109e-01\n",
            "epoch: 637, iter: 11, training_loss: 7.68153e-01\n",
            "epoch: 638, iter: 11, training_loss: 7.67573e-01\n",
            "epoch: 639, iter: 11, training_loss: 8.07947e-01\n",
            "epoch: 640, iter: 11, training_loss: 6.95818e-01\n",
            "epoch: 641, iter: 11, training_loss: 7.33193e-01\n",
            "epoch: 642, iter: 11, training_loss: 7.61186e-01\n",
            "epoch: 643, iter: 11, training_loss: 8.45845e-01\n",
            "epoch: 644, iter: 11, training_loss: 1.27397e+00\n",
            "epoch: 645, iter: 11, training_loss: 9.28319e-01\n",
            "epoch: 646, iter: 11, training_loss: 7.63829e-01\n",
            "epoch: 647, iter: 11, training_loss: 7.13679e-01\n",
            "epoch: 648, iter: 11, training_loss: 7.92073e-01\n",
            "epoch: 649, iter: 11, training_loss: 7.24117e-01\n",
            "epoch: 650, iter: 11, training_loss: 6.70013e-01\n",
            "epoch: 651, iter: 11, training_loss: 7.19896e-01\n",
            "epoch: 652, iter: 11, training_loss: 6.57672e-01\n",
            "epoch: 653, iter: 11, training_loss: 7.58897e-01\n",
            "epoch: 654, iter: 11, training_loss: 9.35729e-01\n",
            "epoch: 655, iter: 11, training_loss: 6.33529e-01\n",
            "epoch: 656, iter: 11, training_loss: 7.53101e-01\n",
            "epoch: 657, iter: 11, training_loss: 6.58275e-01\n",
            "epoch: 658, iter: 11, training_loss: 7.19517e-01\n",
            "epoch: 659, iter: 11, training_loss: 6.98182e-01\n",
            "epoch: 660, iter: 11, training_loss: 6.80868e-01\n",
            "epoch: 661, iter: 11, training_loss: 5.62199e-01\n",
            "epoch: 662, iter: 11, training_loss: 6.98010e-01\n",
            "epoch: 663, iter: 11, training_loss: 7.13928e-01\n",
            "epoch: 664, iter: 11, training_loss: 6.91783e-01\n",
            "epoch: 665, iter: 11, training_loss: 6.80812e-01\n",
            "epoch: 666, iter: 11, training_loss: 6.95180e-01\n",
            "epoch: 667, iter: 11, training_loss: 6.64152e-01\n",
            "epoch: 668, iter: 11, training_loss: 6.91426e-01\n",
            "epoch: 669, iter: 11, training_loss: 6.63096e-01\n",
            "epoch: 670, iter: 11, training_loss: 6.03187e-01\n",
            "epoch: 671, iter: 11, training_loss: 7.49419e-01\n",
            "epoch: 672, iter: 11, training_loss: 8.43864e-01\n",
            "epoch: 673, iter: 11, training_loss: 6.52750e-01\n",
            "epoch: 674, iter: 11, training_loss: 6.70959e-01\n",
            "epoch: 675, iter: 11, training_loss: 6.57225e-01\n",
            "epoch: 676, iter: 11, training_loss: 6.21013e-01\n",
            "epoch: 677, iter: 11, training_loss: 6.60863e-01\n",
            "epoch: 678, iter: 11, training_loss: 5.70950e-01\n",
            "epoch: 679, iter: 11, training_loss: 5.87890e-01\n",
            "epoch: 680, iter: 11, training_loss: 6.38088e-01\n",
            "epoch: 681, iter: 11, training_loss: 6.12286e-01\n",
            "epoch: 682, iter: 11, training_loss: 6.51504e-01\n",
            "epoch: 683, iter: 11, training_loss: 6.45418e-01\n",
            "epoch: 684, iter: 11, training_loss: 6.11649e-01\n",
            "epoch: 685, iter: 11, training_loss: 6.91080e-01\n",
            "epoch: 686, iter: 11, training_loss: 5.44405e-01\n",
            "epoch: 687, iter: 11, training_loss: 5.55352e-01\n",
            "epoch: 688, iter: 11, training_loss: 6.13759e-01\n",
            "epoch: 689, iter: 11, training_loss: 6.44826e-01\n",
            "epoch: 690, iter: 11, training_loss: 6.10212e-01\n",
            "epoch: 691, iter: 11, training_loss: 6.15592e-01\n",
            "epoch: 692, iter: 11, training_loss: 5.79595e-01\n",
            "epoch: 693, iter: 11, training_loss: 5.08754e-01\n",
            "epoch: 694, iter: 11, training_loss: 6.02769e-01\n",
            "epoch: 695, iter: 11, training_loss: 5.99357e-01\n",
            "epoch: 696, iter: 11, training_loss: 6.55327e-01\n",
            "epoch: 697, iter: 11, training_loss: 5.96428e-01\n",
            "epoch: 698, iter: 11, training_loss: 5.45152e-01\n",
            "epoch: 699, iter: 11, training_loss: 5.99496e-01\n",
            "epoch: 700, iter: 11, training_loss: 5.42551e-01\n",
            "epoch: 701, iter: 11, training_loss: 5.37756e-01\n",
            "epoch: 702, iter: 11, training_loss: 4.74768e-01\n",
            "epoch: 703, iter: 11, training_loss: 5.24559e-01\n",
            "epoch: 704, iter: 11, training_loss: 5.36117e-01\n",
            "epoch: 705, iter: 11, training_loss: 5.72201e-01\n",
            "epoch: 706, iter: 11, training_loss: 6.31119e-01\n",
            "epoch: 707, iter: 11, training_loss: 5.26575e-01\n",
            "epoch: 708, iter: 11, training_loss: 4.90999e-01\n",
            "epoch: 709, iter: 11, training_loss: 5.71628e-01\n",
            "epoch: 710, iter: 11, training_loss: 5.96708e-01\n",
            "epoch: 711, iter: 11, training_loss: 4.51684e-01\n",
            "epoch: 712, iter: 11, training_loss: 4.82590e-01\n",
            "epoch: 713, iter: 11, training_loss: 5.76154e-01\n",
            "epoch: 714, iter: 11, training_loss: 4.64352e-01\n",
            "epoch: 715, iter: 11, training_loss: 5.13592e-01\n",
            "epoch: 716, iter: 11, training_loss: 5.18893e-01\n",
            "epoch: 717, iter: 11, training_loss: 5.60301e-01\n",
            "epoch: 718, iter: 11, training_loss: 5.79232e-01\n",
            "epoch: 719, iter: 11, training_loss: 5.25764e-01\n",
            "epoch: 720, iter: 11, training_loss: 4.56642e-01\n",
            "epoch: 721, iter: 11, training_loss: 5.66049e-01\n",
            "epoch: 722, iter: 11, training_loss: 5.74802e-01\n",
            "epoch: 723, iter: 11, training_loss: 5.71998e-01\n",
            "epoch: 724, iter: 11, training_loss: 5.00125e-01\n",
            "epoch: 725, iter: 11, training_loss: 5.14486e-01\n",
            "epoch: 726, iter: 11, training_loss: 4.39990e-01\n",
            "epoch: 727, iter: 11, training_loss: 4.87082e-01\n",
            "epoch: 728, iter: 11, training_loss: 4.93015e-01\n",
            "epoch: 729, iter: 11, training_loss: 5.59159e-01\n",
            "epoch: 730, iter: 11, training_loss: 5.41414e-01\n",
            "epoch: 731, iter: 11, training_loss: 4.87793e-01\n",
            "epoch: 732, iter: 11, training_loss: 4.29707e-01\n",
            "epoch: 733, iter: 11, training_loss: 4.71434e-01\n",
            "epoch: 734, iter: 11, training_loss: 4.77684e-01\n",
            "epoch: 735, iter: 11, training_loss: 5.07969e-01\n",
            "epoch: 736, iter: 11, training_loss: 5.16839e-01\n",
            "epoch: 737, iter: 11, training_loss: 4.56709e-01\n",
            "epoch: 738, iter: 11, training_loss: 4.56600e-01\n",
            "epoch: 739, iter: 11, training_loss: 4.52889e-01\n",
            "epoch: 740, iter: 11, training_loss: 4.30509e-01\n",
            "epoch: 741, iter: 11, training_loss: 4.38688e-01\n",
            "epoch: 742, iter: 11, training_loss: 4.33811e-01\n",
            "epoch: 743, iter: 11, training_loss: 4.22872e-01\n",
            "epoch: 744, iter: 11, training_loss: 5.13657e-01\n",
            "epoch: 745, iter: 11, training_loss: 5.10493e-01\n",
            "epoch: 746, iter: 11, training_loss: 4.47850e-01\n",
            "epoch: 747, iter: 11, training_loss: 5.05151e-01\n",
            "epoch: 748, iter: 11, training_loss: 4.81132e-01\n",
            "epoch: 749, iter: 11, training_loss: 4.71544e-01\n",
            "epoch: 750, iter: 11, training_loss: 4.81931e-01\n",
            "epoch: 751, iter: 11, training_loss: 5.15365e-01\n",
            "epoch: 752, iter: 11, training_loss: 4.50993e-01\n",
            "epoch: 753, iter: 11, training_loss: 5.21212e-01\n",
            "epoch: 754, iter: 11, training_loss: 5.03738e-01\n",
            "epoch: 755, iter: 11, training_loss: 5.18469e-01\n",
            "epoch: 756, iter: 11, training_loss: 4.93628e-01\n",
            "epoch: 757, iter: 11, training_loss: 4.97100e-01\n",
            "epoch: 758, iter: 11, training_loss: 4.62255e-01\n",
            "epoch: 759, iter: 11, training_loss: 4.46766e-01\n",
            "epoch: 760, iter: 11, training_loss: 3.92366e-01\n",
            "epoch: 761, iter: 11, training_loss: 3.89985e-01\n",
            "epoch: 762, iter: 11, training_loss: 4.53003e-01\n",
            "epoch: 763, iter: 11, training_loss: 4.59408e-01\n",
            "epoch: 764, iter: 11, training_loss: 4.36681e-01\n",
            "epoch: 765, iter: 11, training_loss: 4.22110e-01\n",
            "epoch: 766, iter: 11, training_loss: 4.14532e-01\n",
            "epoch: 767, iter: 11, training_loss: 4.39505e-01\n",
            "epoch: 768, iter: 11, training_loss: 4.83667e-01\n",
            "epoch: 769, iter: 11, training_loss: 4.23450e-01\n",
            "epoch: 770, iter: 11, training_loss: 3.79428e-01\n",
            "epoch: 771, iter: 11, training_loss: 5.03183e-01\n",
            "epoch: 772, iter: 11, training_loss: 4.88989e-01\n",
            "epoch: 773, iter: 11, training_loss: 5.75605e-01\n",
            "epoch: 774, iter: 11, training_loss: 4.88420e-01\n",
            "epoch: 775, iter: 11, training_loss: 5.64803e-01\n",
            "epoch: 776, iter: 11, training_loss: 3.91204e-01\n",
            "epoch: 777, iter: 11, training_loss: 3.86046e-01\n",
            "epoch: 778, iter: 11, training_loss: 3.52900e-01\n",
            "epoch: 779, iter: 11, training_loss: 3.53120e-01\n",
            "epoch: 780, iter: 11, training_loss: 4.02897e-01\n",
            "epoch: 781, iter: 11, training_loss: 4.61529e-01\n",
            "epoch: 782, iter: 11, training_loss: 3.79504e-01\n",
            "epoch: 783, iter: 11, training_loss: 4.24144e-01\n",
            "epoch: 784, iter: 11, training_loss: 4.46155e-01\n",
            "epoch: 785, iter: 11, training_loss: 4.63763e-01\n",
            "epoch: 786, iter: 11, training_loss: 4.20937e-01\n",
            "epoch: 787, iter: 11, training_loss: 4.15678e-01\n",
            "epoch: 788, iter: 11, training_loss: 4.58741e-01\n",
            "epoch: 789, iter: 11, training_loss: 4.13674e-01\n",
            "epoch: 790, iter: 11, training_loss: 3.98060e-01\n",
            "epoch: 791, iter: 11, training_loss: 3.89143e-01\n",
            "epoch: 792, iter: 11, training_loss: 3.80413e-01\n",
            "epoch: 793, iter: 11, training_loss: 4.59986e-01\n",
            "epoch: 794, iter: 11, training_loss: 4.08904e-01\n",
            "epoch: 795, iter: 11, training_loss: 4.38296e-01\n",
            "epoch: 796, iter: 11, training_loss: 4.49852e-01\n",
            "epoch: 797, iter: 11, training_loss: 4.81543e-01\n",
            "epoch: 798, iter: 11, training_loss: 4.18479e-01\n",
            "epoch: 799, iter: 11, training_loss: 4.14218e-01\n",
            "epoch: 800, iter: 11, training_loss: 5.10969e-01\n",
            "epoch: 801, iter: 11, training_loss: 4.81506e-01\n",
            "epoch: 802, iter: 11, training_loss: 4.70629e-01\n",
            "epoch: 803, iter: 11, training_loss: 4.26614e-01\n",
            "epoch: 804, iter: 11, training_loss: 4.70146e-01\n",
            "epoch: 805, iter: 11, training_loss: 4.64515e-01\n",
            "epoch: 806, iter: 11, training_loss: 4.95545e-01\n",
            "epoch: 807, iter: 11, training_loss: 4.65078e-01\n",
            "epoch: 808, iter: 11, training_loss: 4.01191e-01\n",
            "epoch: 809, iter: 11, training_loss: 4.34822e-01\n",
            "epoch: 810, iter: 11, training_loss: 4.34019e-01\n",
            "epoch: 811, iter: 11, training_loss: 4.32809e-01\n",
            "epoch: 812, iter: 11, training_loss: 4.15660e-01\n",
            "epoch: 813, iter: 11, training_loss: 3.71367e-01\n",
            "epoch: 814, iter: 11, training_loss: 3.40627e-01\n",
            "epoch: 815, iter: 11, training_loss: 4.85719e-01\n",
            "epoch: 816, iter: 11, training_loss: 5.64953e-01\n",
            "epoch: 817, iter: 11, training_loss: 5.00791e-01\n",
            "epoch: 818, iter: 11, training_loss: 4.32038e-01\n",
            "epoch: 819, iter: 11, training_loss: 4.50757e-01\n",
            "epoch: 820, iter: 11, training_loss: 4.19599e-01\n",
            "epoch: 821, iter: 11, training_loss: 4.00793e-01\n",
            "epoch: 822, iter: 11, training_loss: 3.81093e-01\n",
            "epoch: 823, iter: 11, training_loss: 3.90073e-01\n",
            "epoch: 824, iter: 11, training_loss: 4.77965e-01\n",
            "epoch: 825, iter: 11, training_loss: 4.04193e-01\n",
            "epoch: 826, iter: 11, training_loss: 4.02337e-01\n",
            "epoch: 827, iter: 11, training_loss: 3.88506e-01\n",
            "epoch: 828, iter: 11, training_loss: 4.91455e-01\n",
            "epoch: 829, iter: 11, training_loss: 4.95756e-01\n",
            "epoch: 830, iter: 11, training_loss: 5.68037e-01\n",
            "epoch: 831, iter: 11, training_loss: 4.34954e-01\n",
            "epoch: 832, iter: 11, training_loss: 4.26142e-01\n",
            "epoch: 833, iter: 11, training_loss: 4.51543e-01\n",
            "epoch: 834, iter: 11, training_loss: 4.19386e-01\n",
            "epoch: 835, iter: 11, training_loss: 4.94041e-01\n",
            "epoch: 836, iter: 11, training_loss: 4.39511e-01\n",
            "epoch: 837, iter: 11, training_loss: 3.99926e-01\n",
            "epoch: 838, iter: 11, training_loss: 4.71590e-01\n",
            "epoch: 839, iter: 11, training_loss: 3.72037e-01\n",
            "epoch: 840, iter: 11, training_loss: 3.66510e-01\n",
            "epoch: 841, iter: 11, training_loss: 4.25785e-01\n",
            "epoch: 842, iter: 11, training_loss: 5.37577e-01\n",
            "epoch: 843, iter: 11, training_loss: 4.64135e-01\n",
            "epoch: 844, iter: 11, training_loss: 5.05726e-01\n",
            "epoch: 845, iter: 11, training_loss: 4.54669e-01\n",
            "epoch: 846, iter: 11, training_loss: 4.22745e-01\n",
            "epoch: 847, iter: 11, training_loss: 4.13784e-01\n",
            "epoch: 848, iter: 11, training_loss: 3.85532e-01\n",
            "epoch: 849, iter: 11, training_loss: 4.12412e-01\n",
            "epoch: 850, iter: 11, training_loss: 4.11734e-01\n",
            "epoch: 851, iter: 11, training_loss: 3.60055e-01\n",
            "epoch: 852, iter: 11, training_loss: 4.53685e-01\n",
            "epoch: 853, iter: 11, training_loss: 4.50352e-01\n",
            "epoch: 854, iter: 11, training_loss: 4.28519e-01\n",
            "epoch: 855, iter: 11, training_loss: 4.26827e-01\n",
            "epoch: 856, iter: 11, training_loss: 3.63763e-01\n",
            "epoch: 857, iter: 11, training_loss: 3.73132e-01\n",
            "epoch: 858, iter: 11, training_loss: 4.49806e-01\n",
            "epoch: 859, iter: 11, training_loss: 4.48842e-01\n",
            "epoch: 860, iter: 11, training_loss: 3.91964e-01\n",
            "epoch: 861, iter: 11, training_loss: 4.57217e-01\n",
            "epoch: 862, iter: 11, training_loss: 4.10131e-01\n",
            "epoch: 863, iter: 11, training_loss: 4.06745e-01\n",
            "epoch: 864, iter: 11, training_loss: 4.20162e-01\n",
            "epoch: 865, iter: 11, training_loss: 3.55789e-01\n",
            "epoch: 866, iter: 11, training_loss: 4.16727e-01\n",
            "epoch: 867, iter: 11, training_loss: 4.30187e-01\n",
            "epoch: 868, iter: 11, training_loss: 3.90317e-01\n",
            "epoch: 869, iter: 11, training_loss: 4.30874e-01\n",
            "epoch: 870, iter: 11, training_loss: 4.30666e-01\n",
            "epoch: 871, iter: 11, training_loss: 4.53186e-01\n",
            "epoch: 872, iter: 11, training_loss: 3.71745e-01\n",
            "epoch: 873, iter: 11, training_loss: 4.20673e-01\n",
            "epoch: 874, iter: 11, training_loss: 4.16643e-01\n",
            "epoch: 875, iter: 11, training_loss: 4.10253e-01\n",
            "epoch: 876, iter: 11, training_loss: 3.51002e-01\n",
            "epoch: 877, iter: 11, training_loss: 3.83331e-01\n",
            "epoch: 878, iter: 11, training_loss: 3.91408e-01\n",
            "epoch: 879, iter: 11, training_loss: 3.42873e-01\n",
            "epoch: 880, iter: 11, training_loss: 4.00301e-01\n",
            "epoch: 881, iter: 11, training_loss: 3.84291e-01\n",
            "epoch: 882, iter: 11, training_loss: 4.42700e-01\n",
            "epoch: 883, iter: 11, training_loss: 3.85385e-01\n",
            "epoch: 884, iter: 11, training_loss: 4.00094e-01\n",
            "epoch: 885, iter: 11, training_loss: 4.73060e-01\n",
            "epoch: 886, iter: 11, training_loss: 3.83112e-01\n",
            "epoch: 887, iter: 11, training_loss: 4.25512e-01\n",
            "epoch: 888, iter: 11, training_loss: 3.70063e-01\n",
            "epoch: 889, iter: 11, training_loss: 3.56924e-01\n",
            "epoch: 890, iter: 11, training_loss: 3.49394e-01\n",
            "epoch: 891, iter: 11, training_loss: 4.72103e-01\n",
            "epoch: 892, iter: 11, training_loss: 3.75627e-01\n",
            "epoch: 893, iter: 11, training_loss: 3.80062e-01\n",
            "epoch: 894, iter: 11, training_loss: 4.69307e-01\n",
            "epoch: 895, iter: 11, training_loss: 4.12923e-01\n",
            "epoch: 896, iter: 11, training_loss: 4.10397e-01\n",
            "epoch: 897, iter: 11, training_loss: 4.86575e-01\n",
            "epoch: 898, iter: 11, training_loss: 4.17983e-01\n",
            "epoch: 899, iter: 11, training_loss: 4.51291e-01\n",
            "epoch: 900, iter: 11, training_loss: 3.84057e-01\n",
            "epoch: 901, iter: 11, training_loss: 4.23648e-01\n",
            "epoch: 902, iter: 11, training_loss: 3.41037e-01\n",
            "epoch: 903, iter: 11, training_loss: 3.98184e-01\n",
            "epoch: 904, iter: 11, training_loss: 4.19046e-01\n",
            "epoch: 905, iter: 11, training_loss: 4.04924e-01\n",
            "epoch: 906, iter: 11, training_loss: 4.40936e-01\n",
            "epoch: 907, iter: 11, training_loss: 4.22970e-01\n",
            "epoch: 908, iter: 11, training_loss: 4.79434e-01\n",
            "epoch: 909, iter: 11, training_loss: 3.49847e-01\n",
            "epoch: 910, iter: 11, training_loss: 3.40357e-01\n",
            "epoch: 911, iter: 11, training_loss: 4.11220e-01\n",
            "epoch: 912, iter: 11, training_loss: 4.19871e-01\n",
            "epoch: 913, iter: 11, training_loss: 3.83605e-01\n",
            "epoch: 914, iter: 11, training_loss: 3.39338e-01\n",
            "epoch: 915, iter: 11, training_loss: 3.62327e-01\n",
            "epoch: 916, iter: 11, training_loss: 3.59526e-01\n",
            "epoch: 917, iter: 11, training_loss: 4.03356e-01\n",
            "epoch: 918, iter: 11, training_loss: 4.70630e-01\n",
            "epoch: 919, iter: 11, training_loss: 4.40630e-01\n",
            "epoch: 920, iter: 11, training_loss: 4.44719e-01\n",
            "epoch: 921, iter: 11, training_loss: 3.90108e-01\n",
            "epoch: 922, iter: 11, training_loss: 4.32009e-01\n",
            "epoch: 923, iter: 11, training_loss: 4.65368e-01\n",
            "epoch: 924, iter: 11, training_loss: 4.84180e-01\n",
            "epoch: 925, iter: 11, training_loss: 4.42663e-01\n",
            "epoch: 926, iter: 11, training_loss: 4.06546e-01\n",
            "epoch: 927, iter: 11, training_loss: 3.54616e-01\n",
            "epoch: 928, iter: 11, training_loss: 3.50159e-01\n",
            "epoch: 929, iter: 11, training_loss: 5.02987e-01\n",
            "epoch: 930, iter: 11, training_loss: 4.77459e-01\n",
            "epoch: 931, iter: 11, training_loss: 4.20747e-01\n",
            "epoch: 932, iter: 11, training_loss: 3.86404e-01\n",
            "epoch: 933, iter: 11, training_loss: 4.25795e-01\n",
            "epoch: 934, iter: 11, training_loss: 4.15092e-01\n",
            "epoch: 935, iter: 11, training_loss: 3.78148e-01\n",
            "epoch: 936, iter: 11, training_loss: 3.30646e-01\n",
            "epoch: 937, iter: 11, training_loss: 3.65583e-01\n",
            "epoch: 938, iter: 11, training_loss: 3.76695e-01\n",
            "epoch: 939, iter: 11, training_loss: 3.54442e-01\n",
            "epoch: 940, iter: 11, training_loss: 3.75495e-01\n",
            "epoch: 941, iter: 11, training_loss: 4.14581e-01\n",
            "epoch: 942, iter: 11, training_loss: 3.58387e-01\n",
            "epoch: 943, iter: 11, training_loss: 3.61849e-01\n",
            "epoch: 944, iter: 11, training_loss: 3.88883e-01\n",
            "epoch: 945, iter: 11, training_loss: 3.68202e-01\n",
            "epoch: 946, iter: 11, training_loss: 4.07022e-01\n",
            "epoch: 947, iter: 11, training_loss: 3.91994e-01\n",
            "epoch: 948, iter: 11, training_loss: 3.74972e-01\n",
            "epoch: 949, iter: 11, training_loss: 3.56508e-01\n",
            "epoch: 950, iter: 11, training_loss: 3.46373e-01\n",
            "epoch: 951, iter: 11, training_loss: 3.47318e-01\n",
            "epoch: 952, iter: 11, training_loss: 3.67875e-01\n",
            "epoch: 953, iter: 11, training_loss: 3.60326e-01\n",
            "epoch: 954, iter: 11, training_loss: 3.56836e-01\n",
            "epoch: 955, iter: 11, training_loss: 3.05835e-01\n",
            "epoch: 956, iter: 11, training_loss: 3.26513e-01\n",
            "epoch: 957, iter: 11, training_loss: 4.21251e-01\n",
            "epoch: 958, iter: 11, training_loss: 3.61901e-01\n",
            "epoch: 959, iter: 11, training_loss: 3.98910e-01\n",
            "epoch: 960, iter: 11, training_loss: 4.40024e-01\n",
            "epoch: 961, iter: 11, training_loss: 3.95825e-01\n",
            "epoch: 962, iter: 11, training_loss: 3.52671e-01\n",
            "epoch: 963, iter: 11, training_loss: 4.65285e-01\n",
            "epoch: 964, iter: 11, training_loss: 4.46005e-01\n",
            "epoch: 965, iter: 11, training_loss: 3.64440e-01\n",
            "epoch: 966, iter: 11, training_loss: 4.14073e-01\n",
            "epoch: 967, iter: 11, training_loss: 3.49099e-01\n",
            "epoch: 968, iter: 11, training_loss: 3.50775e-01\n",
            "epoch: 969, iter: 11, training_loss: 4.35366e-01\n",
            "epoch: 970, iter: 11, training_loss: 4.20760e-01\n",
            "epoch: 971, iter: 11, training_loss: 3.95429e-01\n",
            "epoch: 972, iter: 11, training_loss: 3.40025e-01\n",
            "epoch: 973, iter: 11, training_loss: 3.07329e-01\n",
            "epoch: 974, iter: 11, training_loss: 4.09689e-01\n",
            "epoch: 975, iter: 11, training_loss: 4.84691e-01\n",
            "epoch: 976, iter: 11, training_loss: 3.97423e-01\n",
            "epoch: 977, iter: 11, training_loss: 4.06539e-01\n",
            "epoch: 978, iter: 11, training_loss: 3.84784e-01\n",
            "epoch: 979, iter: 11, training_loss: 3.63948e-01\n",
            "epoch: 980, iter: 11, training_loss: 3.59685e-01\n",
            "epoch: 981, iter: 11, training_loss: 3.72917e-01\n",
            "epoch: 982, iter: 11, training_loss: 3.17195e-01\n",
            "epoch: 983, iter: 11, training_loss: 3.30444e-01\n",
            "epoch: 984, iter: 11, training_loss: 4.13942e-01\n",
            "epoch: 985, iter: 11, training_loss: 4.14339e-01\n",
            "epoch: 986, iter: 11, training_loss: 3.70646e-01\n",
            "epoch: 987, iter: 11, training_loss: 3.73161e-01\n",
            "epoch: 988, iter: 11, training_loss: 3.64452e-01\n",
            "epoch: 989, iter: 11, training_loss: 3.43423e-01\n",
            "epoch: 990, iter: 11, training_loss: 3.79829e-01\n",
            "epoch: 991, iter: 11, training_loss: 4.21481e-01\n",
            "epoch: 992, iter: 11, training_loss: 3.49530e-01\n",
            "epoch: 993, iter: 11, training_loss: 3.94368e-01\n",
            "epoch: 994, iter: 11, training_loss: 3.27461e-01\n",
            "epoch: 995, iter: 11, training_loss: 4.22906e-01\n",
            "epoch: 996, iter: 11, training_loss: 3.59509e-01\n",
            "epoch: 997, iter: 11, training_loss: 3.94821e-01\n",
            "epoch: 998, iter: 11, training_loss: 3.52785e-01\n",
            "epoch: 999, iter: 11, training_loss: 3.59541e-01\n",
            "epoch: 1000, iter: 11, training_loss: 3.08519e-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname shoppers --method stasy --mode sample --save_path shoppers_syn.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3k-BWz1i1de",
        "outputId": "bd368054-9d93-4ef3-d19e-7e272d807747"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No NaNs in numerical features, skipping\n",
            "Input dimension: 77\n",
            "NCSNpp(\n",
            "  (act): ELU(alpha=1.0)\n",
            "  (all_modules): ModuleList(\n",
            "    (0): GaussianFourierProjection()\n",
            "    (1): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (3): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=77, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (4): ELU(alpha=1.0)\n",
            "    (5): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=1101, out_features=2048, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=2048, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=2048, bias=True)\n",
            "    )\n",
            "    (6): ELU(alpha=1.0)\n",
            "    (7): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=3149, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (8): ELU(alpha=1.0)\n",
            "    (9): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=4173, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (10): ELU(alpha=1.0)\n",
            "    (11): Linear(in_features=5197, out_features=77, bias=True)\n",
            "  )\n",
            ")\n",
            "the number of parameters 10351030\n",
            "Loading SAVED model at from /content/tabsyn/baselines/stasy/ckpt/shoppers/model.pth\n",
            "Start sampling...\n",
            "(11097, 8)\n",
            "Sampling time = 15.339011907577515\n",
            "Saving sampled data to shoppers_syn.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname beijing --method stasy --mode sample --save_path beijing_syn.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGnppkwU4g5n",
        "outputId": "899322f0-8dda-4957-da51-22916718c256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No NaNs in numerical features, skipping\n",
            "Input dimension: 83\n",
            "NCSNpp(\n",
            "  (act): ELU(alpha=1.0)\n",
            "  (all_modules): ModuleList(\n",
            "    (0): GaussianFourierProjection()\n",
            "    (1): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (3): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=83, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (4): ELU(alpha=1.0)\n",
            "    (5): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=1107, out_features=2048, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=2048, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=2048, bias=True)\n",
            "    )\n",
            "    (6): ELU(alpha=1.0)\n",
            "    (7): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=3155, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (8): ELU(alpha=1.0)\n",
            "    (9): ConcatSquashLinear(\n",
            "      (_layer): Linear(in_features=4179, out_features=1024, bias=True)\n",
            "      (_hyper_bias): Linear(in_features=1, out_features=1024, bias=False)\n",
            "      (_hyper_gate): Linear(in_features=1, out_features=1024, bias=True)\n",
            "    )\n",
            "    (10): ELU(alpha=1.0)\n",
            "    (11): Linear(in_features=5203, out_features=83, bias=True)\n",
            "  )\n",
            ")\n",
            "the number of parameters 10413436\n",
            "Loading SAVED model at from /content/tabsyn/baselines/stasy/ckpt/beijing/model.pth\n",
            "Start sampling...\n",
            "Sampling time = 73.09838771820068\n",
            "Saving sampled data to beijing_syn.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('gen_syn/adult_syn.csv')"
      ],
      "metadata": {
        "id": "XR-m4LQT5DLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "X5HrP_pT5JfQ",
        "outputId": "742d2be3-307b-47aa-cf55-b881e6471917",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             age          workclass      fnlwgt      education  education.num  \\\n",
              "0      21.268696            Private  122065.220        HS-grad            9.0   \n",
              "1      28.000000          Local-gov   35365.266           12th            8.0   \n",
              "2      28.000000            Private   21078.660           12th            8.0   \n",
              "3      32.463060            Private  105450.450        HS-grad            9.0   \n",
              "4      33.000000            Private   99170.750      Assoc-voc           11.0   \n",
              "...          ...                ...         ...            ...            ...   \n",
              "32556  28.000000            Private   32059.720   Some-college           10.0   \n",
              "32557  51.000000                  ?   37364.330    Prof-school           15.0   \n",
              "32558  19.000000            Private  196683.030   Some-college           10.0   \n",
              "32559  17.000000            Private  147142.170        HS-grad            9.0   \n",
              "32560  52.000000   Self-emp-not-inc   94072.195   Some-college           10.0   \n",
              "\n",
              "            marital.status          occupation    relationship    race  \\\n",
              "0            Never-married               Sales   Not-in-family   White   \n",
              "1            Never-married               Sales   Not-in-family   White   \n",
              "2            Never-married       Other-service       Unmarried   White   \n",
              "3            Never-married   Handlers-cleaners   Not-in-family   White   \n",
              "4       Married-civ-spouse        Craft-repair         Husband   Black   \n",
              "...                    ...                 ...             ...     ...   \n",
              "32556        Never-married   Handlers-cleaners       Own-child   White   \n",
              "32557   Married-civ-spouse                   ?         Husband   White   \n",
              "32558        Never-married   Handlers-cleaners       Own-child   White   \n",
              "32559        Never-married   Handlers-cleaners       Own-child   White   \n",
              "32560   Married-civ-spouse        Tech-support         Husband   White   \n",
              "\n",
              "           sex  capital.gain  capital.loss  hours.per.week  native.country  \\\n",
              "0       Female         0.000        0.0000            50.0   United-States   \n",
              "1         Male         0.000        0.0000            40.0   United-States   \n",
              "2       Female         0.000        0.0000            35.0   United-States   \n",
              "3         Male         0.000     2248.0703            40.0   United-States   \n",
              "4         Male         0.000        0.0000            40.0   United-States   \n",
              "...        ...           ...           ...             ...             ...   \n",
              "32556     Male         0.000        0.0000            40.0   United-States   \n",
              "32557     Male      5175.879        0.0000             8.0   United-States   \n",
              "32558     Male         0.000        0.0000            40.0   United-States   \n",
              "32559     Male         0.000        0.0000            10.0   United-States   \n",
              "32560     Male         0.000     2414.5137             6.0   United-States   \n",
              "\n",
              "       income  \n",
              "0       <=50K  \n",
              "1       <=50K  \n",
              "2       <=50K  \n",
              "3       <=50K  \n",
              "4       <=50K  \n",
              "...       ...  \n",
              "32556   <=50K  \n",
              "32557    >50K  \n",
              "32558   <=50K  \n",
              "32559   <=50K  \n",
              "32560   <=50K  \n",
              "\n",
              "[32561 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f56927ff-963f-41b6-8ed5-9af5b320d656\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education.num</th>\n",
              "      <th>marital.status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital.gain</th>\n",
              "      <th>capital.loss</th>\n",
              "      <th>hours.per.week</th>\n",
              "      <th>native.country</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21.268696</td>\n",
              "      <td>Private</td>\n",
              "      <td>122065.220</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Sales</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>50.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28.000000</td>\n",
              "      <td>Local-gov</td>\n",
              "      <td>35365.266</td>\n",
              "      <td>12th</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Sales</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28.000000</td>\n",
              "      <td>Private</td>\n",
              "      <td>21078.660</td>\n",
              "      <td>12th</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Other-service</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>35.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>32.463060</td>\n",
              "      <td>Private</td>\n",
              "      <td>105450.450</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2248.0703</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33.000000</td>\n",
              "      <td>Private</td>\n",
              "      <td>99170.750</td>\n",
              "      <td>Assoc-voc</td>\n",
              "      <td>11.0</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32556</th>\n",
              "      <td>28.000000</td>\n",
              "      <td>Private</td>\n",
              "      <td>32059.720</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32557</th>\n",
              "      <td>51.000000</td>\n",
              "      <td>?</td>\n",
              "      <td>37364.330</td>\n",
              "      <td>Prof-school</td>\n",
              "      <td>15.0</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>?</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>5175.879</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32558</th>\n",
              "      <td>19.000000</td>\n",
              "      <td>Private</td>\n",
              "      <td>196683.030</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32559</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>Private</td>\n",
              "      <td>147142.170</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>10.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32560</th>\n",
              "      <td>52.000000</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>94072.195</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Tech-support</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2414.5137</td>\n",
              "      <td>6.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32561 rows × 15 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f56927ff-963f-41b6-8ed5-9af5b320d656')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f56927ff-963f-41b6-8ed5-9af5b320d656 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f56927ff-963f-41b6-8ed5-9af5b320d656');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c1ff2185-8bc4-4ad3-92e5-90ef07e1a1fc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c1ff2185-8bc4-4ad3-92e5-90ef07e1a1fc')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c1ff2185-8bc4-4ad3-92e5-90ef07e1a1fc button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 32561,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.171284508499477,\n        \"min\": 17.0,\n        \"max\": 90.0,\n        \"num_unique_values\": 2090,\n        \"samples\": [\n          58.92868,\n          81.84867,\n          32.61907\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"workclass\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \" Without-pay\",\n          \" Local-gov\",\n          \" ?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fnlwgt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 88958.81621040749,\n        \"min\": 12285.886,\n        \"max\": 1483849.6,\n        \"num_unique_values\": 32544,\n        \"samples\": [\n          65496.652,\n          176857.3,\n          118802.36\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \" HS-grad\",\n          \" 12th\",\n          \" 7th-8th\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education.num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.5871884657555637,\n        \"min\": 1.0,\n        \"max\": 16.0,\n        \"num_unique_values\": 70,\n        \"samples\": [\n          2.0567443,\n          9.0,\n          5.6808934\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"marital.status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \" Never-married\",\n          \" Married-civ-spouse\",\n          \" Widowed\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"occupation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \" Tech-support\",\n          \" ?\",\n          \" Sales\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relationship\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \" Not-in-family\",\n          \" Unmarried\",\n          \" Wife\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"race\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \" Black\",\n          \" Amer-Indian-Eskimo\",\n          \" Asian-Pac-Islander\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \" Male\",\n          \" Female\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"capital.gain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8013.391488646674,\n        \"min\": 0.0,\n        \"max\": 99999.0,\n        \"num_unique_values\": 1888,\n        \"samples\": [\n          2015.94,\n          14179.636\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"capital.loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 794.2468843149129,\n        \"min\": 0.0,\n        \"max\": 4356.0,\n        \"num_unique_values\": 3895,\n        \"samples\": [\n          2249.4666,\n          1850.8204\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hours.per.week\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.886663179821529,\n        \"min\": 1.0,\n        \"max\": 99.0,\n        \"num_unique_values\": 2475,\n        \"samples\": [\n          44.734653,\n          87.94593\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"native.country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 41,\n        \"samples\": [\n          \" Guatemala\",\n          \" Iran\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"income\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \" >50K\",\n          \" <=50K\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CODI"
      ],
      "metadata": {
        "id": "ls-Q9w9dU0Hk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### adult"
      ],
      "metadata": {
        "id": "KcPjq270U80L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname adult --method codi --mode train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDT5VPSdUzHn",
        "outputId": "7674290e-9a57-4998-cb2f-3e98469c422d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "Epoch:532, step = 4263, Total continuous loss: 0.498, discrete loss: 0.375\n",
            "Time taken: 0.510\n",
            "Time taken: 0.421\n",
            "Time taken: 0.423\n",
            "Time taken: 0.422\n",
            "Time taken: 0.424\n",
            "Time taken: 0.423\n",
            "Time taken: 0.425\n",
            "Time taken: 0.422\n",
            "Epoch:533, step = 4271, diffusion continuous loss: 0.293, discrete loss: 0.215\n",
            "Epoch:533, step = 4271, CL continuous loss: 0.889, discrete loss: 0.780\n",
            "Epoch:533, step = 4271, Total continuous loss: 0.471, discrete loss: 0.371\n",
            "Time taken: 0.412\n",
            "Time taken: 0.429\n",
            "Time taken: 0.451\n",
            "Time taken: 0.446\n",
            "Time taken: 0.442\n",
            "Time taken: 0.448\n",
            "Time taken: 0.446\n",
            "Time taken: 0.420\n",
            "Epoch:534, step = 4279, diffusion continuous loss: 0.331, discrete loss: 0.217\n",
            "Epoch:534, step = 4279, CL continuous loss: 0.919, discrete loss: 0.790\n",
            "Epoch:534, step = 4279, Total continuous loss: 0.515, discrete loss: 0.375\n",
            "Time taken: 0.416\n",
            "Time taken: 0.423\n",
            "Time taken: 0.426\n",
            "Time taken: 0.418\n",
            "Time taken: 0.422\n",
            "Time taken: 0.426\n",
            "Time taken: 0.420\n",
            "Time taken: 0.426\n",
            "Epoch:535, step = 4287, diffusion continuous loss: 0.293, discrete loss: 0.222\n",
            "Epoch:535, step = 4287, CL continuous loss: 0.910, discrete loss: 0.798\n",
            "Epoch:535, step = 4287, Total continuous loss: 0.475, discrete loss: 0.382\n",
            "Time taken: 0.412\n",
            "Time taken: 0.425\n",
            "Time taken: 0.423\n",
            "Time taken: 0.420\n",
            "Time taken: 0.422\n",
            "Time taken: 0.424\n",
            "Time taken: 0.426\n",
            "Time taken: 0.451\n",
            "Epoch:536, step = 4295, diffusion continuous loss: 0.281, discrete loss: 0.217\n",
            "Epoch:536, step = 4295, CL continuous loss: 0.882, discrete loss: 0.785\n",
            "Epoch:536, step = 4295, Total continuous loss: 0.457, discrete loss: 0.374\n",
            "Time taken: 0.412\n",
            "Time taken: 0.421\n",
            "Time taken: 0.423\n",
            "Time taken: 0.421\n",
            "Time taken: 0.422\n",
            "Time taken: 0.423\n",
            "Time taken: 0.433\n",
            "Time taken: 0.572\n",
            "Epoch:537, step = 4303, diffusion continuous loss: 0.338, discrete loss: 0.217\n",
            "Epoch:537, step = 4303, CL continuous loss: 0.911, discrete loss: 0.778\n",
            "Epoch:537, step = 4303, Total continuous loss: 0.520, discrete loss: 0.373\n",
            "Time taken: 0.433\n",
            "Time taken: 0.461\n",
            "Time taken: 0.450\n",
            "Time taken: 0.437\n",
            "Time taken: 0.423\n",
            "Time taken: 0.423\n",
            "Time taken: 0.421\n",
            "Time taken: 0.421\n",
            "Epoch:538, step = 4311, diffusion continuous loss: 0.291, discrete loss: 0.214\n",
            "Epoch:538, step = 4311, CL continuous loss: 0.897, discrete loss: 0.792\n",
            "Epoch:538, step = 4311, Total continuous loss: 0.471, discrete loss: 0.372\n",
            "Time taken: 0.413\n",
            "Time taken: 0.424\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.422\n",
            "Time taken: 0.424\n",
            "Time taken: 0.420\n",
            "Time taken: 0.420\n",
            "Epoch:539, step = 4319, diffusion continuous loss: 0.281, discrete loss: 0.209\n",
            "Epoch:539, step = 4319, CL continuous loss: 0.875, discrete loss: 0.780\n",
            "Epoch:539, step = 4319, Total continuous loss: 0.456, discrete loss: 0.365\n",
            "Time taken: 0.414\n",
            "Time taken: 0.419\n",
            "Time taken: 0.426\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.421\n",
            "Epoch:540, step = 4327, diffusion continuous loss: 0.277, discrete loss: 0.207\n",
            "Epoch:540, step = 4327, CL continuous loss: 0.871, discrete loss: 0.777\n",
            "Epoch:540, step = 4327, Total continuous loss: 0.452, discrete loss: 0.363\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.422\n",
            "Time taken: 0.452\n",
            "Time taken: 0.444\n",
            "Time taken: 0.446\n",
            "Time taken: 0.454\n",
            "Time taken: 0.454\n",
            "Epoch:541, step = 4335, diffusion continuous loss: 0.271, discrete loss: 0.208\n",
            "Epoch:541, step = 4335, CL continuous loss: 0.886, discrete loss: 0.779\n",
            "Epoch:541, step = 4335, Total continuous loss: 0.448, discrete loss: 0.364\n",
            "Time taken: 0.414\n",
            "Time taken: 0.425\n",
            "Time taken: 0.417\n",
            "Time taken: 0.432\n",
            "Time taken: 0.420\n",
            "Time taken: 0.527\n",
            "Time taken: 0.423\n",
            "Time taken: 0.423\n",
            "Epoch:542, step = 4343, diffusion continuous loss: 0.287, discrete loss: 0.228\n",
            "Epoch:542, step = 4343, CL continuous loss: 0.869, discrete loss: 0.782\n",
            "Epoch:542, step = 4343, Total continuous loss: 0.461, discrete loss: 0.384\n",
            "Time taken: 0.413\n",
            "Time taken: 0.422\n",
            "Time taken: 0.422\n",
            "Time taken: 0.423\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.429\n",
            "Epoch:543, step = 4351, diffusion continuous loss: 0.297, discrete loss: 0.219\n",
            "Epoch:543, step = 4351, CL continuous loss: 0.893, discrete loss: 0.782\n",
            "Epoch:543, step = 4351, Total continuous loss: 0.475, discrete loss: 0.375\n",
            "Time taken: 0.413\n",
            "Time taken: 0.425\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.422\n",
            "Time taken: 0.428\n",
            "Epoch:544, step = 4359, diffusion continuous loss: 0.307, discrete loss: 0.219\n",
            "Epoch:544, step = 4359, CL continuous loss: 0.912, discrete loss: 0.779\n",
            "Epoch:544, step = 4359, Total continuous loss: 0.489, discrete loss: 0.374\n",
            "Time taken: 0.443\n",
            "Time taken: 0.449\n",
            "Time taken: 0.441\n",
            "Time taken: 0.447\n",
            "Time taken: 0.448\n",
            "Time taken: 0.437\n",
            "Time taken: 0.420\n",
            "Time taken: 0.424\n",
            "Epoch:545, step = 4367, diffusion continuous loss: 0.294, discrete loss: 0.213\n",
            "Epoch:545, step = 4367, CL continuous loss: 0.894, discrete loss: 0.777\n",
            "Epoch:545, step = 4367, Total continuous loss: 0.473, discrete loss: 0.368\n",
            "Time taken: 0.421\n",
            "Time taken: 0.419\n",
            "Time taken: 0.423\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.426\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Epoch:546, step = 4375, diffusion continuous loss: 0.277, discrete loss: 0.214\n",
            "Epoch:546, step = 4375, CL continuous loss: 0.881, discrete loss: 0.787\n",
            "Epoch:546, step = 4375, Total continuous loss: 0.454, discrete loss: 0.372\n",
            "Time taken: 0.410\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.422\n",
            "Time taken: 0.530\n",
            "Time taken: 0.420\n",
            "Time taken: 0.425\n",
            "Time taken: 0.418\n",
            "Epoch:547, step = 4383, diffusion continuous loss: 0.267, discrete loss: 0.215\n",
            "Epoch:547, step = 4383, CL continuous loss: 0.885, discrete loss: 0.802\n",
            "Epoch:547, step = 4383, Total continuous loss: 0.444, discrete loss: 0.376\n",
            "Time taken: 0.410\n",
            "Time taken: 0.435\n",
            "Time taken: 0.419\n",
            "Time taken: 0.429\n",
            "Time taken: 0.452\n",
            "Time taken: 0.444\n",
            "Time taken: 0.445\n",
            "Time taken: 0.445\n",
            "Epoch:548, step = 4391, diffusion continuous loss: 0.347, discrete loss: 0.211\n",
            "Epoch:548, step = 4391, CL continuous loss: 0.880, discrete loss: 0.791\n",
            "Epoch:548, step = 4391, Total continuous loss: 0.523, discrete loss: 0.369\n",
            "Time taken: 0.454\n",
            "Time taken: 0.427\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.422\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Epoch:549, step = 4399, diffusion continuous loss: 0.343, discrete loss: 0.224\n",
            "Epoch:549, step = 4399, CL continuous loss: 0.881, discrete loss: 0.795\n",
            "Epoch:549, step = 4399, Total continuous loss: 0.519, discrete loss: 0.383\n",
            "Time taken: 0.417\n",
            "Time taken: 0.428\n",
            "Time taken: 0.431\n",
            "Time taken: 0.419\n",
            "Time taken: 0.423\n",
            "Time taken: 0.422\n",
            "Time taken: 0.417\n",
            "Time taken: 0.422\n",
            "Epoch:550, step = 4407, diffusion continuous loss: 0.278, discrete loss: 0.218\n",
            "Epoch:550, step = 4407, CL continuous loss: 0.882, discrete loss: 0.786\n",
            "Epoch:550, step = 4407, Total continuous loss: 0.455, discrete loss: 0.375\n",
            "Time taken: 0.414\n",
            "Time taken: 0.421\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.420\n",
            "Time taken: 0.423\n",
            "Time taken: 0.417\n",
            "Time taken: 0.422\n",
            "Epoch:551, step = 4415, diffusion continuous loss: 0.283, discrete loss: 0.222\n",
            "Epoch:551, step = 4415, CL continuous loss: 0.888, discrete loss: 0.784\n",
            "Epoch:551, step = 4415, Total continuous loss: 0.460, discrete loss: 0.379\n",
            "Time taken: 0.417\n",
            "Time taken: 0.448\n",
            "Time taken: 0.574\n",
            "Time taken: 0.439\n",
            "Time taken: 0.452\n",
            "Time taken: 0.453\n",
            "Time taken: 0.422\n",
            "Time taken: 0.423\n",
            "Epoch:552, step = 4423, diffusion continuous loss: 0.279, discrete loss: 0.224\n",
            "Epoch:552, step = 4423, CL continuous loss: 0.873, discrete loss: 0.790\n",
            "Epoch:552, step = 4423, Total continuous loss: 0.454, discrete loss: 0.382\n",
            "Time taken: 0.410\n",
            "Time taken: 0.423\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.422\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.429\n",
            "Epoch:553, step = 4431, diffusion continuous loss: 0.268, discrete loss: 0.222\n",
            "Epoch:553, step = 4431, CL continuous loss: 0.867, discrete loss: 0.790\n",
            "Epoch:553, step = 4431, Total continuous loss: 0.441, discrete loss: 0.380\n",
            "Time taken: 0.413\n",
            "Time taken: 0.424\n",
            "Time taken: 0.418\n",
            "Time taken: 0.423\n",
            "Time taken: 0.426\n",
            "Time taken: 0.423\n",
            "Time taken: 0.426\n",
            "Time taken: 0.425\n",
            "Epoch:554, step = 4439, diffusion continuous loss: 0.298, discrete loss: 0.228\n",
            "Epoch:554, step = 4439, CL continuous loss: 0.871, discrete loss: 0.816\n",
            "Epoch:554, step = 4439, Total continuous loss: 0.473, discrete loss: 0.391\n",
            "Time taken: 0.411\n",
            "Time taken: 0.418\n",
            "Time taken: 0.424\n",
            "Time taken: 0.427\n",
            "Time taken: 0.425\n",
            "Time taken: 0.429\n",
            "Time taken: 0.444\n",
            "Time taken: 0.444\n",
            "Epoch:555, step = 4447, diffusion continuous loss: 0.286, discrete loss: 0.278\n",
            "Epoch:555, step = 4447, CL continuous loss: 0.892, discrete loss: 0.886\n",
            "Epoch:555, step = 4447, Total continuous loss: 0.465, discrete loss: 0.455\n",
            "Time taken: 0.433\n",
            "Time taken: 0.442\n",
            "Time taken: 0.446\n",
            "Time taken: 0.418\n",
            "Time taken: 0.425\n",
            "Time taken: 0.428\n",
            "Time taken: 0.421\n",
            "Time taken: 0.426\n",
            "Epoch:556, step = 4455, diffusion continuous loss: 0.282, discrete loss: 0.334\n",
            "Epoch:556, step = 4455, CL continuous loss: 0.878, discrete loss: 0.905\n",
            "Epoch:556, step = 4455, Total continuous loss: 0.457, discrete loss: 0.516\n",
            "Time taken: 0.415\n",
            "Time taken: 0.530\n",
            "Time taken: 0.424\n",
            "Time taken: 0.424\n",
            "Time taken: 0.426\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.422\n",
            "Epoch:557, step = 4463, diffusion continuous loss: 0.286, discrete loss: 0.304\n",
            "Epoch:557, step = 4463, CL continuous loss: 0.878, discrete loss: 0.863\n",
            "Epoch:557, step = 4463, Total continuous loss: 0.462, discrete loss: 0.477\n",
            "Time taken: 0.417\n",
            "Time taken: 0.427\n",
            "Time taken: 0.421\n",
            "Time taken: 0.427\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.424\n",
            "Time taken: 0.424\n",
            "Epoch:558, step = 4471, diffusion continuous loss: 0.297, discrete loss: 0.244\n",
            "Epoch:558, step = 4471, CL continuous loss: 0.900, discrete loss: 0.861\n",
            "Epoch:558, step = 4471, Total continuous loss: 0.477, discrete loss: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.422\n",
            "Time taken: 0.447\n",
            "Time taken: 0.440\n",
            "Time taken: 0.435\n",
            "Time taken: 0.453\n",
            "Time taken: 0.454\n",
            "Time taken: 0.419\n",
            "Epoch:559, step = 4479, diffusion continuous loss: 0.286, discrete loss: 0.244\n",
            "Epoch:559, step = 4479, CL continuous loss: 0.894, discrete loss: 0.840\n",
            "Epoch:559, step = 4479, Total continuous loss: 0.464, discrete loss: 0.412\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.433\n",
            "Time taken: 0.420\n",
            "Time taken: 0.423\n",
            "Time taken: 0.422\n",
            "Time taken: 0.424\n",
            "Time taken: 0.425\n",
            "Epoch:560, step = 4487, diffusion continuous loss: 0.265, discrete loss: 0.220\n",
            "Epoch:560, step = 4487, CL continuous loss: 0.880, discrete loss: 0.817\n",
            "Epoch:560, step = 4487, Total continuous loss: 0.441, discrete loss: 0.383\n",
            "Time taken: 0.415\n",
            "Time taken: 0.426\n",
            "Time taken: 0.426\n",
            "Time taken: 0.420\n",
            "Time taken: 0.420\n",
            "Time taken: 0.420\n",
            "Time taken: 0.424\n",
            "Time taken: 0.517\n",
            "Epoch:561, step = 4495, diffusion continuous loss: 0.277, discrete loss: 0.219\n",
            "Epoch:561, step = 4495, CL continuous loss: 0.871, discrete loss: 0.818\n",
            "Epoch:561, step = 4495, Total continuous loss: 0.451, discrete loss: 0.383\n",
            "Time taken: 0.417\n",
            "Time taken: 0.427\n",
            "Time taken: 0.421\n",
            "Time taken: 0.423\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.426\n",
            "Time taken: 0.450\n",
            "Epoch:562, step = 4503, diffusion continuous loss: 0.358, discrete loss: 0.226\n",
            "Epoch:562, step = 4503, CL continuous loss: 0.860, discrete loss: 0.808\n",
            "Epoch:562, step = 4503, Total continuous loss: 0.530, discrete loss: 0.388\n",
            "Time taken: 0.434\n",
            "Time taken: 0.437\n",
            "Time taken: 0.456\n",
            "Time taken: 0.452\n",
            "Time taken: 0.419\n",
            "Time taken: 0.424\n",
            "Time taken: 0.418\n",
            "Time taken: 0.433\n",
            "Epoch:563, step = 4511, diffusion continuous loss: 0.301, discrete loss: 0.212\n",
            "Epoch:563, step = 4511, CL continuous loss: 0.929, discrete loss: 0.805\n",
            "Epoch:563, step = 4511, Total continuous loss: 0.487, discrete loss: 0.373\n",
            "Time taken: 0.410\n",
            "Time taken: 0.427\n",
            "Time taken: 0.424\n",
            "Time taken: 0.423\n",
            "Time taken: 0.423\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.421\n",
            "Epoch:564, step = 4519, diffusion continuous loss: 0.297, discrete loss: 0.217\n",
            "Epoch:564, step = 4519, CL continuous loss: 0.896, discrete loss: 0.799\n",
            "Epoch:564, step = 4519, Total continuous loss: 0.476, discrete loss: 0.376\n",
            "Time taken: 0.413\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Time taken: 0.423\n",
            "Time taken: 0.424\n",
            "Time taken: 0.423\n",
            "Epoch:565, step = 4527, diffusion continuous loss: 0.269, discrete loss: 0.224\n",
            "Epoch:565, step = 4527, CL continuous loss: 0.878, discrete loss: 0.806\n",
            "Epoch:565, step = 4527, Total continuous loss: 0.444, discrete loss: 0.385\n",
            "Time taken: 0.419\n",
            "Time taken: 0.422\n",
            "Time taken: 0.419\n",
            "Time taken: 0.424\n",
            "Time taken: 0.448\n",
            "Time taken: 0.445\n",
            "Time taken: 0.566\n",
            "Time taken: 0.457\n",
            "Epoch:566, step = 4535, diffusion continuous loss: 0.274, discrete loss: 0.220\n",
            "Epoch:566, step = 4535, CL continuous loss: 0.880, discrete loss: 0.812\n",
            "Epoch:566, step = 4535, Total continuous loss: 0.450, discrete loss: 0.383\n",
            "Time taken: 0.431\n",
            "Time taken: 0.417\n",
            "Time taken: 0.422\n",
            "Time taken: 0.420\n",
            "Time taken: 0.430\n",
            "Time taken: 0.419\n",
            "Time taken: 0.423\n",
            "Time taken: 0.420\n",
            "Epoch:567, step = 4543, diffusion continuous loss: 0.277, discrete loss: 0.222\n",
            "Epoch:567, step = 4543, CL continuous loss: 0.869, discrete loss: 0.788\n",
            "Epoch:567, step = 4543, Total continuous loss: 0.451, discrete loss: 0.379\n",
            "Time taken: 0.414\n",
            "Time taken: 0.420\n",
            "Time taken: 0.424\n",
            "Time taken: 0.427\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Time taken: 0.419\n",
            "Time taken: 0.422\n",
            "Epoch:568, step = 4551, diffusion continuous loss: 0.288, discrete loss: 0.217\n",
            "Epoch:568, step = 4551, CL continuous loss: 0.916, discrete loss: 0.789\n",
            "Epoch:568, step = 4551, Total continuous loss: 0.471, discrete loss: 0.374\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Time taken: 0.420\n",
            "Time taken: 0.424\n",
            "Time taken: 0.419\n",
            "Time taken: 0.428\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Epoch:569, step = 4559, diffusion continuous loss: 0.284, discrete loss: 0.228\n",
            "Epoch:569, step = 4559, CL continuous loss: 0.873, discrete loss: 0.796\n",
            "Epoch:569, step = 4559, Total continuous loss: 0.458, discrete loss: 0.387\n",
            "Time taken: 0.441\n",
            "Time taken: 0.445\n",
            "Time taken: 0.442\n",
            "Time taken: 0.451\n",
            "Time taken: 0.456\n",
            "Time taken: 0.431\n",
            "Time taken: 0.423\n",
            "Time taken: 0.419\n",
            "Epoch:570, step = 4567, diffusion continuous loss: 0.316, discrete loss: 0.222\n",
            "Epoch:570, step = 4567, CL continuous loss: 0.910, discrete loss: 0.799\n",
            "Epoch:570, step = 4567, Total continuous loss: 0.498, discrete loss: 0.381\n",
            "Time taken: 0.414\n",
            "Time taken: 0.422\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.516\n",
            "Time taken: 0.420\n",
            "Time taken: 0.430\n",
            "Time taken: 0.426\n",
            "Epoch:571, step = 4575, diffusion continuous loss: 0.340, discrete loss: 0.223\n",
            "Epoch:571, step = 4575, CL continuous loss: 0.850, discrete loss: 0.792\n",
            "Epoch:571, step = 4575, Total continuous loss: 0.510, discrete loss: 0.381\n",
            "Time taken: 0.421\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.424\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Epoch:572, step = 4583, diffusion continuous loss: 0.389, discrete loss: 0.224\n",
            "Epoch:572, step = 4583, CL continuous loss: 0.882, discrete loss: 0.798\n",
            "Epoch:572, step = 4583, Total continuous loss: 0.565, discrete loss: 0.383\n",
            "Time taken: 0.412\n",
            "Time taken: 0.423\n",
            "Time taken: 0.424\n",
            "Time taken: 0.423\n",
            "Time taken: 0.421\n",
            "Time taken: 0.445\n",
            "Time taken: 0.447\n",
            "Time taken: 0.460\n",
            "Epoch:573, step = 4591, diffusion continuous loss: 0.330, discrete loss: 0.201\n",
            "Epoch:573, step = 4591, CL continuous loss: 0.926, discrete loss: 0.796\n",
            "Epoch:573, step = 4591, Total continuous loss: 0.515, discrete loss: 0.360\n",
            "Time taken: 0.440\n",
            "Time taken: 0.471\n",
            "Time taken: 0.448\n",
            "Time taken: 0.463\n",
            "Time taken: 0.466\n",
            "Time taken: 0.465\n",
            "Time taken: 0.430\n",
            "Time taken: 0.429\n",
            "Epoch:574, step = 4599, diffusion continuous loss: 0.305, discrete loss: 0.213\n",
            "Epoch:574, step = 4599, CL continuous loss: 0.902, discrete loss: 0.784\n",
            "Epoch:574, step = 4599, Total continuous loss: 0.485, discrete loss: 0.370\n",
            "Time taken: 0.415\n",
            "Time taken: 0.422\n",
            "Time taken: 0.421\n",
            "Time taken: 0.427\n",
            "Time taken: 0.420\n",
            "Time taken: 0.424\n",
            "Time taken: 0.429\n",
            "Time taken: 0.422\n",
            "Epoch:575, step = 4607, diffusion continuous loss: 0.299, discrete loss: 0.219\n",
            "Epoch:575, step = 4607, CL continuous loss: 0.875, discrete loss: 0.785\n",
            "Epoch:575, step = 4607, Total continuous loss: 0.474, discrete loss: 0.376\n",
            "Time taken: 0.412\n",
            "Time taken: 0.420\n",
            "Time taken: 0.427\n",
            "Time taken: 0.521\n",
            "Time taken: 0.423\n",
            "Time taken: 0.425\n",
            "Time taken: 0.421\n",
            "Time taken: 0.422\n",
            "Epoch:576, step = 4615, diffusion continuous loss: 0.284, discrete loss: 0.209\n",
            "Epoch:576, step = 4615, CL continuous loss: 0.872, discrete loss: 0.791\n",
            "Epoch:576, step = 4615, Total continuous loss: 0.458, discrete loss: 0.367\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.423\n",
            "Time taken: 0.419\n",
            "Time taken: 0.434\n",
            "Time taken: 0.446\n",
            "Time taken: 0.448\n",
            "Time taken: 0.442\n",
            "Epoch:577, step = 4623, diffusion continuous loss: 0.349, discrete loss: 0.234\n",
            "Epoch:577, step = 4623, CL continuous loss: 0.891, discrete loss: 0.794\n",
            "Epoch:577, step = 4623, Total continuous loss: 0.527, discrete loss: 0.393\n",
            "Time taken: 0.437\n",
            "Time taken: 0.452\n",
            "Time taken: 0.421\n",
            "Time taken: 0.424\n",
            "Time taken: 0.418\n",
            "Time taken: 0.425\n",
            "Time taken: 0.418\n",
            "Time taken: 0.422\n",
            "Epoch:578, step = 4631, diffusion continuous loss: 0.312, discrete loss: 0.220\n",
            "Epoch:578, step = 4631, CL continuous loss: 0.906, discrete loss: 0.786\n",
            "Epoch:578, step = 4631, Total continuous loss: 0.493, discrete loss: 0.377\n",
            "Time taken: 0.417\n",
            "Time taken: 0.422\n",
            "Time taken: 0.421\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.436\n",
            "Time taken: 0.418\n",
            "Time taken: 0.425\n",
            "Epoch:579, step = 4639, diffusion continuous loss: 0.370, discrete loss: 0.216\n",
            "Epoch:579, step = 4639, CL continuous loss: 0.913, discrete loss: 0.795\n",
            "Epoch:579, step = 4639, Total continuous loss: 0.553, discrete loss: 0.375\n",
            "Time taken: 0.411\n",
            "Time taken: 0.419\n",
            "Time taken: 0.422\n",
            "Time taken: 0.421\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Time taken: 0.425\n",
            "Time taken: 0.420\n",
            "Epoch:580, step = 4647, diffusion continuous loss: 0.298, discrete loss: 0.222\n",
            "Epoch:580, step = 4647, CL continuous loss: 0.891, discrete loss: 0.798\n",
            "Epoch:580, step = 4647, Total continuous loss: 0.476, discrete loss: 0.381\n",
            "Time taken: 0.413\n",
            "Time taken: 0.543\n",
            "Time taken: 0.443\n",
            "Time taken: 0.450\n",
            "Time taken: 0.441\n",
            "Time taken: 0.448\n",
            "Time taken: 0.438\n",
            "Time taken: 0.418\n",
            "Epoch:581, step = 4655, diffusion continuous loss: 0.325, discrete loss: 0.212\n",
            "Epoch:581, step = 4655, CL continuous loss: 0.869, discrete loss: 0.797\n",
            "Epoch:581, step = 4655, Total continuous loss: 0.499, discrete loss: 0.371\n",
            "Time taken: 0.418\n",
            "Time taken: 0.423\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.422\n",
            "Time taken: 0.424\n",
            "Time taken: 0.423\n",
            "Time taken: 0.421\n",
            "Epoch:582, step = 4663, diffusion continuous loss: 0.292, discrete loss: 0.215\n",
            "Epoch:582, step = 4663, CL continuous loss: 0.898, discrete loss: 0.794\n",
            "Epoch:582, step = 4663, Total continuous loss: 0.471, discrete loss: 0.374\n",
            "Time taken: 0.413\n",
            "Time taken: 0.421\n",
            "Time taken: 0.423\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.423\n",
            "Time taken: 0.421\n",
            "Time taken: 0.430\n",
            "Epoch:583, step = 4671, diffusion continuous loss: 0.291, discrete loss: 0.212\n",
            "Epoch:583, step = 4671, CL continuous loss: 0.891, discrete loss: 0.778\n",
            "Epoch:583, step = 4671, Total continuous loss: 0.469, discrete loss: 0.368\n",
            "Time taken: 0.415\n",
            "Time taken: 0.425\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.424\n",
            "Time taken: 0.425\n",
            "Time taken: 0.451\n",
            "Time taken: 0.442\n",
            "Epoch:584, step = 4679, diffusion continuous loss: 0.285, discrete loss: 0.216\n",
            "Epoch:584, step = 4679, CL continuous loss: 0.892, discrete loss: 0.787\n",
            "Epoch:584, step = 4679, Total continuous loss: 0.463, discrete loss: 0.374\n",
            "Time taken: 0.430\n",
            "Time taken: 0.441\n",
            "Time taken: 0.449\n",
            "Time taken: 0.432\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.420\n",
            "Time taken: 0.421\n",
            "Epoch:585, step = 4687, diffusion continuous loss: 0.292, discrete loss: 0.248\n",
            "Epoch:585, step = 4687, CL continuous loss: 0.879, discrete loss: 0.842\n",
            "Epoch:585, step = 4687, Total continuous loss: 0.468, discrete loss: 0.417\n",
            "Time taken: 0.514\n",
            "Time taken: 0.416\n",
            "Time taken: 0.425\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.422\n",
            "Time taken: 0.418\n",
            "Time taken: 0.427\n",
            "Epoch:586, step = 4695, diffusion continuous loss: 0.344, discrete loss: 0.229\n",
            "Epoch:586, step = 4695, CL continuous loss: 0.878, discrete loss: 0.829\n",
            "Epoch:586, step = 4695, Total continuous loss: 0.519, discrete loss: 0.395\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Time taken: 0.419\n",
            "Time taken: 0.424\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.420\n",
            "Epoch:587, step = 4703, diffusion continuous loss: 0.311, discrete loss: 0.231\n",
            "Epoch:587, step = 4703, CL continuous loss: 0.920, discrete loss: 0.825\n",
            "Epoch:587, step = 4703, Total continuous loss: 0.495, discrete loss: 0.396\n",
            "Time taken: 0.414\n",
            "Time taken: 0.429\n",
            "Time taken: 0.421\n",
            "Time taken: 0.441\n",
            "Time taken: 0.442\n",
            "Time taken: 0.441\n",
            "Time taken: 0.449\n",
            "Time taken: 0.448\n",
            "Epoch:588, step = 4711, diffusion continuous loss: 0.275, discrete loss: 0.233\n",
            "Epoch:588, step = 4711, CL continuous loss: 0.905, discrete loss: 0.817\n",
            "Epoch:588, step = 4711, Total continuous loss: 0.456, discrete loss: 0.396\n",
            "Time taken: 0.412\n",
            "Time taken: 0.417\n",
            "Time taken: 0.422\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.424\n",
            "Time taken: 0.422\n",
            "Time taken: 0.422\n",
            "Epoch:589, step = 4719, diffusion continuous loss: 0.283, discrete loss: 0.223\n",
            "Epoch:589, step = 4719, CL continuous loss: 0.889, discrete loss: 0.814\n",
            "Epoch:589, step = 4719, Total continuous loss: 0.461, discrete loss: 0.386\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Time taken: 0.424\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.518\n",
            "Time taken: 0.419\n",
            "Epoch:590, step = 4727, diffusion continuous loss: 0.286, discrete loss: 0.225\n",
            "Epoch:590, step = 4727, CL continuous loss: 0.908, discrete loss: 0.805\n",
            "Epoch:590, step = 4727, Total continuous loss: 0.467, discrete loss: 0.386\n",
            "Time taken: 0.411\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.422\n",
            "Time taken: 0.422\n",
            "Time taken: 0.424\n",
            "Time taken: 0.422\n",
            "Epoch:591, step = 4735, diffusion continuous loss: 0.284, discrete loss: 0.244\n",
            "Epoch:591, step = 4735, CL continuous loss: 0.898, discrete loss: 0.827\n",
            "Epoch:591, step = 4735, Total continuous loss: 0.464, discrete loss: 0.409\n",
            "Time taken: 0.435\n",
            "Time taken: 0.449\n",
            "Time taken: 0.441\n",
            "Time taken: 0.461\n",
            "Time taken: 0.445\n",
            "Time taken: 0.419\n",
            "Time taken: 0.422\n",
            "Time taken: 0.421\n",
            "Epoch:592, step = 4743, diffusion continuous loss: 0.285, discrete loss: 0.222\n",
            "Epoch:592, step = 4743, CL continuous loss: 0.875, discrete loss: 0.819\n",
            "Epoch:592, step = 4743, Total continuous loss: 0.460, discrete loss: 0.386\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.422\n",
            "Time taken: 0.422\n",
            "Time taken: 0.421\n",
            "Epoch:593, step = 4751, diffusion continuous loss: 0.283, discrete loss: 0.232\n",
            "Epoch:593, step = 4751, CL continuous loss: 0.880, discrete loss: 0.786\n",
            "Epoch:593, step = 4751, Total continuous loss: 0.459, discrete loss: 0.390\n",
            "Time taken: 0.410\n",
            "Time taken: 0.425\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.423\n",
            "Time taken: 0.421\n",
            "Time taken: 0.419\n",
            "Epoch:594, step = 4759, diffusion continuous loss: 0.274, discrete loss: 0.224\n",
            "Epoch:594, step = 4759, CL continuous loss: 0.870, discrete loss: 0.814\n",
            "Epoch:594, step = 4759, Total continuous loss: 0.448, discrete loss: 0.387\n",
            "Time taken: 0.408\n",
            "Time taken: 0.424\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.431\n",
            "Time taken: 0.570\n",
            "Time taken: 0.440\n",
            "Time taken: 0.441\n",
            "Epoch:595, step = 4767, diffusion continuous loss: 0.283, discrete loss: 0.227\n",
            "Epoch:595, step = 4767, CL continuous loss: 0.880, discrete loss: 0.804\n",
            "Epoch:595, step = 4767, Total continuous loss: 0.459, discrete loss: 0.388\n",
            "Time taken: 0.446\n",
            "Time taken: 0.438\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Time taken: 0.421\n",
            "Epoch:596, step = 4775, diffusion continuous loss: 0.289, discrete loss: 0.221\n",
            "Epoch:596, step = 4775, CL continuous loss: 0.870, discrete loss: 0.805\n",
            "Epoch:596, step = 4775, Total continuous loss: 0.463, discrete loss: 0.382\n",
            "Time taken: 0.409\n",
            "Time taken: 0.423\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.424\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Epoch:597, step = 4783, diffusion continuous loss: 0.274, discrete loss: 0.218\n",
            "Epoch:597, step = 4783, CL continuous loss: 0.882, discrete loss: 0.804\n",
            "Epoch:597, step = 4783, Total continuous loss: 0.451, discrete loss: 0.379\n",
            "Time taken: 0.413\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.426\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.426\n",
            "Time taken: 0.422\n",
            "Epoch:598, step = 4791, diffusion continuous loss: 0.355, discrete loss: 0.214\n",
            "Epoch:598, step = 4791, CL continuous loss: 0.903, discrete loss: 0.807\n",
            "Epoch:598, step = 4791, Total continuous loss: 0.536, discrete loss: 0.375\n",
            "Time taken: 0.417\n",
            "Time taken: 0.430\n",
            "Time taken: 0.438\n",
            "Time taken: 0.447\n",
            "Time taken: 0.443\n",
            "Time taken: 0.447\n",
            "Time taken: 0.426\n",
            "Time taken: 0.419\n",
            "Epoch:599, step = 4799, diffusion continuous loss: 0.332, discrete loss: 0.219\n",
            "Epoch:599, step = 4799, CL continuous loss: 0.892, discrete loss: 0.799\n",
            "Epoch:599, step = 4799, Total continuous loss: 0.510, discrete loss: 0.379\n",
            "Time taken: 0.555\n",
            "Time taken: 0.446\n",
            "Time taken: 0.418\n",
            "Time taken: 0.423\n",
            "Time taken: 0.523\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Epoch:600, step = 4807, diffusion continuous loss: 0.301, discrete loss: 0.214\n",
            "Epoch:600, step = 4807, CL continuous loss: 0.883, discrete loss: 0.779\n",
            "Epoch:600, step = 4807, Total continuous loss: 0.478, discrete loss: 0.370\n",
            "Time taken: 0.414\n",
            "Time taken: 0.433\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.428\n",
            "Time taken: 0.419\n",
            "Epoch:601, step = 4815, diffusion continuous loss: 0.288, discrete loss: 0.231\n",
            "Epoch:601, step = 4815, CL continuous loss: 0.896, discrete loss: 0.802\n",
            "Epoch:601, step = 4815, Total continuous loss: 0.467, discrete loss: 0.391\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.426\n",
            "Time taken: 0.437\n",
            "Time taken: 0.440\n",
            "Epoch:602, step = 4823, diffusion continuous loss: 0.304, discrete loss: 0.231\n",
            "Epoch:602, step = 4823, CL continuous loss: 0.893, discrete loss: 0.803\n",
            "Epoch:602, step = 4823, Total continuous loss: 0.482, discrete loss: 0.392\n",
            "Time taken: 0.427\n",
            "Time taken: 0.443\n",
            "Time taken: 0.443\n",
            "Time taken: 0.415\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Epoch:603, step = 4831, diffusion continuous loss: 0.307, discrete loss: 0.224\n",
            "Epoch:603, step = 4831, CL continuous loss: 0.869, discrete loss: 0.797\n",
            "Epoch:603, step = 4831, Total continuous loss: 0.480, discrete loss: 0.384\n",
            "Time taken: 0.410\n",
            "Time taken: 0.423\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Time taken: 0.429\n",
            "Time taken: 0.420\n",
            "Time taken: 0.429\n",
            "Time taken: 0.421\n",
            "Epoch:604, step = 4839, diffusion continuous loss: 0.277, discrete loss: 0.210\n",
            "Epoch:604, step = 4839, CL continuous loss: 0.867, discrete loss: 0.797\n",
            "Epoch:604, step = 4839, Total continuous loss: 0.451, discrete loss: 0.369\n",
            "Time taken: 0.411\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.519\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Epoch:605, step = 4847, diffusion continuous loss: 0.313, discrete loss: 0.213\n",
            "Epoch:605, step = 4847, CL continuous loss: 0.903, discrete loss: 0.791\n",
            "Epoch:605, step = 4847, Total continuous loss: 0.493, discrete loss: 0.372\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.444\n",
            "Time taken: 0.433\n",
            "Time taken: 0.435\n",
            "Time taken: 0.449\n",
            "Time taken: 0.449\n",
            "Time taken: 0.425\n",
            "Epoch:606, step = 4855, diffusion continuous loss: 0.294, discrete loss: 0.208\n",
            "Epoch:606, step = 4855, CL continuous loss: 0.874, discrete loss: 0.796\n",
            "Epoch:606, step = 4855, Total continuous loss: 0.469, discrete loss: 0.368\n",
            "Time taken: 0.412\n",
            "Time taken: 0.422\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.425\n",
            "Time taken: 0.423\n",
            "Time taken: 0.420\n",
            "Epoch:607, step = 4863, diffusion continuous loss: 0.290, discrete loss: 0.222\n",
            "Epoch:607, step = 4863, CL continuous loss: 0.924, discrete loss: 0.796\n",
            "Epoch:607, step = 4863, Total continuous loss: 0.474, discrete loss: 0.381\n",
            "Time taken: 0.410\n",
            "Time taken: 0.424\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Epoch:608, step = 4871, diffusion continuous loss: 0.279, discrete loss: 0.228\n",
            "Epoch:608, step = 4871, CL continuous loss: 0.894, discrete loss: 0.810\n",
            "Epoch:608, step = 4871, Total continuous loss: 0.458, discrete loss: 0.390\n",
            "Time taken: 0.419\n",
            "Time taken: 0.414\n",
            "Time taken: 0.422\n",
            "Time taken: 0.424\n",
            "Time taken: 0.423\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.448\n",
            "Epoch:609, step = 4879, diffusion continuous loss: 0.298, discrete loss: 0.214\n",
            "Epoch:609, step = 4879, CL continuous loss: 0.897, discrete loss: 0.799\n",
            "Epoch:609, step = 4879, Total continuous loss: 0.477, discrete loss: 0.374\n",
            "Time taken: 0.439\n",
            "Time taken: 0.436\n",
            "Time taken: 0.452\n",
            "Time taken: 0.447\n",
            "Time taken: 0.517\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.425\n",
            "Epoch:610, step = 4887, diffusion continuous loss: 0.322, discrete loss: 0.217\n",
            "Epoch:610, step = 4887, CL continuous loss: 0.894, discrete loss: 0.799\n",
            "Epoch:610, step = 4887, Total continuous loss: 0.500, discrete loss: 0.376\n",
            "Time taken: 0.405\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.431\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Epoch:611, step = 4895, diffusion continuous loss: 0.297, discrete loss: 0.220\n",
            "Epoch:611, step = 4895, CL continuous loss: 0.892, discrete loss: 0.794\n",
            "Epoch:611, step = 4895, Total continuous loss: 0.475, discrete loss: 0.379\n",
            "Time taken: 0.411\n",
            "Time taken: 0.418\n",
            "Time taken: 0.422\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.411\n",
            "Time taken: 0.422\n",
            "Epoch:612, step = 4903, diffusion continuous loss: 0.294, discrete loss: 0.219\n",
            "Epoch:612, step = 4903, CL continuous loss: 0.887, discrete loss: 0.800\n",
            "Epoch:612, step = 4903, Total continuous loss: 0.471, discrete loss: 0.379\n",
            "Time taken: 0.412\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.442\n",
            "Time taken: 0.439\n",
            "Time taken: 0.439\n",
            "Time taken: 0.441\n",
            "Epoch:613, step = 4911, diffusion continuous loss: 0.275, discrete loss: 0.231\n",
            "Epoch:613, step = 4911, CL continuous loss: 0.885, discrete loss: 0.803\n",
            "Epoch:613, step = 4911, Total continuous loss: 0.452, discrete loss: 0.392\n",
            "Time taken: 0.441\n",
            "Time taken: 0.418\n",
            "Time taken: 0.422\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Time taken: 0.428\n",
            "Epoch:614, step = 4919, diffusion continuous loss: 0.275, discrete loss: 0.215\n",
            "Epoch:614, step = 4919, CL continuous loss: 0.888, discrete loss: 0.797\n",
            "Epoch:614, step = 4919, Total continuous loss: 0.452, discrete loss: 0.375\n",
            "Time taken: 0.411\n",
            "Time taken: 0.418\n",
            "Time taken: 0.523\n",
            "Time taken: 0.422\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Epoch:615, step = 4927, diffusion continuous loss: 0.310, discrete loss: 0.217\n",
            "Epoch:615, step = 4927, CL continuous loss: 0.853, discrete loss: 0.778\n",
            "Epoch:615, step = 4927, Total continuous loss: 0.481, discrete loss: 0.373\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.419\n",
            "Time taken: 0.422\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Epoch:616, step = 4935, diffusion continuous loss: 0.305, discrete loss: 0.216\n",
            "Epoch:616, step = 4935, CL continuous loss: 0.895, discrete loss: 0.796\n",
            "Epoch:616, step = 4935, Total continuous loss: 0.484, discrete loss: 0.375\n",
            "Time taken: 0.419\n",
            "Time taken: 0.456\n",
            "Time taken: 0.439\n",
            "Time taken: 0.434\n",
            "Time taken: 0.448\n",
            "Time taken: 0.460\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Epoch:617, step = 4943, diffusion continuous loss: 0.294, discrete loss: 0.212\n",
            "Epoch:617, step = 4943, CL continuous loss: 0.889, discrete loss: 0.803\n",
            "Epoch:617, step = 4943, Total continuous loss: 0.472, discrete loss: 0.373\n",
            "Time taken: 0.410\n",
            "Time taken: 0.415\n",
            "Time taken: 0.421\n",
            "Time taken: 0.422\n",
            "Time taken: 0.422\n",
            "Time taken: 0.418\n",
            "Time taken: 0.426\n",
            "Time taken: 0.416\n",
            "Epoch:618, step = 4951, diffusion continuous loss: 0.294, discrete loss: 0.218\n",
            "Epoch:618, step = 4951, CL continuous loss: 0.880, discrete loss: 0.801\n",
            "Epoch:618, step = 4951, Total continuous loss: 0.470, discrete loss: 0.378\n",
            "Time taken: 0.407\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.413\n",
            "Time taken: 0.423\n",
            "Time taken: 0.422\n",
            "Time taken: 0.421\n",
            "Epoch:619, step = 4959, diffusion continuous loss: 0.324, discrete loss: 0.222\n",
            "Epoch:619, step = 4959, CL continuous loss: 0.906, discrete loss: 0.785\n",
            "Epoch:619, step = 4959, Total continuous loss: 0.505, discrete loss: 0.379\n",
            "Time taken: 0.425\n",
            "Time taken: 0.515\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.426\n",
            "Time taken: 0.441\n",
            "Time taken: 0.441\n",
            "Epoch:620, step = 4967, diffusion continuous loss: 0.309, discrete loss: 0.223\n",
            "Epoch:620, step = 4967, CL continuous loss: 0.880, discrete loss: 0.794\n",
            "Epoch:620, step = 4967, Total continuous loss: 0.485, discrete loss: 0.382\n",
            "Time taken: 0.432\n",
            "Time taken: 0.441\n",
            "Time taken: 0.450\n",
            "Time taken: 0.413\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.432\n",
            "Epoch:621, step = 4975, diffusion continuous loss: 0.284, discrete loss: 0.218\n",
            "Epoch:621, step = 4975, CL continuous loss: 0.892, discrete loss: 0.799\n",
            "Epoch:621, step = 4975, Total continuous loss: 0.462, discrete loss: 0.378\n",
            "Time taken: 0.412\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.424\n",
            "Time taken: 0.425\n",
            "Time taken: 0.423\n",
            "Epoch:622, step = 4983, diffusion continuous loss: 0.405, discrete loss: 0.216\n",
            "Epoch:622, step = 4983, CL continuous loss: 0.892, discrete loss: 0.791\n",
            "Epoch:622, step = 4983, Total continuous loss: 0.583, discrete loss: 0.374\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.422\n",
            "Time taken: 0.423\n",
            "Time taken: 0.416\n",
            "Epoch:623, step = 4991, diffusion continuous loss: 0.384, discrete loss: 0.215\n",
            "Epoch:623, step = 4991, CL continuous loss: 0.879, discrete loss: 0.784\n",
            "Epoch:623, step = 4991, Total continuous loss: 0.560, discrete loss: 0.372\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.427\n",
            "Time taken: 0.438\n",
            "Time taken: 0.437\n",
            "Time taken: 0.447\n",
            "Time taken: 0.447\n",
            "Time taken: 0.584\n",
            "Epoch:624, step = 4999, diffusion continuous loss: 0.322, discrete loss: 0.222\n",
            "Epoch:624, step = 4999, CL continuous loss: 0.885, discrete loss: 0.788\n",
            "Epoch:624, step = 4999, Total continuous loss: 0.499, discrete loss: 0.380\n",
            "Time taken: 0.413\n",
            "Time taken: 0.422\n",
            "Time taken: 0.422\n",
            "Time taken: 0.422\n",
            "Time taken: 0.425\n",
            "Time taken: 0.425\n",
            "Time taken: 0.422\n",
            "Time taken: 0.417\n",
            "Epoch:625, step = 5007, diffusion continuous loss: 0.312, discrete loss: 0.207\n",
            "Epoch:625, step = 5007, CL continuous loss: 0.893, discrete loss: 0.786\n",
            "Epoch:625, step = 5007, Total continuous loss: 0.491, discrete loss: 0.365\n",
            "Time taken: 0.415\n",
            "Time taken: 0.424\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Time taken: 0.421\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Epoch:626, step = 5015, diffusion continuous loss: 0.287, discrete loss: 0.209\n",
            "Epoch:626, step = 5015, CL continuous loss: 0.888, discrete loss: 0.797\n",
            "Epoch:626, step = 5015, Total continuous loss: 0.465, discrete loss: 0.368\n",
            "Time taken: 0.413\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.413\n",
            "Time taken: 0.420\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.447\n",
            "Epoch:627, step = 5023, diffusion continuous loss: 0.314, discrete loss: 0.229\n",
            "Epoch:627, step = 5023, CL continuous loss: 0.890, discrete loss: 0.788\n",
            "Epoch:627, step = 5023, Total continuous loss: 0.492, discrete loss: 0.387\n",
            "Time taken: 0.428\n",
            "Time taken: 0.437\n",
            "Time taken: 0.442\n",
            "Time taken: 0.453\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.429\n",
            "Time taken: 0.427\n",
            "Epoch:628, step = 5031, diffusion continuous loss: 0.284, discrete loss: 0.219\n",
            "Epoch:628, step = 5031, CL continuous loss: 0.901, discrete loss: 0.792\n",
            "Epoch:628, step = 5031, Total continuous loss: 0.464, discrete loss: 0.378\n",
            "Time taken: 0.415\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.518\n",
            "Time taken: 0.420\n",
            "Epoch:629, step = 5039, diffusion continuous loss: 0.281, discrete loss: 0.208\n",
            "Epoch:629, step = 5039, CL continuous loss: 0.880, discrete loss: 0.789\n",
            "Epoch:629, step = 5039, Total continuous loss: 0.457, discrete loss: 0.365\n",
            "Time taken: 0.414\n",
            "Time taken: 0.421\n",
            "Time taken: 0.421\n",
            "Time taken: 0.426\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Epoch:630, step = 5047, diffusion continuous loss: 0.305, discrete loss: 0.225\n",
            "Epoch:630, step = 5047, CL continuous loss: 0.865, discrete loss: 0.796\n",
            "Epoch:630, step = 5047, Total continuous loss: 0.478, discrete loss: 0.384\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.425\n",
            "Time taken: 0.423\n",
            "Time taken: 0.440\n",
            "Time taken: 0.436\n",
            "Time taken: 0.438\n",
            "Time taken: 0.451\n",
            "Epoch:631, step = 5055, diffusion continuous loss: 0.285, discrete loss: 0.217\n",
            "Epoch:631, step = 5055, CL continuous loss: 0.886, discrete loss: 0.788\n",
            "Epoch:631, step = 5055, Total continuous loss: 0.462, discrete loss: 0.375\n",
            "Time taken: 0.443\n",
            "Time taken: 0.421\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.423\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Epoch:632, step = 5063, diffusion continuous loss: 0.273, discrete loss: 0.220\n",
            "Epoch:632, step = 5063, CL continuous loss: 0.877, discrete loss: 0.785\n",
            "Epoch:632, step = 5063, Total continuous loss: 0.449, discrete loss: 0.378\n",
            "Time taken: 0.413\n",
            "Time taken: 0.428\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.423\n",
            "Time taken: 0.419\n",
            "Epoch:633, step = 5071, diffusion continuous loss: 0.378, discrete loss: 0.215\n",
            "Epoch:633, step = 5071, CL continuous loss: 0.929, discrete loss: 0.783\n",
            "Epoch:633, step = 5071, Total continuous loss: 0.564, discrete loss: 0.372\n",
            "Time taken: 0.412\n",
            "Time taken: 0.419\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Time taken: 0.513\n",
            "Time taken: 0.420\n",
            "Time taken: 0.424\n",
            "Time taken: 0.424\n",
            "Epoch:634, step = 5079, diffusion continuous loss: 0.339, discrete loss: 0.218\n",
            "Epoch:634, step = 5079, CL continuous loss: 0.923, discrete loss: 0.798\n",
            "Epoch:634, step = 5079, Total continuous loss: 0.524, discrete loss: 0.378\n",
            "Time taken: 0.412\n",
            "Time taken: 0.447\n",
            "Time taken: 0.445\n",
            "Time taken: 0.434\n",
            "Time taken: 0.444\n",
            "Time taken: 0.452\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Epoch:635, step = 5087, diffusion continuous loss: 0.296, discrete loss: 0.212\n",
            "Epoch:635, step = 5087, CL continuous loss: 0.901, discrete loss: 0.823\n",
            "Epoch:635, step = 5087, Total continuous loss: 0.476, discrete loss: 0.377\n",
            "Time taken: 0.413\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.414\n",
            "Epoch:636, step = 5095, diffusion continuous loss: 0.289, discrete loss: 0.221\n",
            "Epoch:636, step = 5095, CL continuous loss: 0.882, discrete loss: 0.798\n",
            "Epoch:636, step = 5095, Total continuous loss: 0.466, discrete loss: 0.380\n",
            "Time taken: 0.413\n",
            "Time taken: 0.418\n",
            "Time taken: 0.423\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.414\n",
            "Epoch:637, step = 5103, diffusion continuous loss: 0.291, discrete loss: 0.209\n",
            "Epoch:637, step = 5103, CL continuous loss: 0.871, discrete loss: 0.787\n",
            "Epoch:637, step = 5103, Total continuous loss: 0.465, discrete loss: 0.366\n",
            "Time taken: 0.413\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.436\n",
            "Time taken: 0.435\n",
            "Epoch:638, step = 5111, diffusion continuous loss: 0.269, discrete loss: 0.215\n",
            "Epoch:638, step = 5111, CL continuous loss: 0.887, discrete loss: 0.787\n",
            "Epoch:638, step = 5111, Total continuous loss: 0.446, discrete loss: 0.373\n",
            "Time taken: 0.430\n",
            "Time taken: 0.443\n",
            "Time taken: 0.451\n",
            "Time taken: 0.509\n",
            "Time taken: 0.425\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Epoch:639, step = 5119, diffusion continuous loss: 0.318, discrete loss: 0.212\n",
            "Epoch:639, step = 5119, CL continuous loss: 0.908, discrete loss: 0.782\n",
            "Epoch:639, step = 5119, Total continuous loss: 0.499, discrete loss: 0.369\n",
            "Time taken: 0.413\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.424\n",
            "Epoch:640, step = 5127, diffusion continuous loss: 0.341, discrete loss: 0.217\n",
            "Epoch:640, step = 5127, CL continuous loss: 0.917, discrete loss: 0.790\n",
            "Epoch:640, step = 5127, Total continuous loss: 0.525, discrete loss: 0.375\n",
            "Time taken: 0.411\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.430\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Epoch:641, step = 5135, diffusion continuous loss: 0.353, discrete loss: 0.211\n",
            "Epoch:641, step = 5135, CL continuous loss: 0.903, discrete loss: 0.789\n",
            "Epoch:641, step = 5135, Total continuous loss: 0.533, discrete loss: 0.369\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.421\n",
            "Time taken: 0.440\n",
            "Time taken: 0.442\n",
            "Time taken: 0.440\n",
            "Time taken: 0.451\n",
            "Time taken: 0.456\n",
            "Epoch:642, step = 5143, diffusion continuous loss: 0.296, discrete loss: 0.211\n",
            "Epoch:642, step = 5143, CL continuous loss: 0.905, discrete loss: 0.795\n",
            "Epoch:642, step = 5143, Total continuous loss: 0.477, discrete loss: 0.370\n",
            "Time taken: 0.409\n",
            "Time taken: 0.427\n",
            "Time taken: 0.420\n",
            "Time taken: 0.421\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Epoch:643, step = 5151, diffusion continuous loss: 0.304, discrete loss: 0.215\n",
            "Epoch:643, step = 5151, CL continuous loss: 0.886, discrete loss: 0.784\n",
            "Epoch:643, step = 5151, Total continuous loss: 0.481, discrete loss: 0.372\n",
            "Time taken: 0.411\n",
            "Time taken: 0.529\n",
            "Time taken: 0.417\n",
            "Time taken: 0.425\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Epoch:644, step = 5159, diffusion continuous loss: 0.287, discrete loss: 0.222\n",
            "Epoch:644, step = 5159, CL continuous loss: 0.874, discrete loss: 0.777\n",
            "Epoch:644, step = 5159, Total continuous loss: 0.462, discrete loss: 0.377\n",
            "Time taken: 0.412\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Time taken: 0.409\n",
            "Time taken: 0.417\n",
            "Time taken: 0.428\n",
            "Time taken: 0.417\n",
            "Time taken: 0.428\n",
            "Epoch:645, step = 5167, diffusion continuous loss: 0.283, discrete loss: 0.223\n",
            "Epoch:645, step = 5167, CL continuous loss: 0.893, discrete loss: 0.791\n",
            "Epoch:645, step = 5167, Total continuous loss: 0.461, discrete loss: 0.381\n",
            "Time taken: 0.440\n",
            "Time taken: 0.440\n",
            "Time taken: 0.453\n",
            "Time taken: 0.448\n",
            "Time taken: 0.455\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.423\n",
            "Epoch:646, step = 5175, diffusion continuous loss: 0.269, discrete loss: 0.214\n",
            "Epoch:646, step = 5175, CL continuous loss: 0.887, discrete loss: 0.790\n",
            "Epoch:646, step = 5175, Total continuous loss: 0.446, discrete loss: 0.372\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Epoch:647, step = 5183, diffusion continuous loss: 0.270, discrete loss: 0.228\n",
            "Epoch:647, step = 5183, CL continuous loss: 0.873, discrete loss: 0.797\n",
            "Epoch:647, step = 5183, Total continuous loss: 0.445, discrete loss: 0.387\n",
            "Time taken: 0.411\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.422\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Epoch:648, step = 5191, diffusion continuous loss: 0.287, discrete loss: 0.214\n",
            "Epoch:648, step = 5191, CL continuous loss: 0.872, discrete loss: 0.795\n",
            "Epoch:648, step = 5191, Total continuous loss: 0.461, discrete loss: 0.373\n",
            "Time taken: 0.517\n",
            "Time taken: 0.415\n",
            "Time taken: 0.427\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Time taken: 0.442\n",
            "Time taken: 0.442\n",
            "Time taken: 0.442\n",
            "Epoch:649, step = 5199, diffusion continuous loss: 0.275, discrete loss: 0.214\n",
            "Epoch:649, step = 5199, CL continuous loss: 0.875, discrete loss: 0.789\n",
            "Epoch:649, step = 5199, Total continuous loss: 0.450, discrete loss: 0.371\n",
            "Time taken: 0.432\n",
            "Time taken: 0.452\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.413\n",
            "Time taken: 0.423\n",
            "Time taken: 0.419\n",
            "Epoch:650, step = 5207, diffusion continuous loss: 0.292, discrete loss: 0.215\n",
            "Epoch:650, step = 5207, CL continuous loss: 0.874, discrete loss: 0.789\n",
            "Epoch:650, step = 5207, Total continuous loss: 0.467, discrete loss: 0.372\n",
            "Time taken: 0.410\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Time taken: 0.413\n",
            "Time taken: 0.422\n",
            "Time taken: 0.415\n",
            "Epoch:651, step = 5215, diffusion continuous loss: 0.364, discrete loss: 0.225\n",
            "Epoch:651, step = 5215, CL continuous loss: 0.919, discrete loss: 0.793\n",
            "Epoch:651, step = 5215, Total continuous loss: 0.548, discrete loss: 0.383\n",
            "Time taken: 0.409\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Epoch:652, step = 5223, diffusion continuous loss: 0.303, discrete loss: 0.228\n",
            "Epoch:652, step = 5223, CL continuous loss: 0.900, discrete loss: 0.789\n",
            "Epoch:652, step = 5223, Total continuous loss: 0.483, discrete loss: 0.385\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.446\n",
            "Time taken: 0.444\n",
            "Time taken: 0.437\n",
            "Time taken: 0.449\n",
            "Time taken: 0.580\n",
            "Time taken: 0.427\n",
            "Epoch:653, step = 5231, diffusion continuous loss: 0.289, discrete loss: 0.214\n",
            "Epoch:653, step = 5231, CL continuous loss: 0.895, discrete loss: 0.791\n",
            "Epoch:653, step = 5231, Total continuous loss: 0.468, discrete loss: 0.372\n",
            "Time taken: 0.409\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.422\n",
            "Time taken: 0.422\n",
            "Epoch:654, step = 5239, diffusion continuous loss: 0.293, discrete loss: 0.217\n",
            "Epoch:654, step = 5239, CL continuous loss: 0.883, discrete loss: 0.800\n",
            "Epoch:654, step = 5239, Total continuous loss: 0.470, discrete loss: 0.377\n",
            "Time taken: 0.409\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.423\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Epoch:655, step = 5247, diffusion continuous loss: 0.308, discrete loss: 0.220\n",
            "Epoch:655, step = 5247, CL continuous loss: 0.899, discrete loss: 0.789\n",
            "Epoch:655, step = 5247, Total continuous loss: 0.488, discrete loss: 0.377\n",
            "Time taken: 0.414\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.427\n",
            "Time taken: 0.440\n",
            "Epoch:656, step = 5255, diffusion continuous loss: 0.294, discrete loss: 0.218\n",
            "Epoch:656, step = 5255, CL continuous loss: 0.883, discrete loss: 0.778\n",
            "Epoch:656, step = 5255, Total continuous loss: 0.471, discrete loss: 0.374\n",
            "Time taken: 0.428\n",
            "Time taken: 0.437\n",
            "Time taken: 0.453\n",
            "Time taken: 0.438\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.429\n",
            "Epoch:657, step = 5263, diffusion continuous loss: 0.296, discrete loss: 0.215\n",
            "Epoch:657, step = 5263, CL continuous loss: 0.863, discrete loss: 0.788\n",
            "Epoch:657, step = 5263, Total continuous loss: 0.469, discrete loss: 0.373\n",
            "Time taken: 0.406\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.525\n",
            "Time taken: 0.420\n",
            "Time taken: 0.415\n",
            "Epoch:658, step = 5271, diffusion continuous loss: 0.272, discrete loss: 0.214\n",
            "Epoch:658, step = 5271, CL continuous loss: 0.871, discrete loss: 0.793\n",
            "Epoch:658, step = 5271, Total continuous loss: 0.446, discrete loss: 0.373\n",
            "Time taken: 0.413\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.422\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.413\n",
            "Time taken: 0.426\n",
            "Epoch:659, step = 5279, diffusion continuous loss: 0.273, discrete loss: 0.222\n",
            "Epoch:659, step = 5279, CL continuous loss: 0.891, discrete loss: 0.782\n",
            "Epoch:659, step = 5279, Total continuous loss: 0.451, discrete loss: 0.378\n",
            "Time taken: 0.429\n",
            "Time taken: 0.436\n",
            "Time taken: 0.438\n",
            "Time taken: 0.467\n",
            "Time taken: 0.460\n",
            "Time taken: 0.498\n",
            "Time taken: 0.435\n",
            "Time taken: 0.446\n",
            "Epoch:660, step = 5287, diffusion continuous loss: 0.301, discrete loss: 0.224\n",
            "Epoch:660, step = 5287, CL continuous loss: 0.879, discrete loss: 0.795\n",
            "Epoch:660, step = 5287, Total continuous loss: 0.477, discrete loss: 0.383\n",
            "Time taken: 0.441\n",
            "Time taken: 0.418\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Time taken: 0.423\n",
            "Time taken: 0.420\n",
            "Epoch:661, step = 5295, diffusion continuous loss: 0.289, discrete loss: 0.216\n",
            "Epoch:661, step = 5295, CL continuous loss: 0.862, discrete loss: 0.788\n",
            "Epoch:661, step = 5295, Total continuous loss: 0.462, discrete loss: 0.374\n",
            "Time taken: 0.402\n",
            "Time taken: 0.422\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Epoch:662, step = 5303, diffusion continuous loss: 0.347, discrete loss: 0.223\n",
            "Epoch:662, step = 5303, CL continuous loss: 0.903, discrete loss: 0.793\n",
            "Epoch:662, step = 5303, Total continuous loss: 0.528, discrete loss: 0.381\n",
            "Time taken: 0.406\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.526\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Epoch:663, step = 5311, diffusion continuous loss: 0.273, discrete loss: 0.210\n",
            "Epoch:663, step = 5311, CL continuous loss: 0.904, discrete loss: 0.795\n",
            "Epoch:663, step = 5311, Total continuous loss: 0.454, discrete loss: 0.369\n",
            "Time taken: 0.406\n",
            "Time taken: 0.447\n",
            "Time taken: 0.442\n",
            "Time taken: 0.433\n",
            "Time taken: 0.453\n",
            "Time taken: 0.444\n",
            "Time taken: 0.417\n",
            "Time taken: 0.428\n",
            "Epoch:664, step = 5319, diffusion continuous loss: 0.304, discrete loss: 0.228\n",
            "Epoch:664, step = 5319, CL continuous loss: 0.875, discrete loss: 0.820\n",
            "Epoch:664, step = 5319, Total continuous loss: 0.479, discrete loss: 0.392\n",
            "Time taken: 0.412\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.412\n",
            "Time taken: 0.429\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.415\n",
            "Epoch:665, step = 5327, diffusion continuous loss: 0.304, discrete loss: 0.211\n",
            "Epoch:665, step = 5327, CL continuous loss: 0.860, discrete loss: 0.797\n",
            "Epoch:665, step = 5327, Total continuous loss: 0.477, discrete loss: 0.370\n",
            "Time taken: 0.409\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.422\n",
            "Time taken: 0.415\n",
            "Time taken: 0.414\n",
            "Time taken: 0.411\n",
            "Time taken: 0.418\n",
            "Epoch:666, step = 5335, diffusion continuous loss: 0.294, discrete loss: 0.215\n",
            "Epoch:666, step = 5335, CL continuous loss: 0.879, discrete loss: 0.804\n",
            "Epoch:666, step = 5335, Total continuous loss: 0.470, discrete loss: 0.375\n",
            "Time taken: 0.411\n",
            "Time taken: 0.417\n",
            "Time taken: 0.413\n",
            "Time taken: 0.418\n",
            "Time taken: 0.413\n",
            "Time taken: 0.422\n",
            "Time taken: 0.446\n",
            "Time taken: 0.443\n",
            "Epoch:667, step = 5343, diffusion continuous loss: 0.281, discrete loss: 0.215\n",
            "Epoch:667, step = 5343, CL continuous loss: 0.879, discrete loss: 0.804\n",
            "Epoch:667, step = 5343, Total continuous loss: 0.456, discrete loss: 0.376\n",
            "Time taken: 0.423\n",
            "Time taken: 0.448\n",
            "Time taken: 0.593\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Epoch:668, step = 5351, diffusion continuous loss: 0.311, discrete loss: 0.220\n",
            "Epoch:668, step = 5351, CL continuous loss: 0.900, discrete loss: 0.794\n",
            "Epoch:668, step = 5351, Total continuous loss: 0.491, discrete loss: 0.379\n",
            "Time taken: 0.412\n",
            "Time taken: 0.424\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Epoch:669, step = 5359, diffusion continuous loss: 0.291, discrete loss: 0.209\n",
            "Epoch:669, step = 5359, CL continuous loss: 0.889, discrete loss: 0.783\n",
            "Epoch:669, step = 5359, Total continuous loss: 0.469, discrete loss: 0.366\n",
            "Time taken: 0.413\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.414\n",
            "Time taken: 0.423\n",
            "Time taken: 0.424\n",
            "Time taken: 0.419\n",
            "Epoch:670, step = 5367, diffusion continuous loss: 0.276, discrete loss: 0.214\n",
            "Epoch:670, step = 5367, CL continuous loss: 0.884, discrete loss: 0.787\n",
            "Epoch:670, step = 5367, Total continuous loss: 0.453, discrete loss: 0.371\n",
            "Time taken: 0.409\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.435\n",
            "Time taken: 0.437\n",
            "Time taken: 0.442\n",
            "Time taken: 0.438\n",
            "Time taken: 0.445\n",
            "Epoch:671, step = 5375, diffusion continuous loss: 0.266, discrete loss: 0.213\n",
            "Epoch:671, step = 5375, CL continuous loss: 0.877, discrete loss: 0.784\n",
            "Epoch:671, step = 5375, Total continuous loss: 0.441, discrete loss: 0.370\n",
            "Time taken: 0.409\n",
            "Time taken: 0.413\n",
            "Time taken: 0.422\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.628\n",
            "Epoch:672, step = 5383, diffusion continuous loss: 0.297, discrete loss: 0.220\n",
            "Epoch:672, step = 5383, CL continuous loss: 0.874, discrete loss: 0.782\n",
            "Epoch:672, step = 5383, Total continuous loss: 0.472, discrete loss: 0.376\n",
            "Time taken: 0.510\n",
            "Time taken: 0.415\n",
            "Time taken: 0.424\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.425\n",
            "Time taken: 0.421\n",
            "Epoch:673, step = 5391, diffusion continuous loss: 0.275, discrete loss: 0.217\n",
            "Epoch:673, step = 5391, CL continuous loss: 0.881, discrete loss: 0.779\n",
            "Epoch:673, step = 5391, Total continuous loss: 0.451, discrete loss: 0.373\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Time taken: 0.439\n",
            "Epoch:674, step = 5399, diffusion continuous loss: 0.277, discrete loss: 0.236\n",
            "Epoch:674, step = 5399, CL continuous loss: 0.892, discrete loss: 0.809\n",
            "Epoch:674, step = 5399, Total continuous loss: 0.455, discrete loss: 0.397\n",
            "Time taken: 0.430\n",
            "Time taken: 0.435\n",
            "Time taken: 0.456\n",
            "Time taken: 0.443\n",
            "Time taken: 0.422\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Epoch:675, step = 5407, diffusion continuous loss: 0.303, discrete loss: 0.243\n",
            "Epoch:675, step = 5407, CL continuous loss: 0.918, discrete loss: 0.827\n",
            "Epoch:675, step = 5407, Total continuous loss: 0.486, discrete loss: 0.409\n",
            "Time taken: 0.408\n",
            "Time taken: 0.419\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Epoch:676, step = 5415, diffusion continuous loss: 0.289, discrete loss: 0.238\n",
            "Epoch:676, step = 5415, CL continuous loss: 0.906, discrete loss: 0.825\n",
            "Epoch:676, step = 5415, Total continuous loss: 0.470, discrete loss: 0.403\n",
            "Time taken: 0.406\n",
            "Time taken: 0.412\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.523\n",
            "Epoch:677, step = 5423, diffusion continuous loss: 0.279, discrete loss: 0.231\n",
            "Epoch:677, step = 5423, CL continuous loss: 0.894, discrete loss: 0.830\n",
            "Epoch:677, step = 5423, Total continuous loss: 0.458, discrete loss: 0.397\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.448\n",
            "Time taken: 0.440\n",
            "Time taken: 0.439\n",
            "Time taken: 0.456\n",
            "Epoch:678, step = 5431, diffusion continuous loss: 0.322, discrete loss: 0.270\n",
            "Epoch:678, step = 5431, CL continuous loss: 0.907, discrete loss: 0.851\n",
            "Epoch:678, step = 5431, Total continuous loss: 0.504, discrete loss: 0.440\n",
            "Time taken: 0.448\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.414\n",
            "Time taken: 0.419\n",
            "Epoch:679, step = 5439, diffusion continuous loss: 0.281, discrete loss: 0.249\n",
            "Epoch:679, step = 5439, CL continuous loss: 0.872, discrete loss: 0.856\n",
            "Epoch:679, step = 5439, Total continuous loss: 0.456, discrete loss: 0.420\n",
            "Time taken: 0.409\n",
            "Time taken: 0.424\n",
            "Time taken: 0.412\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Epoch:680, step = 5447, diffusion continuous loss: 0.287, discrete loss: 0.237\n",
            "Epoch:680, step = 5447, CL continuous loss: 0.872, discrete loss: 0.835\n",
            "Epoch:680, step = 5447, Total continuous loss: 0.461, discrete loss: 0.404\n",
            "Time taken: 0.411\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Epoch:681, step = 5455, diffusion continuous loss: 0.275, discrete loss: 0.237\n",
            "Epoch:681, step = 5455, CL continuous loss: 0.867, discrete loss: 0.833\n",
            "Epoch:681, step = 5455, Total continuous loss: 0.449, discrete loss: 0.404\n",
            "Time taken: 0.408\n",
            "Time taken: 0.445\n",
            "Time taken: 0.437\n",
            "Time taken: 0.434\n",
            "Time taken: 0.440\n",
            "Time taken: 0.594\n",
            "Time taken: 0.420\n",
            "Time taken: 0.424\n",
            "Epoch:682, step = 5463, diffusion continuous loss: 0.279, discrete loss: 0.221\n",
            "Epoch:682, step = 5463, CL continuous loss: 0.866, discrete loss: 0.821\n",
            "Epoch:682, step = 5463, Total continuous loss: 0.452, discrete loss: 0.386\n",
            "Time taken: 0.407\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.423\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.415\n",
            "Epoch:683, step = 5471, diffusion continuous loss: 0.280, discrete loss: 0.221\n",
            "Epoch:683, step = 5471, CL continuous loss: 0.877, discrete loss: 0.827\n",
            "Epoch:683, step = 5471, Total continuous loss: 0.456, discrete loss: 0.387\n",
            "Time taken: 0.410\n",
            "Time taken: 0.430\n",
            "Time taken: 0.414\n",
            "Time taken: 0.430\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Epoch:684, step = 5479, diffusion continuous loss: 0.291, discrete loss: 0.214\n",
            "Epoch:684, step = 5479, CL continuous loss: 0.887, discrete loss: 0.842\n",
            "Epoch:684, step = 5479, Total continuous loss: 0.468, discrete loss: 0.383\n",
            "Time taken: 0.410\n",
            "Time taken: 0.421\n",
            "Time taken: 0.425\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Time taken: 0.441\n",
            "Time taken: 0.436\n",
            "Epoch:685, step = 5487, diffusion continuous loss: 0.296, discrete loss: 0.225\n",
            "Epoch:685, step = 5487, CL continuous loss: 0.878, discrete loss: 0.818\n",
            "Epoch:685, step = 5487, Total continuous loss: 0.472, discrete loss: 0.389\n",
            "Time taken: 0.431\n",
            "Time taken: 0.444\n",
            "Time taken: 0.455\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.436\n",
            "Epoch:686, step = 5495, diffusion continuous loss: 0.304, discrete loss: 0.246\n",
            "Epoch:686, step = 5495, CL continuous loss: 0.897, discrete loss: 0.823\n",
            "Epoch:686, step = 5495, Total continuous loss: 0.483, discrete loss: 0.411\n",
            "Time taken: 0.405\n",
            "Time taken: 0.424\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.513\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Epoch:687, step = 5503, diffusion continuous loss: 0.307, discrete loss: 0.211\n",
            "Epoch:687, step = 5503, CL continuous loss: 0.895, discrete loss: 0.829\n",
            "Epoch:687, step = 5503, Total continuous loss: 0.486, discrete loss: 0.376\n",
            "Time taken: 0.411\n",
            "Time taken: 0.420\n",
            "Time taken: 0.421\n",
            "Time taken: 0.422\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Epoch:688, step = 5511, diffusion continuous loss: 0.296, discrete loss: 0.221\n",
            "Epoch:688, step = 5511, CL continuous loss: 0.883, discrete loss: 0.811\n",
            "Epoch:688, step = 5511, Total continuous loss: 0.473, discrete loss: 0.383\n",
            "Time taken: 0.422\n",
            "Time taken: 0.419\n",
            "Time taken: 0.439\n",
            "Time taken: 0.446\n",
            "Time taken: 0.440\n",
            "Time taken: 0.438\n",
            "Time taken: 0.446\n",
            "Time taken: 0.458\n",
            "Epoch:689, step = 5519, diffusion continuous loss: 0.279, discrete loss: 0.214\n",
            "Epoch:689, step = 5519, CL continuous loss: 0.882, discrete loss: 0.828\n",
            "Epoch:689, step = 5519, Total continuous loss: 0.456, discrete loss: 0.380\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.414\n",
            "Epoch:690, step = 5527, diffusion continuous loss: 0.267, discrete loss: 0.220\n",
            "Epoch:690, step = 5527, CL continuous loss: 0.900, discrete loss: 0.805\n",
            "Epoch:690, step = 5527, Total continuous loss: 0.447, discrete loss: 0.381\n",
            "Time taken: 0.413\n",
            "Time taken: 0.422\n",
            "Time taken: 0.423\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.424\n",
            "Time taken: 0.419\n",
            "Epoch:691, step = 5535, diffusion continuous loss: 0.274, discrete loss: 0.224\n",
            "Epoch:691, step = 5535, CL continuous loss: 0.869, discrete loss: 0.823\n",
            "Epoch:691, step = 5535, Total continuous loss: 0.448, discrete loss: 0.389\n",
            "Time taken: 0.410\n",
            "Time taken: 0.418\n",
            "Time taken: 0.526\n",
            "Time taken: 0.422\n",
            "Time taken: 0.424\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Time taken: 0.423\n",
            "Epoch:692, step = 5543, diffusion continuous loss: 0.302, discrete loss: 0.222\n",
            "Epoch:692, step = 5543, CL continuous loss: 0.878, discrete loss: 0.802\n",
            "Epoch:692, step = 5543, Total continuous loss: 0.477, discrete loss: 0.382\n",
            "Time taken: 0.438\n",
            "Time taken: 0.442\n",
            "Time taken: 0.442\n",
            "Time taken: 0.449\n",
            "Time taken: 0.440\n",
            "Time taken: 0.415\n",
            "Time taken: 0.422\n",
            "Time taken: 0.428\n",
            "Epoch:693, step = 5551, diffusion continuous loss: 0.292, discrete loss: 0.209\n",
            "Epoch:693, step = 5551, CL continuous loss: 0.877, discrete loss: 0.807\n",
            "Epoch:693, step = 5551, Total continuous loss: 0.467, discrete loss: 0.370\n",
            "Time taken: 0.410\n",
            "Time taken: 0.421\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Epoch:694, step = 5559, diffusion continuous loss: 0.287, discrete loss: 0.228\n",
            "Epoch:694, step = 5559, CL continuous loss: 0.901, discrete loss: 0.806\n",
            "Epoch:694, step = 5559, Total continuous loss: 0.467, discrete loss: 0.389\n",
            "Time taken: 0.406\n",
            "Time taken: 0.418\n",
            "Time taken: 0.424\n",
            "Time taken: 0.421\n",
            "Time taken: 0.423\n",
            "Time taken: 0.424\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Epoch:695, step = 5567, diffusion continuous loss: 0.303, discrete loss: 0.217\n",
            "Epoch:695, step = 5567, CL continuous loss: 0.903, discrete loss: 0.794\n",
            "Epoch:695, step = 5567, Total continuous loss: 0.483, discrete loss: 0.375\n",
            "Time taken: 0.412\n",
            "Time taken: 0.419\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Time taken: 0.427\n",
            "Time taken: 0.445\n",
            "Time taken: 0.440\n",
            "Time taken: 0.439\n",
            "Epoch:696, step = 5575, diffusion continuous loss: 0.342, discrete loss: 0.219\n",
            "Epoch:696, step = 5575, CL continuous loss: 0.895, discrete loss: 0.801\n",
            "Epoch:696, step = 5575, Total continuous loss: 0.521, discrete loss: 0.379\n",
            "Time taken: 0.437\n",
            "Time taken: 0.580\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Epoch:697, step = 5583, diffusion continuous loss: 0.311, discrete loss: 0.207\n",
            "Epoch:697, step = 5583, CL continuous loss: 0.914, discrete loss: 0.791\n",
            "Epoch:697, step = 5583, Total continuous loss: 0.494, discrete loss: 0.365\n",
            "Time taken: 0.403\n",
            "Time taken: 0.424\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.426\n",
            "Time taken: 0.418\n",
            "Epoch:698, step = 5591, diffusion continuous loss: 0.311, discrete loss: 0.222\n",
            "Epoch:698, step = 5591, CL continuous loss: 0.889, discrete loss: 0.796\n",
            "Epoch:698, step = 5591, Total continuous loss: 0.489, discrete loss: 0.381\n",
            "Time taken: 0.407\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.427\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Epoch:699, step = 5599, diffusion continuous loss: 0.278, discrete loss: 0.227\n",
            "Epoch:699, step = 5599, CL continuous loss: 0.891, discrete loss: 0.786\n",
            "Epoch:699, step = 5599, Total continuous loss: 0.456, discrete loss: 0.384\n",
            "Time taken: 0.585\n",
            "Time taken: 0.481\n",
            "Time taken: 0.438\n",
            "Time taken: 0.437\n",
            "Time taken: 0.453\n",
            "Time taken: 0.447\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Epoch:700, step = 5607, diffusion continuous loss: 0.323, discrete loss: 0.207\n",
            "Epoch:700, step = 5607, CL continuous loss: 0.912, discrete loss: 0.781\n",
            "Epoch:700, step = 5607, Total continuous loss: 0.506, discrete loss: 0.363\n",
            "Time taken: 0.411\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Epoch:701, step = 5615, diffusion continuous loss: 0.291, discrete loss: 0.215\n",
            "Epoch:701, step = 5615, CL continuous loss: 0.890, discrete loss: 0.789\n",
            "Epoch:701, step = 5615, Total continuous loss: 0.469, discrete loss: 0.373\n",
            "Time taken: 0.505\n",
            "Time taken: 0.415\n",
            "Time taken: 0.423\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.423\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Epoch:702, step = 5623, diffusion continuous loss: 0.384, discrete loss: 0.218\n",
            "Epoch:702, step = 5623, CL continuous loss: 0.889, discrete loss: 0.804\n",
            "Epoch:702, step = 5623, Total continuous loss: 0.562, discrete loss: 0.378\n",
            "Time taken: 0.406\n",
            "Time taken: 0.423\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.443\n",
            "Time taken: 0.445\n",
            "Epoch:703, step = 5631, diffusion continuous loss: 0.279, discrete loss: 0.217\n",
            "Epoch:703, step = 5631, CL continuous loss: 0.866, discrete loss: 0.797\n",
            "Epoch:703, step = 5631, Total continuous loss: 0.452, discrete loss: 0.376\n",
            "Time taken: 0.424\n",
            "Time taken: 0.446\n",
            "Time taken: 0.446\n",
            "Time taken: 0.419\n",
            "Time taken: 0.429\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Epoch:704, step = 5639, diffusion continuous loss: 0.301, discrete loss: 0.223\n",
            "Epoch:704, step = 5639, CL continuous loss: 0.882, discrete loss: 0.788\n",
            "Epoch:704, step = 5639, Total continuous loss: 0.477, discrete loss: 0.381\n",
            "Time taken: 0.410\n",
            "Time taken: 0.422\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.422\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Epoch:705, step = 5647, diffusion continuous loss: 0.273, discrete loss: 0.211\n",
            "Epoch:705, step = 5647, CL continuous loss: 0.876, discrete loss: 0.799\n",
            "Epoch:705, step = 5647, Total continuous loss: 0.448, discrete loss: 0.371\n",
            "Time taken: 0.413\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.413\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Epoch:706, step = 5655, diffusion continuous loss: 0.290, discrete loss: 0.222\n",
            "Epoch:706, step = 5655, CL continuous loss: 0.877, discrete loss: 0.791\n",
            "Epoch:706, step = 5655, Total continuous loss: 0.465, discrete loss: 0.380\n",
            "Time taken: 0.509\n",
            "Time taken: 0.422\n",
            "Time taken: 0.432\n",
            "Time taken: 0.440\n",
            "Time taken: 0.441\n",
            "Time taken: 0.437\n",
            "Time taken: 0.447\n",
            "Time taken: 0.447\n",
            "Epoch:707, step = 5663, diffusion continuous loss: 0.279, discrete loss: 0.213\n",
            "Epoch:707, step = 5663, CL continuous loss: 0.887, discrete loss: 0.780\n",
            "Epoch:707, step = 5663, Total continuous loss: 0.457, discrete loss: 0.369\n",
            "Time taken: 0.407\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.422\n",
            "Time taken: 0.417\n",
            "Epoch:708, step = 5671, diffusion continuous loss: 0.271, discrete loss: 0.221\n",
            "Epoch:708, step = 5671, CL continuous loss: 0.884, discrete loss: 0.785\n",
            "Epoch:708, step = 5671, Total continuous loss: 0.448, discrete loss: 0.378\n",
            "Time taken: 0.410\n",
            "Time taken: 0.410\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Epoch:709, step = 5679, diffusion continuous loss: 0.284, discrete loss: 0.212\n",
            "Epoch:709, step = 5679, CL continuous loss: 0.878, discrete loss: 0.791\n",
            "Epoch:709, step = 5679, Total continuous loss: 0.459, discrete loss: 0.370\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.426\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Epoch:710, step = 5687, diffusion continuous loss: 0.261, discrete loss: 0.209\n",
            "Epoch:710, step = 5687, CL continuous loss: 0.867, discrete loss: 0.786\n",
            "Epoch:710, step = 5687, Total continuous loss: 0.434, discrete loss: 0.366\n",
            "Time taken: 0.755\n",
            "Time taken: 0.455\n",
            "Time taken: 0.441\n",
            "Time taken: 0.448\n",
            "Time taken: 0.435\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.516\n",
            "Epoch:711, step = 5695, diffusion continuous loss: 0.282, discrete loss: 0.203\n",
            "Epoch:711, step = 5695, CL continuous loss: 0.877, discrete loss: 0.799\n",
            "Epoch:711, step = 5695, Total continuous loss: 0.458, discrete loss: 0.363\n",
            "Time taken: 0.413\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.422\n",
            "Time taken: 0.419\n",
            "Time taken: 0.425\n",
            "Epoch:712, step = 5703, diffusion continuous loss: 0.274, discrete loss: 0.219\n",
            "Epoch:712, step = 5703, CL continuous loss: 0.889, discrete loss: 0.784\n",
            "Epoch:712, step = 5703, Total continuous loss: 0.452, discrete loss: 0.376\n",
            "Time taken: 0.404\n",
            "Time taken: 0.414\n",
            "Time taken: 0.428\n",
            "Time taken: 0.416\n",
            "Time taken: 0.412\n",
            "Time taken: 0.419\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Epoch:713, step = 5711, diffusion continuous loss: 0.287, discrete loss: 0.222\n",
            "Epoch:713, step = 5711, CL continuous loss: 0.893, discrete loss: 0.783\n",
            "Epoch:713, step = 5711, Total continuous loss: 0.466, discrete loss: 0.378\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.415\n",
            "Time taken: 0.451\n",
            "Time taken: 0.437\n",
            "Time taken: 0.436\n",
            "Time taken: 0.438\n",
            "Epoch:714, step = 5719, diffusion continuous loss: 0.277, discrete loss: 0.221\n",
            "Epoch:714, step = 5719, CL continuous loss: 0.865, discrete loss: 0.785\n",
            "Epoch:714, step = 5719, Total continuous loss: 0.450, discrete loss: 0.378\n",
            "Time taken: 0.440\n",
            "Time taken: 0.445\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.414\n",
            "Time taken: 0.416\n",
            "Time taken: 0.430\n",
            "Time taken: 0.416\n",
            "Epoch:715, step = 5727, diffusion continuous loss: 0.274, discrete loss: 0.220\n",
            "Epoch:715, step = 5727, CL continuous loss: 0.861, discrete loss: 0.795\n",
            "Epoch:715, step = 5727, Total continuous loss: 0.447, discrete loss: 0.379\n",
            "Time taken: 0.409\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.427\n",
            "Time taken: 0.417\n",
            "Time taken: 0.423\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Epoch:716, step = 5735, diffusion continuous loss: 0.266, discrete loss: 0.227\n",
            "Epoch:716, step = 5735, CL continuous loss: 0.853, discrete loss: 0.796\n",
            "Epoch:716, step = 5735, Total continuous loss: 0.437, discrete loss: 0.386\n",
            "Time taken: 0.509\n",
            "Time taken: 0.415\n",
            "Time taken: 0.623\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Epoch:717, step = 5743, diffusion continuous loss: 0.267, discrete loss: 0.227\n",
            "Epoch:717, step = 5743, CL continuous loss: 0.871, discrete loss: 0.784\n",
            "Epoch:717, step = 5743, Total continuous loss: 0.442, discrete loss: 0.384\n",
            "Time taken: 0.413\n",
            "Time taken: 0.444\n",
            "Time taken: 0.441\n",
            "Time taken: 0.434\n",
            "Time taken: 0.444\n",
            "Time taken: 0.446\n",
            "Time taken: 0.428\n",
            "Time taken: 0.416\n",
            "Epoch:718, step = 5751, diffusion continuous loss: 0.271, discrete loss: 0.215\n",
            "Epoch:718, step = 5751, CL continuous loss: 0.859, discrete loss: 0.790\n",
            "Epoch:718, step = 5751, Total continuous loss: 0.443, discrete loss: 0.373\n",
            "Time taken: 0.414\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.414\n",
            "Time taken: 0.415\n",
            "Epoch:719, step = 5759, diffusion continuous loss: 0.264, discrete loss: 0.223\n",
            "Epoch:719, step = 5759, CL continuous loss: 0.872, discrete loss: 0.784\n",
            "Epoch:719, step = 5759, Total continuous loss: 0.438, discrete loss: 0.380\n",
            "Time taken: 0.408\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Epoch:720, step = 5767, diffusion continuous loss: 0.279, discrete loss: 0.219\n",
            "Epoch:720, step = 5767, CL continuous loss: 0.861, discrete loss: 0.788\n",
            "Epoch:720, step = 5767, Total continuous loss: 0.451, discrete loss: 0.377\n",
            "Time taken: 0.403\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.441\n",
            "Time taken: 0.439\n",
            "Epoch:721, step = 5775, diffusion continuous loss: 0.282, discrete loss: 0.224\n",
            "Epoch:721, step = 5775, CL continuous loss: 0.882, discrete loss: 0.785\n",
            "Epoch:721, step = 5775, Total continuous loss: 0.458, discrete loss: 0.382\n",
            "Time taken: 0.558\n",
            "Time taken: 0.449\n",
            "Time taken: 0.444\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.412\n",
            "Time taken: 0.419\n",
            "Epoch:722, step = 5783, diffusion continuous loss: 0.279, discrete loss: 0.215\n",
            "Epoch:722, step = 5783, CL continuous loss: 0.868, discrete loss: 0.789\n",
            "Epoch:722, step = 5783, Total continuous loss: 0.453, discrete loss: 0.373\n",
            "Time taken: 0.406\n",
            "Time taken: 0.412\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Epoch:723, step = 5791, diffusion continuous loss: 0.293, discrete loss: 0.218\n",
            "Epoch:723, step = 5791, CL continuous loss: 0.892, discrete loss: 0.798\n",
            "Epoch:723, step = 5791, Total continuous loss: 0.471, discrete loss: 0.377\n",
            "Time taken: 0.407\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.412\n",
            "Time taken: 0.423\n",
            "Epoch:724, step = 5799, diffusion continuous loss: 0.305, discrete loss: 0.217\n",
            "Epoch:724, step = 5799, CL continuous loss: 0.893, discrete loss: 0.786\n",
            "Epoch:724, step = 5799, Total continuous loss: 0.484, discrete loss: 0.374\n",
            "Time taken: 0.406\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.438\n",
            "Time taken: 0.438\n",
            "Time taken: 0.439\n",
            "Time taken: 0.455\n",
            "Time taken: 0.444\n",
            "Epoch:725, step = 5807, diffusion continuous loss: 0.288, discrete loss: 0.224\n",
            "Epoch:725, step = 5807, CL continuous loss: 0.911, discrete loss: 0.781\n",
            "Epoch:725, step = 5807, Total continuous loss: 0.470, discrete loss: 0.380\n",
            "Time taken: 0.407\n",
            "Time taken: 0.431\n",
            "Time taken: 0.413\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.414\n",
            "Epoch:726, step = 5815, diffusion continuous loss: 0.388, discrete loss: 0.213\n",
            "Epoch:726, step = 5815, CL continuous loss: 0.933, discrete loss: 0.780\n",
            "Epoch:726, step = 5815, Total continuous loss: 0.574, discrete loss: 0.369\n",
            "Time taken: 0.414\n",
            "Time taken: 0.518\n",
            "Time taken: 0.420\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Epoch:727, step = 5823, diffusion continuous loss: 0.316, discrete loss: 0.219\n",
            "Epoch:727, step = 5823, CL continuous loss: 0.901, discrete loss: 0.795\n",
            "Epoch:727, step = 5823, Total continuous loss: 0.496, discrete loss: 0.378\n",
            "Time taken: 0.412\n",
            "Time taken: 0.414\n",
            "Time taken: 0.423\n",
            "Time taken: 0.421\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.430\n",
            "Epoch:728, step = 5831, diffusion continuous loss: 0.300, discrete loss: 0.214\n",
            "Epoch:728, step = 5831, CL continuous loss: 0.883, discrete loss: 0.798\n",
            "Epoch:728, step = 5831, Total continuous loss: 0.477, discrete loss: 0.373\n",
            "Time taken: 0.428\n",
            "Time taken: 0.440\n",
            "Time taken: 0.446\n",
            "Time taken: 0.444\n",
            "Time taken: 0.448\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Epoch:729, step = 5839, diffusion continuous loss: 0.292, discrete loss: 0.212\n",
            "Epoch:729, step = 5839, CL continuous loss: 0.881, discrete loss: 0.781\n",
            "Epoch:729, step = 5839, Total continuous loss: 0.468, discrete loss: 0.368\n",
            "Time taken: 0.402\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Epoch:730, step = 5847, diffusion continuous loss: 0.295, discrete loss: 0.217\n",
            "Epoch:730, step = 5847, CL continuous loss: 0.895, discrete loss: 0.783\n",
            "Epoch:730, step = 5847, Total continuous loss: 0.474, discrete loss: 0.373\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Epoch:731, step = 5855, diffusion continuous loss: 0.307, discrete loss: 0.215\n",
            "Epoch:731, step = 5855, CL continuous loss: 0.893, discrete loss: 0.780\n",
            "Epoch:731, step = 5855, Total continuous loss: 0.485, discrete loss: 0.371\n",
            "Time taken: 0.413\n",
            "Time taken: 0.511\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.426\n",
            "Time taken: 0.443\n",
            "Time taken: 0.436\n",
            "Time taken: 0.437\n",
            "Epoch:732, step = 5863, diffusion continuous loss: 0.291, discrete loss: 0.224\n",
            "Epoch:732, step = 5863, CL continuous loss: 0.906, discrete loss: 0.784\n",
            "Epoch:732, step = 5863, Total continuous loss: 0.472, discrete loss: 0.381\n",
            "Time taken: 0.436\n",
            "Time taken: 0.455\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.413\n",
            "Time taken: 0.424\n",
            "Time taken: 0.416\n",
            "Epoch:733, step = 5871, diffusion continuous loss: 0.284, discrete loss: 0.229\n",
            "Epoch:733, step = 5871, CL continuous loss: 0.868, discrete loss: 0.783\n",
            "Epoch:733, step = 5871, Total continuous loss: 0.458, discrete loss: 0.386\n",
            "Time taken: 0.413\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.424\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Epoch:734, step = 5879, diffusion continuous loss: 0.372, discrete loss: 0.203\n",
            "Epoch:734, step = 5879, CL continuous loss: 0.900, discrete loss: 0.774\n",
            "Epoch:734, step = 5879, Total continuous loss: 0.552, discrete loss: 0.357\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Epoch:735, step = 5887, diffusion continuous loss: 0.360, discrete loss: 0.217\n",
            "Epoch:735, step = 5887, CL continuous loss: 0.875, discrete loss: 0.780\n",
            "Epoch:735, step = 5887, Total continuous loss: 0.535, discrete loss: 0.374\n",
            "Time taken: 0.411\n",
            "Time taken: 0.420\n",
            "Time taken: 0.456\n",
            "Time taken: 0.438\n",
            "Time taken: 0.434\n",
            "Time taken: 0.454\n",
            "Time taken: 0.448\n",
            "Time taken: 0.518\n",
            "Epoch:736, step = 5895, diffusion continuous loss: 0.300, discrete loss: 0.212\n",
            "Epoch:736, step = 5895, CL continuous loss: 0.904, discrete loss: 0.780\n",
            "Epoch:736, step = 5895, Total continuous loss: 0.480, discrete loss: 0.368\n",
            "Time taken: 0.408\n",
            "Time taken: 0.423\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Epoch:737, step = 5903, diffusion continuous loss: 0.294, discrete loss: 0.215\n",
            "Epoch:737, step = 5903, CL continuous loss: 0.897, discrete loss: 0.789\n",
            "Epoch:737, step = 5903, Total continuous loss: 0.474, discrete loss: 0.373\n",
            "Time taken: 0.411\n",
            "Time taken: 0.433\n",
            "Time taken: 0.417\n",
            "Time taken: 0.422\n",
            "Time taken: 0.421\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Epoch:738, step = 5911, diffusion continuous loss: 0.276, discrete loss: 0.213\n",
            "Epoch:738, step = 5911, CL continuous loss: 0.879, discrete loss: 0.785\n",
            "Epoch:738, step = 5911, Total continuous loss: 0.452, discrete loss: 0.370\n",
            "Time taken: 0.413\n",
            "Time taken: 0.420\n",
            "Time taken: 0.423\n",
            "Time taken: 0.415\n",
            "Time taken: 0.422\n",
            "Time taken: 0.422\n",
            "Time taken: 0.423\n",
            "Time taken: 0.440\n",
            "Epoch:739, step = 5919, diffusion continuous loss: 0.278, discrete loss: 0.210\n",
            "Epoch:739, step = 5919, CL continuous loss: 0.877, discrete loss: 0.779\n",
            "Epoch:739, step = 5919, Total continuous loss: 0.453, discrete loss: 0.365\n",
            "Time taken: 0.426\n",
            "Time taken: 0.442\n",
            "Time taken: 0.470\n",
            "Time taken: 0.448\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Epoch:740, step = 5927, diffusion continuous loss: 0.292, discrete loss: 0.204\n",
            "Epoch:740, step = 5927, CL continuous loss: 0.864, discrete loss: 0.782\n",
            "Epoch:740, step = 5927, Total continuous loss: 0.465, discrete loss: 0.360\n",
            "Time taken: 0.412\n",
            "Time taken: 0.428\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.415\n",
            "Time taken: 0.523\n",
            "Time taken: 0.419\n",
            "Epoch:741, step = 5935, diffusion continuous loss: 0.281, discrete loss: 0.220\n",
            "Epoch:741, step = 5935, CL continuous loss: 0.879, discrete loss: 0.776\n",
            "Epoch:741, step = 5935, Total continuous loss: 0.457, discrete loss: 0.375\n",
            "Time taken: 0.406\n",
            "Time taken: 0.419\n",
            "Time taken: 0.415\n",
            "Time taken: 0.424\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Epoch:742, step = 5943, diffusion continuous loss: 0.289, discrete loss: 0.219\n",
            "Epoch:742, step = 5943, CL continuous loss: 0.889, discrete loss: 0.779\n",
            "Epoch:742, step = 5943, Total continuous loss: 0.466, discrete loss: 0.375\n",
            "Time taken: 0.414\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.437\n",
            "Time taken: 0.438\n",
            "Time taken: 0.433\n",
            "Time taken: 0.438\n",
            "Epoch:743, step = 5951, diffusion continuous loss: 0.287, discrete loss: 0.213\n",
            "Epoch:743, step = 5951, CL continuous loss: 0.888, discrete loss: 0.781\n",
            "Epoch:743, step = 5951, Total continuous loss: 0.464, discrete loss: 0.370\n",
            "Time taken: 0.448\n",
            "Time taken: 0.414\n",
            "Time taken: 0.421\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Epoch:744, step = 5959, diffusion continuous loss: 0.287, discrete loss: 0.219\n",
            "Epoch:744, step = 5959, CL continuous loss: 0.876, discrete loss: 0.780\n",
            "Epoch:744, step = 5959, Total continuous loss: 0.462, discrete loss: 0.375\n",
            "Time taken: 0.411\n",
            "Time taken: 0.425\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.414\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.423\n",
            "Epoch:745, step = 5967, diffusion continuous loss: 0.287, discrete loss: 0.216\n",
            "Epoch:745, step = 5967, CL continuous loss: 0.872, discrete loss: 0.788\n",
            "Epoch:745, step = 5967, Total continuous loss: 0.461, discrete loss: 0.374\n",
            "Time taken: 0.430\n",
            "Time taken: 0.445\n",
            "Time taken: 0.436\n",
            "Time taken: 0.460\n",
            "Time taken: 0.588\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Epoch:746, step = 5975, diffusion continuous loss: 0.306, discrete loss: 0.218\n",
            "Epoch:746, step = 5975, CL continuous loss: 0.912, discrete loss: 0.794\n",
            "Epoch:746, step = 5975, Total continuous loss: 0.488, discrete loss: 0.377\n",
            "Time taken: 0.434\n",
            "Time taken: 0.438\n",
            "Time taken: 0.442\n",
            "Time taken: 0.453\n",
            "Time taken: 0.458\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Epoch:747, step = 5983, diffusion continuous loss: 0.282, discrete loss: 0.215\n",
            "Epoch:747, step = 5983, CL continuous loss: 0.893, discrete loss: 0.791\n",
            "Epoch:747, step = 5983, Total continuous loss: 0.460, discrete loss: 0.373\n",
            "Time taken: 0.411\n",
            "Time taken: 0.422\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.425\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Epoch:748, step = 5991, diffusion continuous loss: 0.275, discrete loss: 0.218\n",
            "Epoch:748, step = 5991, CL continuous loss: 0.866, discrete loss: 0.804\n",
            "Epoch:748, step = 5991, Total continuous loss: 0.448, discrete loss: 0.378\n",
            "Time taken: 0.410\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Epoch:749, step = 5999, diffusion continuous loss: 0.296, discrete loss: 0.214\n",
            "Epoch:749, step = 5999, CL continuous loss: 0.861, discrete loss: 0.786\n",
            "Epoch:749, step = 5999, Total continuous loss: 0.469, discrete loss: 0.371\n",
            "Time taken: 0.412\n",
            "Time taken: 0.414\n",
            "Time taken: 0.423\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.446\n",
            "Time taken: 0.441\n",
            "Time taken: 0.434\n",
            "Epoch:750, step = 6007, diffusion continuous loss: 0.294, discrete loss: 0.228\n",
            "Epoch:750, step = 6007, CL continuous loss: 0.878, discrete loss: 0.776\n",
            "Epoch:750, step = 6007, Total continuous loss: 0.470, discrete loss: 0.383\n",
            "Time taken: 0.439\n",
            "Time taken: 0.451\n",
            "Time taken: 0.429\n",
            "Time taken: 0.514\n",
            "Time taken: 0.419\n",
            "Time taken: 0.413\n",
            "Time taken: 0.422\n",
            "Time taken: 0.416\n",
            "Epoch:751, step = 6015, diffusion continuous loss: 0.281, discrete loss: 0.228\n",
            "Epoch:751, step = 6015, CL continuous loss: 0.863, discrete loss: 0.777\n",
            "Epoch:751, step = 6015, Total continuous loss: 0.453, discrete loss: 0.383\n",
            "Time taken: 0.410\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.414\n",
            "Epoch:752, step = 6023, diffusion continuous loss: 0.281, discrete loss: 0.214\n",
            "Epoch:752, step = 6023, CL continuous loss: 0.857, discrete loss: 0.788\n",
            "Epoch:752, step = 6023, Total continuous loss: 0.452, discrete loss: 0.371\n",
            "Time taken: 0.407\n",
            "Time taken: 0.419\n",
            "Time taken: 0.413\n",
            "Time taken: 0.416\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Time taken: 0.414\n",
            "Time taken: 0.419\n",
            "Epoch:753, step = 6031, diffusion continuous loss: 0.285, discrete loss: 0.237\n",
            "Epoch:753, step = 6031, CL continuous loss: 0.879, discrete loss: 0.786\n",
            "Epoch:753, step = 6031, Total continuous loss: 0.461, discrete loss: 0.394\n",
            "Time taken: 0.406\n",
            "Time taken: 0.416\n",
            "Time taken: 0.456\n",
            "Time taken: 0.437\n",
            "Time taken: 0.434\n",
            "Time taken: 0.459\n",
            "Time taken: 0.449\n",
            "Time taken: 0.420\n",
            "Epoch:754, step = 6039, diffusion continuous loss: 0.274, discrete loss: 0.218\n",
            "Epoch:754, step = 6039, CL continuous loss: 0.859, discrete loss: 0.789\n",
            "Epoch:754, step = 6039, Total continuous loss: 0.445, discrete loss: 0.376\n",
            "Time taken: 0.411\n",
            "Time taken: 0.422\n",
            "Time taken: 0.420\n",
            "Time taken: 0.420\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Epoch:755, step = 6047, diffusion continuous loss: 0.268, discrete loss: 0.200\n",
            "Epoch:755, step = 6047, CL continuous loss: 0.890, discrete loss: 0.784\n",
            "Epoch:755, step = 6047, Total continuous loss: 0.446, discrete loss: 0.357\n",
            "Time taken: 0.410\n",
            "Time taken: 0.520\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.427\n",
            "Time taken: 0.414\n",
            "Epoch:756, step = 6055, diffusion continuous loss: 0.271, discrete loss: 0.200\n",
            "Epoch:756, step = 6055, CL continuous loss: 0.858, discrete loss: 0.781\n",
            "Epoch:756, step = 6055, Total continuous loss: 0.442, discrete loss: 0.356\n",
            "Time taken: 0.624\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Time taken: 0.430\n",
            "Time taken: 0.441\n",
            "Epoch:757, step = 6063, diffusion continuous loss: 0.281, discrete loss: 0.213\n",
            "Epoch:757, step = 6063, CL continuous loss: 0.851, discrete loss: 0.798\n",
            "Epoch:757, step = 6063, Total continuous loss: 0.451, discrete loss: 0.373\n",
            "Time taken: 0.426\n",
            "Time taken: 0.453\n",
            "Time taken: 0.449\n",
            "Time taken: 0.441\n",
            "Time taken: 0.422\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.411\n",
            "Epoch:758, step = 6071, diffusion continuous loss: 0.276, discrete loss: 0.222\n",
            "Epoch:758, step = 6071, CL continuous loss: 0.907, discrete loss: 0.773\n",
            "Epoch:758, step = 6071, Total continuous loss: 0.457, discrete loss: 0.376\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Epoch:759, step = 6079, diffusion continuous loss: 0.290, discrete loss: 0.227\n",
            "Epoch:759, step = 6079, CL continuous loss: 0.892, discrete loss: 0.783\n",
            "Epoch:759, step = 6079, Total continuous loss: 0.469, discrete loss: 0.384\n",
            "Time taken: 0.406\n",
            "Time taken: 0.416\n",
            "Time taken: 0.423\n",
            "Time taken: 0.422\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.511\n",
            "Epoch:760, step = 6087, diffusion continuous loss: 0.285, discrete loss: 0.213\n",
            "Epoch:760, step = 6087, CL continuous loss: 0.903, discrete loss: 0.791\n",
            "Epoch:760, step = 6087, Total continuous loss: 0.466, discrete loss: 0.371\n",
            "Time taken: 0.410\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.424\n",
            "Time taken: 0.437\n",
            "Time taken: 0.435\n",
            "Time taken: 0.441\n",
            "Time taken: 0.455\n",
            "Epoch:761, step = 6095, diffusion continuous loss: 0.276, discrete loss: 0.213\n",
            "Epoch:761, step = 6095, CL continuous loss: 0.876, discrete loss: 0.780\n",
            "Epoch:761, step = 6095, Total continuous loss: 0.451, discrete loss: 0.369\n",
            "Time taken: 0.437\n",
            "Time taken: 0.414\n",
            "Time taken: 0.414\n",
            "Time taken: 0.414\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Epoch:762, step = 6103, diffusion continuous loss: 0.276, discrete loss: 0.216\n",
            "Epoch:762, step = 6103, CL continuous loss: 0.873, discrete loss: 0.771\n",
            "Epoch:762, step = 6103, Total continuous loss: 0.450, discrete loss: 0.370\n",
            "Time taken: 0.407\n",
            "Time taken: 0.422\n",
            "Time taken: 0.424\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.412\n",
            "Time taken: 0.425\n",
            "Time taken: 0.416\n",
            "Epoch:763, step = 6111, diffusion continuous loss: 0.271, discrete loss: 0.218\n",
            "Epoch:763, step = 6111, CL continuous loss: 0.873, discrete loss: 0.786\n",
            "Epoch:763, step = 6111, Total continuous loss: 0.446, discrete loss: 0.375\n",
            "Time taken: 0.407\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Time taken: 0.422\n",
            "Time taken: 0.414\n",
            "Time taken: 0.422\n",
            "Time taken: 0.419\n",
            "Time taken: 0.412\n",
            "Epoch:764, step = 6119, diffusion continuous loss: 0.269, discrete loss: 0.217\n",
            "Epoch:764, step = 6119, CL continuous loss: 0.872, discrete loss: 0.774\n",
            "Epoch:764, step = 6119, Total continuous loss: 0.443, discrete loss: 0.372\n",
            "Time taken: 0.417\n",
            "Time taken: 0.438\n",
            "Time taken: 0.437\n",
            "Time taken: 0.433\n",
            "Time taken: 0.448\n",
            "Time taken: 0.447\n",
            "Time taken: 0.414\n",
            "Time taken: 0.422\n",
            "Epoch:765, step = 6127, diffusion continuous loss: 0.282, discrete loss: 0.221\n",
            "Epoch:765, step = 6127, CL continuous loss: 0.859, discrete loss: 0.769\n",
            "Epoch:765, step = 6127, Total continuous loss: 0.453, discrete loss: 0.375\n",
            "Time taken: 0.505\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.426\n",
            "Time taken: 0.419\n",
            "Epoch:766, step = 6135, diffusion continuous loss: 0.266, discrete loss: 0.216\n",
            "Epoch:766, step = 6135, CL continuous loss: 0.873, discrete loss: 0.796\n",
            "Epoch:766, step = 6135, Total continuous loss: 0.440, discrete loss: 0.375\n",
            "Time taken: 0.402\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Epoch:767, step = 6143, diffusion continuous loss: 0.272, discrete loss: 0.212\n",
            "Epoch:767, step = 6143, CL continuous loss: 0.862, discrete loss: 0.790\n",
            "Epoch:767, step = 6143, Total continuous loss: 0.444, discrete loss: 0.370\n",
            "Time taken: 0.412\n",
            "Time taken: 0.414\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.428\n",
            "Time taken: 0.437\n",
            "Time taken: 0.443\n",
            "Epoch:768, step = 6151, diffusion continuous loss: 0.283, discrete loss: 0.214\n",
            "Epoch:768, step = 6151, CL continuous loss: 0.865, discrete loss: 0.783\n",
            "Epoch:768, step = 6151, Total continuous loss: 0.456, discrete loss: 0.370\n",
            "Time taken: 0.431\n",
            "Time taken: 0.445\n",
            "Time taken: 0.461\n",
            "Time taken: 0.632\n",
            "Time taken: 0.425\n",
            "Time taken: 0.413\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Epoch:769, step = 6159, diffusion continuous loss: 0.289, discrete loss: 0.210\n",
            "Epoch:769, step = 6159, CL continuous loss: 0.857, discrete loss: 0.769\n",
            "Epoch:769, step = 6159, Total continuous loss: 0.460, discrete loss: 0.364\n",
            "Time taken: 0.409\n",
            "Time taken: 0.424\n",
            "Time taken: 0.415\n",
            "Time taken: 0.423\n",
            "Time taken: 0.420\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.414\n",
            "Epoch:770, step = 6167, diffusion continuous loss: 0.293, discrete loss: 0.232\n",
            "Epoch:770, step = 6167, CL continuous loss: 0.884, discrete loss: 0.800\n",
            "Epoch:770, step = 6167, Total continuous loss: 0.470, discrete loss: 0.392\n",
            "Time taken: 0.508\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.411\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Epoch:771, step = 6175, diffusion continuous loss: 0.288, discrete loss: 0.214\n",
            "Epoch:771, step = 6175, CL continuous loss: 0.865, discrete loss: 0.790\n",
            "Epoch:771, step = 6175, Total continuous loss: 0.461, discrete loss: 0.372\n",
            "Time taken: 0.406\n",
            "Time taken: 0.417\n",
            "Time taken: 0.450\n",
            "Time taken: 0.441\n",
            "Time taken: 0.438\n",
            "Time taken: 0.442\n",
            "Time taken: 0.450\n",
            "Time taken: 0.438\n",
            "Epoch:772, step = 6183, diffusion continuous loss: 0.359, discrete loss: 0.225\n",
            "Epoch:772, step = 6183, CL continuous loss: 0.943, discrete loss: 0.771\n",
            "Epoch:772, step = 6183, Total continuous loss: 0.547, discrete loss: 0.379\n",
            "Time taken: 0.406\n",
            "Time taken: 0.424\n",
            "Time taken: 0.415\n",
            "Time taken: 0.414\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Epoch:773, step = 6191, diffusion continuous loss: 0.303, discrete loss: 0.215\n",
            "Epoch:773, step = 6191, CL continuous loss: 0.888, discrete loss: 0.778\n",
            "Epoch:773, step = 6191, Total continuous loss: 0.481, discrete loss: 0.370\n",
            "Time taken: 0.409\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Epoch:774, step = 6199, diffusion continuous loss: 0.294, discrete loss: 0.206\n",
            "Epoch:774, step = 6199, CL continuous loss: 0.916, discrete loss: 0.783\n",
            "Epoch:774, step = 6199, Total continuous loss: 0.478, discrete loss: 0.362\n",
            "Time taken: 0.417\n",
            "Time taken: 0.423\n",
            "Time taken: 0.424\n",
            "Time taken: 0.420\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.422\n",
            "Time taken: 0.445\n",
            "Epoch:775, step = 6207, diffusion continuous loss: 0.306, discrete loss: 0.224\n",
            "Epoch:775, step = 6207, CL continuous loss: 0.887, discrete loss: 0.783\n",
            "Epoch:775, step = 6207, Total continuous loss: 0.483, discrete loss: 0.381\n",
            "Time taken: 0.432\n",
            "Time taken: 0.581\n",
            "Time taken: 0.445\n",
            "Time taken: 0.459\n",
            "Time taken: 0.442\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Epoch:776, step = 6215, diffusion continuous loss: 0.284, discrete loss: 0.216\n",
            "Epoch:776, step = 6215, CL continuous loss: 0.873, discrete loss: 0.783\n",
            "Epoch:776, step = 6215, Total continuous loss: 0.459, discrete loss: 0.373\n",
            "Time taken: 0.413\n",
            "Time taken: 0.429\n",
            "Time taken: 0.414\n",
            "Time taken: 0.425\n",
            "Time taken: 0.418\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.414\n",
            "Epoch:777, step = 6223, diffusion continuous loss: 0.264, discrete loss: 0.214\n",
            "Epoch:777, step = 6223, CL continuous loss: 0.851, discrete loss: 0.785\n",
            "Epoch:777, step = 6223, Total continuous loss: 0.434, discrete loss: 0.371\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Epoch:778, step = 6231, diffusion continuous loss: 0.280, discrete loss: 0.222\n",
            "Epoch:778, step = 6231, CL continuous loss: 0.887, discrete loss: 0.792\n",
            "Epoch:778, step = 6231, Total continuous loss: 0.457, discrete loss: 0.381\n",
            "Time taken: 0.410\n",
            "Time taken: 0.411\n",
            "Time taken: 0.424\n",
            "Time taken: 0.418\n",
            "Time taken: 0.431\n",
            "Time taken: 0.439\n",
            "Time taken: 0.436\n",
            "Time taken: 0.454\n",
            "Epoch:779, step = 6239, diffusion continuous loss: 0.283, discrete loss: 0.215\n",
            "Epoch:779, step = 6239, CL continuous loss: 0.869, discrete loss: 0.791\n",
            "Epoch:779, step = 6239, Total continuous loss: 0.457, discrete loss: 0.373\n",
            "Time taken: 0.440\n",
            "Time taken: 0.445\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.422\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Epoch:780, step = 6247, diffusion continuous loss: 0.277, discrete loss: 0.211\n",
            "Epoch:780, step = 6247, CL continuous loss: 0.874, discrete loss: 0.777\n",
            "Epoch:780, step = 6247, Total continuous loss: 0.452, discrete loss: 0.367\n",
            "Time taken: 0.409\n",
            "Time taken: 0.528\n",
            "Time taken: 0.423\n",
            "Time taken: 0.422\n",
            "Time taken: 0.422\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Time taken: 0.421\n",
            "Epoch:781, step = 6255, diffusion continuous loss: 0.295, discrete loss: 0.215\n",
            "Epoch:781, step = 6255, CL continuous loss: 0.873, discrete loss: 0.778\n",
            "Epoch:781, step = 6255, Total continuous loss: 0.469, discrete loss: 0.371\n",
            "Time taken: 0.414\n",
            "Time taken: 0.424\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.413\n",
            "Time taken: 0.418\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Epoch:782, step = 6263, diffusion continuous loss: 0.319, discrete loss: 0.211\n",
            "Epoch:782, step = 6263, CL continuous loss: 0.919, discrete loss: 0.767\n",
            "Epoch:782, step = 6263, Total continuous loss: 0.503, discrete loss: 0.365\n",
            "Time taken: 0.410\n",
            "Time taken: 0.443\n",
            "Time taken: 0.451\n",
            "Time taken: 0.438\n",
            "Time taken: 0.449\n",
            "Time taken: 0.447\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Epoch:783, step = 6271, diffusion continuous loss: 0.288, discrete loss: 0.217\n",
            "Epoch:783, step = 6271, CL continuous loss: 0.917, discrete loss: 0.790\n",
            "Epoch:783, step = 6271, Total continuous loss: 0.472, discrete loss: 0.375\n",
            "Time taken: 0.409\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.422\n",
            "Time taken: 0.419\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.413\n",
            "Epoch:784, step = 6279, diffusion continuous loss: 0.283, discrete loss: 0.216\n",
            "Epoch:784, step = 6279, CL continuous loss: 0.900, discrete loss: 0.789\n",
            "Epoch:784, step = 6279, Total continuous loss: 0.463, discrete loss: 0.373\n",
            "Time taken: 0.411\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.422\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Time taken: 0.515\n",
            "Epoch:785, step = 6287, diffusion continuous loss: 0.287, discrete loss: 0.221\n",
            "Epoch:785, step = 6287, CL continuous loss: 0.858, discrete loss: 0.787\n",
            "Epoch:785, step = 6287, Total continuous loss: 0.459, discrete loss: 0.378\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.423\n",
            "Time taken: 0.456\n",
            "Time taken: 0.446\n",
            "Epoch:786, step = 6295, diffusion continuous loss: 0.282, discrete loss: 0.218\n",
            "Epoch:786, step = 6295, CL continuous loss: 0.886, discrete loss: 0.777\n",
            "Epoch:786, step = 6295, Total continuous loss: 0.460, discrete loss: 0.373\n",
            "Time taken: 0.432\n",
            "Time taken: 0.466\n",
            "Time taken: 0.469\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.413\n",
            "Time taken: 0.419\n",
            "Epoch:787, step = 6303, diffusion continuous loss: 0.312, discrete loss: 0.213\n",
            "Epoch:787, step = 6303, CL continuous loss: 0.878, discrete loss: 0.780\n",
            "Epoch:787, step = 6303, Total continuous loss: 0.487, discrete loss: 0.369\n",
            "Time taken: 0.412\n",
            "Time taken: 0.425\n",
            "Time taken: 0.419\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.422\n",
            "Time taken: 0.424\n",
            "Time taken: 0.416\n",
            "Epoch:788, step = 6311, diffusion continuous loss: 0.307, discrete loss: 0.218\n",
            "Epoch:788, step = 6311, CL continuous loss: 0.886, discrete loss: 0.773\n",
            "Epoch:788, step = 6311, Total continuous loss: 0.484, discrete loss: 0.372\n",
            "Time taken: 0.413\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.412\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Epoch:789, step = 6319, diffusion continuous loss: 0.296, discrete loss: 0.213\n",
            "Epoch:789, step = 6319, CL continuous loss: 0.869, discrete loss: 0.780\n",
            "Epoch:789, step = 6319, Total continuous loss: 0.470, discrete loss: 0.369\n",
            "Time taken: 0.411\n",
            "Time taken: 0.414\n",
            "Time taken: 0.422\n",
            "Time taken: 0.445\n",
            "Time taken: 0.433\n",
            "Time taken: 0.444\n",
            "Time taken: 0.586\n",
            "Time taken: 0.452\n",
            "Epoch:790, step = 6327, diffusion continuous loss: 0.299, discrete loss: 0.202\n",
            "Epoch:790, step = 6327, CL continuous loss: 0.858, discrete loss: 0.769\n",
            "Epoch:790, step = 6327, Total continuous loss: 0.470, discrete loss: 0.356\n",
            "Time taken: 0.411\n",
            "Time taken: 0.421\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.413\n",
            "Epoch:791, step = 6335, diffusion continuous loss: 0.285, discrete loss: 0.222\n",
            "Epoch:791, step = 6335, CL continuous loss: 0.862, discrete loss: 0.795\n",
            "Epoch:791, step = 6335, Total continuous loss: 0.457, discrete loss: 0.381\n",
            "Time taken: 0.413\n",
            "Time taken: 0.414\n",
            "Time taken: 0.415\n",
            "Time taken: 0.423\n",
            "Time taken: 0.415\n",
            "Time taken: 0.414\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Epoch:792, step = 6343, diffusion continuous loss: 0.294, discrete loss: 0.220\n",
            "Epoch:792, step = 6343, CL continuous loss: 0.883, discrete loss: 0.783\n",
            "Epoch:792, step = 6343, Total continuous loss: 0.470, discrete loss: 0.376\n",
            "Time taken: 0.407\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.414\n",
            "Time taken: 0.419\n",
            "Time taken: 0.433\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Epoch:793, step = 6351, diffusion continuous loss: 0.291, discrete loss: 0.222\n",
            "Epoch:793, step = 6351, CL continuous loss: 0.874, discrete loss: 0.769\n",
            "Epoch:793, step = 6351, Total continuous loss: 0.466, discrete loss: 0.375\n",
            "Time taken: 0.442\n",
            "Time taken: 0.447\n",
            "Time taken: 0.454\n",
            "Time taken: 0.443\n",
            "Time taken: 0.450\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Epoch:794, step = 6359, diffusion continuous loss: 0.282, discrete loss: 0.215\n",
            "Epoch:794, step = 6359, CL continuous loss: 0.892, discrete loss: 0.781\n",
            "Epoch:794, step = 6359, Total continuous loss: 0.460, discrete loss: 0.372\n",
            "Time taken: 0.407\n",
            "Time taken: 0.423\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.515\n",
            "Time taken: 0.417\n",
            "Time taken: 0.425\n",
            "Time taken: 0.414\n",
            "Epoch:795, step = 6367, diffusion continuous loss: 0.305, discrete loss: 0.226\n",
            "Epoch:795, step = 6367, CL continuous loss: 0.878, discrete loss: 0.799\n",
            "Epoch:795, step = 6367, Total continuous loss: 0.481, discrete loss: 0.386\n",
            "Time taken: 0.408\n",
            "Time taken: 0.414\n",
            "Time taken: 0.414\n",
            "Time taken: 0.430\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.411\n",
            "Time taken: 0.418\n",
            "Epoch:796, step = 6375, diffusion continuous loss: 0.278, discrete loss: 0.223\n",
            "Epoch:796, step = 6375, CL continuous loss: 0.872, discrete loss: 0.790\n",
            "Epoch:796, step = 6375, Total continuous loss: 0.452, discrete loss: 0.381\n",
            "Time taken: 0.408\n",
            "Time taken: 0.415\n",
            "Time taken: 0.422\n",
            "Time taken: 0.416\n",
            "Time taken: 0.410\n",
            "Time taken: 0.439\n",
            "Time taken: 0.443\n",
            "Time taken: 0.443\n",
            "Epoch:797, step = 6383, diffusion continuous loss: 0.330, discrete loss: 0.210\n",
            "Epoch:797, step = 6383, CL continuous loss: 0.876, discrete loss: 0.789\n",
            "Epoch:797, step = 6383, Total continuous loss: 0.506, discrete loss: 0.368\n",
            "Time taken: 0.438\n",
            "Time taken: 0.448\n",
            "Time taken: 0.420\n",
            "Time taken: 0.414\n",
            "Time taken: 0.429\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Epoch:798, step = 6391, diffusion continuous loss: 0.314, discrete loss: 0.219\n",
            "Epoch:798, step = 6391, CL continuous loss: 0.876, discrete loss: 0.784\n",
            "Epoch:798, step = 6391, Total continuous loss: 0.489, discrete loss: 0.375\n",
            "Time taken: 0.407\n",
            "Time taken: 0.421\n",
            "Time taken: 0.415\n",
            "Time taken: 0.428\n",
            "Time taken: 0.417\n",
            "Time taken: 0.422\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Epoch:799, step = 6399, diffusion continuous loss: 0.299, discrete loss: 0.215\n",
            "Epoch:799, step = 6399, CL continuous loss: 0.899, discrete loss: 0.791\n",
            "Epoch:799, step = 6399, Total continuous loss: 0.479, discrete loss: 0.373\n",
            "Time taken: 0.540\n",
            "Time taken: 0.445\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.515\n",
            "Time taken: 0.427\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Epoch:800, step = 6407, diffusion continuous loss: 0.290, discrete loss: 0.218\n",
            "Epoch:800, step = 6407, CL continuous loss: 0.878, discrete loss: 0.774\n",
            "Epoch:800, step = 6407, Total continuous loss: 0.466, discrete loss: 0.373\n",
            "Time taken: 0.411\n",
            "Time taken: 0.424\n",
            "Time taken: 0.444\n",
            "Time taken: 0.444\n",
            "Time taken: 0.444\n",
            "Time taken: 0.453\n",
            "Time taken: 0.452\n",
            "Time taken: 0.418\n",
            "Epoch:801, step = 6415, diffusion continuous loss: 0.270, discrete loss: 0.216\n",
            "Epoch:801, step = 6415, CL continuous loss: 0.881, discrete loss: 0.773\n",
            "Epoch:801, step = 6415, Total continuous loss: 0.446, discrete loss: 0.371\n",
            "Time taken: 0.403\n",
            "Time taken: 0.420\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Time taken: 0.412\n",
            "Time taken: 0.421\n",
            "Time taken: 0.415\n",
            "Epoch:802, step = 6423, diffusion continuous loss: 0.277, discrete loss: 0.215\n",
            "Epoch:802, step = 6423, CL continuous loss: 0.879, discrete loss: 0.789\n",
            "Epoch:802, step = 6423, Total continuous loss: 0.453, discrete loss: 0.372\n",
            "Time taken: 0.409\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.413\n",
            "Time taken: 0.421\n",
            "Time taken: 0.409\n",
            "Time taken: 0.413\n",
            "Epoch:803, step = 6431, diffusion continuous loss: 0.282, discrete loss: 0.220\n",
            "Epoch:803, step = 6431, CL continuous loss: 0.865, discrete loss: 0.792\n",
            "Epoch:803, step = 6431, Total continuous loss: 0.455, discrete loss: 0.378\n",
            "Time taken: 0.412\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.425\n",
            "Time taken: 0.419\n",
            "Time taken: 0.440\n",
            "Epoch:804, step = 6439, diffusion continuous loss: 0.267, discrete loss: 0.216\n",
            "Epoch:804, step = 6439, CL continuous loss: 0.857, discrete loss: 0.788\n",
            "Epoch:804, step = 6439, Total continuous loss: 0.438, discrete loss: 0.374\n",
            "Time taken: 0.439\n",
            "Time taken: 0.438\n",
            "Time taken: 0.471\n",
            "Time taken: 0.592\n",
            "Time taken: 0.430\n",
            "Time taken: 0.414\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Epoch:805, step = 6447, diffusion continuous loss: 0.320, discrete loss: 0.214\n",
            "Epoch:805, step = 6447, CL continuous loss: 0.867, discrete loss: 0.775\n",
            "Epoch:805, step = 6447, Total continuous loss: 0.493, discrete loss: 0.369\n",
            "Time taken: 0.409\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.412\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Epoch:806, step = 6455, diffusion continuous loss: 0.300, discrete loss: 0.214\n",
            "Epoch:806, step = 6455, CL continuous loss: 0.903, discrete loss: 0.788\n",
            "Epoch:806, step = 6455, Total continuous loss: 0.481, discrete loss: 0.371\n",
            "Time taken: 0.409\n",
            "Time taken: 0.413\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.414\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Epoch:807, step = 6463, diffusion continuous loss: 0.280, discrete loss: 0.224\n",
            "Epoch:807, step = 6463, CL continuous loss: 0.867, discrete loss: 0.782\n",
            "Epoch:807, step = 6463, Total continuous loss: 0.453, discrete loss: 0.380\n",
            "Time taken: 0.406\n",
            "Time taken: 0.410\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.442\n",
            "Time taken: 0.456\n",
            "Time taken: 0.439\n",
            "Time taken: 0.442\n",
            "Epoch:808, step = 6471, diffusion continuous loss: 0.284, discrete loss: 0.218\n",
            "Epoch:808, step = 6471, CL continuous loss: 0.858, discrete loss: 0.781\n",
            "Epoch:808, step = 6471, Total continuous loss: 0.456, discrete loss: 0.374\n",
            "Time taken: 0.442\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.410\n",
            "Time taken: 0.419\n",
            "Epoch:809, step = 6479, diffusion continuous loss: 0.281, discrete loss: 0.216\n",
            "Epoch:809, step = 6479, CL continuous loss: 0.875, discrete loss: 0.773\n",
            "Epoch:809, step = 6479, Total continuous loss: 0.456, discrete loss: 0.371\n",
            "Time taken: 0.405\n",
            "Time taken: 0.417\n",
            "Time taken: 0.414\n",
            "Time taken: 0.515\n",
            "Time taken: 0.426\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.414\n",
            "Epoch:810, step = 6487, diffusion continuous loss: 0.300, discrete loss: 0.219\n",
            "Epoch:810, step = 6487, CL continuous loss: 0.857, discrete loss: 0.781\n",
            "Epoch:810, step = 6487, Total continuous loss: 0.472, discrete loss: 0.376\n",
            "Time taken: 0.404\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.414\n",
            "Time taken: 0.419\n",
            "Epoch:811, step = 6495, diffusion continuous loss: 0.270, discrete loss: 0.221\n",
            "Epoch:811, step = 6495, CL continuous loss: 0.896, discrete loss: 0.786\n",
            "Epoch:811, step = 6495, Total continuous loss: 0.450, discrete loss: 0.379\n",
            "Time taken: 0.410\n",
            "Time taken: 0.441\n",
            "Time taken: 0.438\n",
            "Time taken: 0.437\n",
            "Time taken: 0.453\n",
            "Time taken: 0.449\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Epoch:812, step = 6503, diffusion continuous loss: 0.268, discrete loss: 0.211\n",
            "Epoch:812, step = 6503, CL continuous loss: 0.862, discrete loss: 0.787\n",
            "Epoch:812, step = 6503, Total continuous loss: 0.440, discrete loss: 0.368\n",
            "Time taken: 0.402\n",
            "Time taken: 0.418\n",
            "Time taken: 0.414\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Time taken: 0.412\n",
            "Time taken: 0.418\n",
            "Epoch:813, step = 6511, diffusion continuous loss: 0.291, discrete loss: 0.226\n",
            "Epoch:813, step = 6511, CL continuous loss: 0.913, discrete loss: 0.789\n",
            "Epoch:813, step = 6511, Total continuous loss: 0.474, discrete loss: 0.384\n",
            "Time taken: 0.403\n",
            "Time taken: 0.421\n",
            "Time taken: 0.414\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Time taken: 0.412\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Epoch:814, step = 6519, diffusion continuous loss: 0.279, discrete loss: 0.214\n",
            "Epoch:814, step = 6519, CL continuous loss: 0.874, discrete loss: 0.778\n",
            "Epoch:814, step = 6519, Total continuous loss: 0.454, discrete loss: 0.369\n",
            "Time taken: 0.411\n",
            "Time taken: 0.415\n",
            "Time taken: 0.517\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.445\n",
            "Time taken: 0.437\n",
            "Epoch:815, step = 6527, diffusion continuous loss: 0.290, discrete loss: 0.214\n",
            "Epoch:815, step = 6527, CL continuous loss: 0.865, discrete loss: 0.783\n",
            "Epoch:815, step = 6527, Total continuous loss: 0.463, discrete loss: 0.370\n",
            "Time taken: 0.425\n",
            "Time taken: 0.445\n",
            "Time taken: 0.459\n",
            "Time taken: 0.416\n",
            "Time taken: 0.422\n",
            "Time taken: 0.414\n",
            "Time taken: 0.419\n",
            "Time taken: 0.426\n",
            "Epoch:816, step = 6535, diffusion continuous loss: 0.279, discrete loss: 0.217\n",
            "Epoch:816, step = 6535, CL continuous loss: 0.848, discrete loss: 0.775\n",
            "Epoch:816, step = 6535, Total continuous loss: 0.448, discrete loss: 0.372\n",
            "Time taken: 0.404\n",
            "Time taken: 0.419\n",
            "Time taken: 0.415\n",
            "Time taken: 0.412\n",
            "Time taken: 0.428\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.414\n",
            "Epoch:817, step = 6543, diffusion continuous loss: 0.318, discrete loss: 0.216\n",
            "Epoch:817, step = 6543, CL continuous loss: 0.856, discrete loss: 0.776\n",
            "Epoch:817, step = 6543, Total continuous loss: 0.489, discrete loss: 0.372\n",
            "Time taken: 0.403\n",
            "Time taken: 0.423\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Time taken: 0.414\n",
            "Time taken: 0.416\n",
            "Epoch:818, step = 6551, diffusion continuous loss: 0.285, discrete loss: 0.231\n",
            "Epoch:818, step = 6551, CL continuous loss: 0.902, discrete loss: 0.781\n",
            "Epoch:818, step = 6551, Total continuous loss: 0.465, discrete loss: 0.387\n",
            "Time taken: 0.411\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.452\n",
            "Time taken: 0.447\n",
            "Time taken: 0.444\n",
            "Time taken: 0.441\n",
            "Time taken: 0.445\n",
            "Epoch:819, step = 6559, diffusion continuous loss: 0.262, discrete loss: 0.213\n",
            "Epoch:819, step = 6559, CL continuous loss: 0.864, discrete loss: 0.792\n",
            "Epoch:819, step = 6559, Total continuous loss: 0.434, discrete loss: 0.372\n",
            "Time taken: 0.551\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.413\n",
            "Time taken: 0.418\n",
            "Time taken: 0.413\n",
            "Time taken: 0.417\n",
            "Time taken: 0.414\n",
            "Epoch:820, step = 6567, diffusion continuous loss: 0.287, discrete loss: 0.213\n",
            "Epoch:820, step = 6567, CL continuous loss: 0.871, discrete loss: 0.779\n",
            "Epoch:820, step = 6567, Total continuous loss: 0.461, discrete loss: 0.369\n",
            "Time taken: 0.412\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.412\n",
            "Time taken: 0.418\n",
            "Time taken: 0.411\n",
            "Time taken: 0.418\n",
            "Time taken: 0.412\n",
            "Epoch:821, step = 6575, diffusion continuous loss: 0.273, discrete loss: 0.218\n",
            "Epoch:821, step = 6575, CL continuous loss: 0.878, discrete loss: 0.789\n",
            "Epoch:821, step = 6575, Total continuous loss: 0.449, discrete loss: 0.376\n",
            "Time taken: 0.411\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Time taken: 0.422\n",
            "Time taken: 0.418\n",
            "Time taken: 0.424\n",
            "Time taken: 0.417\n",
            "Time taken: 0.414\n",
            "Epoch:822, step = 6583, diffusion continuous loss: 0.297, discrete loss: 0.210\n",
            "Epoch:822, step = 6583, CL continuous loss: 0.874, discrete loss: 0.778\n",
            "Epoch:822, step = 6583, Total continuous loss: 0.472, discrete loss: 0.366\n",
            "Time taken: 0.437\n",
            "Time taken: 0.438\n",
            "Time taken: 0.444\n",
            "Time taken: 0.433\n",
            "Time taken: 0.445\n",
            "Time taken: 0.445\n",
            "Time taken: 0.411\n",
            "Time taken: 0.417\n",
            "Epoch:823, step = 6591, diffusion continuous loss: 0.269, discrete loss: 0.218\n",
            "Epoch:823, step = 6591, CL continuous loss: 0.866, discrete loss: 0.794\n",
            "Epoch:823, step = 6591, Total continuous loss: 0.442, discrete loss: 0.377\n",
            "Time taken: 0.409\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.414\n",
            "Time taken: 0.422\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.507\n",
            "Epoch:824, step = 6599, diffusion continuous loss: 0.276, discrete loss: 0.216\n",
            "Epoch:824, step = 6599, CL continuous loss: 0.859, discrete loss: 0.777\n",
            "Epoch:824, step = 6599, Total continuous loss: 0.448, discrete loss: 0.372\n",
            "Time taken: 0.408\n",
            "Time taken: 0.423\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.422\n",
            "Time taken: 0.417\n",
            "Epoch:825, step = 6607, diffusion continuous loss: 0.330, discrete loss: 0.209\n",
            "Epoch:825, step = 6607, CL continuous loss: 0.905, discrete loss: 0.784\n",
            "Epoch:825, step = 6607, Total continuous loss: 0.511, discrete loss: 0.366\n",
            "Time taken: 0.408\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Time taken: 0.412\n",
            "Time taken: 0.442\n",
            "Time taken: 0.448\n",
            "Time taken: 0.438\n",
            "Epoch:826, step = 6615, diffusion continuous loss: 0.296, discrete loss: 0.219\n",
            "Epoch:826, step = 6615, CL continuous loss: 0.877, discrete loss: 0.790\n",
            "Epoch:826, step = 6615, Total continuous loss: 0.471, discrete loss: 0.377\n",
            "Time taken: 0.447\n",
            "Time taken: 0.442\n",
            "Time taken: 0.443\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Time taken: 0.414\n",
            "Time taken: 0.414\n",
            "Time taken: 0.422\n",
            "Epoch:827, step = 6623, diffusion continuous loss: 0.301, discrete loss: 0.221\n",
            "Epoch:827, step = 6623, CL continuous loss: 0.896, discrete loss: 0.784\n",
            "Epoch:827, step = 6623, Total continuous loss: 0.480, discrete loss: 0.378\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.422\n",
            "Time taken: 0.419\n",
            "Time taken: 0.414\n",
            "Time taken: 0.416\n",
            "Epoch:828, step = 6631, diffusion continuous loss: 0.280, discrete loss: 0.211\n",
            "Epoch:828, step = 6631, CL continuous loss: 0.874, discrete loss: 0.783\n",
            "Epoch:828, step = 6631, Total continuous loss: 0.455, discrete loss: 0.368\n",
            "Time taken: 0.401\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Time taken: 0.515\n",
            "Time taken: 0.426\n",
            "Time taken: 0.422\n",
            "Epoch:829, step = 6639, diffusion continuous loss: 0.271, discrete loss: 0.215\n",
            "Epoch:829, step = 6639, CL continuous loss: 0.879, discrete loss: 0.791\n",
            "Epoch:829, step = 6639, Total continuous loss: 0.447, discrete loss: 0.373\n",
            "Time taken: 0.407\n",
            "Time taken: 0.420\n",
            "Time taken: 0.449\n",
            "Time taken: 0.446\n",
            "Time taken: 0.436\n",
            "Time taken: 0.443\n",
            "Time taken: 0.448\n",
            "Time taken: 0.438\n",
            "Epoch:830, step = 6647, diffusion continuous loss: 0.266, discrete loss: 0.217\n",
            "Epoch:830, step = 6647, CL continuous loss: 0.874, discrete loss: 0.788\n",
            "Epoch:830, step = 6647, Total continuous loss: 0.441, discrete loss: 0.375\n",
            "Time taken: 0.411\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.412\n",
            "Time taken: 0.421\n",
            "Time taken: 0.422\n",
            "Time taken: 0.413\n",
            "Time taken: 0.421\n",
            "Epoch:831, step = 6655, diffusion continuous loss: 0.267, discrete loss: 0.222\n",
            "Epoch:831, step = 6655, CL continuous loss: 0.861, discrete loss: 0.785\n",
            "Epoch:831, step = 6655, Total continuous loss: 0.439, discrete loss: 0.379\n",
            "Time taken: 0.408\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Epoch:832, step = 6663, diffusion continuous loss: 0.300, discrete loss: 0.204\n",
            "Epoch:832, step = 6663, CL continuous loss: 0.871, discrete loss: 0.781\n",
            "Epoch:832, step = 6663, Total continuous loss: 0.475, discrete loss: 0.360\n",
            "Time taken: 0.425\n",
            "Time taken: 0.444\n",
            "Time taken: 0.437\n",
            "Time taken: 0.437\n",
            "Time taken: 0.441\n",
            "Time taken: 0.451\n",
            "Time taken: 0.419\n",
            "Time taken: 0.445\n",
            "Epoch:833, step = 6671, diffusion continuous loss: 0.286, discrete loss: 0.210\n",
            "Epoch:833, step = 6671, CL continuous loss: 0.873, discrete loss: 0.788\n",
            "Epoch:833, step = 6671, Total continuous loss: 0.460, discrete loss: 0.368\n",
            "Time taken: 0.434\n",
            "Time taken: 0.442\n",
            "Time taken: 0.443\n",
            "Time taken: 0.448\n",
            "Time taken: 0.533\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.421\n",
            "Epoch:834, step = 6679, diffusion continuous loss: 0.280, discrete loss: 0.218\n",
            "Epoch:834, step = 6679, CL continuous loss: 0.874, discrete loss: 0.772\n",
            "Epoch:834, step = 6679, Total continuous loss: 0.454, discrete loss: 0.373\n",
            "Time taken: 0.409\n",
            "Time taken: 0.414\n",
            "Time taken: 0.416\n",
            "Time taken: 0.414\n",
            "Time taken: 0.419\n",
            "Time taken: 0.410\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Epoch:835, step = 6687, diffusion continuous loss: 0.285, discrete loss: 0.212\n",
            "Epoch:835, step = 6687, CL continuous loss: 0.878, discrete loss: 0.768\n",
            "Epoch:835, step = 6687, Total continuous loss: 0.460, discrete loss: 0.366\n",
            "Time taken: 0.410\n",
            "Time taken: 0.421\n",
            "Time taken: 0.413\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.419\n",
            "Epoch:836, step = 6695, diffusion continuous loss: 0.279, discrete loss: 0.226\n",
            "Epoch:836, step = 6695, CL continuous loss: 0.878, discrete loss: 0.780\n",
            "Epoch:836, step = 6695, Total continuous loss: 0.455, discrete loss: 0.382\n",
            "Time taken: 0.410\n",
            "Time taken: 0.421\n",
            "Time taken: 0.413\n",
            "Time taken: 0.419\n",
            "Time taken: 0.448\n",
            "Time taken: 0.437\n",
            "Time taken: 0.440\n",
            "Time taken: 0.440\n",
            "Epoch:837, step = 6703, diffusion continuous loss: 0.274, discrete loss: 0.214\n",
            "Epoch:837, step = 6703, CL continuous loss: 0.867, discrete loss: 0.779\n",
            "Epoch:837, step = 6703, Total continuous loss: 0.448, discrete loss: 0.370\n",
            "Time taken: 0.456\n",
            "Time taken: 0.434\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Time taken: 0.429\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Epoch:838, step = 6711, diffusion continuous loss: 0.334, discrete loss: 0.207\n",
            "Epoch:838, step = 6711, CL continuous loss: 0.893, discrete loss: 0.783\n",
            "Epoch:838, step = 6711, Total continuous loss: 0.513, discrete loss: 0.363\n",
            "Time taken: 0.407\n",
            "Time taken: 0.419\n",
            "Time taken: 0.511\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.414\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Epoch:839, step = 6719, diffusion continuous loss: 0.276, discrete loss: 0.227\n",
            "Epoch:839, step = 6719, CL continuous loss: 0.899, discrete loss: 0.785\n",
            "Epoch:839, step = 6719, Total continuous loss: 0.455, discrete loss: 0.384\n",
            "Time taken: 0.405\n",
            "Time taken: 0.419\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.412\n",
            "Time taken: 0.423\n",
            "Time taken: 0.419\n",
            "Time taken: 0.415\n",
            "Epoch:840, step = 6727, diffusion continuous loss: 0.274, discrete loss: 0.224\n",
            "Epoch:840, step = 6727, CL continuous loss: 0.870, discrete loss: 0.791\n",
            "Epoch:840, step = 6727, Total continuous loss: 0.448, discrete loss: 0.382\n",
            "Time taken: 0.413\n",
            "Time taken: 0.447\n",
            "Time taken: 0.440\n",
            "Time taken: 0.436\n",
            "Time taken: 0.444\n",
            "Time taken: 0.455\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Epoch:841, step = 6735, diffusion continuous loss: 0.266, discrete loss: 0.233\n",
            "Epoch:841, step = 6735, CL continuous loss: 0.858, discrete loss: 0.805\n",
            "Epoch:841, step = 6735, Total continuous loss: 0.438, discrete loss: 0.394\n",
            "Time taken: 0.410\n",
            "Time taken: 0.415\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.412\n",
            "Time taken: 0.417\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Epoch:842, step = 6743, diffusion continuous loss: 0.309, discrete loss: 0.227\n",
            "Epoch:842, step = 6743, CL continuous loss: 0.892, discrete loss: 0.794\n",
            "Epoch:842, step = 6743, Total continuous loss: 0.488, discrete loss: 0.386\n",
            "Time taken: 0.406\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.412\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Epoch:843, step = 6751, diffusion continuous loss: 0.352, discrete loss: 0.207\n",
            "Epoch:843, step = 6751, CL continuous loss: 0.916, discrete loss: 0.804\n",
            "Epoch:843, step = 6751, Total continuous loss: 0.535, discrete loss: 0.368\n",
            "Time taken: 0.416\n",
            "Time taken: 0.534\n",
            "Time taken: 0.424\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Time taken: 0.448\n",
            "Time taken: 0.443\n",
            "Epoch:844, step = 6759, diffusion continuous loss: 0.308, discrete loss: 0.212\n",
            "Epoch:844, step = 6759, CL continuous loss: 0.887, discrete loss: 0.802\n",
            "Epoch:844, step = 6759, Total continuous loss: 0.486, discrete loss: 0.372\n",
            "Time taken: 0.433\n",
            "Time taken: 0.447\n",
            "Time taken: 0.451\n",
            "Time taken: 0.435\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.413\n",
            "Time taken: 0.416\n",
            "Epoch:845, step = 6767, diffusion continuous loss: 0.305, discrete loss: 0.277\n",
            "Epoch:845, step = 6767, CL continuous loss: 0.896, discrete loss: 0.834\n",
            "Epoch:845, step = 6767, Total continuous loss: 0.484, discrete loss: 0.443\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.422\n",
            "Epoch:846, step = 6775, diffusion continuous loss: 0.308, discrete loss: 0.285\n",
            "Epoch:846, step = 6775, CL continuous loss: 0.863, discrete loss: 0.873\n",
            "Epoch:846, step = 6775, Total continuous loss: 0.480, discrete loss: 0.460\n",
            "Time taken: 0.406\n",
            "Time taken: 0.424\n",
            "Time taken: 0.415\n",
            "Time taken: 0.422\n",
            "Time taken: 0.428\n",
            "Time taken: 0.418\n",
            "Time taken: 0.423\n",
            "Time taken: 0.418\n",
            "Epoch:847, step = 6783, diffusion continuous loss: 0.305, discrete loss: 0.284\n",
            "Epoch:847, step = 6783, CL continuous loss: 0.856, discrete loss: 0.924\n",
            "Epoch:847, step = 6783, Total continuous loss: 0.476, discrete loss: 0.469\n",
            "Time taken: 0.440\n",
            "Time taken: 0.429\n",
            "Time taken: 0.425\n",
            "Time taken: 0.463\n",
            "Time taken: 0.463\n",
            "Time taken: 0.446\n",
            "Time taken: 0.433\n",
            "Time taken: 0.582\n",
            "Epoch:848, step = 6791, diffusion continuous loss: 0.285, discrete loss: 0.287\n",
            "Epoch:848, step = 6791, CL continuous loss: 0.886, discrete loss: 0.927\n",
            "Epoch:848, step = 6791, Total continuous loss: 0.462, discrete loss: 0.473\n",
            "Time taken: 0.429\n",
            "Time taken: 0.425\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.414\n",
            "Time taken: 0.423\n",
            "Time taken: 0.422\n",
            "Time taken: 0.422\n",
            "Epoch:849, step = 6799, diffusion continuous loss: 0.326, discrete loss: 0.279\n",
            "Epoch:849, step = 6799, CL continuous loss: 0.866, discrete loss: 0.926\n",
            "Epoch:849, step = 6799, Total continuous loss: 0.500, discrete loss: 0.464\n",
            "Time taken: 0.406\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.412\n",
            "Epoch:850, step = 6807, diffusion continuous loss: 0.289, discrete loss: 0.270\n",
            "Epoch:850, step = 6807, CL continuous loss: 0.902, discrete loss: 0.929\n",
            "Epoch:850, step = 6807, Total continuous loss: 0.469, discrete loss: 0.455\n",
            "Time taken: 0.413\n",
            "Time taken: 0.422\n",
            "Time taken: 0.420\n",
            "Time taken: 0.421\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.423\n",
            "Time taken: 0.419\n",
            "Epoch:851, step = 6815, diffusion continuous loss: 0.321, discrete loss: 0.248\n",
            "Epoch:851, step = 6815, CL continuous loss: 0.938, discrete loss: 0.898\n",
            "Epoch:851, step = 6815, Total continuous loss: 0.508, discrete loss: 0.428\n",
            "Time taken: 0.423\n",
            "Time taken: 0.441\n",
            "Time taken: 0.446\n",
            "Time taken: 0.447\n",
            "Time taken: 0.456\n",
            "Time taken: 0.457\n",
            "Time taken: 0.414\n",
            "Time taken: 0.420\n",
            "Epoch:852, step = 6823, diffusion continuous loss: 0.287, discrete loss: 0.257\n",
            "Epoch:852, step = 6823, CL continuous loss: 0.899, discrete loss: 0.889\n",
            "Epoch:852, step = 6823, Total continuous loss: 0.467, discrete loss: 0.435\n",
            "Time taken: 0.407\n",
            "Time taken: 0.413\n",
            "Time taken: 0.424\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.511\n",
            "Time taken: 0.421\n",
            "Epoch:853, step = 6831, diffusion continuous loss: 0.274, discrete loss: 0.240\n",
            "Epoch:853, step = 6831, CL continuous loss: 0.873, discrete loss: 0.860\n",
            "Epoch:853, step = 6831, Total continuous loss: 0.448, discrete loss: 0.412\n",
            "Time taken: 0.412\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Epoch:854, step = 6839, diffusion continuous loss: 0.281, discrete loss: 0.230\n",
            "Epoch:854, step = 6839, CL continuous loss: 0.854, discrete loss: 0.847\n",
            "Epoch:854, step = 6839, Total continuous loss: 0.452, discrete loss: 0.399\n",
            "Time taken: 0.408\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.423\n",
            "Time taken: 0.420\n",
            "Time taken: 0.426\n",
            "Time taken: 0.447\n",
            "Time taken: 0.441\n",
            "Epoch:855, step = 6847, diffusion continuous loss: 0.268, discrete loss: 0.221\n",
            "Epoch:855, step = 6847, CL continuous loss: 0.852, discrete loss: 0.851\n",
            "Epoch:855, step = 6847, Total continuous loss: 0.438, discrete loss: 0.392\n",
            "Time taken: 0.433\n",
            "Time taken: 0.446\n",
            "Time taken: 0.460\n",
            "Time taken: 0.423\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Epoch:856, step = 6855, diffusion continuous loss: 0.282, discrete loss: 0.228\n",
            "Epoch:856, step = 6855, CL continuous loss: 0.900, discrete loss: 0.831\n",
            "Epoch:856, step = 6855, Total continuous loss: 0.462, discrete loss: 0.394\n",
            "Time taken: 0.412\n",
            "Time taken: 0.420\n",
            "Time taken: 0.422\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.423\n",
            "Epoch:857, step = 6863, diffusion continuous loss: 0.288, discrete loss: 0.221\n",
            "Epoch:857, step = 6863, CL continuous loss: 0.878, discrete loss: 0.824\n",
            "Epoch:857, step = 6863, Total continuous loss: 0.464, discrete loss: 0.386\n",
            "Time taken: 0.407\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.538\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.413\n",
            "Epoch:858, step = 6871, diffusion continuous loss: 0.274, discrete loss: 0.230\n",
            "Epoch:858, step = 6871, CL continuous loss: 0.886, discrete loss: 0.819\n",
            "Epoch:858, step = 6871, Total continuous loss: 0.451, discrete loss: 0.394\n",
            "Time taken: 0.412\n",
            "Time taken: 0.421\n",
            "Time taken: 0.423\n",
            "Time taken: 0.443\n",
            "Time taken: 0.441\n",
            "Time taken: 0.437\n",
            "Time taken: 0.453\n",
            "Time taken: 0.460\n",
            "Epoch:859, step = 6879, diffusion continuous loss: 0.260, discrete loss: 0.220\n",
            "Epoch:859, step = 6879, CL continuous loss: 0.877, discrete loss: 0.809\n",
            "Epoch:859, step = 6879, Total continuous loss: 0.436, discrete loss: 0.381\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.426\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.422\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Epoch:860, step = 6887, diffusion continuous loss: 0.263, discrete loss: 0.236\n",
            "Epoch:860, step = 6887, CL continuous loss: 0.865, discrete loss: 0.812\n",
            "Epoch:860, step = 6887, Total continuous loss: 0.436, discrete loss: 0.399\n",
            "Time taken: 0.405\n",
            "Time taken: 0.422\n",
            "Time taken: 0.424\n",
            "Time taken: 0.420\n",
            "Time taken: 0.421\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.435\n",
            "Epoch:861, step = 6895, diffusion continuous loss: 0.287, discrete loss: 0.235\n",
            "Epoch:861, step = 6895, CL continuous loss: 0.891, discrete loss: 0.812\n",
            "Epoch:861, step = 6895, Total continuous loss: 0.465, discrete loss: 0.397\n",
            "Time taken: 0.413\n",
            "Time taken: 0.422\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.432\n",
            "Time taken: 0.421\n",
            "Epoch:862, step = 6903, diffusion continuous loss: 0.326, discrete loss: 0.226\n",
            "Epoch:862, step = 6903, CL continuous loss: 0.875, discrete loss: 0.801\n",
            "Epoch:862, step = 6903, Total continuous loss: 0.501, discrete loss: 0.386\n",
            "Time taken: 0.446\n",
            "Time taken: 0.439\n",
            "Time taken: 0.442\n",
            "Time taken: 0.608\n",
            "Time taken: 0.452\n",
            "Time taken: 0.431\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Epoch:863, step = 6911, diffusion continuous loss: 0.330, discrete loss: 0.215\n",
            "Epoch:863, step = 6911, CL continuous loss: 0.894, discrete loss: 0.807\n",
            "Epoch:863, step = 6911, Total continuous loss: 0.509, discrete loss: 0.376\n",
            "Time taken: 0.408\n",
            "Time taken: 0.418\n",
            "Time taken: 0.423\n",
            "Time taken: 0.420\n",
            "Time taken: 0.427\n",
            "Time taken: 0.421\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Epoch:864, step = 6919, diffusion continuous loss: 0.302, discrete loss: 0.216\n",
            "Epoch:864, step = 6919, CL continuous loss: 0.875, discrete loss: 0.796\n",
            "Epoch:864, step = 6919, Total continuous loss: 0.477, discrete loss: 0.376\n",
            "Time taken: 0.412\n",
            "Time taken: 0.419\n",
            "Time taken: 0.423\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Epoch:865, step = 6927, diffusion continuous loss: 0.286, discrete loss: 0.216\n",
            "Epoch:865, step = 6927, CL continuous loss: 0.876, discrete loss: 0.801\n",
            "Epoch:865, step = 6927, Total continuous loss: 0.461, discrete loss: 0.376\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.443\n",
            "Time taken: 0.447\n",
            "Time taken: 0.435\n",
            "Epoch:866, step = 6935, diffusion continuous loss: 0.278, discrete loss: 0.228\n",
            "Epoch:866, step = 6935, CL continuous loss: 0.861, discrete loss: 0.794\n",
            "Epoch:866, step = 6935, Total continuous loss: 0.451, discrete loss: 0.387\n",
            "Time taken: 0.445\n",
            "Time taken: 0.451\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Time taken: 0.415\n",
            "Time taken: 0.425\n",
            "Time taken: 0.418\n",
            "Time taken: 0.413\n",
            "Epoch:867, step = 6943, diffusion continuous loss: 0.295, discrete loss: 0.217\n",
            "Epoch:867, step = 6943, CL continuous loss: 0.886, discrete loss: 0.797\n",
            "Epoch:867, step = 6943, Total continuous loss: 0.472, discrete loss: 0.377\n",
            "Time taken: 0.411\n",
            "Time taken: 0.517\n",
            "Time taken: 0.421\n",
            "Time taken: 0.421\n",
            "Time taken: 0.411\n",
            "Time taken: 0.414\n",
            "Time taken: 0.419\n",
            "Time taken: 0.424\n",
            "Epoch:868, step = 6951, diffusion continuous loss: 0.304, discrete loss: 0.213\n",
            "Epoch:868, step = 6951, CL continuous loss: 0.879, discrete loss: 0.805\n",
            "Epoch:868, step = 6951, Total continuous loss: 0.479, discrete loss: 0.374\n",
            "Time taken: 0.407\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.427\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Epoch:869, step = 6959, diffusion continuous loss: 0.282, discrete loss: 0.221\n",
            "Epoch:869, step = 6959, CL continuous loss: 0.874, discrete loss: 0.801\n",
            "Epoch:869, step = 6959, Total continuous loss: 0.456, discrete loss: 0.381\n",
            "Time taken: 0.402\n",
            "Time taken: 0.431\n",
            "Time taken: 0.447\n",
            "Time taken: 0.440\n",
            "Time taken: 0.437\n",
            "Time taken: 0.449\n",
            "Time taken: 0.446\n",
            "Time taken: 0.415\n",
            "Epoch:870, step = 6967, diffusion continuous loss: 0.282, discrete loss: 0.223\n",
            "Epoch:870, step = 6967, CL continuous loss: 0.865, discrete loss: 0.798\n",
            "Epoch:870, step = 6967, Total continuous loss: 0.455, discrete loss: 0.383\n",
            "Time taken: 0.412\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Time taken: 0.412\n",
            "Time taken: 0.416\n",
            "Time taken: 0.414\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Epoch:871, step = 6975, diffusion continuous loss: 0.277, discrete loss: 0.210\n",
            "Epoch:871, step = 6975, CL continuous loss: 0.867, discrete loss: 0.795\n",
            "Epoch:871, step = 6975, Total continuous loss: 0.450, discrete loss: 0.369\n",
            "Time taken: 0.410\n",
            "Time taken: 0.416\n",
            "Time taken: 0.422\n",
            "Time taken: 0.415\n",
            "Time taken: 0.422\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Epoch:872, step = 6983, diffusion continuous loss: 0.295, discrete loss: 0.222\n",
            "Epoch:872, step = 6983, CL continuous loss: 0.882, discrete loss: 0.794\n",
            "Epoch:872, step = 6983, Total continuous loss: 0.471, discrete loss: 0.381\n",
            "Time taken: 0.505\n",
            "Time taken: 0.422\n",
            "Time taken: 0.422\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.447\n",
            "Epoch:873, step = 6991, diffusion continuous loss: 0.306, discrete loss: 0.222\n",
            "Epoch:873, step = 6991, CL continuous loss: 0.920, discrete loss: 0.794\n",
            "Epoch:873, step = 6991, Total continuous loss: 0.490, discrete loss: 0.381\n",
            "Time taken: 0.426\n",
            "Time taken: 0.438\n",
            "Time taken: 0.453\n",
            "Time taken: 0.458\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Epoch:874, step = 6999, diffusion continuous loss: 0.296, discrete loss: 0.226\n",
            "Epoch:874, step = 6999, CL continuous loss: 0.876, discrete loss: 0.794\n",
            "Epoch:874, step = 6999, Total continuous loss: 0.472, discrete loss: 0.385\n",
            "Time taken: 0.413\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.423\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Epoch:875, step = 7007, diffusion continuous loss: 0.278, discrete loss: 0.222\n",
            "Epoch:875, step = 7007, CL continuous loss: 0.881, discrete loss: 0.799\n",
            "Epoch:875, step = 7007, Total continuous loss: 0.454, discrete loss: 0.382\n",
            "Time taken: 0.413\n",
            "Time taken: 0.420\n",
            "Time taken: 0.426\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.423\n",
            "Epoch:876, step = 7015, diffusion continuous loss: 0.298, discrete loss: 0.218\n",
            "Epoch:876, step = 7015, CL continuous loss: 0.864, discrete loss: 0.789\n",
            "Epoch:876, step = 7015, Total continuous loss: 0.471, discrete loss: 0.375\n",
            "Time taken: 0.411\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.444\n",
            "Time taken: 0.435\n",
            "Time taken: 0.594\n",
            "Time taken: 0.444\n",
            "Epoch:877, step = 7023, diffusion continuous loss: 0.268, discrete loss: 0.210\n",
            "Epoch:877, step = 7023, CL continuous loss: 0.862, discrete loss: 0.778\n",
            "Epoch:877, step = 7023, Total continuous loss: 0.440, discrete loss: 0.365\n",
            "Time taken: 0.447\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.423\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Epoch:878, step = 7031, diffusion continuous loss: 0.268, discrete loss: 0.220\n",
            "Epoch:878, step = 7031, CL continuous loss: 0.869, discrete loss: 0.780\n",
            "Epoch:878, step = 7031, Total continuous loss: 0.441, discrete loss: 0.376\n",
            "Time taken: 0.409\n",
            "Time taken: 0.411\n",
            "Time taken: 0.421\n",
            "Time taken: 0.412\n",
            "Time taken: 0.422\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Epoch:879, step = 7039, diffusion continuous loss: 0.296, discrete loss: 0.223\n",
            "Epoch:879, step = 7039, CL continuous loss: 0.870, discrete loss: 0.783\n",
            "Epoch:879, step = 7039, Total continuous loss: 0.470, discrete loss: 0.379\n",
            "Time taken: 0.406\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Epoch:880, step = 7047, diffusion continuous loss: 0.314, discrete loss: 0.215\n",
            "Epoch:880, step = 7047, CL continuous loss: 0.880, discrete loss: 0.784\n",
            "Epoch:880, step = 7047, Total continuous loss: 0.490, discrete loss: 0.372\n",
            "Time taken: 0.408\n",
            "Time taken: 0.437\n",
            "Time taken: 0.445\n",
            "Time taken: 0.456\n",
            "Time taken: 0.446\n",
            "Time taken: 0.448\n",
            "Time taken: 0.422\n",
            "Time taken: 0.419\n",
            "Epoch:881, step = 7055, diffusion continuous loss: 0.295, discrete loss: 0.207\n",
            "Epoch:881, step = 7055, CL continuous loss: 0.894, discrete loss: 0.788\n",
            "Epoch:881, step = 7055, Total continuous loss: 0.474, discrete loss: 0.365\n",
            "Time taken: 0.407\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.425\n",
            "Time taken: 0.418\n",
            "Time taken: 0.531\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Epoch:882, step = 7063, diffusion continuous loss: 0.275, discrete loss: 0.217\n",
            "Epoch:882, step = 7063, CL continuous loss: 0.876, discrete loss: 0.788\n",
            "Epoch:882, step = 7063, Total continuous loss: 0.450, discrete loss: 0.375\n",
            "Time taken: 0.410\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.413\n",
            "Time taken: 0.417\n",
            "Time taken: 0.414\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Epoch:883, step = 7071, diffusion continuous loss: 0.266, discrete loss: 0.226\n",
            "Epoch:883, step = 7071, CL continuous loss: 0.865, discrete loss: 0.789\n",
            "Epoch:883, step = 7071, Total continuous loss: 0.439, discrete loss: 0.384\n",
            "Time taken: 0.411\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.423\n",
            "Time taken: 0.418\n",
            "Time taken: 0.435\n",
            "Time taken: 0.436\n",
            "Epoch:884, step = 7079, diffusion continuous loss: 0.276, discrete loss: 0.206\n",
            "Epoch:884, step = 7079, CL continuous loss: 0.856, discrete loss: 0.779\n",
            "Epoch:884, step = 7079, Total continuous loss: 0.447, discrete loss: 0.361\n",
            "Time taken: 0.429\n",
            "Time taken: 0.453\n",
            "Time taken: 0.447\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.421\n",
            "Time taken: 0.412\n",
            "Time taken: 0.416\n",
            "Epoch:885, step = 7087, diffusion continuous loss: 0.282, discrete loss: 0.225\n",
            "Epoch:885, step = 7087, CL continuous loss: 0.859, discrete loss: 0.777\n",
            "Epoch:885, step = 7087, Total continuous loss: 0.454, discrete loss: 0.380\n",
            "Time taken: 0.409\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.412\n",
            "Time taken: 0.418\n",
            "Epoch:886, step = 7095, diffusion continuous loss: 0.264, discrete loss: 0.213\n",
            "Epoch:886, step = 7095, CL continuous loss: 0.867, discrete loss: 0.784\n",
            "Epoch:886, step = 7095, Total continuous loss: 0.437, discrete loss: 0.370\n",
            "Time taken: 0.406\n",
            "Time taken: 0.415\n",
            "Time taken: 0.421\n",
            "Time taken: 0.513\n",
            "Time taken: 0.415\n",
            "Time taken: 0.423\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Epoch:887, step = 7103, diffusion continuous loss: 0.270, discrete loss: 0.217\n",
            "Epoch:887, step = 7103, CL continuous loss: 0.899, discrete loss: 0.787\n",
            "Epoch:887, step = 7103, Total continuous loss: 0.450, discrete loss: 0.375\n",
            "Time taken: 0.411\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Time taken: 0.450\n",
            "Time taken: 0.440\n",
            "Time taken: 0.439\n",
            "Time taken: 0.461\n",
            "Time taken: 0.447\n",
            "Epoch:888, step = 7111, diffusion continuous loss: 0.282, discrete loss: 0.216\n",
            "Epoch:888, step = 7111, CL continuous loss: 0.897, discrete loss: 0.778\n",
            "Epoch:888, step = 7111, Total continuous loss: 0.461, discrete loss: 0.371\n",
            "Time taken: 0.405\n",
            "Time taken: 0.428\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.412\n",
            "Time taken: 0.419\n",
            "Epoch:889, step = 7119, diffusion continuous loss: 0.271, discrete loss: 0.211\n",
            "Epoch:889, step = 7119, CL continuous loss: 0.858, discrete loss: 0.788\n",
            "Epoch:889, step = 7119, Total continuous loss: 0.442, discrete loss: 0.369\n",
            "Time taken: 0.407\n",
            "Time taken: 0.418\n",
            "Time taken: 0.423\n",
            "Time taken: 0.416\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Epoch:890, step = 7127, diffusion continuous loss: 0.277, discrete loss: 0.228\n",
            "Epoch:890, step = 7127, CL continuous loss: 0.863, discrete loss: 0.783\n",
            "Epoch:890, step = 7127, Total continuous loss: 0.449, discrete loss: 0.384\n",
            "Time taken: 0.410\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.413\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Epoch:891, step = 7135, diffusion continuous loss: 0.274, discrete loss: 0.218\n",
            "Epoch:891, step = 7135, CL continuous loss: 0.886, discrete loss: 0.798\n",
            "Epoch:891, step = 7135, Total continuous loss: 0.451, discrete loss: 0.378\n",
            "Time taken: 0.437\n",
            "Time taken: 0.437\n",
            "Time taken: 0.572\n",
            "Time taken: 0.447\n",
            "Time taken: 0.456\n",
            "Time taken: 0.416\n",
            "Time taken: 0.422\n",
            "Time taken: 0.421\n",
            "Epoch:892, step = 7143, diffusion continuous loss: 0.314, discrete loss: 0.216\n",
            "Epoch:892, step = 7143, CL continuous loss: 0.888, discrete loss: 0.785\n",
            "Epoch:892, step = 7143, Total continuous loss: 0.492, discrete loss: 0.373\n",
            "Time taken: 0.406\n",
            "Time taken: 0.420\n",
            "Time taken: 0.411\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Epoch:893, step = 7151, diffusion continuous loss: 0.320, discrete loss: 0.214\n",
            "Epoch:893, step = 7151, CL continuous loss: 0.870, discrete loss: 0.802\n",
            "Epoch:893, step = 7151, Total continuous loss: 0.494, discrete loss: 0.375\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.427\n",
            "Time taken: 0.411\n",
            "Time taken: 0.419\n",
            "Epoch:894, step = 7159, diffusion continuous loss: 0.280, discrete loss: 0.225\n",
            "Epoch:894, step = 7159, CL continuous loss: 0.875, discrete loss: 0.783\n",
            "Epoch:894, step = 7159, Total continuous loss: 0.455, discrete loss: 0.381\n",
            "Time taken: 0.409\n",
            "Time taken: 0.419\n",
            "Time taken: 0.422\n",
            "Time taken: 0.421\n",
            "Time taken: 0.424\n",
            "Time taken: 0.445\n",
            "Time taken: 0.443\n",
            "Time taken: 0.437\n",
            "Epoch:895, step = 7167, diffusion continuous loss: 0.307, discrete loss: 0.215\n",
            "Epoch:895, step = 7167, CL continuous loss: 0.863, discrete loss: 0.775\n",
            "Epoch:895, step = 7167, Total continuous loss: 0.480, discrete loss: 0.370\n",
            "Time taken: 0.432\n",
            "Time taken: 0.450\n",
            "Time taken: 0.434\n",
            "Time taken: 0.415\n",
            "Time taken: 0.414\n",
            "Time taken: 0.414\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Epoch:896, step = 7175, diffusion continuous loss: 0.280, discrete loss: 0.225\n",
            "Epoch:896, step = 7175, CL continuous loss: 0.884, discrete loss: 0.788\n",
            "Epoch:896, step = 7175, Total continuous loss: 0.456, discrete loss: 0.383\n",
            "Time taken: 0.505\n",
            "Time taken: 0.412\n",
            "Time taken: 0.418\n",
            "Time taken: 0.429\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.415\n",
            "Epoch:897, step = 7183, diffusion continuous loss: 0.294, discrete loss: 0.217\n",
            "Epoch:897, step = 7183, CL continuous loss: 0.869, discrete loss: 0.785\n",
            "Epoch:897, step = 7183, Total continuous loss: 0.468, discrete loss: 0.374\n",
            "Time taken: 0.414\n",
            "Time taken: 0.413\n",
            "Time taken: 0.417\n",
            "Time taken: 0.412\n",
            "Time taken: 0.416\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Epoch:898, step = 7191, diffusion continuous loss: 0.331, discrete loss: 0.225\n",
            "Epoch:898, step = 7191, CL continuous loss: 0.883, discrete loss: 0.788\n",
            "Epoch:898, step = 7191, Total continuous loss: 0.508, discrete loss: 0.382\n",
            "Time taken: 0.409\n",
            "Time taken: 0.422\n",
            "Time taken: 0.454\n",
            "Time taken: 0.435\n",
            "Time taken: 0.447\n",
            "Time taken: 0.442\n",
            "Time taken: 0.453\n",
            "Time taken: 0.433\n",
            "Epoch:899, step = 7199, diffusion continuous loss: 0.275, discrete loss: 0.206\n",
            "Epoch:899, step = 7199, CL continuous loss: 0.895, discrete loss: 0.789\n",
            "Epoch:899, step = 7199, Total continuous loss: 0.454, discrete loss: 0.364\n",
            "Time taken: 0.555\n",
            "Time taken: 0.461\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.412\n",
            "Time taken: 0.417\n",
            "Time taken: 0.413\n",
            "Time taken: 0.418\n",
            "Epoch:900, step = 7207, diffusion continuous loss: 0.285, discrete loss: 0.212\n",
            "Epoch:900, step = 7207, CL continuous loss: 0.856, discrete loss: 0.788\n",
            "Epoch:900, step = 7207, Total continuous loss: 0.456, discrete loss: 0.370\n",
            "Time taken: 0.409\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.422\n",
            "Time taken: 0.426\n",
            "Time taken: 0.414\n",
            "Epoch:901, step = 7215, diffusion continuous loss: 0.280, discrete loss: 0.221\n",
            "Epoch:901, step = 7215, CL continuous loss: 0.866, discrete loss: 0.779\n",
            "Epoch:901, step = 7215, Total continuous loss: 0.453, discrete loss: 0.377\n",
            "Time taken: 0.509\n",
            "Time taken: 0.420\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.419\n",
            "Time taken: 0.424\n",
            "Time taken: 0.437\n",
            "Epoch:902, step = 7223, diffusion continuous loss: 0.267, discrete loss: 0.212\n",
            "Epoch:902, step = 7223, CL continuous loss: 0.866, discrete loss: 0.781\n",
            "Epoch:902, step = 7223, Total continuous loss: 0.440, discrete loss: 0.368\n",
            "Time taken: 0.431\n",
            "Time taken: 0.436\n",
            "Time taken: 0.448\n",
            "Time taken: 0.446\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Time taken: 0.423\n",
            "Time taken: 0.415\n",
            "Epoch:903, step = 7231, diffusion continuous loss: 0.271, discrete loss: 0.215\n",
            "Epoch:903, step = 7231, CL continuous loss: 0.857, discrete loss: 0.781\n",
            "Epoch:903, step = 7231, Total continuous loss: 0.442, discrete loss: 0.371\n",
            "Time taken: 0.410\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Time taken: 0.412\n",
            "Epoch:904, step = 7239, diffusion continuous loss: 0.274, discrete loss: 0.213\n",
            "Epoch:904, step = 7239, CL continuous loss: 0.858, discrete loss: 0.786\n",
            "Epoch:904, step = 7239, Total continuous loss: 0.445, discrete loss: 0.371\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.419\n",
            "Time taken: 0.414\n",
            "Epoch:905, step = 7247, diffusion continuous loss: 0.278, discrete loss: 0.218\n",
            "Epoch:905, step = 7247, CL continuous loss: 0.860, discrete loss: 0.783\n",
            "Epoch:905, step = 7247, Total continuous loss: 0.450, discrete loss: 0.374\n",
            "Time taken: 0.411\n",
            "Time taken: 0.416\n",
            "Time taken: 0.429\n",
            "Time taken: 0.418\n",
            "Time taken: 0.453\n",
            "Time taken: 0.436\n",
            "Time taken: 0.437\n",
            "Time taken: 0.601\n",
            "Epoch:906, step = 7255, diffusion continuous loss: 0.300, discrete loss: 0.219\n",
            "Epoch:906, step = 7255, CL continuous loss: 0.879, discrete loss: 0.785\n",
            "Epoch:906, step = 7255, Total continuous loss: 0.476, discrete loss: 0.376\n",
            "Time taken: 0.445\n",
            "Time taken: 0.429\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Time taken: 0.414\n",
            "Time taken: 0.421\n",
            "Time taken: 0.418\n",
            "Epoch:907, step = 7263, diffusion continuous loss: 0.281, discrete loss: 0.214\n",
            "Epoch:907, step = 7263, CL continuous loss: 0.860, discrete loss: 0.807\n",
            "Epoch:907, step = 7263, Total continuous loss: 0.453, discrete loss: 0.376\n",
            "Time taken: 0.407\n",
            "Time taken: 0.420\n",
            "Time taken: 0.413\n",
            "Time taken: 0.421\n",
            "Time taken: 0.417\n",
            "Time taken: 0.413\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Epoch:908, step = 7271, diffusion continuous loss: 0.274, discrete loss: 0.219\n",
            "Epoch:908, step = 7271, CL continuous loss: 0.869, discrete loss: 0.785\n",
            "Epoch:908, step = 7271, Total continuous loss: 0.448, discrete loss: 0.376\n",
            "Time taken: 0.405\n",
            "Time taken: 0.422\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.414\n",
            "Time taken: 0.419\n",
            "Time taken: 0.421\n",
            "Time taken: 0.422\n",
            "Epoch:909, step = 7279, diffusion continuous loss: 0.331, discrete loss: 0.222\n",
            "Epoch:909, step = 7279, CL continuous loss: 0.912, discrete loss: 0.783\n",
            "Epoch:909, step = 7279, Total continuous loss: 0.513, discrete loss: 0.379\n",
            "Time taken: 0.405\n",
            "Time taken: 0.438\n",
            "Time taken: 0.436\n",
            "Time taken: 0.435\n",
            "Time taken: 0.455\n",
            "Time taken: 0.452\n",
            "Time taken: 0.419\n",
            "Time taken: 0.414\n",
            "Epoch:910, step = 7287, diffusion continuous loss: 0.315, discrete loss: 0.210\n",
            "Epoch:910, step = 7287, CL continuous loss: 0.909, discrete loss: 0.782\n",
            "Epoch:910, step = 7287, Total continuous loss: 0.497, discrete loss: 0.366\n",
            "Time taken: 0.411\n",
            "Time taken: 0.421\n",
            "Time taken: 0.415\n",
            "Time taken: 0.421\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.428\n",
            "Time taken: 0.520\n",
            "Epoch:911, step = 7295, diffusion continuous loss: 0.278, discrete loss: 0.214\n",
            "Epoch:911, step = 7295, CL continuous loss: 0.874, discrete loss: 0.783\n",
            "Epoch:911, step = 7295, Total continuous loss: 0.453, discrete loss: 0.370\n",
            "Time taken: 0.412\n",
            "Time taken: 0.421\n",
            "Time taken: 0.413\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Epoch:912, step = 7303, diffusion continuous loss: 0.294, discrete loss: 0.222\n",
            "Epoch:912, step = 7303, CL continuous loss: 0.884, discrete loss: 0.796\n",
            "Epoch:912, step = 7303, Total continuous loss: 0.471, discrete loss: 0.381\n",
            "Time taken: 0.407\n",
            "Time taken: 0.414\n",
            "Time taken: 0.422\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.445\n",
            "Time taken: 0.445\n",
            "Epoch:913, step = 7311, diffusion continuous loss: 0.296, discrete loss: 0.229\n",
            "Epoch:913, step = 7311, CL continuous loss: 0.872, discrete loss: 0.787\n",
            "Epoch:913, step = 7311, Total continuous loss: 0.470, discrete loss: 0.386\n",
            "Time taken: 0.428\n",
            "Time taken: 0.446\n",
            "Time taken: 0.444\n",
            "Time taken: 0.414\n",
            "Time taken: 0.426\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Time taken: 0.412\n",
            "Epoch:914, step = 7319, diffusion continuous loss: 0.273, discrete loss: 0.212\n",
            "Epoch:914, step = 7319, CL continuous loss: 0.866, discrete loss: 0.798\n",
            "Epoch:914, step = 7319, Total continuous loss: 0.446, discrete loss: 0.372\n",
            "Time taken: 0.408\n",
            "Time taken: 0.430\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.421\n",
            "Time taken: 0.414\n",
            "Epoch:915, step = 7327, diffusion continuous loss: 0.266, discrete loss: 0.212\n",
            "Epoch:915, step = 7327, CL continuous loss: 0.870, discrete loss: 0.783\n",
            "Epoch:915, step = 7327, Total continuous loss: 0.440, discrete loss: 0.368\n",
            "Time taken: 0.412\n",
            "Time taken: 0.412\n",
            "Time taken: 0.419\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Time taken: 0.420\n",
            "Time taken: 0.517\n",
            "Time taken: 0.436\n",
            "Epoch:916, step = 7335, diffusion continuous loss: 0.272, discrete loss: 0.217\n",
            "Epoch:916, step = 7335, CL continuous loss: 0.855, discrete loss: 0.773\n",
            "Epoch:916, step = 7335, Total continuous loss: 0.443, discrete loss: 0.371\n",
            "Time taken: 0.409\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.443\n",
            "Time taken: 0.440\n",
            "Time taken: 0.438\n",
            "Time taken: 0.447\n",
            "Time taken: 0.443\n",
            "Epoch:917, step = 7343, diffusion continuous loss: 0.272, discrete loss: 0.216\n",
            "Epoch:917, step = 7343, CL continuous loss: 0.861, discrete loss: 0.786\n",
            "Epoch:917, step = 7343, Total continuous loss: 0.444, discrete loss: 0.373\n",
            "Time taken: 0.405\n",
            "Time taken: 0.414\n",
            "Time taken: 0.416\n",
            "Time taken: 0.413\n",
            "Time taken: 0.418\n",
            "Time taken: 0.413\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Epoch:918, step = 7351, diffusion continuous loss: 0.269, discrete loss: 0.218\n",
            "Epoch:918, step = 7351, CL continuous loss: 0.851, discrete loss: 0.800\n",
            "Epoch:918, step = 7351, Total continuous loss: 0.439, discrete loss: 0.378\n",
            "Time taken: 0.411\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.437\n",
            "Time taken: 0.434\n",
            "Time taken: 0.435\n",
            "Time taken: 0.434\n",
            "Time taken: 0.450\n",
            "Epoch:919, step = 7359, diffusion continuous loss: 0.266, discrete loss: 0.216\n",
            "Epoch:919, step = 7359, CL continuous loss: 0.855, discrete loss: 0.800\n",
            "Epoch:919, step = 7359, Total continuous loss: 0.437, discrete loss: 0.376\n",
            "Time taken: 0.441\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Epoch:920, step = 7367, diffusion continuous loss: 0.260, discrete loss: 0.219\n",
            "Epoch:920, step = 7367, CL continuous loss: 0.862, discrete loss: 0.800\n",
            "Epoch:920, step = 7367, Total continuous loss: 0.432, discrete loss: 0.379\n",
            "Time taken: 0.440\n",
            "Time taken: 0.438\n",
            "Time taken: 0.442\n",
            "Time taken: 0.451\n",
            "Time taken: 0.616\n",
            "Time taken: 0.418\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Epoch:921, step = 7375, diffusion continuous loss: 0.282, discrete loss: 0.217\n",
            "Epoch:921, step = 7375, CL continuous loss: 0.897, discrete loss: 0.801\n",
            "Epoch:921, step = 7375, Total continuous loss: 0.461, discrete loss: 0.377\n",
            "Time taken: 0.410\n",
            "Time taken: 0.421\n",
            "Time taken: 0.414\n",
            "Time taken: 0.413\n",
            "Time taken: 0.418\n",
            "Time taken: 0.421\n",
            "Time taken: 0.426\n",
            "Time taken: 0.417\n",
            "Epoch:922, step = 7383, diffusion continuous loss: 0.273, discrete loss: 0.219\n",
            "Epoch:922, step = 7383, CL continuous loss: 0.875, discrete loss: 0.789\n",
            "Epoch:922, step = 7383, Total continuous loss: 0.449, discrete loss: 0.377\n",
            "Time taken: 0.413\n",
            "Time taken: 0.412\n",
            "Time taken: 0.418\n",
            "Time taken: 0.413\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.415\n",
            "Epoch:923, step = 7391, diffusion continuous loss: 0.347, discrete loss: 0.209\n",
            "Epoch:923, step = 7391, CL continuous loss: 0.889, discrete loss: 0.799\n",
            "Epoch:923, step = 7391, Total continuous loss: 0.524, discrete loss: 0.369\n",
            "Time taken: 0.411\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.454\n",
            "Time taken: 0.447\n",
            "Time taken: 0.441\n",
            "Epoch:924, step = 7399, diffusion continuous loss: 0.312, discrete loss: 0.220\n",
            "Epoch:924, step = 7399, CL continuous loss: 0.860, discrete loss: 0.791\n",
            "Epoch:924, step = 7399, Total continuous loss: 0.484, discrete loss: 0.378\n",
            "Time taken: 0.442\n",
            "Time taken: 0.454\n",
            "Time taken: 0.433\n",
            "Time taken: 0.418\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.423\n",
            "Time taken: 0.416\n",
            "Epoch:925, step = 7407, diffusion continuous loss: 0.284, discrete loss: 0.221\n",
            "Epoch:925, step = 7407, CL continuous loss: 0.890, discrete loss: 0.781\n",
            "Epoch:925, step = 7407, Total continuous loss: 0.462, discrete loss: 0.377\n",
            "Time taken: 0.410\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.531\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.423\n",
            "Time taken: 0.415\n",
            "Epoch:926, step = 7415, diffusion continuous loss: 0.292, discrete loss: 0.229\n",
            "Epoch:926, step = 7415, CL continuous loss: 0.879, discrete loss: 0.788\n",
            "Epoch:926, step = 7415, Total continuous loss: 0.468, discrete loss: 0.387\n",
            "Time taken: 0.412\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Epoch:927, step = 7423, diffusion continuous loss: 0.282, discrete loss: 0.221\n",
            "Epoch:927, step = 7423, CL continuous loss: 0.865, discrete loss: 0.786\n",
            "Epoch:927, step = 7423, Total continuous loss: 0.454, discrete loss: 0.378\n",
            "Time taken: 0.409\n",
            "Time taken: 0.416\n",
            "Time taken: 0.449\n",
            "Time taken: 0.442\n",
            "Time taken: 0.439\n",
            "Time taken: 0.457\n",
            "Time taken: 0.452\n",
            "Time taken: 0.430\n",
            "Epoch:928, step = 7431, diffusion continuous loss: 0.269, discrete loss: 0.213\n",
            "Epoch:928, step = 7431, CL continuous loss: 0.860, discrete loss: 0.797\n",
            "Epoch:928, step = 7431, Total continuous loss: 0.441, discrete loss: 0.372\n",
            "Time taken: 0.411\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.413\n",
            "Time taken: 0.418\n",
            "Time taken: 0.411\n",
            "Time taken: 0.409\n",
            "Time taken: 0.417\n",
            "Epoch:929, step = 7439, diffusion continuous loss: 0.283, discrete loss: 0.215\n",
            "Epoch:929, step = 7439, CL continuous loss: 0.893, discrete loss: 0.776\n",
            "Epoch:929, step = 7439, Total continuous loss: 0.462, discrete loss: 0.370\n",
            "Time taken: 0.402\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.408\n",
            "Time taken: 0.418\n",
            "Time taken: 0.411\n",
            "Epoch:930, step = 7447, diffusion continuous loss: 0.268, discrete loss: 0.219\n",
            "Epoch:930, step = 7447, CL continuous loss: 0.867, discrete loss: 0.786\n",
            "Epoch:930, step = 7447, Total continuous loss: 0.441, discrete loss: 0.377\n",
            "Time taken: 0.403\n",
            "Time taken: 0.511\n",
            "Time taken: 0.415\n",
            "Time taken: 0.429\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.448\n",
            "Epoch:931, step = 7455, diffusion continuous loss: 0.274, discrete loss: 0.212\n",
            "Epoch:931, step = 7455, CL continuous loss: 0.864, discrete loss: 0.792\n",
            "Epoch:931, step = 7455, Total continuous loss: 0.447, discrete loss: 0.370\n",
            "Time taken: 0.433\n",
            "Time taken: 0.438\n",
            "Time taken: 0.454\n",
            "Time taken: 0.442\n",
            "Time taken: 0.439\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.420\n",
            "Epoch:932, step = 7463, diffusion continuous loss: 0.269, discrete loss: 0.212\n",
            "Epoch:932, step = 7463, CL continuous loss: 0.873, discrete loss: 0.774\n",
            "Epoch:932, step = 7463, Total continuous loss: 0.444, discrete loss: 0.367\n",
            "Time taken: 0.408\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Epoch:933, step = 7471, diffusion continuous loss: 0.272, discrete loss: 0.216\n",
            "Epoch:933, step = 7471, CL continuous loss: 0.883, discrete loss: 0.787\n",
            "Epoch:933, step = 7471, Total continuous loss: 0.448, discrete loss: 0.373\n",
            "Time taken: 0.407\n",
            "Time taken: 0.419\n",
            "Time taken: 0.419\n",
            "Time taken: 0.414\n",
            "Time taken: 0.414\n",
            "Time taken: 0.416\n",
            "Time taken: 0.426\n",
            "Time taken: 0.424\n",
            "Epoch:934, step = 7479, diffusion continuous loss: 0.261, discrete loss: 0.221\n",
            "Epoch:934, step = 7479, CL continuous loss: 0.866, discrete loss: 0.791\n",
            "Epoch:934, step = 7479, Total continuous loss: 0.434, discrete loss: 0.379\n",
            "Time taken: 0.402\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.425\n",
            "Time taken: 0.426\n",
            "Time taken: 0.446\n",
            "Time taken: 0.436\n",
            "Time taken: 0.436\n",
            "Epoch:935, step = 7487, diffusion continuous loss: 0.263, discrete loss: 0.224\n",
            "Epoch:935, step = 7487, CL continuous loss: 0.872, discrete loss: 0.791\n",
            "Epoch:935, step = 7487, Total continuous loss: 0.437, discrete loss: 0.382\n",
            "Time taken: 0.574\n",
            "Time taken: 0.437\n",
            "Time taken: 0.429\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Time taken: 0.414\n",
            "Time taken: 0.419\n",
            "Epoch:936, step = 7495, diffusion continuous loss: 0.259, discrete loss: 0.217\n",
            "Epoch:936, step = 7495, CL continuous loss: 0.865, discrete loss: 0.782\n",
            "Epoch:936, step = 7495, Total continuous loss: 0.432, discrete loss: 0.374\n",
            "Time taken: 0.403\n",
            "Time taken: 0.421\n",
            "Time taken: 0.414\n",
            "Time taken: 0.411\n",
            "Time taken: 0.417\n",
            "Time taken: 0.411\n",
            "Time taken: 0.425\n",
            "Time taken: 0.423\n",
            "Epoch:937, step = 7503, diffusion continuous loss: 0.298, discrete loss: 0.219\n",
            "Epoch:937, step = 7503, CL continuous loss: 0.875, discrete loss: 0.801\n",
            "Epoch:937, step = 7503, Total continuous loss: 0.473, discrete loss: 0.379\n",
            "Time taken: 0.404\n",
            "Time taken: 0.413\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Epoch:938, step = 7511, diffusion continuous loss: 0.286, discrete loss: 0.221\n",
            "Epoch:938, step = 7511, CL continuous loss: 0.885, discrete loss: 0.785\n",
            "Epoch:938, step = 7511, Total continuous loss: 0.463, discrete loss: 0.378\n",
            "Time taken: 0.413\n",
            "Time taken: 0.422\n",
            "Time taken: 0.443\n",
            "Time taken: 0.443\n",
            "Time taken: 0.434\n",
            "Time taken: 0.446\n",
            "Time taken: 0.440\n",
            "Time taken: 0.418\n",
            "Epoch:939, step = 7519, diffusion continuous loss: 0.309, discrete loss: 0.213\n",
            "Epoch:939, step = 7519, CL continuous loss: 0.890, discrete loss: 0.786\n",
            "Epoch:939, step = 7519, Total continuous loss: 0.488, discrete loss: 0.371\n",
            "Time taken: 0.409\n",
            "Time taken: 0.414\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.526\n",
            "Time taken: 0.414\n",
            "Epoch:940, step = 7527, diffusion continuous loss: 0.293, discrete loss: 0.218\n",
            "Epoch:940, step = 7527, CL continuous loss: 0.866, discrete loss: 0.788\n",
            "Epoch:940, step = 7527, Total continuous loss: 0.466, discrete loss: 0.375\n",
            "Time taken: 0.414\n",
            "Time taken: 0.413\n",
            "Time taken: 0.420\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Epoch:941, step = 7535, diffusion continuous loss: 0.290, discrete loss: 0.217\n",
            "Epoch:941, step = 7535, CL continuous loss: 0.902, discrete loss: 0.788\n",
            "Epoch:941, step = 7535, Total continuous loss: 0.471, discrete loss: 0.374\n",
            "Time taken: 0.405\n",
            "Time taken: 0.413\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Time taken: 0.425\n",
            "Time taken: 0.443\n",
            "Epoch:942, step = 7543, diffusion continuous loss: 0.276, discrete loss: 0.218\n",
            "Epoch:942, step = 7543, CL continuous loss: 0.899, discrete loss: 0.783\n",
            "Epoch:942, step = 7543, Total continuous loss: 0.456, discrete loss: 0.374\n",
            "Time taken: 0.442\n",
            "Time taken: 0.434\n",
            "Time taken: 0.450\n",
            "Time taken: 0.440\n",
            "Time taken: 0.411\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Epoch:943, step = 7551, diffusion continuous loss: 0.279, discrete loss: 0.212\n",
            "Epoch:943, step = 7551, CL continuous loss: 0.877, discrete loss: 0.789\n",
            "Epoch:943, step = 7551, Total continuous loss: 0.454, discrete loss: 0.370\n",
            "Time taken: 0.410\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.413\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Epoch:944, step = 7559, diffusion continuous loss: 0.274, discrete loss: 0.214\n",
            "Epoch:944, step = 7559, CL continuous loss: 0.880, discrete loss: 0.788\n",
            "Epoch:944, step = 7559, Total continuous loss: 0.450, discrete loss: 0.372\n",
            "Time taken: 0.411\n",
            "Time taken: 0.417\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Time taken: 0.424\n",
            "Time taken: 0.514\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Epoch:945, step = 7567, diffusion continuous loss: 0.265, discrete loss: 0.211\n",
            "Epoch:945, step = 7567, CL continuous loss: 0.878, discrete loss: 0.782\n",
            "Epoch:945, step = 7567, Total continuous loss: 0.441, discrete loss: 0.367\n",
            "Time taken: 0.402\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.426\n",
            "Time taken: 0.440\n",
            "Time taken: 0.438\n",
            "Time taken: 0.443\n",
            "Time taken: 0.466\n",
            "Epoch:946, step = 7575, diffusion continuous loss: 0.279, discrete loss: 0.215\n",
            "Epoch:946, step = 7575, CL continuous loss: 0.866, discrete loss: 0.789\n",
            "Epoch:946, step = 7575, Total continuous loss: 0.452, discrete loss: 0.373\n",
            "Time taken: 0.439\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.423\n",
            "Epoch:947, step = 7583, diffusion continuous loss: 0.274, discrete loss: 0.222\n",
            "Epoch:947, step = 7583, CL continuous loss: 0.854, discrete loss: 0.787\n",
            "Epoch:947, step = 7583, Total continuous loss: 0.445, discrete loss: 0.379\n",
            "Time taken: 0.407\n",
            "Time taken: 0.414\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.412\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Epoch:948, step = 7591, diffusion continuous loss: 0.280, discrete loss: 0.232\n",
            "Epoch:948, step = 7591, CL continuous loss: 0.857, discrete loss: 0.783\n",
            "Epoch:948, step = 7591, Total continuous loss: 0.451, discrete loss: 0.389\n",
            "Time taken: 0.410\n",
            "Time taken: 0.419\n",
            "Time taken: 0.410\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.419\n",
            "Time taken: 0.413\n",
            "Epoch:949, step = 7599, diffusion continuous loss: 0.288, discrete loss: 0.212\n",
            "Epoch:949, step = 7599, CL continuous loss: 0.858, discrete loss: 0.779\n",
            "Epoch:949, step = 7599, Total continuous loss: 0.460, discrete loss: 0.368\n",
            "Time taken: 0.414\n",
            "Time taken: 0.438\n",
            "Time taken: 0.447\n",
            "Time taken: 0.574\n",
            "Time taken: 0.443\n",
            "Time taken: 0.444\n",
            "Time taken: 0.411\n",
            "Time taken: 0.418\n",
            "Epoch:950, step = 7607, diffusion continuous loss: 0.304, discrete loss: 0.216\n",
            "Epoch:950, step = 7607, CL continuous loss: 0.897, discrete loss: 0.778\n",
            "Epoch:950, step = 7607, Total continuous loss: 0.483, discrete loss: 0.372\n",
            "Time taken: 0.406\n",
            "Time taken: 0.411\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.412\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Epoch:951, step = 7615, diffusion continuous loss: 0.285, discrete loss: 0.202\n",
            "Epoch:951, step = 7615, CL continuous loss: 0.877, discrete loss: 0.787\n",
            "Epoch:951, step = 7615, Total continuous loss: 0.460, discrete loss: 0.360\n",
            "Time taken: 0.405\n",
            "Time taken: 0.418\n",
            "Time taken: 0.414\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.412\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Epoch:952, step = 7623, diffusion continuous loss: 0.279, discrete loss: 0.216\n",
            "Epoch:952, step = 7623, CL continuous loss: 0.842, discrete loss: 0.781\n",
            "Epoch:952, step = 7623, Total continuous loss: 0.447, discrete loss: 0.373\n",
            "Time taken: 0.404\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.440\n",
            "Time taken: 0.440\n",
            "Epoch:953, step = 7631, diffusion continuous loss: 0.268, discrete loss: 0.205\n",
            "Epoch:953, step = 7631, CL continuous loss: 0.882, discrete loss: 0.775\n",
            "Epoch:953, step = 7631, Total continuous loss: 0.444, discrete loss: 0.360\n",
            "Time taken: 0.419\n",
            "Time taken: 0.445\n",
            "Time taken: 0.456\n",
            "Time taken: 0.413\n",
            "Time taken: 0.419\n",
            "Time taken: 0.413\n",
            "Time taken: 0.418\n",
            "Time taken: 0.412\n",
            "Epoch:954, step = 7639, diffusion continuous loss: 0.275, discrete loss: 0.217\n",
            "Epoch:954, step = 7639, CL continuous loss: 0.864, discrete loss: 0.780\n",
            "Epoch:954, step = 7639, Total continuous loss: 0.447, discrete loss: 0.373\n",
            "Time taken: 0.413\n",
            "Time taken: 0.416\n",
            "Time taken: 0.521\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.411\n",
            "Time taken: 0.417\n",
            "Time taken: 0.421\n",
            "Epoch:955, step = 7647, diffusion continuous loss: 0.282, discrete loss: 0.212\n",
            "Epoch:955, step = 7647, CL continuous loss: 0.893, discrete loss: 0.777\n",
            "Epoch:955, step = 7647, Total continuous loss: 0.461, discrete loss: 0.367\n",
            "Time taken: 0.409\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.420\n",
            "Time taken: 0.415\n",
            "Time taken: 0.418\n",
            "Time taken: 0.415\n",
            "Epoch:956, step = 7655, diffusion continuous loss: 0.280, discrete loss: 0.207\n",
            "Epoch:956, step = 7655, CL continuous loss: 0.899, discrete loss: 0.778\n",
            "Epoch:956, step = 7655, Total continuous loss: 0.460, discrete loss: 0.362\n",
            "Time taken: 0.409\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.448\n",
            "Time taken: 0.438\n",
            "Time taken: 0.435\n",
            "Time taken: 0.444\n",
            "Time taken: 0.446\n",
            "Epoch:957, step = 7663, diffusion continuous loss: 0.312, discrete loss: 0.223\n",
            "Epoch:957, step = 7663, CL continuous loss: 0.906, discrete loss: 0.788\n",
            "Epoch:957, step = 7663, Total continuous loss: 0.493, discrete loss: 0.381\n",
            "Time taken: 0.404\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.422\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Epoch:958, step = 7671, diffusion continuous loss: 0.288, discrete loss: 0.220\n",
            "Epoch:958, step = 7671, CL continuous loss: 0.859, discrete loss: 0.778\n",
            "Epoch:958, step = 7671, Total continuous loss: 0.459, discrete loss: 0.376\n",
            "Time taken: 0.418\n",
            "Time taken: 0.413\n",
            "Time taken: 0.419\n",
            "Time taken: 0.413\n",
            "Time taken: 0.423\n",
            "Time taken: 0.422\n",
            "Time taken: 0.406\n",
            "Time taken: 0.416\n",
            "Epoch:959, step = 7679, diffusion continuous loss: 0.285, discrete loss: 0.209\n",
            "Epoch:959, step = 7679, CL continuous loss: 0.876, discrete loss: 0.785\n",
            "Epoch:959, step = 7679, Total continuous loss: 0.460, discrete loss: 0.366\n",
            "Time taken: 0.511\n",
            "Time taken: 0.409\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.414\n",
            "Time taken: 0.412\n",
            "Time taken: 0.418\n",
            "Epoch:960, step = 7687, diffusion continuous loss: 0.345, discrete loss: 0.207\n",
            "Epoch:960, step = 7687, CL continuous loss: 0.911, discrete loss: 0.781\n",
            "Epoch:960, step = 7687, Total continuous loss: 0.527, discrete loss: 0.364\n",
            "Time taken: 0.430\n",
            "Time taken: 0.440\n",
            "Time taken: 0.442\n",
            "Time taken: 0.443\n",
            "Time taken: 0.447\n",
            "Time taken: 0.411\n",
            "Time taken: 0.419\n",
            "Time taken: 0.414\n",
            "Epoch:961, step = 7695, diffusion continuous loss: 0.321, discrete loss: 0.219\n",
            "Epoch:961, step = 7695, CL continuous loss: 0.902, discrete loss: 0.788\n",
            "Epoch:961, step = 7695, Total continuous loss: 0.501, discrete loss: 0.377\n",
            "Time taken: 0.414\n",
            "Time taken: 0.415\n",
            "Time taken: 0.415\n",
            "Time taken: 0.421\n",
            "Time taken: 0.414\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Time taken: 0.412\n",
            "Epoch:962, step = 7703, diffusion continuous loss: 0.283, discrete loss: 0.211\n",
            "Epoch:962, step = 7703, CL continuous loss: 0.899, discrete loss: 0.784\n",
            "Epoch:962, step = 7703, Total continuous loss: 0.462, discrete loss: 0.367\n",
            "Time taken: 0.420\n",
            "Time taken: 0.412\n",
            "Time taken: 0.416\n",
            "Time taken: 0.411\n",
            "Time taken: 0.416\n",
            "Time taken: 0.420\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Epoch:963, step = 7711, diffusion continuous loss: 0.269, discrete loss: 0.225\n",
            "Epoch:963, step = 7711, CL continuous loss: 0.884, discrete loss: 0.804\n",
            "Epoch:963, step = 7711, Total continuous loss: 0.446, discrete loss: 0.386\n",
            "Time taken: 0.411\n",
            "Time taken: 0.415\n",
            "Time taken: 0.422\n",
            "Time taken: 0.410\n",
            "Time taken: 0.423\n",
            "Time taken: 0.442\n",
            "Time taken: 0.437\n",
            "Time taken: 0.571\n",
            "Epoch:964, step = 7719, diffusion continuous loss: 0.276, discrete loss: 0.220\n",
            "Epoch:964, step = 7719, CL continuous loss: 0.875, discrete loss: 0.804\n",
            "Epoch:964, step = 7719, Total continuous loss: 0.451, discrete loss: 0.381\n",
            "Time taken: 0.446\n",
            "Time taken: 0.452\n",
            "Time taken: 0.420\n",
            "Time taken: 0.418\n",
            "Time taken: 0.413\n",
            "Time taken: 0.418\n",
            "Time taken: 0.411\n",
            "Time taken: 0.415\n",
            "Epoch:965, step = 7727, diffusion continuous loss: 0.288, discrete loss: 0.221\n",
            "Epoch:965, step = 7727, CL continuous loss: 0.871, discrete loss: 0.816\n",
            "Epoch:965, step = 7727, Total continuous loss: 0.462, discrete loss: 0.384\n",
            "Time taken: 0.410\n",
            "Time taken: 0.412\n",
            "Time taken: 0.416\n",
            "Time taken: 0.414\n",
            "Time taken: 0.412\n",
            "Time taken: 0.419\n",
            "Time taken: 0.412\n",
            "Time taken: 0.415\n",
            "Epoch:966, step = 7735, diffusion continuous loss: 0.286, discrete loss: 0.225\n",
            "Epoch:966, step = 7735, CL continuous loss: 0.872, discrete loss: 0.798\n",
            "Epoch:966, step = 7735, Total continuous loss: 0.460, discrete loss: 0.385\n",
            "Time taken: 0.403\n",
            "Time taken: 0.415\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.410\n",
            "Time taken: 0.423\n",
            "Epoch:967, step = 7743, diffusion continuous loss: 0.284, discrete loss: 0.216\n",
            "Epoch:967, step = 7743, CL continuous loss: 0.875, discrete loss: 0.782\n",
            "Epoch:967, step = 7743, Total continuous loss: 0.459, discrete loss: 0.372\n",
            "Time taken: 0.405\n",
            "Time taken: 0.417\n",
            "Time taken: 0.430\n",
            "Time taken: 0.438\n",
            "Time taken: 0.438\n",
            "Time taken: 0.437\n",
            "Time taken: 0.444\n",
            "Time taken: 0.442\n",
            "Epoch:968, step = 7751, diffusion continuous loss: 0.291, discrete loss: 0.236\n",
            "Epoch:968, step = 7751, CL continuous loss: 0.864, discrete loss: 0.787\n",
            "Epoch:968, step = 7751, Total continuous loss: 0.464, discrete loss: 0.393\n",
            "Time taken: 0.409\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Time taken: 0.410\n",
            "Time taken: 0.411\n",
            "Time taken: 0.511\n",
            "Time taken: 0.412\n",
            "Time taken: 0.416\n",
            "Epoch:969, step = 7759, diffusion continuous loss: 0.261, discrete loss: 0.216\n",
            "Epoch:969, step = 7759, CL continuous loss: 0.879, discrete loss: 0.788\n",
            "Epoch:969, step = 7759, Total continuous loss: 0.437, discrete loss: 0.373\n",
            "Time taken: 0.410\n",
            "Time taken: 0.423\n",
            "Time taken: 0.413\n",
            "Time taken: 0.410\n",
            "Time taken: 0.418\n",
            "Time taken: 0.423\n",
            "Time taken: 0.413\n",
            "Time taken: 0.417\n",
            "Epoch:970, step = 7767, diffusion continuous loss: 0.306, discrete loss: 0.215\n",
            "Epoch:970, step = 7767, CL continuous loss: 0.895, discrete loss: 0.783\n",
            "Epoch:970, step = 7767, Total continuous loss: 0.485, discrete loss: 0.372\n",
            "Time taken: 0.406\n",
            "Time taken: 0.417\n",
            "Time taken: 0.419\n",
            "Time taken: 0.416\n",
            "Time taken: 0.413\n",
            "Time taken: 0.413\n",
            "Time taken: 0.415\n",
            "Time taken: 0.422\n",
            "Epoch:971, step = 7775, diffusion continuous loss: 0.283, discrete loss: 0.220\n",
            "Epoch:971, step = 7775, CL continuous loss: 0.882, discrete loss: 0.780\n",
            "Epoch:971, step = 7775, Total continuous loss: 0.459, discrete loss: 0.376\n",
            "Time taken: 0.431\n",
            "Time taken: 0.436\n",
            "Time taken: 0.438\n",
            "Time taken: 0.443\n",
            "Time taken: 0.453\n",
            "Time taken: 0.415\n",
            "Time taken: 0.411\n",
            "Time taken: 0.419\n",
            "Epoch:972, step = 7783, diffusion continuous loss: 0.275, discrete loss: 0.224\n",
            "Epoch:972, step = 7783, CL continuous loss: 0.889, discrete loss: 0.777\n",
            "Epoch:972, step = 7783, Total continuous loss: 0.452, discrete loss: 0.379\n",
            "Time taken: 0.403\n",
            "Time taken: 0.415\n",
            "Time taken: 0.416\n",
            "Time taken: 0.411\n",
            "Time taken: 0.417\n",
            "Time taken: 0.410\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Epoch:973, step = 7791, diffusion continuous loss: 0.315, discrete loss: 0.225\n",
            "Epoch:973, step = 7791, CL continuous loss: 0.897, discrete loss: 0.780\n",
            "Epoch:973, step = 7791, Total continuous loss: 0.495, discrete loss: 0.381\n",
            "Time taken: 0.402\n",
            "Time taken: 0.421\n",
            "Time taken: 0.416\n",
            "Time taken: 0.418\n",
            "Time taken: 0.514\n",
            "Time taken: 0.416\n",
            "Time taken: 0.413\n",
            "Time taken: 0.416\n",
            "Epoch:974, step = 7799, diffusion continuous loss: 0.275, discrete loss: 0.213\n",
            "Epoch:974, step = 7799, CL continuous loss: 0.881, discrete loss: 0.784\n",
            "Epoch:974, step = 7799, Total continuous loss: 0.451, discrete loss: 0.370\n",
            "Time taken: 0.404\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.447\n",
            "Time taken: 0.439\n",
            "Time taken: 0.437\n",
            "Epoch:975, step = 7807, diffusion continuous loss: 0.259, discrete loss: 0.210\n",
            "Epoch:975, step = 7807, CL continuous loss: 0.874, discrete loss: 0.772\n",
            "Epoch:975, step = 7807, Total continuous loss: 0.434, discrete loss: 0.364\n",
            "Time taken: 0.433\n",
            "Time taken: 0.449\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.414\n",
            "Time taken: 0.415\n",
            "Epoch:976, step = 7815, diffusion continuous loss: 0.277, discrete loss: 0.211\n",
            "Epoch:976, step = 7815, CL continuous loss: 0.862, discrete loss: 0.784\n",
            "Epoch:976, step = 7815, Total continuous loss: 0.449, discrete loss: 0.368\n",
            "Time taken: 0.409\n",
            "Time taken: 0.420\n",
            "Time taken: 0.411\n",
            "Time taken: 0.410\n",
            "Time taken: 0.413\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Time taken: 0.410\n",
            "Epoch:977, step = 7823, diffusion continuous loss: 0.269, discrete loss: 0.219\n",
            "Epoch:977, step = 7823, CL continuous loss: 0.869, discrete loss: 0.779\n",
            "Epoch:977, step = 7823, Total continuous loss: 0.443, discrete loss: 0.374\n",
            "Time taken: 0.404\n",
            "Time taken: 0.414\n",
            "Time taken: 0.416\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.413\n",
            "Time taken: 0.416\n",
            "Time taken: 0.409\n",
            "Epoch:978, step = 7831, diffusion continuous loss: 0.290, discrete loss: 0.213\n",
            "Epoch:978, step = 7831, CL continuous loss: 0.874, discrete loss: 0.775\n",
            "Epoch:978, step = 7831, Total continuous loss: 0.465, discrete loss: 0.369\n",
            "Time taken: 0.409\n",
            "Time taken: 0.422\n",
            "Time taken: 0.583\n",
            "Time taken: 0.435\n",
            "Time taken: 0.433\n",
            "Time taken: 0.441\n",
            "Time taken: 0.453\n",
            "Time taken: 0.414\n",
            "Epoch:979, step = 7839, diffusion continuous loss: 0.277, discrete loss: 0.210\n",
            "Epoch:979, step = 7839, CL continuous loss: 0.886, discrete loss: 0.785\n",
            "Epoch:979, step = 7839, Total continuous loss: 0.454, discrete loss: 0.367\n",
            "Time taken: 0.413\n",
            "Time taken: 0.413\n",
            "Time taken: 0.417\n",
            "Time taken: 0.411\n",
            "Time taken: 0.412\n",
            "Time taken: 0.414\n",
            "Time taken: 0.416\n",
            "Time taken: 0.414\n",
            "Epoch:980, step = 7847, diffusion continuous loss: 0.292, discrete loss: 0.213\n",
            "Epoch:980, step = 7847, CL continuous loss: 0.846, discrete loss: 0.775\n",
            "Epoch:980, step = 7847, Total continuous loss: 0.461, discrete loss: 0.368\n",
            "Time taken: 0.401\n",
            "Time taken: 0.420\n",
            "Time taken: 0.416\n",
            "Time taken: 0.416\n",
            "Time taken: 0.413\n",
            "Time taken: 0.412\n",
            "Time taken: 0.417\n",
            "Time taken: 0.413\n",
            "Epoch:981, step = 7855, diffusion continuous loss: 0.273, discrete loss: 0.213\n",
            "Epoch:981, step = 7855, CL continuous loss: 0.889, discrete loss: 0.783\n",
            "Epoch:981, step = 7855, Total continuous loss: 0.451, discrete loss: 0.369\n",
            "Time taken: 0.411\n",
            "Time taken: 0.414\n",
            "Time taken: 0.417\n",
            "Time taken: 0.416\n",
            "Time taken: 0.415\n",
            "Time taken: 0.409\n",
            "Time taken: 0.416\n",
            "Time taken: 0.444\n",
            "Epoch:982, step = 7863, diffusion continuous loss: 0.276, discrete loss: 0.212\n",
            "Epoch:982, step = 7863, CL continuous loss: 0.887, discrete loss: 0.787\n",
            "Epoch:982, step = 7863, Total continuous loss: 0.454, discrete loss: 0.369\n",
            "Time taken: 0.433\n",
            "Time taken: 0.432\n",
            "Time taken: 0.439\n",
            "Time taken: 0.444\n",
            "Time taken: 0.433\n",
            "Time taken: 0.419\n",
            "Time taken: 0.417\n",
            "Time taken: 0.420\n",
            "Epoch:983, step = 7871, diffusion continuous loss: 0.259, discrete loss: 0.209\n",
            "Epoch:983, step = 7871, CL continuous loss: 0.878, discrete loss: 0.785\n",
            "Epoch:983, step = 7871, Total continuous loss: 0.434, discrete loss: 0.366\n",
            "Time taken: 0.410\n",
            "Time taken: 0.510\n",
            "Time taken: 0.411\n",
            "Time taken: 0.418\n",
            "Time taken: 0.417\n",
            "Time taken: 0.415\n",
            "Time taken: 0.410\n",
            "Time taken: 0.419\n",
            "Epoch:984, step = 7879, diffusion continuous loss: 0.270, discrete loss: 0.210\n",
            "Epoch:984, step = 7879, CL continuous loss: 0.870, discrete loss: 0.770\n",
            "Epoch:984, step = 7879, Total continuous loss: 0.444, discrete loss: 0.364\n",
            "Time taken: 0.403\n",
            "Time taken: 0.421\n",
            "Time taken: 0.414\n",
            "Time taken: 0.418\n",
            "Time taken: 0.414\n",
            "Time taken: 0.412\n",
            "Time taken: 0.422\n",
            "Time taken: 0.419\n",
            "Epoch:985, step = 7887, diffusion continuous loss: 0.277, discrete loss: 0.215\n",
            "Epoch:985, step = 7887, CL continuous loss: 0.874, discrete loss: 0.779\n",
            "Epoch:985, step = 7887, Total continuous loss: 0.452, discrete loss: 0.371\n",
            "Time taken: 0.405\n",
            "Time taken: 0.414\n",
            "Time taken: 0.416\n",
            "Time taken: 0.419\n",
            "Time taken: 0.428\n",
            "Time taken: 0.439\n",
            "Time taken: 0.435\n",
            "Time taken: 0.438\n",
            "Epoch:986, step = 7895, diffusion continuous loss: 0.332, discrete loss: 0.213\n",
            "Epoch:986, step = 7895, CL continuous loss: 0.915, discrete loss: 0.777\n",
            "Epoch:986, step = 7895, Total continuous loss: 0.515, discrete loss: 0.368\n",
            "Time taken: 0.443\n",
            "Time taken: 0.436\n",
            "Time taken: 0.413\n",
            "Time taken: 0.415\n",
            "Time taken: 0.413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname adult --method codi --mode sample --save_path adult_codi.csv"
      ],
      "metadata": {
        "id": "Cda_gqk1U4Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Default"
      ],
      "metadata": {
        "id": "A9gD8wQuU-sX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname default --method codi --mode train"
      ],
      "metadata": {
        "id": "nNLAVNxfVSai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname default --method codi --mode sample --save_path default_codi.csv"
      ],
      "metadata": {
        "id": "4zxDwDLUVSei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Shoppers"
      ],
      "metadata": {
        "id": "X009THKcVCfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname shoppers --method codi --mode train"
      ],
      "metadata": {
        "id": "ZPswC0OMVS-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname shoppers --method codi --mode sample --save_path shoppers_codi.csv"
      ],
      "metadata": {
        "id": "46A-HjmHVD5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Magic"
      ],
      "metadata": {
        "id": "gUefXV1dVEVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname magic --method codi --mode train"
      ],
      "metadata": {
        "id": "7UV3tOfhVTft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname magic --method codi --mode sample --save_path magic_codi.csv"
      ],
      "metadata": {
        "id": "2J0O0bqoVTiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Beijing"
      ],
      "metadata": {
        "id": "vqsED83YVGb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname beijing --method codi --mode train"
      ],
      "metadata": {
        "id": "9JNz-uFvVT7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataname beijing --method codi --mode sample --save_path beijing_codi.csv"
      ],
      "metadata": {
        "id": "O19nEN96VT9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metrics"
      ],
      "metadata": {
        "id": "MB9NQyIO6ep7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install sdv\n",
        "!pip install ucimlrepo\n",
        "!pio install sdmetrics\n",
        "!pip install -U kaleido\n",
        "!pip install synthcity[full]"
      ],
      "metadata": {
        "id": "9DWKxsrr6pnO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.4.0 torchvision --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yD_TSVTI984j",
        "outputId": "b1a537d3-1eae-4716-f936-c53488162895"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.11/dist-packages (2.4.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.19.0)\n",
            "Collecting torchvision\n",
            "  Using cached torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (2.8.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0) (12.9.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "  Using cached torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Using cached torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Using cached torchvision-0.20.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Using cached torchvision-0.19.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sdv\n",
        "import json\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "from sdv.metadata import SingleTableMetadata\n",
        "from sdmetrics.reports.single_table import QualityReport, DiagnosticReport\n",
        "from sdmetrics.visualization import get_column_plot\n",
        "from sdmetrics.column_pairs import CorrelationSimilarity\n",
        "from sdmetrics.column_pairs import ContingencySimilarity\n",
        "from itertools import combinations\n",
        "import statistics\n",
        "from sdmetrics.single_table import LogisticDetection\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from synthcity.plugins.core.dataloader import GenericDataLoader\n",
        "from synthcity.metrics import eval_detection, eval_performance, eval_statistical\n",
        "import torch\n",
        "from sklearn.preprocessing import OrdinalEncoder"
      ],
      "metadata": {
        "id": "Fv_9tn8_6n2C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3bd7181-8247-4a05-9185-85128afe6494"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[KeOps] Warning : CUDA libraries not found or could not be loaded; Switching to CPU only.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adult = pd.read_csv('../adult_syn.csv')"
      ],
      "metadata": {
        "id": "6KhVDuje_xwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adult_train = pd.read_csv('/content/tabsyn/data/adult/train.csv')"
      ],
      "metadata": {
        "id": "f-qrcdEw_43N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Metrics:\n",
        "    def __init__(self, train_path, test_path, synthetic_path, numeric_cols, cat_cols, target_col, classification=True):\n",
        "        self.real_df = pd.read_csv(train_path)\n",
        "        self.test = pd.read_csv(test_path)\n",
        "        self.synthetic_df = pd.read_csv(synthetic_path)\n",
        "        self.numeric_cols = self.real_df.columns[numeric_cols].to_list()\n",
        "        self.cat_cols = self.real_df.columns[cat_cols].to_list()\n",
        "        self.target_col = self.real_df.columns[target_col]\n",
        "        self.metadata = SingleTableMetadata()\n",
        "        self.metadata.detect_from_dataframe(data=self.real_df)\n",
        "        self.metadata = self.metadata.to_dict()\n",
        "        self.classification = classification\n",
        "        if self.classification:\n",
        "            self.cat_cols.append(self.target_col)\n",
        "\n",
        "    def preprocess_data(self, data):\n",
        "        df = data.copy()\n",
        "        enc_dict = {}\n",
        "        for column in self.cat_cols:\n",
        "            if column in df.columns:\n",
        "                enc = OrdinalEncoder(\n",
        "                    handle_unknown='use_encoded_value',\n",
        "                    unknown_value=-1\n",
        "                )\n",
        "                arr = df[[column]].astype(str)\n",
        "                df[column] = enc.fit_transform(arr).astype(int)\n",
        "                enc_dict[column] = enc\n",
        "        return df, enc_dict\n",
        "\n",
        "    def encode_data(self, data, enc_dict):\n",
        "        df = data.copy()\n",
        "        for column in self.cat_cols:\n",
        "            if column in df.columns and column in enc_dict:\n",
        "                enc = enc_dict[column]\n",
        "                arr = df[[column]].astype(str)\n",
        "                df[column] = enc.transform(arr).astype(int)\n",
        "        return df\n",
        "\n",
        "    def train_and_evaluate(self, X_train, X_test, y_train, y_test, n_splits=20):\n",
        "        param_grid = {\n",
        "            'n_estimators': [10, 50, 100],\n",
        "            'min_child_weight': [5, 10, 20],\n",
        "            'max_depth': [1, 10],\n",
        "            'gamma': [0.0, 1.0]\n",
        "        }\n",
        "\n",
        "        scores = []\n",
        "\n",
        "        for i in range(n_splits):\n",
        "            X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
        "                X_train, y_train, test_size=0.111, random_state=i\n",
        "            )\n",
        "\n",
        "            if self.classification:\n",
        "                model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "                scoring = 'roc_auc'\n",
        "            else:\n",
        "                model = XGBRegressor(use_label_encoder=False)\n",
        "                scoring = 'neg_mean_squared_error'\n",
        "            grid_search = GridSearchCV(\n",
        "                model, param_grid, scoring=scoring, cv=3\n",
        "            )\n",
        "\n",
        "            grid_search.fit(X_train_split, y_train_split)\n",
        "\n",
        "            if self.classification:\n",
        "                best_model = XGBClassifier(**grid_search.best_params_,\n",
        "                                    use_label_encoder=False,\n",
        "                                    eval_metric='auc')\n",
        "            else:\n",
        "                best_model = XGBRegressor(**grid_search.best_params_,\n",
        "                                    use_label_encoder=False, objective='reg:squarederror')\n",
        "\n",
        "            best_model.fit(X_train, y_train)\n",
        "\n",
        "            if self.classification:\n",
        "                y_pred = best_model.predict_proba(X_test)[:, 1]\n",
        "                score = roc_auc_score(y_test, y_pred)\n",
        "            else:\n",
        "                y_pred = best_model.predict(X_test)\n",
        "                score = mean_squared_error(y_test, y_pred)\n",
        "                score = np.sqrt(score)\n",
        "            scores.append(score)\n",
        "\n",
        "        return np.mean(scores), np.std(scores)\n",
        "\n",
        "    def classification_metrics(self):\n",
        "            X_train_real = self.real_df.drop(columns=[self.target_col], axis=1)\n",
        "            y_train_real = self.real_df[self.target_col]\n",
        "\n",
        "            X_test = self.test.drop(columns=[self.target_col], axis=1)\n",
        "            y_test = self.test[self.target_col]\n",
        "\n",
        "            X_train_synthetic = self.synthetic_df.drop(self.target_col, axis=1)\n",
        "            y_train_synthetic = self.synthetic_df[self.target_col]\n",
        "\n",
        "            X_train_real, enc_dict_X = self.preprocess_data(X_train_real)\n",
        "            X_test = self.encode_data(X_test, enc_dict_X)\n",
        "            X_train_synthetic = self.encode_data(X_train_synthetic, enc_dict_X)\n",
        "\n",
        "            if self.target_col in self.cat_cols:\n",
        "                enc_target = OrdinalEncoder(\n",
        "                    handle_unknown='use_encoded_value',\n",
        "                    unknown_value=-1\n",
        "                )\n",
        "\n",
        "                y_tr = y_train_real.astype(str).to_frame()\n",
        "                y_train_real = enc_target.fit_transform(y_tr).ravel().astype(int)\n",
        "                y_train_synthetic = enc_target.transform(\n",
        "                    y_train_synthetic.astype(str).to_frame()\n",
        "                ).ravel().astype(int)\n",
        "                y_test = enc_target.transform(\n",
        "                    y_test.astype(str).to_frame()\n",
        "                ).ravel().astype(int)\n",
        "\n",
        "            real_mean, real_std = self.train_and_evaluate(\n",
        "                X_train_real, X_test, y_train_real, y_test\n",
        "            )\n",
        "            synthetic_mean, synthetic_std = self.train_and_evaluate(\n",
        "                X_train_synthetic, X_test, y_train_synthetic, y_test\n",
        "            )\n",
        "\n",
        "            if self.classification:\n",
        "                print(\"Classificator results (AUC):\")\n",
        "            else:\n",
        "                print(\"Regression results (MSE):\")\n",
        "            print(f\"Real data - : {real_mean:.3f} ± {real_std:.3f}\")\n",
        "            print(f\"Synthetic data - : {synthetic_mean:.3f} ± {synthetic_std:.3f}\")\n",
        "\n",
        "            return {\n",
        "                'real_mean': real_mean, 'real_std': real_std,\n",
        "                'synthetic_mean': synthetic_mean, 'synthetic_std': synthetic_std\n",
        "            }\n",
        "\n",
        "\n",
        "    def density_estimation(self) -> dict:\n",
        "        qual_report = QualityReport()\n",
        "        qual_report.generate(self.real_df, self.synthetic_df, self.metadata)\n",
        "\n",
        "        diag_report = DiagnosticReport()\n",
        "        diag_report.generate(self.real_df, self.synthetic_df, self.metadata)\n",
        "\n",
        "        fig_shape = qual_report.get_visualization(property_name='Column Shapes')\n",
        "        fig_trend = qual_report.get_visualization(property_name='Column Pair Trends')\n",
        "        fig_shape.show()\n",
        "        fig_trend.show()\n",
        "\n",
        "        quality_scores = qual_report.get_score()\n",
        "        diag_scores = diag_report.get_score()\n",
        "        quality =  qual_report.get_properties()\n",
        "\n",
        "        Shape = quality['Score'][0]\n",
        "        Trend = quality['Score'][1]\n",
        "        shapes = qual_report.get_details(property_name='Column Shapes')\n",
        "        trends = qual_report.get_details(property_name='Column Pair Trends')\n",
        "        validity = diag_report.get_details('Data Validity')\n",
        "        structure = diag_report.get_details('Data Structure')\n",
        "\n",
        "        metrics = {\n",
        "            'overall_quality': {\n",
        "                'shapes': Shape,\n",
        "                'trends': Trend,\n",
        "                'total_score': (Shape + Trend) / 2\n",
        "            },\n",
        "            'details': {\n",
        "                'column_shapes': shapes,\n",
        "                'column_trends': trends,\n",
        "                'data_validity': validity,\n",
        "                'data_structure': structure\n",
        "            }\n",
        "        }\n",
        "\n",
        "        print(f\"\\n{' METRICS REPORT ':=^80}\")\n",
        "        print(f\"Column Shapes Score: {metrics['overall_quality']['shapes']:.3f}\")\n",
        "        print(f\"Column Trends Score: {metrics['overall_quality']['trends']:.3f}\")\n",
        "        print(f\"Overall Score: {metrics['overall_quality']['total_score']:.3f}\")\n",
        "\n",
        "        #fig = qual_report.get_visualization(property_name='Column Pair Trends')\n",
        "        #fig.show()\n",
        "\n",
        "        return metrics\n",
        "\n",
        "\n",
        "    def visualize_distr(self):\n",
        "        for i in self.numeric_cols:\n",
        "            fig = get_column_plot(\n",
        "                real_data=self.real_df,\n",
        "                synthetic_data=self.synthetic_df,\n",
        "                column_name= i,\n",
        "                plot_type='distplot'\n",
        "            )\n",
        "\n",
        "            fig.show()\n",
        "\n",
        "    def correlation_similarity(self):\n",
        "        correlation_score = CorrelationSimilarity.compute(\n",
        "            real_data=self.real_df[self.numeric_cols],\n",
        "            synthetic_data=self.synthetic_df[self.numeric_cols],\n",
        "            coefficient='Pearson'\n",
        "        )\n",
        "        print(f'correlation score: {correlation_score:.3f}')\n",
        "        return correlation_score\n",
        "\n",
        "    def contingency_similarity(self):\n",
        "        res = []\n",
        "        for col1, col2 in combinations(self.numeric_cols, 2):\n",
        "            similarity = ContingencySimilarity.compute(\n",
        "                real_data=self.real_df[[col1, col2]],\n",
        "                synthetic_data=self.synthetic_df[[col1, col2]],\n",
        "                continuous_column_names=[col1, col2]\n",
        "            )\n",
        "            res.append(similarity)\n",
        "        mean_similarity = statistics.mean(res)\n",
        "        print(f'contingency similarity score: {mean_similarity:.3f}')\n",
        "        return mean_similarity\n",
        "\n",
        "    def logistic_detection(self):\n",
        "        log_detection_score = LogisticDetection.compute(\n",
        "            real_data=self.real_df,\n",
        "            synthetic_data=self.synthetic_df,\n",
        "            metadata=self.metadata\n",
        "        )\n",
        "        print(f'log detection score: {log_detection_score:.3f}')\n",
        "        return log_detection_score\n",
        "\n",
        "    def alpha_precision(self):\n",
        "        num_real_data = self.real_df[self.numeric_cols]\n",
        "        cat_real_data = self.real_df[self.cat_cols]\n",
        "\n",
        "        num_syn_data = self.synthetic_df[self.numeric_cols]\n",
        "        cat_syn_data = self.synthetic_df[self.cat_cols]\n",
        "\n",
        "        encoder = OneHotEncoder()\n",
        "        cat_real_data_oh = encoder.fit_transform(cat_real_data.astype(str)).toarray()\n",
        "        cat_syn_data_oh = encoder.transform(cat_syn_data.astype(str)).toarray()\n",
        "\n",
        "        le_real_data = pd.DataFrame(np.concatenate([num_real_data.to_numpy(), cat_real_data_oh], axis=1))\n",
        "        le_syn_data = pd.DataFrame(np.concatenate([num_syn_data.to_numpy(), cat_syn_data_oh], axis=1))\n",
        "\n",
        "        X_real_loader = GenericDataLoader(le_real_data)\n",
        "        X_syn_loader = GenericDataLoader(le_syn_data)\n",
        "\n",
        "        quality_evaluator = eval_statistical.AlphaPrecision()\n",
        "        qual_res = quality_evaluator.evaluate(X_real_loader, X_syn_loader)\n",
        "\n",
        "        qual_res = {k: v for (k, v) in qual_res.items() if \"naive\" in k}\n",
        "        qual_score = np.mean(list(qual_res.values()))\n",
        "\n",
        "        print(f'Alpha Precision: {qual_res[\"delta_precision_alpha_naive\"]:.6f}, '\n",
        "              f'Beta Recall: {qual_res[\"delta_coverage_beta_naive\"]:.6f}')\n",
        "\n",
        "        return qual_res['delta_precision_alpha_naive'], qual_res['delta_coverage_beta_naive']\n",
        "\n",
        "    def dcr_score(self):\n",
        "        test_size = len(self.test)\n",
        "        train_data = self.real_df.sample(n=test_size, random_state=42)\n",
        "        test_data = self.test\n",
        "        synthetic_data = self.synthetic_df.sample(n=test_size, random_state=42)\n",
        "\n",
        "        num_train_data = train_data[self.numeric_cols]\n",
        "        num_synthetic_data = synthetic_data[self.numeric_cols]\n",
        "        num_test_data = test_data[self.numeric_cols]\n",
        "\n",
        "        num_train_data_np = num_train_data.to_numpy().astype(float)\n",
        "        num_synthetic_data_np = num_synthetic_data.to_numpy().astype(float)\n",
        "        num_test_data_np = num_test_data.to_numpy().astype(float)\n",
        "\n",
        "        num_ranges = np.array([train_data[col].max() - train_data[col].min() for col in self.numeric_cols]).astype(float)\n",
        "        num_train_data_np /= num_ranges\n",
        "        num_synthetic_data_np /= num_ranges\n",
        "        num_test_data_np /= num_ranges\n",
        "\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        train_data_th = torch.tensor(num_train_data_np).to(device)\n",
        "        synthetic_data_th = torch.tensor(num_synthetic_data_np).to(device)\n",
        "        test_data_th = torch.tensor(num_test_data_np).to(device)\n",
        "\n",
        "        batch_size = 100\n",
        "        dcrs_train = []\n",
        "        dcrs_test = []\n",
        "\n",
        "        for i in range((synthetic_data_th.shape[0] // batch_size) + 1):\n",
        "            batch_synthetic_data_th = synthetic_data_th[i*batch_size: (i+1) * batch_size]\n",
        "            dcr_train = (batch_synthetic_data_th[:, None] - train_data_th).abs().sum(dim=2).min(dim=1).values\n",
        "            dcr_test = (batch_synthetic_data_th[:, None] - test_data_th).abs().sum(dim=2).min(dim=1).values\n",
        "            dcrs_train.append(dcr_train)\n",
        "            dcrs_test.append(dcr_test)\n",
        "\n",
        "        dcrs_train = torch.cat(dcrs_train)\n",
        "        dcrs_test = torch.cat(dcrs_test)\n",
        "\n",
        "        score = (dcrs_train < dcrs_test).nonzero().shape[0] / dcrs_train.shape[0]\n",
        "        print(f'DCR Score = {score:.6f}')\n",
        "\n",
        "        return score\n",
        "\n",
        "    def collect_all_metrics(self):\n",
        "        metrics_dict = {}\n",
        "\n",
        "        # Классификационные метрики\n",
        "        classification_metrics_result = self.classification_metrics()\n",
        "        metrics_dict.update(classification_metrics_result)\n",
        "\n",
        "        # Оценка плотности\n",
        "        density_metrics = self.density_estimation()\n",
        "        metrics_dict['density_metrics'] = density_metrics\n",
        "\n",
        "        # Корреляционное сходство\n",
        "        correlation_score = self.correlation_similarity()\n",
        "        metrics_dict['correlation_score'] = correlation_score\n",
        "\n",
        "        # Контингентное сходство\n",
        "        contingency_similarity_score = self.contingency_similarity()\n",
        "        metrics_dict['contingency_similarity_score'] = contingency_similarity_score\n",
        "\n",
        "        # Логистическое обнаружение\n",
        "        log_detection_score = self.logistic_detection()\n",
        "        metrics_dict['log_detection_score'] = log_detection_score\n",
        "\n",
        "        # Alpha Precision\n",
        "        alpha_precision, beta_recall = self.alpha_precision()\n",
        "        metrics_dict['alpha_precision'] = alpha_precision\n",
        "        metrics_dict['beta_recall'] = beta_recall\n",
        "\n",
        "        # DCR Score\n",
        "        dcr_score_value = self.dcr_score()\n",
        "        metrics_dict['dcr_score'] = dcr_score_value\n",
        "\n",
        "        return metrics_dict"
      ],
      "metadata": {
        "id": "-lBJFTzq6goM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adult metrics"
      ],
      "metadata": {
        "id": "q6y5Fx-XVtUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "file_path = '/content/tabsyn/data/adult/info.json'\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    data = json.load(file)"
      ],
      "metadata": {
        "id": "ecmRcKrsDKqP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nc5JfeE8DasU",
        "outputId": "e964ce39-1a35-4b9b-d112-8c690acdaa83"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'adult',\n",
              " 'task_type': 'binclass',\n",
              " 'header': None,\n",
              " 'column_names': ['age',\n",
              "  'workclass',\n",
              "  'fnlwgt',\n",
              "  'education',\n",
              "  'education.num',\n",
              "  'marital.status',\n",
              "  'occupation',\n",
              "  'relationship',\n",
              "  'race',\n",
              "  'sex',\n",
              "  'capital.gain',\n",
              "  'capital.loss',\n",
              "  'hours.per.week',\n",
              "  'native.country',\n",
              "  'income'],\n",
              " 'num_col_idx': [0, 2, 4, 10, 11, 12],\n",
              " 'cat_col_idx': [1, 3, 5, 6, 7, 8, 9, 13],\n",
              " 'target_col_idx': [14],\n",
              " 'file_type': 'csv',\n",
              " 'data_path': 'data/adult/adult.data',\n",
              " 'test_path': 'data/adult/adult.test',\n",
              " 'column_info': {'0': {},\n",
              "  'type': 'categorical',\n",
              "  'max': 99.0,\n",
              "  'min': 1.0,\n",
              "  '2': {},\n",
              "  '4': {},\n",
              "  '10': {},\n",
              "  '11': {},\n",
              "  '12': {},\n",
              "  '1': {},\n",
              "  'categorizes': [' >50K', ' <=50K'],\n",
              "  '3': {},\n",
              "  '5': {},\n",
              "  '6': {},\n",
              "  '7': {},\n",
              "  '8': {},\n",
              "  '9': {},\n",
              "  '13': {},\n",
              "  '14': {}},\n",
              " 'train_num': 32561,\n",
              " 'test_num': 16281,\n",
              " 'idx_mapping': {'0': 0,\n",
              "  '1': 6,\n",
              "  '2': 1,\n",
              "  '3': 7,\n",
              "  '4': 2,\n",
              "  '5': 8,\n",
              "  '6': 9,\n",
              "  '7': 10,\n",
              "  '8': 11,\n",
              "  '9': 12,\n",
              "  '10': 3,\n",
              "  '11': 4,\n",
              "  '12': 5,\n",
              "  '13': 13,\n",
              "  '14': 14},\n",
              " 'inverse_idx_mapping': {'0': 0,\n",
              "  '6': 1,\n",
              "  '1': 2,\n",
              "  '7': 3,\n",
              "  '2': 4,\n",
              "  '8': 5,\n",
              "  '9': 6,\n",
              "  '10': 7,\n",
              "  '11': 8,\n",
              "  '12': 9,\n",
              "  '3': 10,\n",
              "  '4': 11,\n",
              "  '5': 12,\n",
              "  '13': 13,\n",
              "  '14': 14},\n",
              " 'idx_name_mapping': {'0': 'age',\n",
              "  '1': 'workclass',\n",
              "  '2': 'fnlwgt',\n",
              "  '3': 'education',\n",
              "  '4': 'education.num',\n",
              "  '5': 'marital.status',\n",
              "  '6': 'occupation',\n",
              "  '7': 'relationship',\n",
              "  '8': 'race',\n",
              "  '9': 'sex',\n",
              "  '10': 'capital.gain',\n",
              "  '11': 'capital.loss',\n",
              "  '12': 'hours.per.week',\n",
              "  '13': 'native.country',\n",
              "  '14': 'income'},\n",
              " 'metadata': {'columns': {'0': {'sdtype': 'numerical',\n",
              "    'computer_representation': 'Float'},\n",
              "   '2': {'sdtype': 'numerical', 'computer_representation': 'Float'},\n",
              "   '4': {'sdtype': 'numerical', 'computer_representation': 'Float'},\n",
              "   '10': {'sdtype': 'numerical', 'computer_representation': 'Float'},\n",
              "   '11': {'sdtype': 'numerical', 'computer_representation': 'Float'},\n",
              "   '12': {'sdtype': 'numerical', 'computer_representation': 'Float'},\n",
              "   '1': {'sdtype': 'categorical'},\n",
              "   '3': {'sdtype': 'categorical'},\n",
              "   '5': {'sdtype': 'categorical'},\n",
              "   '6': {'sdtype': 'categorical'},\n",
              "   '7': {'sdtype': 'categorical'},\n",
              "   '8': {'sdtype': 'categorical'},\n",
              "   '9': {'sdtype': 'categorical'},\n",
              "   '13': {'sdtype': 'categorical'},\n",
              "   '14': {'sdtype': 'categorical'}}}}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adult_metrics = Metrics(train_path='/content/tabsyn/data/adult/train.csv',\n",
        "                        test_path='/content/tabsyn/data/adult/test.csv',\n",
        "                        synthetic_path='/content/adult_syn.csv',\n",
        "                        numeric_cols=data['num_col_idx'], cat_cols=data[\"cat_col_idx\"],\n",
        "                        target_col=data['target_col_idx'][0])"
      ],
      "metadata": {
        "id": "XxdI4v1nCq0a"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = adult_metrics.collect_all_metrics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E_XCVTNXDydj",
        "outputId": "963b7a5f-d712-4533-c3ad-e54c0f0e69af"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classificator results (AUC):\n",
            "Real data - : 0.925 ± 0.000\n",
            "Synthetic data - : 0.908 ± 0.000\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Column Shapes: |██████████| 15/15 [00:00<00:00, 91.29it/s]|\n",
            "Column Shapes Score: 88.9%\n",
            "\n",
            "(2/2) Evaluating Column Pair Trends: |██████████| 105/105 [00:01<00:00, 58.40it/s]|\n",
            "Column Pair Trends Score: 84.49%\n",
            "\n",
            "Overall Score (Average): 86.7%\n",
            "\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Data Validity: |██████████| 15/15 [00:00<00:00, 294.31it/s]|\n",
            "Data Validity Score: 100.0%\n",
            "\n",
            "(2/2) Evaluating Data Structure: |██████████| 1/1 [00:00<00:00, 270.58it/s]|\n",
            "Data Structure Score: 100.0%\n",
            "\n",
            "Overall Score (Average): 100.0%\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"6b10e8c0-f010-4ad0-9f2c-8c07fbe15951\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6b10e8c0-f010-4ad0-9f2c-8c07fbe15951\")) {                    Plotly.newPlot(                        \"6b10e8c0-f010-4ad0-9f2c-8c07fbe15951\",                        [{\"alignmentgroup\":\"True\",\"customdata\":[[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"age\",\"fnlwgt\",\"education.num\",\"capital.gain\",\"capital.loss\",\"hours.per.week\"],\"legendgroup\":\"KSComplement\",\"marker\":{\"color\":\"#000036\",\"pattern\":{\"shape\":\"\"}},\"name\":\"KSComplement\",\"offsetgroup\":\"KSComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"age\",\"fnlwgt\",\"education.num\",\"capital.gain\",\"capital.loss\",\"hours.per.week\"],\"xaxis\":\"x\",\"y\":[0.8151469549461012,0.9397131537729185,0.9368876877245784,0.9716224931666718,0.9953318387027426,0.7450324007247935],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"customdata\":[[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"workclass\",\"education\",\"marital.status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"native.country\",\"income\"],\"legendgroup\":\"TVComplement\",\"marker\":{\"color\":\"#03AFF1\",\"pattern\":{\"shape\":\"\\u002f\"}},\"name\":\"TVComplement\",\"offsetgroup\":\"TVComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"workclass\",\"education\",\"marital.status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"native.country\",\"income\"],\"xaxis\":\"x\",\"y\":[0.9344307607260219,0.9063296581800313,0.9070667362795983,0.7894106446362212,0.8063634409262614,0.8354780258591566,0.9210097969964067,0.902275728632413,0.9291176560916433],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Column\"},\"categoryorder\":\"total ascending\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Score\"},\"range\":[0,1]},\"legend\":{\"title\":{\"text\":\"Metric\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Data Quality: Column Shapes (Average Score=0.89)\"},\"barmode\":\"relative\",\"margin\":{\"t\":150},\"font\":{\"size\":18},\"plot_bgcolor\":\"#F5F5F8\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('6b10e8c0-f010-4ad0-9f2c-8c07fbe15951');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"91645272-b4eb-4925-a438-5a10c5b582ab\" class=\"plotly-graph-div\" style=\"height:900px; width:900px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"91645272-b4eb-4925-a438-5a10c5b582ab\")) {                    Plotly.newPlot(                        \"91645272-b4eb-4925-a438-5a10c5b582ab\",                        [{\"coloraxis\":\"coloraxis\",\"hovertemplate\":\"\\u003cb\\u003eColumn Pair\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSimilarity: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education.num\",\"marital.status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital.gain\",\"capital.loss\",\"hours.per.week\",\"native.country\",\"income\"],\"y\":[\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education.num\",\"marital.status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital.gain\",\"capital.loss\",\"hours.per.week\",\"native.country\",\"income\"],\"z\":[[1.0,0.8,0.995,0.789,0.988,0.802,0.719,0.748,0.777,0.796,0.996,0.998,0.966,0.795,0.813],[0.8,1.0,0.92,0.88,0.887,0.89,0.769,0.795,0.813,0.899,0.93,0.931,0.686,0.866,0.922],[0.995,0.92,1.0,0.884,0.995,0.892,0.78,0.793,0.833,0.914,0.992,0.987,0.98,0.897,0.907],[0.789,0.88,0.884,1.0,0.904,0.861,0.751,0.778,0.816,0.879,0.901,0.903,0.685,0.858,0.889],[0.988,0.887,0.995,0.904,1.0,0.868,0.755,0.779,0.823,0.886,0.984,0.989,0.972,0.867,0.889],[0.802,0.89,0.892,0.861,0.868,1.0,0.765,0.792,0.82,0.79,0.902,0.903,0.689,0.871,0.905],[0.719,0.769,0.78,0.751,0.755,0.765,1.0,0.706,0.731,0.771,0.786,0.786,0.602,0.754,0.781],[0.748,0.795,0.793,0.778,0.779,0.792,0.706,1.0,0.76,0.787,0.802,0.804,0.639,0.785,0.805],[0.777,0.813,0.833,0.816,0.823,0.82,0.731,0.76,1.0,0.833,0.834,0.835,0.63,0.788,0.835],[0.796,0.899,0.914,0.879,0.886,0.79,0.771,0.787,0.833,1.0,0.919,0.918,0.694,0.866,0.902],[0.996,0.93,0.992,0.901,0.984,0.902,0.786,0.802,0.834,0.919,1.0,0.997,0.975,0.901,0.928],[0.998,0.931,0.987,0.903,0.989,0.903,0.786,0.804,0.835,0.918,0.997,1.0,0.983,0.9,0.928],[0.966,0.686,0.98,0.685,0.972,0.689,0.602,0.639,0.63,0.694,0.975,0.983,1.0,0.661,0.694],[0.795,0.866,0.897,0.858,0.867,0.871,0.754,0.785,0.788,0.866,0.901,0.9,0.661,1.0,0.901],[0.813,0.922,0.907,0.889,0.889,0.905,0.781,0.805,0.835,0.902,0.928,0.928,0.694,0.901,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,-0.086,0.061,0.085,0.055,0.138],[-0.086,1.0,-0.054,-0.015,-0.035,-0.058],[0.061,-0.054,1.0,0.09,0.058,0.093],[0.085,-0.015,0.09,1.0,-0.026,0.028],[0.055,-0.035,0.058,-0.026,1.0,0.087],[0.138,-0.058,0.093,0.028,0.087,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"age\",\"fnlwgt\",\"education.num\",\"capital.gain\",\"capital.loss\",\"hours.per.week\"],\"y\":[\"age\",\"fnlwgt\",\"education.num\",\"capital.gain\",\"capital.loss\",\"hours.per.week\"],\"z\":[[1.0,-0.077,0.037,0.078,0.058,0.069],[-0.077,1.0,-0.043,0.0,-0.01,-0.019],[0.037,-0.043,1.0,0.123,0.08,0.148],[0.078,0.0,0.123,1.0,-0.032,0.078],[0.058,-0.01,0.08,-0.032,1.0,0.054],[0.069,-0.019,0.148,0.078,0.054,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,-0.077,0.037,0.078,0.058,0.069],[-0.077,1.0,-0.043,0.0,-0.01,-0.019],[0.037,-0.043,1.0,0.123,0.08,0.148],[0.078,0.0,0.123,1.0,-0.032,0.078],[0.058,-0.01,0.08,-0.032,1.0,0.054],[0.069,-0.019,0.148,0.078,0.054,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"age\",\"fnlwgt\",\"education.num\",\"capital.gain\",\"capital.loss\",\"hours.per.week\"],\"y\":[\"age\",\"fnlwgt\",\"education.num\",\"capital.gain\",\"capital.loss\",\"hours.per.week\"],\"z\":[[1.0,-0.086,0.061,0.085,0.055,0.138],[-0.086,1.0,-0.054,-0.015,-0.035,-0.058],[0.061,-0.054,1.0,0.09,0.058,0.093],[0.085,-0.015,0.09,1.0,-0.026,0.028],[0.055,-0.035,0.058,-0.026,1.0,0.087],[0.138,-0.058,0.093,0.028,0.087,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.26,0.74],\"tickangle\":45},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"autorange\":\"reversed\"},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,0.45],\"tickangle\":45},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.375],\"autorange\":\"reversed\"},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.55,1.0],\"tickangle\":45,\"matches\":\"x2\"},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"visible\":false,\"matches\":\"y2\",\"autorange\":\"reversed\"},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Real vs. Synthetic Similarity\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Real Data)\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Synthetic Data)\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Data Quality: Column Pair Trends (Average Score=0.84)\"},\"coloraxis\":{\"colorbar\":{\"len\":0.5,\"x\":0.8,\"y\":0.8},\"cmin\":0,\"cmax\":1,\"colorscale\":[[0.0,\"#FF0000\"],[0.5,\"#F16141\"],[1.0,\"#36B37E\"]]},\"coloraxis2\":{\"colorbar\":{\"len\":0.5,\"y\":0.2},\"cmin\":-1,\"cmax\":1,\"colorscale\":[[0.0,\"#03AFF1\"],[0.5,\"#000036\"],[1.0,\"#01E0C9\"]]},\"font\":{\"size\":18},\"height\":900,\"width\":900},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('91645272-b4eb-4925-a438-5a10c5b582ab');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================ METRICS REPORT ================================\n",
            "Column Shapes Score: 0.889\n",
            "Column Trends Score: 0.845\n",
            "Overall Score: 0.867\n",
            "correlation score: 0.995\n",
            "contingency similarity score: 0.833\n",
            "log detection score: 0.410\n",
            "Alpha Precision: 0.743218, Beta Recall: 0.310463\n",
            "DCR Score = 0.505190\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Default metrics"
      ],
      "metadata": {
        "id": "rAQq7--VVwyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/tabsyn/data/default/info.json'\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "default_metrics = Metrics(train_path='/content/tabsyn/data/default/train.csv',\n",
        "                        test_path='/content/tabsyn/data/default/test.csv',\n",
        "                        synthetic_path='/content/default_syn.csv',\n",
        "                        numeric_cols=data['num_col_idx'], cat_cols=data[\"cat_col_idx\"],\n",
        "                        target_col=data['target_col_idx'][0])"
      ],
      "metadata": {
        "id": "BImWzDh5RZ2e"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = default_metrics.collect_all_metrics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qu2Fb4QlRsLn",
        "outputId": "d578f38a-a683-4988-8caa-361aafd74563"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classificator results (AUC):\n",
            "Real data - : 0.763 ± 0.003\n",
            "Synthetic data - : 0.754 ± 0.000\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Column Shapes: |██████████| 24/24 [00:00<00:00, 67.10it/s]|\n",
            "Column Shapes Score: 90.82%\n",
            "\n",
            "(2/2) Evaluating Column Pair Trends: |██████████| 276/276 [00:01<00:00, 163.65it/s]|\n",
            "Column Pair Trends Score: 96.56%\n",
            "\n",
            "Overall Score (Average): 93.69%\n",
            "\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Data Validity: |██████████| 24/24 [00:00<00:00, 685.23it/s]|\n",
            "Data Validity Score: 100.0%\n",
            "\n",
            "(2/2) Evaluating Data Structure: |██████████| 1/1 [00:00<00:00, 352.97it/s]|\n",
            "Data Structure Score: 100.0%\n",
            "\n",
            "Overall Score (Average): 100.0%\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"1a6b445d-167a-4655-8d75-2f2f6d9e99b9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1a6b445d-167a-4655-8d75-2f2f6d9e99b9\")) {                    Plotly.newPlot(                        \"1a6b445d-167a-4655-8d75-2f2f6d9e99b9\",                        [{\"alignmentgroup\":\"True\",\"customdata\":[[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"LIMIT_BAL\",\"AGE\",\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\"],\"legendgroup\":\"KSComplement\",\"marker\":{\"color\":\"#000036\",\"pattern\":{\"shape\":\"\"}},\"name\":\"KSComplement\",\"offsetgroup\":\"KSComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"LIMIT_BAL\",\"AGE\",\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\"],\"xaxis\":\"x\",\"y\":[0.9279629629629629,0.9365925925925925,0.9547037037037037,0.9870740740740741,0.9491111111111111,0.9492962962962963,0.9552592592592593,0.9651851851851851,0.8870740740740741,0.9183703703703704,0.8977777777777778,0.8955185185185185,0.9036666666666666,0.9077407407407407,0.9155925925925925,0.7535925925925926,0.7352592592592593,0.808037037037037,0.8049629629629629,0.9385925925925926],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"customdata\":[[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"SEX\",\"EDUCATION\",\"MARRIAGE\",\"default payment next month\"],\"legendgroup\":\"TVComplement\",\"marker\":{\"color\":\"#03AFF1\",\"pattern\":{\"shape\":\"\\u002f\"}},\"name\":\"TVComplement\",\"offsetgroup\":\"TVComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"SEX\",\"EDUCATION\",\"MARRIAGE\",\"default payment next month\"],\"xaxis\":\"x\",\"y\":[0.9161111111111111,0.9487407407407408,0.9668888888888889,0.9731481481481482],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Column\"},\"categoryorder\":\"total ascending\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Score\"},\"range\":[0,1]},\"legend\":{\"title\":{\"text\":\"Metric\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Data Quality: Column Shapes (Average Score=0.91)\"},\"barmode\":\"relative\",\"margin\":{\"t\":150},\"font\":{\"size\":18},\"plot_bgcolor\":\"#F5F5F8\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1a6b445d-167a-4655-8d75-2f2f6d9e99b9');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"dad91ef5-3797-4387-a6a3-89b2842260f9\" class=\"plotly-graph-div\" style=\"height:900px; width:900px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"dad91ef5-3797-4387-a6a3-89b2842260f9\")) {                    Plotly.newPlot(                        \"dad91ef5-3797-4387-a6a3-89b2842260f9\",                        [{\"coloraxis\":\"coloraxis\",\"hovertemplate\":\"\\u003cb\\u003eColumn Pair\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSimilarity: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"LIMIT_BAL\",\"SEX\",\"EDUCATION\",\"MARRIAGE\",\"AGE\",\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\",\"default payment next month\"],\"y\":[\"LIMIT_BAL\",\"SEX\",\"EDUCATION\",\"MARRIAGE\",\"AGE\",\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\",\"default payment next month\"],\"z\":[[1.0,0.896,0.921,0.919,0.954,0.987,0.976,0.977,0.981,0.984,0.982,0.973,0.982,0.991,0.988,0.977,0.992,0.995,1.0,0.984,0.959,0.986,0.98,0.929],[0.896,1.0,0.914,0.915,0.904,0.905,0.911,0.892,0.87,0.873,0.899,0.911,0.909,0.913,0.909,0.899,0.911,0.915,0.914,0.905,0.903,0.903,0.914,0.916],[0.921,0.914,1.0,0.948,0.917,0.933,0.944,0.923,0.904,0.909,0.932,0.935,0.927,0.938,0.908,0.914,0.919,0.948,0.946,0.937,0.94,0.935,0.946,0.938],[0.919,0.915,0.948,1.0,0.918,0.94,0.956,0.925,0.904,0.906,0.934,0.958,0.935,0.961,0.909,0.916,0.934,0.965,0.964,0.955,0.954,0.955,0.965,0.958],[0.954,0.904,0.917,0.918,1.0,0.988,0.978,0.988,0.985,0.985,0.983,0.993,0.998,0.997,0.998,0.996,0.998,0.988,0.998,0.997,0.996,0.994,0.994,0.934],[0.987,0.905,0.933,0.94,0.988,1.0,0.999,0.99,0.998,0.997,0.996,0.995,1.0,0.985,0.998,0.989,0.996,0.998,0.989,0.992,0.999,0.99,0.994,0.934],[0.976,0.911,0.944,0.956,0.978,0.999,1.0,0.951,0.963,0.966,0.965,0.97,0.977,0.964,0.981,0.969,0.975,0.995,0.986,0.998,0.994,0.999,0.995,0.96],[0.977,0.892,0.923,0.925,0.988,0.99,0.951,1.0,0.967,0.965,0.959,0.993,0.996,0.976,0.994,0.984,0.989,0.983,1.0,0.996,0.995,0.995,0.995,0.918],[0.981,0.87,0.904,0.904,0.985,0.998,0.963,0.967,1.0,0.962,0.946,0.994,0.989,0.986,0.994,0.994,1.0,0.989,0.995,0.99,0.995,0.997,0.997,0.897],[0.984,0.873,0.909,0.906,0.985,0.997,0.966,0.965,0.962,1.0,0.941,0.999,0.997,0.979,0.995,0.987,0.993,0.987,0.993,0.992,0.979,0.999,0.994,0.904],[0.982,0.899,0.932,0.934,0.983,0.996,0.965,0.959,0.946,0.941,1.0,0.988,0.991,0.971,0.994,0.983,0.986,0.984,0.991,0.994,0.981,0.986,0.99,0.933],[0.973,0.911,0.935,0.958,0.993,0.995,0.97,0.993,0.994,0.999,0.988,1.0,0.973,0.936,0.95,0.947,0.948,0.998,0.987,0.998,0.979,0.979,0.983,0.955],[0.982,0.909,0.927,0.935,0.998,1.0,0.977,0.996,0.989,0.997,0.991,0.973,1.0,0.951,0.958,0.95,0.954,0.977,0.997,0.993,0.987,0.983,0.986,0.942],[0.991,0.913,0.938,0.961,0.997,0.985,0.964,0.976,0.986,0.979,0.971,0.936,0.951,1.0,0.942,0.937,0.941,0.966,0.993,0.995,0.984,0.99,0.978,0.961],[0.988,0.909,0.908,0.909,0.998,0.998,0.981,0.994,0.994,0.995,0.994,0.95,0.958,0.942,1.0,0.965,0.965,0.964,0.99,0.984,0.996,0.988,0.975,0.909],[0.977,0.899,0.914,0.916,0.996,0.989,0.969,0.984,0.994,0.987,0.983,0.947,0.95,0.937,0.965,1.0,0.97,0.971,1.0,0.998,0.955,0.988,0.98,0.917],[0.992,0.911,0.919,0.934,0.998,0.996,0.975,0.989,1.0,0.993,0.986,0.948,0.954,0.941,0.965,0.97,1.0,0.968,0.991,0.984,0.985,0.966,0.993,0.935],[0.995,0.915,0.948,0.965,0.988,0.998,0.995,0.983,0.989,0.987,0.984,0.998,0.977,0.966,0.964,0.971,0.968,1.0,0.915,0.948,0.98,0.991,0.971,0.971],[1.0,0.914,0.946,0.964,0.998,0.989,0.986,1.0,0.995,0.993,0.991,0.987,0.997,0.993,0.99,1.0,0.991,0.915,1.0,0.975,0.996,0.998,0.975,0.968],[0.984,0.905,0.937,0.955,0.997,0.992,0.998,0.996,0.99,0.992,0.994,0.998,0.993,0.995,0.984,0.998,0.984,0.948,0.975,1.0,0.995,0.995,0.973,0.952],[0.959,0.903,0.94,0.954,0.996,0.999,0.994,0.995,0.995,0.979,0.981,0.979,0.987,0.984,0.996,0.955,0.985,0.98,0.996,0.995,1.0,0.971,0.987,0.951],[0.986,0.903,0.935,0.955,0.994,0.99,0.999,0.995,0.997,0.999,0.986,0.979,0.983,0.99,0.988,0.988,0.966,0.991,0.998,0.995,0.971,1.0,0.991,0.952],[0.98,0.914,0.946,0.965,0.994,0.994,0.995,0.995,0.997,0.994,0.99,0.983,0.986,0.978,0.975,0.98,0.993,0.971,0.975,0.973,0.987,0.991,1.0,0.971],[0.929,0.916,0.938,0.958,0.934,0.934,0.96,0.918,0.897,0.904,0.933,0.955,0.942,0.961,0.909,0.917,0.935,0.971,0.968,0.952,0.951,0.952,0.971,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,0.053,-0.246,-0.251,-0.241,-0.229,-0.217,-0.201,0.338,0.315,0.301,0.316,0.342,0.306,0.206,0.173,0.241,0.283,0.242,0.181],[0.053,1.0,-0.013,-0.003,-0.026,-0.016,-0.02,-0.014,0.046,0.053,0.049,0.05,0.044,0.046,0.002,0.026,0.025,0.013,0.008,0.003],[-0.246,-0.013,1.0,0.674,0.555,0.533,0.503,0.465,0.177,0.19,0.15,0.184,0.158,0.169,-0.082,-0.047,-0.056,-0.063,-0.041,-0.045],[-0.251,-0.003,0.674,1.0,0.67,0.588,0.556,0.505,0.175,0.189,0.151,0.185,0.159,0.169,-0.092,-0.031,-0.052,-0.06,-0.035,-0.046],[-0.241,-0.026,0.555,0.67,1.0,0.711,0.618,0.553,0.195,0.231,0.18,0.215,0.194,0.201,-0.036,-0.066,-0.065,-0.058,-0.046,-0.045],[-0.229,-0.016,0.533,0.588,0.711,1.0,0.746,0.609,0.216,0.247,0.218,0.259,0.231,0.238,-0.033,-0.014,-0.089,-0.055,-0.028,-0.031],[-0.217,-0.02,0.503,0.556,0.618,0.746,1.0,0.699,0.203,0.231,0.2,0.28,0.242,0.247,-0.034,-0.019,-0.007,-0.1,-0.032,-0.034],[-0.201,-0.014,0.465,0.505,0.553,0.609,0.699,1.0,0.183,0.206,0.181,0.253,0.255,0.254,-0.034,-0.025,-0.007,-0.017,-0.075,-0.047],[0.338,0.046,0.177,0.175,0.195,0.216,0.203,0.183,1.0,0.898,0.764,0.76,0.725,0.701,0.145,0.124,0.153,0.199,0.21,0.137],[0.315,0.053,0.19,0.189,0.231,0.247,0.231,0.206,0.898,1.0,0.829,0.808,0.761,0.742,0.233,0.106,0.137,0.172,0.193,0.139],[0.301,0.049,0.15,0.151,0.18,0.218,0.2,0.181,0.764,0.829,1.0,0.808,0.757,0.737,0.172,0.302,0.139,0.174,0.203,0.128],[0.316,0.05,0.184,0.185,0.215,0.259,0.28,0.253,0.76,0.808,0.808,1.0,0.869,0.831,0.157,0.183,0.328,0.136,0.185,0.119],[0.342,0.044,0.158,0.159,0.194,0.231,0.242,0.255,0.725,0.761,0.757,0.869,1.0,0.887,0.156,0.175,0.252,0.384,0.165,0.117],[0.306,0.046,0.169,0.169,0.201,0.238,0.247,0.254,0.701,0.742,0.737,0.831,0.887,1.0,0.133,0.151,0.198,0.28,0.374,0.098],[0.206,0.002,-0.082,-0.092,-0.036,-0.033,-0.034,-0.034,0.145,0.233,0.172,0.157,0.156,0.133,1.0,0.129,0.151,0.155,0.122,0.129],[0.173,0.026,-0.047,-0.031,-0.066,-0.014,-0.019,-0.025,0.124,0.106,0.302,0.183,0.175,0.151,0.129,1.0,0.199,0.188,0.18,0.102],[0.241,0.025,-0.056,-0.052,-0.065,-0.089,-0.007,-0.007,0.153,0.137,0.139,0.328,0.252,0.198,0.151,0.199,1.0,0.202,0.156,0.103],[0.283,0.013,-0.063,-0.06,-0.058,-0.055,-0.1,-0.017,0.199,0.172,0.174,0.136,0.384,0.28,0.155,0.188,0.202,1.0,0.196,0.119],[0.242,0.008,-0.041,-0.035,-0.046,-0.028,-0.032,-0.075,0.21,0.193,0.203,0.185,0.165,0.374,0.122,0.18,0.156,0.196,1.0,0.128],[0.181,0.003,-0.045,-0.046,-0.045,-0.031,-0.034,-0.047,0.137,0.139,0.128,0.119,0.117,0.098,0.129,0.102,0.103,0.119,0.128,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"LIMIT_BAL\",\"AGE\",\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\"],\"y\":[\"LIMIT_BAL\",\"AGE\",\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\"],\"z\":[[1.0,0.145,-0.272,-0.298,-0.287,-0.267,-0.25,-0.236,0.285,0.278,0.282,0.293,0.296,0.291,0.196,0.173,0.208,0.202,0.215,0.222],[0.145,1.0,-0.036,-0.047,-0.05,-0.047,-0.051,-0.049,0.059,0.057,0.056,0.054,0.052,0.05,0.026,0.021,0.031,0.021,0.02,0.014],[-0.272,-0.036,1.0,0.671,0.575,0.537,0.509,0.474,0.187,0.19,0.18,0.179,0.18,0.176,-0.079,-0.068,-0.071,-0.065,-0.06,-0.058],[-0.298,-0.047,0.671,1.0,0.768,0.661,0.624,0.576,0.235,0.235,0.224,0.223,0.221,0.219,-0.081,-0.059,-0.056,-0.048,-0.038,-0.036],[-0.287,-0.05,0.575,0.768,1.0,0.778,0.688,0.634,0.21,0.238,0.228,0.228,0.226,0.223,-0.002,-0.066,-0.056,-0.047,-0.037,-0.036],[-0.267,-0.047,0.537,0.661,0.778,1.0,0.821,0.716,0.203,0.226,0.245,0.246,0.243,0.239,-0.011,-0.003,-0.07,-0.045,-0.034,-0.026],[-0.25,-0.051,0.509,0.624,0.688,0.821,1.0,0.817,0.206,0.226,0.242,0.271,0.268,0.261,-0.008,-0.004,0.008,-0.058,-0.034,-0.023],[-0.236,-0.049,0.474,0.576,0.634,0.716,0.817,1.0,0.206,0.225,0.239,0.265,0.289,0.283,-0.003,-0.007,0.006,0.02,-0.047,-0.027],[0.285,0.059,0.187,0.235,0.21,0.203,0.206,0.206,1.0,0.952,0.892,0.861,0.831,0.806,0.14,0.098,0.156,0.157,0.167,0.17],[0.278,0.057,0.19,0.235,0.238,0.226,0.226,0.225,0.952,1.0,0.928,0.893,0.86,0.834,0.279,0.1,0.152,0.146,0.159,0.167],[0.282,0.056,0.18,0.224,0.228,0.245,0.242,0.239,0.892,0.928,1.0,0.923,0.883,0.855,0.24,0.316,0.129,0.141,0.183,0.171],[0.293,0.054,0.179,0.223,0.228,0.246,0.271,0.265,0.861,0.893,0.923,1.0,0.939,0.901,0.229,0.202,0.297,0.129,0.161,0.17],[0.296,0.052,0.18,0.221,0.226,0.243,0.268,0.289,0.831,0.86,0.883,0.939,1.0,0.947,0.214,0.175,0.249,0.294,0.141,0.156],[0.291,0.05,0.176,0.219,0.223,0.239,0.261,0.283,0.806,0.834,0.855,0.901,0.947,1.0,0.197,0.169,0.229,0.251,0.306,0.112],[0.196,0.026,-0.079,-0.081,-0.002,-0.011,-0.008,-0.003,0.14,0.279,0.24,0.229,0.214,0.197,1.0,0.298,0.254,0.196,0.14,0.188],[0.173,0.021,-0.068,-0.059,-0.066,-0.003,-0.004,-0.007,0.098,0.1,0.316,0.202,0.175,0.169,0.298,1.0,0.249,0.18,0.185,0.151],[0.208,0.031,-0.071,-0.056,-0.056,-0.07,0.008,0.006,0.156,0.152,0.129,0.297,0.249,0.229,0.254,0.249,1.0,0.212,0.147,0.158],[0.202,0.021,-0.065,-0.048,-0.047,-0.045,-0.058,0.02,0.157,0.146,0.141,0.129,0.294,0.251,0.196,0.18,0.212,1.0,0.138,0.146],[0.215,0.02,-0.06,-0.038,-0.037,-0.034,-0.034,-0.047,0.167,0.159,0.183,0.161,0.141,0.306,0.14,0.185,0.147,0.138,1.0,0.145],[0.222,0.014,-0.058,-0.036,-0.036,-0.026,-0.023,-0.027,0.17,0.167,0.171,0.17,0.156,0.112,0.188,0.151,0.158,0.146,0.145,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,0.145,-0.272,-0.298,-0.287,-0.267,-0.25,-0.236,0.285,0.278,0.282,0.293,0.296,0.291,0.196,0.173,0.208,0.202,0.215,0.222],[0.145,1.0,-0.036,-0.047,-0.05,-0.047,-0.051,-0.049,0.059,0.057,0.056,0.054,0.052,0.05,0.026,0.021,0.031,0.021,0.02,0.014],[-0.272,-0.036,1.0,0.671,0.575,0.537,0.509,0.474,0.187,0.19,0.18,0.179,0.18,0.176,-0.079,-0.068,-0.071,-0.065,-0.06,-0.058],[-0.298,-0.047,0.671,1.0,0.768,0.661,0.624,0.576,0.235,0.235,0.224,0.223,0.221,0.219,-0.081,-0.059,-0.056,-0.048,-0.038,-0.036],[-0.287,-0.05,0.575,0.768,1.0,0.778,0.688,0.634,0.21,0.238,0.228,0.228,0.226,0.223,-0.002,-0.066,-0.056,-0.047,-0.037,-0.036],[-0.267,-0.047,0.537,0.661,0.778,1.0,0.821,0.716,0.203,0.226,0.245,0.246,0.243,0.239,-0.011,-0.003,-0.07,-0.045,-0.034,-0.026],[-0.25,-0.051,0.509,0.624,0.688,0.821,1.0,0.817,0.206,0.226,0.242,0.271,0.268,0.261,-0.008,-0.004,0.008,-0.058,-0.034,-0.023],[-0.236,-0.049,0.474,0.576,0.634,0.716,0.817,1.0,0.206,0.225,0.239,0.265,0.289,0.283,-0.003,-0.007,0.006,0.02,-0.047,-0.027],[0.285,0.059,0.187,0.235,0.21,0.203,0.206,0.206,1.0,0.952,0.892,0.861,0.831,0.806,0.14,0.098,0.156,0.157,0.167,0.17],[0.278,0.057,0.19,0.235,0.238,0.226,0.226,0.225,0.952,1.0,0.928,0.893,0.86,0.834,0.279,0.1,0.152,0.146,0.159,0.167],[0.282,0.056,0.18,0.224,0.228,0.245,0.242,0.239,0.892,0.928,1.0,0.923,0.883,0.855,0.24,0.316,0.129,0.141,0.183,0.171],[0.293,0.054,0.179,0.223,0.228,0.246,0.271,0.265,0.861,0.893,0.923,1.0,0.939,0.901,0.229,0.202,0.297,0.129,0.161,0.17],[0.296,0.052,0.18,0.221,0.226,0.243,0.268,0.289,0.831,0.86,0.883,0.939,1.0,0.947,0.214,0.175,0.249,0.294,0.141,0.156],[0.291,0.05,0.176,0.219,0.223,0.239,0.261,0.283,0.806,0.834,0.855,0.901,0.947,1.0,0.197,0.169,0.229,0.251,0.306,0.112],[0.196,0.026,-0.079,-0.081,-0.002,-0.011,-0.008,-0.003,0.14,0.279,0.24,0.229,0.214,0.197,1.0,0.298,0.254,0.196,0.14,0.188],[0.173,0.021,-0.068,-0.059,-0.066,-0.003,-0.004,-0.007,0.098,0.1,0.316,0.202,0.175,0.169,0.298,1.0,0.249,0.18,0.185,0.151],[0.208,0.031,-0.071,-0.056,-0.056,-0.07,0.008,0.006,0.156,0.152,0.129,0.297,0.249,0.229,0.254,0.249,1.0,0.212,0.147,0.158],[0.202,0.021,-0.065,-0.048,-0.047,-0.045,-0.058,0.02,0.157,0.146,0.141,0.129,0.294,0.251,0.196,0.18,0.212,1.0,0.138,0.146],[0.215,0.02,-0.06,-0.038,-0.037,-0.034,-0.034,-0.047,0.167,0.159,0.183,0.161,0.141,0.306,0.14,0.185,0.147,0.138,1.0,0.145],[0.222,0.014,-0.058,-0.036,-0.036,-0.026,-0.023,-0.027,0.17,0.167,0.171,0.17,0.156,0.112,0.188,0.151,0.158,0.146,0.145,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"LIMIT_BAL\",\"AGE\",\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\"],\"y\":[\"LIMIT_BAL\",\"AGE\",\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\"],\"z\":[[1.0,0.053,-0.246,-0.251,-0.241,-0.229,-0.217,-0.201,0.338,0.315,0.301,0.316,0.342,0.306,0.206,0.173,0.241,0.283,0.242,0.181],[0.053,1.0,-0.013,-0.003,-0.026,-0.016,-0.02,-0.014,0.046,0.053,0.049,0.05,0.044,0.046,0.002,0.026,0.025,0.013,0.008,0.003],[-0.246,-0.013,1.0,0.674,0.555,0.533,0.503,0.465,0.177,0.19,0.15,0.184,0.158,0.169,-0.082,-0.047,-0.056,-0.063,-0.041,-0.045],[-0.251,-0.003,0.674,1.0,0.67,0.588,0.556,0.505,0.175,0.189,0.151,0.185,0.159,0.169,-0.092,-0.031,-0.052,-0.06,-0.035,-0.046],[-0.241,-0.026,0.555,0.67,1.0,0.711,0.618,0.553,0.195,0.231,0.18,0.215,0.194,0.201,-0.036,-0.066,-0.065,-0.058,-0.046,-0.045],[-0.229,-0.016,0.533,0.588,0.711,1.0,0.746,0.609,0.216,0.247,0.218,0.259,0.231,0.238,-0.033,-0.014,-0.089,-0.055,-0.028,-0.031],[-0.217,-0.02,0.503,0.556,0.618,0.746,1.0,0.699,0.203,0.231,0.2,0.28,0.242,0.247,-0.034,-0.019,-0.007,-0.1,-0.032,-0.034],[-0.201,-0.014,0.465,0.505,0.553,0.609,0.699,1.0,0.183,0.206,0.181,0.253,0.255,0.254,-0.034,-0.025,-0.007,-0.017,-0.075,-0.047],[0.338,0.046,0.177,0.175,0.195,0.216,0.203,0.183,1.0,0.898,0.764,0.76,0.725,0.701,0.145,0.124,0.153,0.199,0.21,0.137],[0.315,0.053,0.19,0.189,0.231,0.247,0.231,0.206,0.898,1.0,0.829,0.808,0.761,0.742,0.233,0.106,0.137,0.172,0.193,0.139],[0.301,0.049,0.15,0.151,0.18,0.218,0.2,0.181,0.764,0.829,1.0,0.808,0.757,0.737,0.172,0.302,0.139,0.174,0.203,0.128],[0.316,0.05,0.184,0.185,0.215,0.259,0.28,0.253,0.76,0.808,0.808,1.0,0.869,0.831,0.157,0.183,0.328,0.136,0.185,0.119],[0.342,0.044,0.158,0.159,0.194,0.231,0.242,0.255,0.725,0.761,0.757,0.869,1.0,0.887,0.156,0.175,0.252,0.384,0.165,0.117],[0.306,0.046,0.169,0.169,0.201,0.238,0.247,0.254,0.701,0.742,0.737,0.831,0.887,1.0,0.133,0.151,0.198,0.28,0.374,0.098],[0.206,0.002,-0.082,-0.092,-0.036,-0.033,-0.034,-0.034,0.145,0.233,0.172,0.157,0.156,0.133,1.0,0.129,0.151,0.155,0.122,0.129],[0.173,0.026,-0.047,-0.031,-0.066,-0.014,-0.019,-0.025,0.124,0.106,0.302,0.183,0.175,0.151,0.129,1.0,0.199,0.188,0.18,0.102],[0.241,0.025,-0.056,-0.052,-0.065,-0.089,-0.007,-0.007,0.153,0.137,0.139,0.328,0.252,0.198,0.151,0.199,1.0,0.202,0.156,0.103],[0.283,0.013,-0.063,-0.06,-0.058,-0.055,-0.1,-0.017,0.199,0.172,0.174,0.136,0.384,0.28,0.155,0.188,0.202,1.0,0.196,0.119],[0.242,0.008,-0.041,-0.035,-0.046,-0.028,-0.032,-0.075,0.21,0.193,0.203,0.185,0.165,0.374,0.122,0.18,0.156,0.196,1.0,0.128],[0.181,0.003,-0.045,-0.046,-0.045,-0.031,-0.034,-0.047,0.137,0.139,0.128,0.119,0.117,0.098,0.129,0.102,0.103,0.119,0.128,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.26,0.74],\"tickangle\":45},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"autorange\":\"reversed\"},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,0.45],\"tickangle\":45},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.375],\"autorange\":\"reversed\"},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.55,1.0],\"tickangle\":45,\"matches\":\"x2\"},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"visible\":false,\"matches\":\"y2\",\"autorange\":\"reversed\"},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Real vs. Synthetic Similarity\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Real Data)\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Synthetic Data)\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Data Quality: Column Pair Trends (Average Score=0.97)\"},\"coloraxis\":{\"colorbar\":{\"len\":0.5,\"x\":0.8,\"y\":0.8},\"cmin\":0,\"cmax\":1,\"colorscale\":[[0.0,\"#FF0000\"],[0.5,\"#F16141\"],[1.0,\"#36B37E\"]]},\"coloraxis2\":{\"colorbar\":{\"len\":0.5,\"y\":0.2},\"cmin\":-1,\"cmax\":1,\"colorscale\":[[0.0,\"#03AFF1\"],[0.5,\"#000036\"],[1.0,\"#01E0C9\"]]},\"font\":{\"size\":18},\"height\":900,\"width\":900},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('dad91ef5-3797-4387-a6a3-89b2842260f9');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================ METRICS REPORT ================================\n",
            "Column Shapes Score: 0.908\n",
            "Column Trends Score: 0.966\n",
            "Overall Score: 0.937\n",
            "correlation score: 0.954\n",
            "contingency similarity score: 0.919\n",
            "log detection score: 0.618\n",
            "Alpha Precision: 0.950197, Beta Recall: 0.400217\n",
            "DCR Score = 0.497667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Shoppers metrics"
      ],
      "metadata": {
        "id": "r9EePrbOV0GE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/tabsyn/data/shoppers/info.json'\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "shoppers_metrics = Metrics(train_path='/content/tabsyn/data/shoppers/train.csv',\n",
        "                        test_path='/content/tabsyn/data/shoppers/test.csv',\n",
        "                        synthetic_path='/content/shoppers_syn.csv',\n",
        "                        numeric_cols=data['num_col_idx'], cat_cols=data[\"cat_col_idx\"],\n",
        "                        target_col=data['target_col_idx'][0])\n",
        "metrics = shoppers_metrics.collect_all_metrics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0Rf6bkgXVnxu",
        "outputId": "92d6d50b-dcba-4c20-988a-1e9d0f10379d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classificator results (AUC):\n",
            "Real data - : 0.927 ± 0.001\n",
            "Synthetic data - : 0.919 ± 0.002\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Column Shapes: |██████████| 18/18 [00:00<00:00, 169.00it/s]|\n",
            "Column Shapes Score: 90.22%\n",
            "\n",
            "(2/2) Evaluating Column Pair Trends: |██████████| 153/153 [00:00<00:00, 198.12it/s]|\n",
            "Column Pair Trends Score: 90.14%\n",
            "\n",
            "Overall Score (Average): 90.18%\n",
            "\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Data Validity: |██████████| 18/18 [00:00<00:00, 986.57it/s]|\n",
            "Data Validity Score: 100.0%\n",
            "\n",
            "(2/2) Evaluating Data Structure: |██████████| 1/1 [00:00<00:00, 285.39it/s]|\n",
            "Data Structure Score: 100.0%\n",
            "\n",
            "Overall Score (Average): 100.0%\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"cc87415e-b600-4308-81fa-cf6029a647f2\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"cc87415e-b600-4308-81fa-cf6029a647f2\")) {                    Plotly.newPlot(                        \"cc87415e-b600-4308-81fa-cf6029a647f2\",                        [{\"alignmentgroup\":\"True\",\"customdata\":[[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"Administrative\",\"Administrative_Duration\",\"Informational\",\"Informational_Duration\",\"ProductRelated\",\"ProductRelated_Duration\",\"BounceRates\",\"ExitRates\",\"PageValues\",\"SpecialDay\",\"Browser\",\"TrafficType\"],\"legendgroup\":\"KSComplement\",\"marker\":{\"color\":\"#000036\",\"pattern\":{\"shape\":\"\"}},\"name\":\"KSComplement\",\"offsetgroup\":\"KSComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"Administrative\",\"Administrative_Duration\",\"Informational\",\"Informational_Duration\",\"ProductRelated\",\"ProductRelated_Duration\",\"BounceRates\",\"ExitRates\",\"PageValues\",\"SpecialDay\",\"Browser\",\"TrafficType\"],\"xaxis\":\"x\",\"y\":[0.92502478147247,0.9148418491484185,0.9899972965666396,0.9441290438857349,0.887086599981977,0.949806253942507,0.8770838965486167,0.8857348833017933,0.9015049112372713,0.961611246282779,0.8344597639001532,0.8135532125799766],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"customdata\":[[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"Month\",\"OperatingSystems\",\"Region\",\"VisitorType\",\"Weekend\",\"Revenue\"],\"legendgroup\":\"TVComplement\",\"marker\":{\"color\":\"#03AFF1\",\"pattern\":{\"shape\":\"\\u002f\"}},\"name\":\"TVComplement\",\"offsetgroup\":\"TVComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"Month\",\"OperatingSystems\",\"Region\",\"VisitorType\",\"Weekend\",\"Revenue\"],\"xaxis\":\"x\",\"y\":[0.8309453005316751,0.8855546544111021,0.7939082634946382,0.979814364242588,0.9669279985581689,0.8976299900874111],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Column\"},\"categoryorder\":\"total ascending\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Score\"},\"range\":[0,1]},\"legend\":{\"title\":{\"text\":\"Metric\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Data Quality: Column Shapes (Average Score=0.9)\"},\"barmode\":\"relative\",\"margin\":{\"t\":150},\"font\":{\"size\":18},\"plot_bgcolor\":\"#F5F5F8\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('cc87415e-b600-4308-81fa-cf6029a647f2');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"194cdffd-0308-4648-84e7-aa3eb18fac3d\" class=\"plotly-graph-div\" style=\"height:900px; width:900px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"194cdffd-0308-4648-84e7-aa3eb18fac3d\")) {                    Plotly.newPlot(                        \"194cdffd-0308-4648-84e7-aa3eb18fac3d\",                        [{\"coloraxis\":\"coloraxis\",\"hovertemplate\":\"\\u003cb\\u003eColumn Pair\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSimilarity: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"Administrative\",\"Administrative_Duration\",\"Informational\",\"Informational_Duration\",\"ProductRelated\",\"ProductRelated_Duration\",\"BounceRates\",\"ExitRates\",\"PageValues\",\"SpecialDay\",\"Month\",\"OperatingSystems\",\"Browser\",\"Region\",\"TrafficType\",\"VisitorType\",\"Weekend\",\"Revenue\"],\"y\":[\"Administrative\",\"Administrative_Duration\",\"Informational\",\"Informational_Duration\",\"ProductRelated\",\"ProductRelated_Duration\",\"BounceRates\",\"ExitRates\",\"PageValues\",\"SpecialDay\",\"Month\",\"OperatingSystems\",\"Browser\",\"Region\",\"TrafficType\",\"VisitorType\",\"Weekend\",\"Revenue\"],\"z\":[[1.0,0.943,0.926,0.95,0.975,0.955,0.966,0.971,0.988,0.995,0.807,0.88,0.987,0.779,0.965,0.935,0.926,0.887],[0.943,1.0,0.903,0.92,0.944,0.895,0.974,0.973,0.998,0.997,0.828,0.873,0.994,0.789,0.977,0.974,0.964,0.888],[0.926,0.903,1.0,0.972,0.935,0.911,0.971,0.96,0.978,0.997,0.83,0.883,0.994,0.789,0.989,0.975,0.961,0.893],[0.95,0.92,0.972,1.0,0.95,0.923,0.982,0.978,0.99,1.0,0.823,0.884,0.996,0.787,0.999,0.964,0.954,0.894],[0.975,0.944,0.935,0.95,1.0,0.938,0.975,0.982,0.997,0.995,0.816,0.865,1.0,0.781,0.981,0.955,0.955,0.876],[0.955,0.895,0.911,0.923,0.938,1.0,0.965,0.964,0.991,0.995,0.828,0.884,0.999,0.79,0.985,0.976,0.963,0.896],[0.966,0.974,0.971,0.982,0.975,0.965,1.0,0.963,0.991,0.983,0.785,0.865,0.997,0.77,0.988,0.882,0.897,0.898],[0.971,0.973,0.96,0.978,0.982,0.964,0.963,1.0,0.999,0.983,0.791,0.845,0.997,0.769,0.972,0.875,0.881,0.877],[0.988,0.998,0.978,0.99,0.997,0.991,0.991,0.999,1.0,0.994,0.817,0.856,0.985,0.781,0.996,0.949,0.951,0.884],[0.995,0.997,0.997,1.0,0.995,0.995,0.983,0.983,0.994,1.0,0.792,0.867,0.999,0.777,0.989,0.962,0.953,0.871],[0.807,0.828,0.83,0.823,0.816,0.828,0.785,0.791,0.817,0.792,1.0,0.79,0.754,0.72,0.655,0.828,0.823,0.807],[0.88,0.873,0.883,0.884,0.865,0.884,0.865,0.845,0.856,0.867,0.79,1.0,0.717,0.759,0.717,0.885,0.886,0.827],[0.987,0.994,0.994,0.996,1.0,0.999,0.997,0.997,0.985,0.999,0.754,0.717,1.0,0.721,0.971,0.808,0.809,0.766],[0.779,0.789,0.789,0.787,0.781,0.79,0.77,0.769,0.781,0.777,0.72,0.759,0.721,1.0,0.644,0.794,0.794,0.774],[0.965,0.977,0.989,0.999,0.981,0.985,0.988,0.972,0.996,0.989,0.655,0.717,0.971,0.644,1.0,0.748,0.748,0.751],[0.935,0.974,0.975,0.964,0.955,0.976,0.882,0.875,0.949,0.962,0.828,0.885,0.808,0.794,0.748,1.0,0.96,0.897],[0.926,0.964,0.961,0.954,0.955,0.963,0.897,0.881,0.951,0.953,0.823,0.886,0.809,0.794,0.748,0.96,1.0,0.898],[0.887,0.888,0.893,0.894,0.876,0.896,0.898,0.877,0.884,0.871,0.807,0.827,0.766,0.774,0.751,0.897,0.898,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,0.489,0.23,0.157,0.388,0.286,-0.154,-0.258,0.072,-0.083,-0.046,-0.106],[0.489,1.0,0.118,0.088,0.187,0.159,-0.09,-0.149,0.061,-0.067,-0.025,-0.06],[0.23,0.118,1.0,0.668,0.246,0.215,-0.057,-0.083,0.003,-0.039,-0.048,-0.047],[0.157,0.088,0.668,1.0,0.181,0.202,-0.037,-0.059,0.007,-0.028,-0.025,-0.017],[0.388,0.187,0.246,0.181,1.0,0.735,-0.152,-0.253,0.049,-0.012,-0.012,-0.079],[0.286,0.159,0.215,0.202,0.735,1.0,-0.111,-0.176,0.032,-0.024,-0.005,-0.067],[-0.154,-0.09,-0.057,-0.037,-0.152,-0.111,1.0,0.838,-0.1,0.042,-0.019,0.1],[-0.258,-0.149,-0.083,-0.059,-0.253,-0.176,0.838,1.0,-0.172,0.071,-0.005,0.132],[0.072,0.061,0.003,0.007,0.049,0.032,-0.1,-0.172,1.0,-0.075,0.018,0.005],[-0.083,-0.067,-0.039,-0.028,-0.012,-0.024,0.042,0.071,-0.075,1.0,0.005,0.072],[-0.046,-0.025,-0.048,-0.025,-0.012,-0.005,-0.019,-0.005,0.018,0.005,1.0,0.165],[-0.106,-0.06,-0.047,-0.017,-0.079,-0.067,0.1,0.132,0.005,0.072,0.165,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"Administrative\",\"Administrative_Duration\",\"Informational\",\"Informational_Duration\",\"ProductRelated\",\"ProductRelated_Duration\",\"BounceRates\",\"ExitRates\",\"PageValues\",\"SpecialDay\",\"Browser\",\"TrafficType\"],\"y\":[\"Administrative\",\"Administrative_Duration\",\"Informational\",\"Informational_Duration\",\"ProductRelated\",\"ProductRelated_Duration\",\"BounceRates\",\"ExitRates\",\"PageValues\",\"SpecialDay\",\"Browser\",\"TrafficType\"],\"z\":[[1.0,0.603,0.377,0.257,0.437,0.376,-0.222,-0.315,0.096,-0.092,-0.021,-0.035],[0.603,1.0,0.313,0.249,0.299,0.369,-0.143,-0.204,0.065,-0.072,-0.013,-0.013],[0.377,0.313,1.0,0.612,0.377,0.394,-0.115,-0.163,0.048,-0.045,-0.036,-0.026],[0.257,0.249,0.612,1.0,0.282,0.356,-0.073,-0.104,0.028,-0.029,-0.018,-0.018],[0.437,0.299,0.377,0.282,1.0,0.859,-0.202,-0.289,0.054,-0.022,-0.012,-0.042],[0.376,0.369,0.394,0.356,0.859,1.0,-0.182,-0.248,0.05,-0.034,-0.006,-0.036],[-0.222,-0.143,-0.115,-0.073,-0.202,-0.182,1.0,0.912,-0.118,0.075,-0.024,0.075],[-0.315,-0.204,-0.163,-0.104,-0.289,-0.248,0.912,1.0,-0.173,0.104,-0.011,0.076],[0.096,0.065,0.048,0.028,0.054,0.05,-0.118,-0.173,1.0,-0.062,0.047,0.014],[-0.092,-0.072,-0.045,-0.029,-0.022,-0.034,0.075,0.104,-0.062,1.0,0.003,0.049],[-0.021,-0.013,-0.036,-0.018,-0.012,-0.006,-0.024,-0.011,0.047,0.003,1.0,0.106],[-0.035,-0.013,-0.026,-0.018,-0.042,-0.036,0.075,0.076,0.014,0.049,0.106,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,0.603,0.377,0.257,0.437,0.376,-0.222,-0.315,0.096,-0.092,-0.021,-0.035],[0.603,1.0,0.313,0.249,0.299,0.369,-0.143,-0.204,0.065,-0.072,-0.013,-0.013],[0.377,0.313,1.0,0.612,0.377,0.394,-0.115,-0.163,0.048,-0.045,-0.036,-0.026],[0.257,0.249,0.612,1.0,0.282,0.356,-0.073,-0.104,0.028,-0.029,-0.018,-0.018],[0.437,0.299,0.377,0.282,1.0,0.859,-0.202,-0.289,0.054,-0.022,-0.012,-0.042],[0.376,0.369,0.394,0.356,0.859,1.0,-0.182,-0.248,0.05,-0.034,-0.006,-0.036],[-0.222,-0.143,-0.115,-0.073,-0.202,-0.182,1.0,0.912,-0.118,0.075,-0.024,0.075],[-0.315,-0.204,-0.163,-0.104,-0.289,-0.248,0.912,1.0,-0.173,0.104,-0.011,0.076],[0.096,0.065,0.048,0.028,0.054,0.05,-0.118,-0.173,1.0,-0.062,0.047,0.014],[-0.092,-0.072,-0.045,-0.029,-0.022,-0.034,0.075,0.104,-0.062,1.0,0.003,0.049],[-0.021,-0.013,-0.036,-0.018,-0.012,-0.006,-0.024,-0.011,0.047,0.003,1.0,0.106],[-0.035,-0.013,-0.026,-0.018,-0.042,-0.036,0.075,0.076,0.014,0.049,0.106,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"Administrative\",\"Administrative_Duration\",\"Informational\",\"Informational_Duration\",\"ProductRelated\",\"ProductRelated_Duration\",\"BounceRates\",\"ExitRates\",\"PageValues\",\"SpecialDay\",\"Browser\",\"TrafficType\"],\"y\":[\"Administrative\",\"Administrative_Duration\",\"Informational\",\"Informational_Duration\",\"ProductRelated\",\"ProductRelated_Duration\",\"BounceRates\",\"ExitRates\",\"PageValues\",\"SpecialDay\",\"Browser\",\"TrafficType\"],\"z\":[[1.0,0.489,0.23,0.157,0.388,0.286,-0.154,-0.258,0.072,-0.083,-0.046,-0.106],[0.489,1.0,0.118,0.088,0.187,0.159,-0.09,-0.149,0.061,-0.067,-0.025,-0.06],[0.23,0.118,1.0,0.668,0.246,0.215,-0.057,-0.083,0.003,-0.039,-0.048,-0.047],[0.157,0.088,0.668,1.0,0.181,0.202,-0.037,-0.059,0.007,-0.028,-0.025,-0.017],[0.388,0.187,0.246,0.181,1.0,0.735,-0.152,-0.253,0.049,-0.012,-0.012,-0.079],[0.286,0.159,0.215,0.202,0.735,1.0,-0.111,-0.176,0.032,-0.024,-0.005,-0.067],[-0.154,-0.09,-0.057,-0.037,-0.152,-0.111,1.0,0.838,-0.1,0.042,-0.019,0.1],[-0.258,-0.149,-0.083,-0.059,-0.253,-0.176,0.838,1.0,-0.172,0.071,-0.005,0.132],[0.072,0.061,0.003,0.007,0.049,0.032,-0.1,-0.172,1.0,-0.075,0.018,0.005],[-0.083,-0.067,-0.039,-0.028,-0.012,-0.024,0.042,0.071,-0.075,1.0,0.005,0.072],[-0.046,-0.025,-0.048,-0.025,-0.012,-0.005,-0.019,-0.005,0.018,0.005,1.0,0.165],[-0.106,-0.06,-0.047,-0.017,-0.079,-0.067,0.1,0.132,0.005,0.072,0.165,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.26,0.74],\"tickangle\":45},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"autorange\":\"reversed\"},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,0.45],\"tickangle\":45},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.375],\"autorange\":\"reversed\"},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.55,1.0],\"tickangle\":45,\"matches\":\"x2\"},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"visible\":false,\"matches\":\"y2\",\"autorange\":\"reversed\"},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Real vs. Synthetic Similarity\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Real Data)\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Synthetic Data)\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Data Quality: Column Pair Trends (Average Score=0.9)\"},\"coloraxis\":{\"colorbar\":{\"len\":0.5,\"x\":0.8,\"y\":0.8},\"cmin\":0,\"cmax\":1,\"colorscale\":[[0.0,\"#FF0000\"],[0.5,\"#F16141\"],[1.0,\"#36B37E\"]]},\"coloraxis2\":{\"colorbar\":{\"len\":0.5,\"y\":0.2},\"cmin\":-1,\"cmax\":1,\"colorscale\":[[0.0,\"#03AFF1\"],[0.5,\"#000036\"],[1.0,\"#01E0C9\"]]},\"font\":{\"size\":18},\"height\":900,\"width\":900},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('194cdffd-0308-4648-84e7-aa3eb18fac3d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================ METRICS REPORT ================================\n",
            "Column Shapes Score: 0.902\n",
            "Column Trends Score: 0.901\n",
            "Overall Score: 0.902\n",
            "correlation score: 0.943\n",
            "contingency similarity score: 0.927\n",
            "log detection score: 0.553\n",
            "Alpha Precision: 0.899248, Beta Recall: 0.317762\n",
            "DCR Score = 0.498783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Magic metrics"
      ],
      "metadata": {
        "id": "SwT1TJtsV2MJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/tabsyn/data/magic/info.json'\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "magic_metrics = Metrics(train_path='/content/tabsyn/data/magic/train.csv',\n",
        "                        test_path='/content/tabsyn/data/magic/test.csv',\n",
        "                        synthetic_path='/content/magic_syn.csv',\n",
        "                        numeric_cols=data['num_col_idx'], cat_cols=data[\"cat_col_idx\"],\n",
        "                        target_col=data['target_col_idx'][0])\n",
        "metrics = magic_metrics.collect_all_metrics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6MSs6V6mWEXz",
        "outputId": "2ff617bc-3887-4d93-8cfb-f1ab8b26fb37"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classificator results (AUC):\n",
            "Real data - : 0.947 ± 0.001\n",
            "Synthetic data - : 0.936 ± 0.002\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Column Shapes: |██████████| 11/11 [00:00<00:00, 86.81it/s]|\n",
            "Column Shapes Score: 86.95%\n",
            "\n",
            "(2/2) Evaluating Column Pair Trends: |██████████| 55/55 [00:00<00:00, 112.04it/s]|\n",
            "Column Pair Trends Score: 95.16%\n",
            "\n",
            "Overall Score (Average): 91.05%\n",
            "\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Data Validity: |██████████| 11/11 [00:00<00:00, 370.29it/s]|\n",
            "Data Validity Score: 100.0%\n",
            "\n",
            "(2/2) Evaluating Data Structure: |██████████| 1/1 [00:00<00:00, 475.76it/s]|\n",
            "Data Structure Score: 100.0%\n",
            "\n",
            "Overall Score (Average): 100.0%\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"9663e882-94d8-4869-9ca9-52e44fb980f8\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9663e882-94d8-4869-9ca9-52e44fb980f8\")) {                    Plotly.newPlot(                        \"9663e882-94d8-4869-9ca9-52e44fb980f8\",                        [{\"alignmentgroup\":\"True\",\"customdata\":[[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"Length\",\"Width\",\"Size\",\"Conc\",\"Conc1\",\"Asym\",\"M3Long\",\"M3Trans\",\"Alpha\",\"Dist\"],\"legendgroup\":\"KSComplement\",\"marker\":{\"color\":\"#000036\",\"pattern\":{\"shape\":\"\"}},\"name\":\"KSComplement\",\"offsetgroup\":\"KSComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"Length\",\"Width\",\"Size\",\"Conc\",\"Conc1\",\"Asym\",\"M3Long\",\"M3Trans\",\"Alpha\",\"Dist\"],\"xaxis\":\"x\",\"y\":[0.8211719343342876,0.8819302447858854,0.8559326984868845,0.8548226908920956,0.8548226908920955,0.927732663434013,0.7868201203481918,0.9234678974119297,0.8999240521119354,0.8092539580533972],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"customdata\":[[\"TVComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"class\"],\"legendgroup\":\"TVComplement\",\"marker\":{\"color\":\"#03AFF1\",\"pattern\":{\"shape\":\"\\u002f\"}},\"name\":\"TVComplement\",\"offsetgroup\":\"TVComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"class\"],\"xaxis\":\"x\",\"y\":[0.9484722790208564],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Column\"},\"categoryorder\":\"total ascending\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Score\"},\"range\":[0,1]},\"legend\":{\"title\":{\"text\":\"Metric\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Data Quality: Column Shapes (Average Score=0.87)\"},\"barmode\":\"relative\",\"margin\":{\"t\":150},\"font\":{\"size\":18},\"plot_bgcolor\":\"#F5F5F8\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9663e882-94d8-4869-9ca9-52e44fb980f8');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"f6ad5772-aa85-47cb-91ca-72e90f0eb788\" class=\"plotly-graph-div\" style=\"height:900px; width:900px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f6ad5772-aa85-47cb-91ca-72e90f0eb788\")) {                    Plotly.newPlot(                        \"f6ad5772-aa85-47cb-91ca-72e90f0eb788\",                        [{\"coloraxis\":\"coloraxis\",\"hovertemplate\":\"\\u003cb\\u003eColumn Pair\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSimilarity: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"Length\",\"Width\",\"Size\",\"Conc\",\"Conc1\",\"Asym\",\"M3Long\",\"M3Trans\",\"Alpha\",\"Dist\",\"class\"],\"y\":[\"Length\",\"Width\",\"Size\",\"Conc\",\"Conc1\",\"Asym\",\"M3Long\",\"M3Trans\",\"Alpha\",\"Dist\",\"class\"],\"z\":[[1.0,0.988,0.998,0.978,0.974,0.944,0.848,0.949,0.973,0.974,0.858],[0.988,1.0,0.987,0.988,0.988,0.971,0.91,0.917,0.979,0.983,0.872],[0.998,0.987,1.0,0.995,0.991,0.976,0.924,0.958,0.959,0.99,0.86],[0.978,0.988,0.995,1.0,0.996,0.983,0.92,0.964,0.972,0.986,0.863],[0.974,0.988,0.991,0.996,1.0,0.986,0.922,0.966,0.97,0.983,0.87],[0.944,0.971,0.976,0.983,0.986,1.0,0.969,0.975,0.972,0.994,0.883],[0.848,0.91,0.924,0.92,0.922,0.969,1.0,0.992,0.99,0.972,0.872],[0.949,0.917,0.958,0.964,0.966,0.975,0.992,1.0,0.974,0.999,0.928],[0.973,0.979,0.959,0.972,0.97,0.972,0.99,0.974,1.0,0.997,0.901],[0.974,0.983,0.99,0.986,0.983,0.994,0.972,0.999,0.997,1.0,0.808],[0.858,0.872,0.86,0.863,0.87,0.883,0.872,0.928,0.901,0.808,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,0.749,0.698,-0.676,-0.651,-0.266,0.185,-0.083,-0.062,0.47],[0.749,1.0,0.748,-0.637,-0.609,-0.225,0.0,-0.116,0.023,0.374],[0.698,0.748,1.0,-0.86,-0.826,-0.116,0.248,-0.062,-0.268,0.458],[-0.676,-0.637,-0.86,1.0,0.985,0.082,-0.281,0.057,0.293,-0.358],[-0.651,-0.609,-0.826,0.985,1.0,0.076,-0.276,0.053,0.291,-0.34],[-0.266,-0.225,-0.116,0.082,0.076,1.0,0.213,0.037,0.002,-0.216],[0.185,0.0,0.248,-0.281,-0.276,0.213,1.0,-0.004,-0.165,0.094],[-0.083,-0.116,-0.062,0.057,0.053,0.037,-0.004,1.0,-0.044,0.004],[-0.062,0.023,-0.268,0.293,0.291,0.002,-0.165,-0.044,1.0,-0.228],[0.47,0.374,0.458,-0.358,-0.34,-0.216,0.094,0.004,-0.228,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"Length\",\"Width\",\"Size\",\"Conc\",\"Conc1\",\"Asym\",\"M3Long\",\"M3Trans\",\"Alpha\",\"Dist\"],\"y\":[\"Length\",\"Width\",\"Size\",\"Conc\",\"Conc1\",\"Asym\",\"M3Long\",\"M3Trans\",\"Alpha\",\"Dist\"],\"z\":[[1.0,0.773,0.703,-0.632,-0.599,-0.377,-0.12,0.019,-0.007,0.419],[0.773,1.0,0.721,-0.613,-0.584,-0.283,-0.181,0.05,0.065,0.34],[0.703,0.721,1.0,-0.851,-0.809,-0.163,0.095,0.022,-0.187,0.438],[-0.632,-0.613,-0.851,1.0,0.977,0.117,-0.122,-0.016,0.237,-0.331],[-0.599,-0.584,-0.809,0.977,1.0,0.105,-0.119,-0.015,0.231,-0.306],[-0.377,-0.283,-0.163,0.117,0.105,1.0,0.274,-0.014,-0.054,-0.204],[-0.12,-0.181,0.095,-0.122,-0.119,0.274,1.0,-0.02,-0.185,0.038],[0.019,0.05,0.022,-0.016,-0.015,-0.014,-0.02,1.0,0.007,0.006],[-0.007,0.065,-0.187,0.237,0.231,-0.054,-0.185,0.007,1.0,-0.221],[0.419,0.34,0.438,-0.331,-0.306,-0.204,0.038,0.006,-0.221,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,0.773,0.703,-0.632,-0.599,-0.377,-0.12,0.019,-0.007,0.419],[0.773,1.0,0.721,-0.613,-0.584,-0.283,-0.181,0.05,0.065,0.34],[0.703,0.721,1.0,-0.851,-0.809,-0.163,0.095,0.022,-0.187,0.438],[-0.632,-0.613,-0.851,1.0,0.977,0.117,-0.122,-0.016,0.237,-0.331],[-0.599,-0.584,-0.809,0.977,1.0,0.105,-0.119,-0.015,0.231,-0.306],[-0.377,-0.283,-0.163,0.117,0.105,1.0,0.274,-0.014,-0.054,-0.204],[-0.12,-0.181,0.095,-0.122,-0.119,0.274,1.0,-0.02,-0.185,0.038],[0.019,0.05,0.022,-0.016,-0.015,-0.014,-0.02,1.0,0.007,0.006],[-0.007,0.065,-0.187,0.237,0.231,-0.054,-0.185,0.007,1.0,-0.221],[0.419,0.34,0.438,-0.331,-0.306,-0.204,0.038,0.006,-0.221,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"Length\",\"Width\",\"Size\",\"Conc\",\"Conc1\",\"Asym\",\"M3Long\",\"M3Trans\",\"Alpha\",\"Dist\"],\"y\":[\"Length\",\"Width\",\"Size\",\"Conc\",\"Conc1\",\"Asym\",\"M3Long\",\"M3Trans\",\"Alpha\",\"Dist\"],\"z\":[[1.0,0.749,0.698,-0.676,-0.651,-0.266,0.185,-0.083,-0.062,0.47],[0.749,1.0,0.748,-0.637,-0.609,-0.225,0.0,-0.116,0.023,0.374],[0.698,0.748,1.0,-0.86,-0.826,-0.116,0.248,-0.062,-0.268,0.458],[-0.676,-0.637,-0.86,1.0,0.985,0.082,-0.281,0.057,0.293,-0.358],[-0.651,-0.609,-0.826,0.985,1.0,0.076,-0.276,0.053,0.291,-0.34],[-0.266,-0.225,-0.116,0.082,0.076,1.0,0.213,0.037,0.002,-0.216],[0.185,0.0,0.248,-0.281,-0.276,0.213,1.0,-0.004,-0.165,0.094],[-0.083,-0.116,-0.062,0.057,0.053,0.037,-0.004,1.0,-0.044,0.004],[-0.062,0.023,-0.268,0.293,0.291,0.002,-0.165,-0.044,1.0,-0.228],[0.47,0.374,0.458,-0.358,-0.34,-0.216,0.094,0.004,-0.228,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.26,0.74],\"tickangle\":45},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"autorange\":\"reversed\"},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,0.45],\"tickangle\":45},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.375],\"autorange\":\"reversed\"},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.55,1.0],\"tickangle\":45,\"matches\":\"x2\"},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"visible\":false,\"matches\":\"y2\",\"autorange\":\"reversed\"},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Real vs. Synthetic Similarity\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Real Data)\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Synthetic Data)\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Data Quality: Column Pair Trends (Average Score=0.95)\"},\"coloraxis\":{\"colorbar\":{\"len\":0.5,\"x\":0.8,\"y\":0.8},\"cmin\":0,\"cmax\":1,\"colorscale\":[[0.0,\"#FF0000\"],[0.5,\"#F16141\"],[1.0,\"#36B37E\"]]},\"coloraxis2\":{\"colorbar\":{\"len\":0.5,\"y\":0.2},\"cmin\":-1,\"cmax\":1,\"colorscale\":[[0.0,\"#03AFF1\"],[0.5,\"#000036\"],[1.0,\"#01E0C9\"]]},\"font\":{\"size\":18},\"height\":900,\"width\":900},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f6ad5772-aa85-47cb-91ca-72e90f0eb788');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================ METRICS REPORT ================================\n",
            "Column Shapes Score: 0.869\n",
            "Column Trends Score: 0.952\n",
            "Overall Score: 0.911\n",
            "correlation score: 0.988\n",
            "contingency similarity score: 0.830\n",
            "log detection score: 0.666\n",
            "Alpha Precision: 0.969312, Beta Recall: 0.500664\n",
            "DCR Score = 0.523659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Beijing metrics"
      ],
      "metadata": {
        "id": "t5sVZtYGV3nx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/tabsyn/data/beijing/info.json'\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "beijing_metrics = Metrics(train_path='/content/tabsyn/data/beijing/train.csv',\n",
        "                        test_path='/content/tabsyn/data/beijing/test.csv',\n",
        "                        synthetic_path='/content/beijing_syn.csv',\n",
        "                        numeric_cols=data['num_col_idx'], cat_cols=data[\"cat_col_idx\"],\n",
        "                        target_col=data['target_col_idx'][0], classification=False)\n",
        "metrics = beijing_metrics.collect_all_metrics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V_ttfonFWThz",
        "outputId": "8ed3d1a1-b8bf-4afe-dec6-4deb1fce75f2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression results (MSE):\n",
            "Real data - : 35.902 ± 0.079\n",
            "Synthetic data - : 62.031 ± 0.004\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Column Shapes: |██████████| 12/12 [00:00<00:00, 43.98it/s]|\n",
            "Column Shapes Score: 95.23%\n",
            "\n",
            "(2/2) Evaluating Column Pair Trends: |██████████| 66/66 [00:00<00:00, 135.91it/s]|\n",
            "Column Pair Trends Score: 95.81%\n",
            "\n",
            "Overall Score (Average): 95.52%\n",
            "\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Data Validity: |██████████| 12/12 [00:00<00:00, 446.64it/s]|\n",
            "Data Validity Score: 100.0%\n",
            "\n",
            "(2/2) Evaluating Data Structure: |██████████| 1/1 [00:00<00:00, 335.36it/s]|\n",
            "Data Structure Score: 100.0%\n",
            "\n",
            "Overall Score (Average): 100.0%\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"5af06eab-dad3-481e-8a43-86bf7f381234\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5af06eab-dad3-481e-8a43-86bf7f381234\")) {                    Plotly.newPlot(                        \"5af06eab-dad3-481e-8a43-86bf7f381234\",                        [{\"alignmentgroup\":\"True\",\"customdata\":[[\"TVComplement\"],[\"TVComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"year\",\"cbwd\"],\"legendgroup\":\"TVComplement\",\"marker\":{\"color\":\"#03AFF1\",\"pattern\":{\"shape\":\"\"}},\"name\":\"TVComplement\",\"offsetgroup\":\"TVComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"year\",\"cbwd\"],\"xaxis\":\"x\",\"y\":[0.891221627950294,0.9735504643303797],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"customdata\":[[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"month\",\"day\",\"hour\",\"pm2.5\",\"DEWP\",\"TEMP\",\"PRES\",\"Iws\",\"Is\",\"Ir\"],\"legendgroup\":\"KSComplement\",\"marker\":{\"color\":\"#000036\",\"pattern\":{\"shape\":\"\\u002f\"}},\"name\":\"KSComplement\",\"offsetgroup\":\"KSComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"month\",\"day\",\"hour\",\"pm2.5\",\"DEWP\",\"TEMP\",\"PRES\",\"Iws\",\"Is\",\"Ir\"],\"xaxis\":\"x\",\"y\":[0.9350203560309731,0.9517043186716692,0.952742077113435,0.9588089726191426,0.9571858119794577,0.9624012133791011,0.9431361592293978,0.9598999494425374,0.9938266677310343,0.9482185146749688],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Column\"},\"categoryorder\":\"total ascending\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Score\"},\"range\":[0,1]},\"legend\":{\"title\":{\"text\":\"Metric\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Data Quality: Column Shapes (Average Score=0.95)\"},\"barmode\":\"relative\",\"margin\":{\"t\":150},\"font\":{\"size\":18},\"plot_bgcolor\":\"#F5F5F8\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5af06eab-dad3-481e-8a43-86bf7f381234');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"a4f1835d-50ff-4aa0-9f68-ff0222a4e1c2\" class=\"plotly-graph-div\" style=\"height:900px; width:900px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a4f1835d-50ff-4aa0-9f68-ff0222a4e1c2\")) {                    Plotly.newPlot(                        \"a4f1835d-50ff-4aa0-9f68-ff0222a4e1c2\",                        [{\"coloraxis\":\"coloraxis\",\"hovertemplate\":\"\\u003cb\\u003eColumn Pair\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSimilarity: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"year\",\"month\",\"day\",\"hour\",\"pm2.5\",\"DEWP\",\"TEMP\",\"PRES\",\"cbwd\",\"Iws\",\"Is\",\"Ir\"],\"y\":[\"year\",\"month\",\"day\",\"hour\",\"pm2.5\",\"DEWP\",\"TEMP\",\"PRES\",\"cbwd\",\"Iws\",\"Is\",\"Ir\"],\"z\":[[1.0,0.828,0.85,0.853,0.882,0.865,0.871,0.845,0.89,0.886,0.889,0.886],[0.828,1.0,0.999,0.998,1.0,0.973,0.965,0.957,0.849,0.993,1.0,1.0],[0.85,0.999,1.0,0.999,0.991,0.995,0.99,0.989,0.881,0.999,0.994,0.999],[0.853,0.998,0.999,1.0,0.993,0.99,0.986,0.993,0.894,0.992,0.991,0.996],[0.882,1.0,0.991,0.993,1.0,0.966,0.979,0.973,0.958,0.992,0.997,0.993],[0.865,0.973,0.995,0.99,0.966,1.0,0.997,0.996,0.909,0.977,0.992,0.978],[0.871,0.965,0.99,0.986,0.979,0.997,1.0,0.998,0.919,0.973,0.987,0.995],[0.845,0.957,0.989,0.993,0.973,0.996,0.998,1.0,0.878,0.977,0.987,0.991],[0.89,0.849,0.881,0.894,0.958,0.909,0.919,0.878,1.0,0.957,0.971,0.958],[0.886,0.993,0.999,0.992,0.992,0.977,0.973,0.977,0.957,1.0,0.995,0.991],[0.889,1.0,0.994,0.991,0.997,0.992,0.987,0.987,0.971,0.995,1.0,0.994],[0.886,1.0,0.999,0.996,0.993,0.978,0.995,0.991,0.958,0.991,0.994,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,0.012,0.003,-0.021,0.183,0.106,0.017,-0.001,-0.065,0.041],[0.012,1.0,0.004,0.065,0.025,0.004,0.011,-0.003,-0.029,0.002],[0.003,0.004,1.0,-0.01,-0.0,0.123,-0.029,0.043,0.014,-0.002],[-0.021,0.065,-0.01,1.0,0.103,-0.132,0.006,-0.233,0.026,-0.067],[0.183,0.025,-0.0,0.103,1.0,0.818,-0.785,-0.247,-0.053,0.168],[0.106,0.004,0.123,-0.132,0.818,1.0,-0.831,-0.096,-0.123,0.059],[0.017,0.011,-0.029,0.006,-0.785,-0.831,1.0,0.133,0.097,-0.099],[-0.001,-0.003,0.043,-0.233,-0.247,-0.096,0.133,1.0,0.014,0.01],[-0.065,-0.029,0.014,0.026,-0.053,-0.123,0.097,0.014,1.0,0.001],[0.041,0.002,-0.002,-0.067,0.168,0.059,-0.099,0.01,0.001,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"month\",\"day\",\"hour\",\"pm2.5\",\"DEWP\",\"TEMP\",\"PRES\",\"Iws\",\"Is\",\"Ir\"],\"y\":[\"month\",\"day\",\"hour\",\"pm2.5\",\"DEWP\",\"TEMP\",\"PRES\",\"Iws\",\"Is\",\"Ir\"],\"z\":[[1.0,0.01,-0.0,-0.021,0.238,0.175,-0.069,0.013,-0.065,0.041],[0.01,1.0,0.001,0.083,0.035,0.024,-0.011,-0.005,-0.04,0.001],[-0.0,0.001,1.0,-0.023,-0.02,0.151,-0.043,0.059,-0.003,-0.01],[-0.021,0.083,-0.023,1.0,0.171,-0.09,-0.048,-0.248,0.019,-0.053],[0.238,0.035,-0.02,0.171,1.0,0.825,-0.778,-0.293,-0.036,0.125],[0.175,0.024,0.151,-0.09,0.825,1.0,-0.827,-0.149,-0.097,0.049],[-0.069,-0.011,-0.043,-0.048,-0.778,-0.827,1.0,0.178,0.072,-0.08],[0.013,-0.005,0.059,-0.248,-0.293,-0.149,0.178,1.0,0.023,-0.008],[-0.065,-0.04,-0.003,0.019,-0.036,-0.097,0.072,0.023,1.0,-0.01],[0.041,0.001,-0.01,-0.053,0.125,0.049,-0.08,-0.008,-0.01,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,0.01,-0.0,-0.021,0.238,0.175,-0.069,0.013,-0.065,0.041],[0.01,1.0,0.001,0.083,0.035,0.024,-0.011,-0.005,-0.04,0.001],[-0.0,0.001,1.0,-0.023,-0.02,0.151,-0.043,0.059,-0.003,-0.01],[-0.021,0.083,-0.023,1.0,0.171,-0.09,-0.048,-0.248,0.019,-0.053],[0.238,0.035,-0.02,0.171,1.0,0.825,-0.778,-0.293,-0.036,0.125],[0.175,0.024,0.151,-0.09,0.825,1.0,-0.827,-0.149,-0.097,0.049],[-0.069,-0.011,-0.043,-0.048,-0.778,-0.827,1.0,0.178,0.072,-0.08],[0.013,-0.005,0.059,-0.248,-0.293,-0.149,0.178,1.0,0.023,-0.008],[-0.065,-0.04,-0.003,0.019,-0.036,-0.097,0.072,0.023,1.0,-0.01],[0.041,0.001,-0.01,-0.053,0.125,0.049,-0.08,-0.008,-0.01,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"month\",\"day\",\"hour\",\"pm2.5\",\"DEWP\",\"TEMP\",\"PRES\",\"Iws\",\"Is\",\"Ir\"],\"y\":[\"month\",\"day\",\"hour\",\"pm2.5\",\"DEWP\",\"TEMP\",\"PRES\",\"Iws\",\"Is\",\"Ir\"],\"z\":[[1.0,0.012,0.003,-0.021,0.183,0.106,0.017,-0.001,-0.065,0.041],[0.012,1.0,0.004,0.065,0.025,0.004,0.011,-0.003,-0.029,0.002],[0.003,0.004,1.0,-0.01,-0.0,0.123,-0.029,0.043,0.014,-0.002],[-0.021,0.065,-0.01,1.0,0.103,-0.132,0.006,-0.233,0.026,-0.067],[0.183,0.025,-0.0,0.103,1.0,0.818,-0.785,-0.247,-0.053,0.168],[0.106,0.004,0.123,-0.132,0.818,1.0,-0.831,-0.096,-0.123,0.059],[0.017,0.011,-0.029,0.006,-0.785,-0.831,1.0,0.133,0.097,-0.099],[-0.001,-0.003,0.043,-0.233,-0.247,-0.096,0.133,1.0,0.014,0.01],[-0.065,-0.029,0.014,0.026,-0.053,-0.123,0.097,0.014,1.0,0.001],[0.041,0.002,-0.002,-0.067,0.168,0.059,-0.099,0.01,0.001,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.26,0.74],\"tickangle\":45},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"autorange\":\"reversed\"},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,0.45],\"tickangle\":45},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.375],\"autorange\":\"reversed\"},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.55,1.0],\"tickangle\":45,\"matches\":\"x2\"},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"visible\":false,\"matches\":\"y2\",\"autorange\":\"reversed\"},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Real vs. Synthetic Similarity\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Real Data)\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Synthetic Data)\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Data Quality: Column Pair Trends (Average Score=0.96)\"},\"coloraxis\":{\"colorbar\":{\"len\":0.5,\"x\":0.8,\"y\":0.8},\"cmin\":0,\"cmax\":1,\"colorscale\":[[0.0,\"#FF0000\"],[0.5,\"#F16141\"],[1.0,\"#36B37E\"]]},\"coloraxis2\":{\"colorbar\":{\"len\":0.5,\"y\":0.2},\"cmin\":-1,\"cmax\":1,\"colorscale\":[[0.0,\"#03AFF1\"],[0.5,\"#000036\"],[1.0,\"#01E0C9\"]]},\"font\":{\"size\":18},\"height\":900,\"width\":900},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a4f1835d-50ff-4aa0-9f68-ff0222a4e1c2');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================ METRICS REPORT ================================\n",
            "Column Shapes Score: 0.952\n",
            "Column Trends Score: 0.958\n",
            "Overall Score: 0.955\n",
            "correlation score: 0.997\n",
            "contingency similarity score: 0.933\n",
            "log detection score: 0.850\n",
            "Alpha Precision: 0.929997, Beta Recall: 0.516170\n",
            "DCR Score = 0.492098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Codi metrics"
      ],
      "metadata": {
        "id": "cpzEGnu_yrAZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adult"
      ],
      "metadata": {
        "id": "hHmJI9fdytwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "file_path = '/content/tabsyn/data/adult/info.json'\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    data = json.load(file)\n",
        "adult_metrics = Metrics(train_path='/content/tabsyn/data/adult/train.csv',\n",
        "                        test_path='/content/tabsyn/data/adult/test.csv',\n",
        "                        synthetic_path='/content/adult_codi.csv',\n",
        "                        numeric_cols=data['num_col_idx'], cat_cols=data[\"cat_col_idx\"],\n",
        "                        target_col=data['target_col_idx'][0])\n",
        "metrics = adult_metrics.collect_all_metrics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aKM6bsLfy4vO",
        "outputId": "994bbf05-fa30-44b9-a046-3580ce324d20"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classificator results (AUC):\n",
            "Real data - : 0.925 ± 0.000\n",
            "Synthetic data - : 0.742 ± 0.009\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Column Shapes: |██████████| 15/15 [00:00<00:00, 102.26it/s]|\n",
            "Column Shapes Score: 79.77%\n",
            "\n",
            "(2/2) Evaluating Column Pair Trends: |██████████| 105/105 [00:01<00:00, 78.23it/s]|\n",
            "Column Pair Trends Score: 78.1%\n",
            "\n",
            "Overall Score (Average): 78.94%\n",
            "\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Data Validity: |██████████| 15/15 [00:00<00:00, 281.17it/s]|\n",
            "Data Validity Score: 100.0%\n",
            "\n",
            "(2/2) Evaluating Data Structure: |██████████| 1/1 [00:00<00:00, 210.61it/s]|\n",
            "Data Structure Score: 100.0%\n",
            "\n",
            "Overall Score (Average): 100.0%\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"f882bed3-4d00-4cb1-974c-d090cb5af6e6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f882bed3-4d00-4cb1-974c-d090cb5af6e6\")) {                    Plotly.newPlot(                        \"f882bed3-4d00-4cb1-974c-d090cb5af6e6\",                        [{\"alignmentgroup\":\"True\",\"customdata\":[[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"age\",\"fnlwgt\",\"education.num\",\"capital.gain\",\"capital.loss\",\"hours.per.week\"],\"legendgroup\":\"KSComplement\",\"marker\":{\"color\":\"#000036\",\"pattern\":{\"shape\":\"\"}},\"name\":\"KSComplement\",\"offsetgroup\":\"KSComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"age\",\"fnlwgt\",\"education.num\",\"capital.gain\",\"capital.loss\",\"hours.per.week\"],\"xaxis\":\"x\",\"y\":[0.9055618684929825,0.8798562697705844,0.7662848192623077,0.4731734283345106,0.7364331562298456,0.639845213599091],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"customdata\":[[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"workclass\",\"education\",\"marital.status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"native.country\",\"income\"],\"legendgroup\":\"TVComplement\",\"marker\":{\"color\":\"#03AFF1\",\"pattern\":{\"shape\":\"\\u002f\"}},\"name\":\"TVComplement\",\"offsetgroup\":\"TVComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"workclass\",\"education\",\"marital.status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"native.country\",\"income\"],\"xaxis\":\"x\",\"y\":[0.7182211848530451,0.8319154817112496,0.8465341973526612,0.7361260403550259,0.8364915082460612,0.9129019379011701,0.9548232548140413,0.7321642455698536,0.9958846472774178],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Column\"},\"categoryorder\":\"total ascending\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Score\"},\"range\":[0,1]},\"legend\":{\"title\":{\"text\":\"Metric\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Data Quality: Column Shapes (Average Score=0.8)\"},\"barmode\":\"relative\",\"margin\":{\"t\":150},\"font\":{\"size\":18},\"plot_bgcolor\":\"#F5F5F8\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f882bed3-4d00-4cb1-974c-d090cb5af6e6');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"d13c6774-29f3-4755-9fed-8640137c2dc8\" class=\"plotly-graph-div\" style=\"height:900px; width:900px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d13c6774-29f3-4755-9fed-8640137c2dc8\")) {                    Plotly.newPlot(                        \"d13c6774-29f3-4755-9fed-8640137c2dc8\",                        [{\"coloraxis\":\"coloraxis\",\"hovertemplate\":\"\\u003cb\\u003eColumn Pair\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSimilarity: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education.num\",\"marital.status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital.gain\",\"capital.loss\",\"hours.per.week\",\"native.country\",\"income\"],\"y\":[\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education.num\",\"marital.status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital.gain\",\"capital.loss\",\"hours.per.week\",\"native.country\",\"income\"],\"z\":[[1.0,0.677,0.995,0.815,0.977,0.771,0.708,0.799,0.888,0.906,0.989,0.995,0.989,0.729,0.908],[0.677,1.0,0.631,0.645,0.599,0.622,0.515,0.631,0.671,0.706,0.713,0.666,0.668,0.543,0.718],[0.995,0.631,1.0,0.746,0.992,0.747,0.672,0.735,0.799,0.801,0.998,0.986,0.996,0.656,0.801],[0.815,0.645,0.746,1.0,0.51,0.648,0.676,0.771,0.811,0.824,0.827,0.802,0.788,0.686,0.822],[0.977,0.599,0.992,0.51,1.0,0.724,0.626,0.769,0.762,0.794,0.995,0.997,0.989,0.632,0.791],[0.771,0.622,0.747,0.648,0.724,1.0,0.612,0.528,0.781,0.754,0.839,0.786,0.78,0.639,0.782],[0.708,0.515,0.672,0.676,0.626,0.612,1.0,0.64,0.705,0.691,0.73,0.702,0.696,0.572,0.726],[0.799,0.631,0.735,0.771,0.769,0.528,0.64,1.0,0.775,0.74,0.83,0.818,0.771,0.705,0.784],[0.888,0.671,0.799,0.811,0.762,0.781,0.705,0.775,1.0,0.835,0.906,0.849,0.84,0.694,0.912],[0.906,0.706,0.801,0.824,0.794,0.754,0.691,0.74,0.835,1.0,0.948,0.901,0.859,0.732,0.955],[0.989,0.713,0.998,0.827,0.995,0.839,0.73,0.83,0.906,0.948,1.0,0.988,0.992,0.726,0.988],[0.995,0.666,0.986,0.802,0.997,0.786,0.702,0.818,0.849,0.901,0.988,1.0,0.994,0.673,0.911],[0.989,0.668,0.996,0.788,0.989,0.78,0.696,0.771,0.84,0.859,0.992,0.994,1.0,0.672,0.866],[0.729,0.543,0.656,0.686,0.632,0.639,0.572,0.705,0.694,0.732,0.726,0.673,0.672,1.0,0.732],[0.908,0.718,0.801,0.822,0.791,0.782,0.726,0.784,0.912,0.955,0.988,0.911,0.866,0.732,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,-0.088,-0.01,0.055,0.048,0.046],[-0.088,1.0,-0.06,0.005,-0.038,-0.012],[-0.01,-0.06,1.0,0.112,0.087,0.17],[0.055,0.005,0.112,1.0,-0.055,0.094],[0.048,-0.038,0.087,-0.055,1.0,0.066],[0.046,-0.012,0.17,0.094,0.066,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"age\",\"fnlwgt\",\"education.num\",\"capital.gain\",\"capital.loss\",\"hours.per.week\"],\"y\":[\"age\",\"fnlwgt\",\"education.num\",\"capital.gain\",\"capital.loss\",\"hours.per.week\"],\"z\":[[1.0,-0.077,0.037,0.078,0.058,0.069],[-0.077,1.0,-0.043,0.0,-0.01,-0.019],[0.037,-0.043,1.0,0.123,0.08,0.148],[0.078,0.0,0.123,1.0,-0.032,0.078],[0.058,-0.01,0.08,-0.032,1.0,0.054],[0.069,-0.019,0.148,0.078,0.054,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,-0.077,0.037,0.078,0.058,0.069],[-0.077,1.0,-0.043,0.0,-0.01,-0.019],[0.037,-0.043,1.0,0.123,0.08,0.148],[0.078,0.0,0.123,1.0,-0.032,0.078],[0.058,-0.01,0.08,-0.032,1.0,0.054],[0.069,-0.019,0.148,0.078,0.054,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"age\",\"fnlwgt\",\"education.num\",\"capital.gain\",\"capital.loss\",\"hours.per.week\"],\"y\":[\"age\",\"fnlwgt\",\"education.num\",\"capital.gain\",\"capital.loss\",\"hours.per.week\"],\"z\":[[1.0,-0.088,-0.01,0.055,0.048,0.046],[-0.088,1.0,-0.06,0.005,-0.038,-0.012],[-0.01,-0.06,1.0,0.112,0.087,0.17],[0.055,0.005,0.112,1.0,-0.055,0.094],[0.048,-0.038,0.087,-0.055,1.0,0.066],[0.046,-0.012,0.17,0.094,0.066,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.26,0.74],\"tickangle\":45},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"autorange\":\"reversed\"},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,0.45],\"tickangle\":45},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.375],\"autorange\":\"reversed\"},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.55,1.0],\"tickangle\":45,\"matches\":\"x2\"},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"visible\":false,\"matches\":\"y2\",\"autorange\":\"reversed\"},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Real vs. Synthetic Similarity\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Real Data)\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Synthetic Data)\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Data Quality: Column Pair Trends (Average Score=0.78)\"},\"coloraxis\":{\"colorbar\":{\"len\":0.5,\"x\":0.8,\"y\":0.8},\"cmin\":0,\"cmax\":1,\"colorscale\":[[0.0,\"#FF0000\"],[0.5,\"#F16141\"],[1.0,\"#36B37E\"]]},\"coloraxis2\":{\"colorbar\":{\"len\":0.5,\"y\":0.2},\"cmin\":-1,\"cmax\":1,\"colorscale\":[[0.0,\"#03AFF1\"],[0.5,\"#000036\"],[1.0,\"#01E0C9\"]]},\"font\":{\"size\":18},\"height\":900,\"width\":900},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d13c6774-29f3-4755-9fed-8640137c2dc8');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================ METRICS REPORT ================================\n",
            "Column Shapes Score: 0.798\n",
            "Column Trends Score: 0.781\n",
            "Overall Score: 0.789\n",
            "correlation score: 0.995\n",
            "contingency similarity score: 0.842\n",
            "log detection score: 0.208\n",
            "Alpha Precision: 0.757997, Beta Recall: 0.087104\n",
            "DCR Score = 0.499724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Beijing"
      ],
      "metadata": {
        "id": "2GFDNwPRyvvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/tabsyn/data/beijing/info.json'\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "beijing_metrics = Metrics(train_path='/content/tabsyn/data/beijing/train.csv',\n",
        "                        test_path='/content/tabsyn/data/beijing/test.csv',\n",
        "                        synthetic_path='/content/beijing_codi.csv',\n",
        "                        numeric_cols=data['num_col_idx'], cat_cols=data[\"cat_col_idx\"],\n",
        "                        target_col=data['target_col_idx'][0], classification=False)\n",
        "metrics = beijing_metrics.collect_all_metrics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3yKn7pmezIMY",
        "outputId": "8600880e-930e-4360-bb5d-0cdcab1df71e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression results (MSE):\n",
            "Real data - : 35.902 ± 0.079\n",
            "Synthetic data - : 89.789 ± 0.059\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Column Shapes: |██████████| 12/12 [00:00<00:00, 52.22it/s]|\n",
            "Column Shapes Score: 80.51%\n",
            "\n",
            "(2/2) Evaluating Column Pair Trends: |██████████| 66/66 [00:00<00:00, 127.87it/s]|\n",
            "Column Pair Trends Score: 95.68%\n",
            "\n",
            "Overall Score (Average): 88.09%\n",
            "\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Data Validity: |██████████| 12/12 [00:00<00:00, 446.54it/s]|\n",
            "Data Validity Score: 99.86%\n",
            "\n",
            "(2/2) Evaluating Data Structure: |██████████| 1/1 [00:00<00:00, 337.81it/s]|\n",
            "Data Structure Score: 100.0%\n",
            "\n",
            "Overall Score (Average): 99.93%\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"c584c980-131e-4f19-a330-59783baf78a9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c584c980-131e-4f19-a330-59783baf78a9\")) {                    Plotly.newPlot(                        \"c584c980-131e-4f19-a330-59783baf78a9\",                        [{\"alignmentgroup\":\"True\",\"customdata\":[[\"TVComplement\"],[\"TVComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"year\",\"cbwd\"],\"legendgroup\":\"TVComplement\",\"marker\":{\"color\":\"#03AFF1\",\"pattern\":{\"shape\":\"\"}},\"name\":\"TVComplement\",\"offsetgroup\":\"TVComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"year\",\"cbwd\"],\"xaxis\":\"x\",\"y\":[0.9666586839094223,0.9103536361459248],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"customdata\":[[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"month\",\"day\",\"hour\",\"pm2.5\",\"DEWP\",\"TEMP\",\"PRES\",\"Iws\",\"Is\",\"Ir\"],\"legendgroup\":\"KSComplement\",\"marker\":{\"color\":\"#000036\",\"pattern\":{\"shape\":\"\\u002f\"}},\"name\":\"KSComplement\",\"offsetgroup\":\"KSComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"month\",\"day\",\"hour\",\"pm2.5\",\"DEWP\",\"TEMP\",\"PRES\",\"Iws\",\"Is\",\"Ir\"],\"xaxis\":\"x\",\"y\":[0.9371224821053192,0.9686011548388813,0.9648226497432213,0.9105399004816264,0.896197546632607,0.9483781698198558,0.9084111652164657,0.7474255607886964,0.3062451770841649,0.1961363454937335],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Column\"},\"categoryorder\":\"total ascending\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Score\"},\"range\":[0,1]},\"legend\":{\"title\":{\"text\":\"Metric\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Data Quality: Column Shapes (Average Score=0.81)\"},\"barmode\":\"relative\",\"margin\":{\"t\":150},\"font\":{\"size\":18},\"plot_bgcolor\":\"#F5F5F8\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c584c980-131e-4f19-a330-59783baf78a9');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"ce3f6eb9-8eec-4379-8810-3c0c0131b343\" class=\"plotly-graph-div\" style=\"height:900px; width:900px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ce3f6eb9-8eec-4379-8810-3c0c0131b343\")) {                    Plotly.newPlot(                        \"ce3f6eb9-8eec-4379-8810-3c0c0131b343\",                        [{\"coloraxis\":\"coloraxis\",\"hovertemplate\":\"\\u003cb\\u003eColumn Pair\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSimilarity: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"year\",\"month\",\"day\",\"hour\",\"pm2.5\",\"DEWP\",\"TEMP\",\"PRES\",\"cbwd\",\"Iws\",\"Is\",\"Ir\"],\"y\":[\"year\",\"month\",\"day\",\"hour\",\"pm2.5\",\"DEWP\",\"TEMP\",\"PRES\",\"cbwd\",\"Iws\",\"Is\",\"Ir\"],\"z\":[[1.0,0.902,0.937,0.941,0.92,0.898,0.907,0.897,0.905,0.94,0.962,0.962],[0.902,1.0,0.994,1.0,0.987,0.994,0.998,0.989,0.888,0.975,0.987,0.982],[0.937,0.994,1.0,0.998,0.988,0.996,0.998,0.995,0.901,0.986,0.991,0.996],[0.941,1.0,0.998,1.0,0.986,0.993,0.978,0.991,0.891,0.959,0.982,0.984],[0.92,0.987,0.988,0.986,1.0,0.96,0.971,0.95,0.874,0.964,0.993,0.911],[0.898,0.994,0.996,0.993,0.96,1.0,0.982,0.992,0.882,0.96,0.998,0.933],[0.907,0.998,0.998,0.978,0.971,0.982,1.0,0.998,0.871,0.998,0.984,0.993],[0.897,0.989,0.995,0.991,0.95,0.992,0.998,1.0,0.884,0.979,0.992,0.961],[0.905,0.888,0.901,0.891,0.874,0.882,0.871,0.884,1.0,0.902,0.906,0.904],[0.94,0.975,0.986,0.959,0.964,0.96,0.998,0.979,0.902,1.0,0.986,0.848],[0.962,0.987,0.991,0.982,0.993,0.998,0.984,0.992,0.906,0.986,1.0,0.99],[0.962,0.982,0.996,0.984,0.911,0.933,0.993,0.961,0.904,0.848,0.99,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,-0.003,-0.001,-0.047,0.226,0.171,-0.092,-0.037,-0.039,0.005],[-0.003,1.0,0.004,0.06,0.026,0.028,-0.001,-0.033,-0.023,0.01],[-0.001,0.004,1.0,-0.051,-0.035,0.106,-0.026,-0.023,0.032,-0.042],[-0.047,0.06,-0.051,1.0,0.092,-0.148,0.052,-0.175,0.004,0.124],[0.226,0.026,-0.035,0.092,1.0,0.788,-0.762,-0.373,-0.04,-0.009],[0.171,0.028,0.106,-0.148,0.788,1.0,-0.823,-0.144,-0.13,0.063],[-0.092,-0.001,-0.026,0.052,-0.762,-0.823,1.0,0.22,0.088,-0.001],[-0.037,-0.033,-0.023,-0.175,-0.373,-0.144,0.22,1.0,0.051,0.297],[-0.039,-0.023,0.032,0.004,-0.04,-0.13,0.088,0.051,1.0,0.009],[0.005,0.01,-0.042,0.124,-0.009,0.063,-0.001,0.297,0.009,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"month\",\"day\",\"hour\",\"pm2.5\",\"DEWP\",\"TEMP\",\"PRES\",\"Iws\",\"Is\",\"Ir\"],\"y\":[\"month\",\"day\",\"hour\",\"pm2.5\",\"DEWP\",\"TEMP\",\"PRES\",\"Iws\",\"Is\",\"Ir\"],\"z\":[[1.0,0.01,-0.0,-0.021,0.238,0.175,-0.069,0.013,-0.065,0.041],[0.01,1.0,0.001,0.083,0.035,0.024,-0.011,-0.005,-0.04,0.001],[-0.0,0.001,1.0,-0.023,-0.02,0.151,-0.043,0.059,-0.003,-0.01],[-0.021,0.083,-0.023,1.0,0.171,-0.09,-0.048,-0.248,0.019,-0.053],[0.238,0.035,-0.02,0.171,1.0,0.825,-0.778,-0.293,-0.036,0.125],[0.175,0.024,0.151,-0.09,0.825,1.0,-0.827,-0.149,-0.097,0.049],[-0.069,-0.011,-0.043,-0.048,-0.778,-0.827,1.0,0.178,0.072,-0.08],[0.013,-0.005,0.059,-0.248,-0.293,-0.149,0.178,1.0,0.023,-0.008],[-0.065,-0.04,-0.003,0.019,-0.036,-0.097,0.072,0.023,1.0,-0.01],[0.041,0.001,-0.01,-0.053,0.125,0.049,-0.08,-0.008,-0.01,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,0.01,-0.0,-0.021,0.238,0.175,-0.069,0.013,-0.065,0.041],[0.01,1.0,0.001,0.083,0.035,0.024,-0.011,-0.005,-0.04,0.001],[-0.0,0.001,1.0,-0.023,-0.02,0.151,-0.043,0.059,-0.003,-0.01],[-0.021,0.083,-0.023,1.0,0.171,-0.09,-0.048,-0.248,0.019,-0.053],[0.238,0.035,-0.02,0.171,1.0,0.825,-0.778,-0.293,-0.036,0.125],[0.175,0.024,0.151,-0.09,0.825,1.0,-0.827,-0.149,-0.097,0.049],[-0.069,-0.011,-0.043,-0.048,-0.778,-0.827,1.0,0.178,0.072,-0.08],[0.013,-0.005,0.059,-0.248,-0.293,-0.149,0.178,1.0,0.023,-0.008],[-0.065,-0.04,-0.003,0.019,-0.036,-0.097,0.072,0.023,1.0,-0.01],[0.041,0.001,-0.01,-0.053,0.125,0.049,-0.08,-0.008,-0.01,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"month\",\"day\",\"hour\",\"pm2.5\",\"DEWP\",\"TEMP\",\"PRES\",\"Iws\",\"Is\",\"Ir\"],\"y\":[\"month\",\"day\",\"hour\",\"pm2.5\",\"DEWP\",\"TEMP\",\"PRES\",\"Iws\",\"Is\",\"Ir\"],\"z\":[[1.0,-0.003,-0.001,-0.047,0.226,0.171,-0.092,-0.037,-0.039,0.005],[-0.003,1.0,0.004,0.06,0.026,0.028,-0.001,-0.033,-0.023,0.01],[-0.001,0.004,1.0,-0.051,-0.035,0.106,-0.026,-0.023,0.032,-0.042],[-0.047,0.06,-0.051,1.0,0.092,-0.148,0.052,-0.175,0.004,0.124],[0.226,0.026,-0.035,0.092,1.0,0.788,-0.762,-0.373,-0.04,-0.009],[0.171,0.028,0.106,-0.148,0.788,1.0,-0.823,-0.144,-0.13,0.063],[-0.092,-0.001,-0.026,0.052,-0.762,-0.823,1.0,0.22,0.088,-0.001],[-0.037,-0.033,-0.023,-0.175,-0.373,-0.144,0.22,1.0,0.051,0.297],[-0.039,-0.023,0.032,0.004,-0.04,-0.13,0.088,0.051,1.0,0.009],[0.005,0.01,-0.042,0.124,-0.009,0.063,-0.001,0.297,0.009,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.26,0.74],\"tickangle\":45},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"autorange\":\"reversed\"},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,0.45],\"tickangle\":45},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.375],\"autorange\":\"reversed\"},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.55,1.0],\"tickangle\":45,\"matches\":\"x2\"},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"visible\":false,\"matches\":\"y2\",\"autorange\":\"reversed\"},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Real vs. Synthetic Similarity\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Real Data)\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Synthetic Data)\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Data Quality: Column Pair Trends (Average Score=0.96)\"},\"coloraxis\":{\"colorbar\":{\"len\":0.5,\"x\":0.8,\"y\":0.8},\"cmin\":0,\"cmax\":1,\"colorscale\":[[0.0,\"#FF0000\"],[0.5,\"#F16141\"],[1.0,\"#36B37E\"]]},\"coloraxis2\":{\"colorbar\":{\"len\":0.5,\"y\":0.2},\"cmin\":-1,\"cmax\":1,\"colorscale\":[[0.0,\"#03AFF1\"],[0.5,\"#000036\"],[1.0,\"#01E0C9\"]]},\"font\":{\"size\":18},\"height\":900,\"width\":900},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ce3f6eb9-8eec-4379-8810-3c0c0131b343');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================ METRICS REPORT ================================\n",
            "Column Shapes Score: 0.805\n",
            "Column Trends Score: 0.957\n",
            "Overall Score: 0.881\n",
            "correlation score: 0.982\n",
            "contingency similarity score: 0.909\n",
            "log detection score: 0.573\n",
            "Alpha Precision: 0.957218, Beta Recall: 0.531987\n",
            "DCR Score = 0.495929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Default"
      ],
      "metadata": {
        "id": "oq4KEzuNyzK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/tabsyn/data/default/info.json'\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "default_metrics = Metrics(train_path='/content/tabsyn/data/default/train.csv',\n",
        "                        test_path='/content/tabsyn/data/default/test.csv',\n",
        "                        synthetic_path='/content/default_codi.csv',\n",
        "                        numeric_cols=data['num_col_idx'], cat_cols=data[\"cat_col_idx\"],\n",
        "                        target_col=data['target_col_idx'][0])\n",
        "metrics = adult_metrics.collect_all_metrics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5QPxEPRGzIpl",
        "outputId": "3c1dc0ff-f118-4f33-821b-09ff7a720fc9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classificator results (AUC):\n",
            "Real data - : 0.925 ± 0.000\n",
            "Synthetic data - : 0.742 ± 0.009\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Column Shapes: |██████████| 15/15 [00:00<00:00, 105.59it/s]|\n",
            "Column Shapes Score: 79.77%\n",
            "\n",
            "(2/2) Evaluating Column Pair Trends: |██████████| 105/105 [00:01<00:00, 73.71it/s]|\n",
            "Column Pair Trends Score: 78.1%\n",
            "\n",
            "Overall Score (Average): 78.94%\n",
            "\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Data Validity: |██████████| 15/15 [00:00<00:00, 184.34it/s]|\n",
            "Data Validity Score: 100.0%\n",
            "\n",
            "(2/2) Evaluating Data Structure: |██████████| 1/1 [00:00<00:00, 316.81it/s]|\n",
            "Data Structure Score: 100.0%\n",
            "\n",
            "Overall Score (Average): 100.0%\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"4981d7c3-9437-48f8-8d20-7ffdca18fa2b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4981d7c3-9437-48f8-8d20-7ffdca18fa2b\")) {                    Plotly.newPlot(                        \"4981d7c3-9437-48f8-8d20-7ffdca18fa2b\",                        [{\"alignmentgroup\":\"True\",\"customdata\":[[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"age\",\"fnlwgt\",\"education.num\",\"capital.gain\",\"capital.loss\",\"hours.per.week\"],\"legendgroup\":\"KSComplement\",\"marker\":{\"color\":\"#000036\",\"pattern\":{\"shape\":\"\"}},\"name\":\"KSComplement\",\"offsetgroup\":\"KSComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"age\",\"fnlwgt\",\"education.num\",\"capital.gain\",\"capital.loss\",\"hours.per.week\"],\"xaxis\":\"x\",\"y\":[0.9055618684929825,0.8798562697705844,0.7662848192623077,0.4731734283345106,0.7364331562298456,0.639845213599091],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"customdata\":[[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"workclass\",\"education\",\"marital.status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"native.country\",\"income\"],\"legendgroup\":\"TVComplement\",\"marker\":{\"color\":\"#03AFF1\",\"pattern\":{\"shape\":\"\\u002f\"}},\"name\":\"TVComplement\",\"offsetgroup\":\"TVComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"workclass\",\"education\",\"marital.status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"native.country\",\"income\"],\"xaxis\":\"x\",\"y\":[0.7182211848530451,0.8319154817112496,0.8465341973526612,0.7361260403550259,0.8364915082460612,0.9129019379011701,0.9548232548140413,0.7321642455698536,0.9958846472774178],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Column\"},\"categoryorder\":\"total ascending\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Score\"},\"range\":[0,1]},\"legend\":{\"title\":{\"text\":\"Metric\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Data Quality: Column Shapes (Average Score=0.8)\"},\"barmode\":\"relative\",\"margin\":{\"t\":150},\"font\":{\"size\":18},\"plot_bgcolor\":\"#F5F5F8\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4981d7c3-9437-48f8-8d20-7ffdca18fa2b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"322436af-1e3d-4f95-99be-45294ab2d31c\" class=\"plotly-graph-div\" style=\"height:900px; width:900px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"322436af-1e3d-4f95-99be-45294ab2d31c\")) {                    Plotly.newPlot(                        \"322436af-1e3d-4f95-99be-45294ab2d31c\",                        [{\"coloraxis\":\"coloraxis\",\"hovertemplate\":\"\\u003cb\\u003eColumn Pair\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSimilarity: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education.num\",\"marital.status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital.gain\",\"capital.loss\",\"hours.per.week\",\"native.country\",\"income\"],\"y\":[\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education.num\",\"marital.status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital.gain\",\"capital.loss\",\"hours.per.week\",\"native.country\",\"income\"],\"z\":[[1.0,0.677,0.995,0.815,0.977,0.771,0.708,0.799,0.888,0.906,0.989,0.995,0.989,0.729,0.908],[0.677,1.0,0.631,0.645,0.599,0.622,0.515,0.631,0.671,0.706,0.713,0.666,0.668,0.543,0.718],[0.995,0.631,1.0,0.746,0.992,0.747,0.672,0.735,0.799,0.801,0.998,0.986,0.996,0.656,0.801],[0.815,0.645,0.746,1.0,0.51,0.648,0.676,0.771,0.811,0.824,0.827,0.802,0.788,0.686,0.822],[0.977,0.599,0.992,0.51,1.0,0.724,0.626,0.769,0.762,0.794,0.995,0.997,0.989,0.632,0.791],[0.771,0.622,0.747,0.648,0.724,1.0,0.612,0.528,0.781,0.754,0.839,0.786,0.78,0.639,0.782],[0.708,0.515,0.672,0.676,0.626,0.612,1.0,0.64,0.705,0.691,0.73,0.702,0.696,0.572,0.726],[0.799,0.631,0.735,0.771,0.769,0.528,0.64,1.0,0.775,0.74,0.83,0.818,0.771,0.705,0.784],[0.888,0.671,0.799,0.811,0.762,0.781,0.705,0.775,1.0,0.835,0.906,0.849,0.84,0.694,0.912],[0.906,0.706,0.801,0.824,0.794,0.754,0.691,0.74,0.835,1.0,0.948,0.901,0.859,0.732,0.955],[0.989,0.713,0.998,0.827,0.995,0.839,0.73,0.83,0.906,0.948,1.0,0.988,0.992,0.726,0.988],[0.995,0.666,0.986,0.802,0.997,0.786,0.702,0.818,0.849,0.901,0.988,1.0,0.994,0.673,0.911],[0.989,0.668,0.996,0.788,0.989,0.78,0.696,0.771,0.84,0.859,0.992,0.994,1.0,0.672,0.866],[0.729,0.543,0.656,0.686,0.632,0.639,0.572,0.705,0.694,0.732,0.726,0.673,0.672,1.0,0.732],[0.908,0.718,0.801,0.822,0.791,0.782,0.726,0.784,0.912,0.955,0.988,0.911,0.866,0.732,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,-0.088,-0.01,0.055,0.048,0.046],[-0.088,1.0,-0.06,0.005,-0.038,-0.012],[-0.01,-0.06,1.0,0.112,0.087,0.17],[0.055,0.005,0.112,1.0,-0.055,0.094],[0.048,-0.038,0.087,-0.055,1.0,0.066],[0.046,-0.012,0.17,0.094,0.066,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"age\",\"fnlwgt\",\"education.num\",\"capital.gain\",\"capital.loss\",\"hours.per.week\"],\"y\":[\"age\",\"fnlwgt\",\"education.num\",\"capital.gain\",\"capital.loss\",\"hours.per.week\"],\"z\":[[1.0,-0.077,0.037,0.078,0.058,0.069],[-0.077,1.0,-0.043,0.0,-0.01,-0.019],[0.037,-0.043,1.0,0.123,0.08,0.148],[0.078,0.0,0.123,1.0,-0.032,0.078],[0.058,-0.01,0.08,-0.032,1.0,0.054],[0.069,-0.019,0.148,0.078,0.054,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,-0.077,0.037,0.078,0.058,0.069],[-0.077,1.0,-0.043,0.0,-0.01,-0.019],[0.037,-0.043,1.0,0.123,0.08,0.148],[0.078,0.0,0.123,1.0,-0.032,0.078],[0.058,-0.01,0.08,-0.032,1.0,0.054],[0.069,-0.019,0.148,0.078,0.054,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"age\",\"fnlwgt\",\"education.num\",\"capital.gain\",\"capital.loss\",\"hours.per.week\"],\"y\":[\"age\",\"fnlwgt\",\"education.num\",\"capital.gain\",\"capital.loss\",\"hours.per.week\"],\"z\":[[1.0,-0.088,-0.01,0.055,0.048,0.046],[-0.088,1.0,-0.06,0.005,-0.038,-0.012],[-0.01,-0.06,1.0,0.112,0.087,0.17],[0.055,0.005,0.112,1.0,-0.055,0.094],[0.048,-0.038,0.087,-0.055,1.0,0.066],[0.046,-0.012,0.17,0.094,0.066,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.26,0.74],\"tickangle\":45},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"autorange\":\"reversed\"},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,0.45],\"tickangle\":45},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.375],\"autorange\":\"reversed\"},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.55,1.0],\"tickangle\":45,\"matches\":\"x2\"},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"visible\":false,\"matches\":\"y2\",\"autorange\":\"reversed\"},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Real vs. Synthetic Similarity\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Real Data)\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Synthetic Data)\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Data Quality: Column Pair Trends (Average Score=0.78)\"},\"coloraxis\":{\"colorbar\":{\"len\":0.5,\"x\":0.8,\"y\":0.8},\"cmin\":0,\"cmax\":1,\"colorscale\":[[0.0,\"#FF0000\"],[0.5,\"#F16141\"],[1.0,\"#36B37E\"]]},\"coloraxis2\":{\"colorbar\":{\"len\":0.5,\"y\":0.2},\"cmin\":-1,\"cmax\":1,\"colorscale\":[[0.0,\"#03AFF1\"],[0.5,\"#000036\"],[1.0,\"#01E0C9\"]]},\"font\":{\"size\":18},\"height\":900,\"width\":900},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('322436af-1e3d-4f95-99be-45294ab2d31c');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================ METRICS REPORT ================================\n",
            "Column Shapes Score: 0.798\n",
            "Column Trends Score: 0.781\n",
            "Overall Score: 0.789\n",
            "correlation score: 0.995\n",
            "contingency similarity score: 0.842\n",
            "log detection score: 0.218\n",
            "Alpha Precision: 0.757997, Beta Recall: 0.087104\n",
            "DCR Score = 0.499724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Magic"
      ],
      "metadata": {
        "id": "eGS5rmO7y1R_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/tabsyn/data/magic/info.json'\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "magic_metrics = Metrics(train_path='/content/tabsyn/data/magic/train.csv',\n",
        "                        test_path='/content/tabsyn/data/magic/test.csv',\n",
        "                        synthetic_path='/content/magic_codi.csv',\n",
        "                        numeric_cols=data['num_col_idx'], cat_cols=data[\"cat_col_idx\"],\n",
        "                        target_col=data['target_col_idx'][0])\n",
        "metrics = magic_metrics.collect_all_metrics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s59O3cKlzJCI",
        "outputId": "02855e59-bf16-4806-9adc-a376c3defd7a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classificator results (AUC):\n",
            "Real data - : 0.947 ± 0.001\n",
            "Synthetic data - : 0.928 ± 0.001\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Column Shapes: |██████████| 11/11 [00:00<00:00, 63.36it/s]|\n",
            "Column Shapes Score: 89.63%\n",
            "\n",
            "(2/2) Evaluating Column Pair Trends: |██████████| 55/55 [00:00<00:00, 106.61it/s]|\n",
            "Column Pair Trends Score: 92.51%\n",
            "\n",
            "Overall Score (Average): 91.07%\n",
            "\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Data Validity: |██████████| 11/11 [00:00<00:00, 460.01it/s]|\n",
            "Data Validity Score: 100.0%\n",
            "\n",
            "(2/2) Evaluating Data Structure: |██████████| 1/1 [00:00<00:00, 322.74it/s]|\n",
            "Data Structure Score: 100.0%\n",
            "\n",
            "Overall Score (Average): 100.0%\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"6d3d15f8-b868-4d8d-88ab-0ffbb464d8d0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6d3d15f8-b868-4d8d-88ab-0ffbb464d8d0\")) {                    Plotly.newPlot(                        \"6d3d15f8-b868-4d8d-88ab-0ffbb464d8d0\",                        [{\"alignmentgroup\":\"True\",\"customdata\":[[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"Length\",\"Width\",\"Size\",\"Conc\",\"Conc1\",\"Asym\",\"M3Long\",\"M3Trans\",\"Alpha\",\"Dist\"],\"legendgroup\":\"KSComplement\",\"marker\":{\"color\":\"#000036\",\"pattern\":{\"shape\":\"\"}},\"name\":\"KSComplement\",\"offsetgroup\":\"KSComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"Length\",\"Width\",\"Size\",\"Conc\",\"Conc1\",\"Asym\",\"M3Long\",\"M3Trans\",\"Alpha\",\"Dist\"],\"xaxis\":\"x\",\"y\":[0.8507331892270842,0.8759712566454402,0.9041888181340187,0.9250452766255769,0.9372553601682537,0.8866623824268272,0.9041888181340187,0.9414032832856225,0.8794181223345212,0.9218905181982824],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"customdata\":[[\"TVComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"class\"],\"legendgroup\":\"TVComplement\",\"marker\":{\"color\":\"#03AFF1\",\"pattern\":{\"shape\":\"\\u002f\"}},\"name\":\"TVComplement\",\"offsetgroup\":\"TVComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"class\"],\"xaxis\":\"x\",\"y\":[0.8323888531868903],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Column\"},\"categoryorder\":\"total ascending\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Score\"},\"range\":[0,1]},\"legend\":{\"title\":{\"text\":\"Metric\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Data Quality: Column Shapes (Average Score=0.9)\"},\"barmode\":\"relative\",\"margin\":{\"t\":150},\"font\":{\"size\":18},\"plot_bgcolor\":\"#F5F5F8\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('6d3d15f8-b868-4d8d-88ab-0ffbb464d8d0');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"b3ea6be3-0a9b-4a04-b494-7d0c099689a3\" class=\"plotly-graph-div\" style=\"height:900px; width:900px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b3ea6be3-0a9b-4a04-b494-7d0c099689a3\")) {                    Plotly.newPlot(                        \"b3ea6be3-0a9b-4a04-b494-7d0c099689a3\",                        [{\"coloraxis\":\"coloraxis\",\"hovertemplate\":\"\\u003cb\\u003eColumn Pair\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSimilarity: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"Length\",\"Width\",\"Size\",\"Conc\",\"Conc1\",\"Asym\",\"M3Long\",\"M3Trans\",\"Alpha\",\"Dist\",\"class\"],\"y\":[\"Length\",\"Width\",\"Size\",\"Conc\",\"Conc1\",\"Asym\",\"M3Long\",\"M3Trans\",\"Alpha\",\"Dist\",\"class\"],\"z\":[[1.0,0.986,0.99,0.99,0.989,0.958,0.915,0.996,0.94,0.995,0.814],[0.986,1.0,0.986,0.984,0.982,0.965,0.931,1.0,0.94,0.976,0.744],[0.99,0.986,1.0,0.993,0.991,0.947,0.899,0.988,0.934,0.971,0.77],[0.99,0.984,0.993,1.0,0.999,0.955,0.928,0.991,0.937,0.99,0.828],[0.989,0.982,0.991,0.999,1.0,0.954,0.929,0.992,0.94,0.991,0.83],[0.958,0.965,0.947,0.955,0.954,1.0,0.966,0.995,0.986,0.969,0.576],[0.915,0.931,0.899,0.928,0.929,0.966,1.0,0.981,0.984,0.921,0.764],[0.996,1.0,0.988,0.991,0.992,0.995,0.981,1.0,0.996,0.988,0.29],[0.94,0.94,0.934,0.937,0.94,0.986,0.984,0.996,1.0,0.975,0.821],[0.995,0.976,0.971,0.99,0.991,0.969,0.921,0.988,0.975,1.0,0.83],[0.814,0.744,0.77,0.828,0.83,0.576,0.764,0.29,0.821,0.83,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,0.8,0.722,-0.652,-0.621,-0.461,-0.29,0.027,0.114,0.428],[0.8,1.0,0.75,-0.644,-0.619,-0.353,-0.319,0.051,0.186,0.389],[0.722,0.75,1.0,-0.865,-0.826,-0.269,-0.107,-0.002,-0.054,0.495],[-0.652,-0.644,-0.865,1.0,0.979,0.207,0.022,0.002,0.111,-0.35],[-0.621,-0.619,-0.826,0.979,1.0,0.197,0.022,0.001,0.112,-0.325],[-0.461,-0.353,-0.269,0.207,0.197,1.0,0.343,-0.023,-0.026,-0.265],[-0.29,-0.319,-0.107,0.022,0.022,0.343,1.0,0.017,-0.154,-0.119],[0.027,0.051,-0.002,0.002,0.001,-0.023,0.017,1.0,0.015,-0.018],[0.114,0.186,-0.054,0.111,0.112,-0.026,-0.154,0.015,1.0,-0.172],[0.428,0.389,0.495,-0.35,-0.325,-0.265,-0.119,-0.018,-0.172,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"Length\",\"Width\",\"Size\",\"Conc\",\"Conc1\",\"Asym\",\"M3Long\",\"M3Trans\",\"Alpha\",\"Dist\"],\"y\":[\"Length\",\"Width\",\"Size\",\"Conc\",\"Conc1\",\"Asym\",\"M3Long\",\"M3Trans\",\"Alpha\",\"Dist\"],\"z\":[[1.0,0.773,0.703,-0.632,-0.599,-0.377,-0.12,0.019,-0.007,0.419],[0.773,1.0,0.721,-0.613,-0.584,-0.283,-0.181,0.05,0.065,0.34],[0.703,0.721,1.0,-0.851,-0.809,-0.163,0.095,0.022,-0.187,0.438],[-0.632,-0.613,-0.851,1.0,0.977,0.117,-0.122,-0.016,0.237,-0.331],[-0.599,-0.584,-0.809,0.977,1.0,0.105,-0.119,-0.015,0.231,-0.306],[-0.377,-0.283,-0.163,0.117,0.105,1.0,0.274,-0.014,-0.054,-0.204],[-0.12,-0.181,0.095,-0.122,-0.119,0.274,1.0,-0.02,-0.185,0.038],[0.019,0.05,0.022,-0.016,-0.015,-0.014,-0.02,1.0,0.007,0.006],[-0.007,0.065,-0.187,0.237,0.231,-0.054,-0.185,0.007,1.0,-0.221],[0.419,0.34,0.438,-0.331,-0.306,-0.204,0.038,0.006,-0.221,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,0.773,0.703,-0.632,-0.599,-0.377,-0.12,0.019,-0.007,0.419],[0.773,1.0,0.721,-0.613,-0.584,-0.283,-0.181,0.05,0.065,0.34],[0.703,0.721,1.0,-0.851,-0.809,-0.163,0.095,0.022,-0.187,0.438],[-0.632,-0.613,-0.851,1.0,0.977,0.117,-0.122,-0.016,0.237,-0.331],[-0.599,-0.584,-0.809,0.977,1.0,0.105,-0.119,-0.015,0.231,-0.306],[-0.377,-0.283,-0.163,0.117,0.105,1.0,0.274,-0.014,-0.054,-0.204],[-0.12,-0.181,0.095,-0.122,-0.119,0.274,1.0,-0.02,-0.185,0.038],[0.019,0.05,0.022,-0.016,-0.015,-0.014,-0.02,1.0,0.007,0.006],[-0.007,0.065,-0.187,0.237,0.231,-0.054,-0.185,0.007,1.0,-0.221],[0.419,0.34,0.438,-0.331,-0.306,-0.204,0.038,0.006,-0.221,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"Length\",\"Width\",\"Size\",\"Conc\",\"Conc1\",\"Asym\",\"M3Long\",\"M3Trans\",\"Alpha\",\"Dist\"],\"y\":[\"Length\",\"Width\",\"Size\",\"Conc\",\"Conc1\",\"Asym\",\"M3Long\",\"M3Trans\",\"Alpha\",\"Dist\"],\"z\":[[1.0,0.8,0.722,-0.652,-0.621,-0.461,-0.29,0.027,0.114,0.428],[0.8,1.0,0.75,-0.644,-0.619,-0.353,-0.319,0.051,0.186,0.389],[0.722,0.75,1.0,-0.865,-0.826,-0.269,-0.107,-0.002,-0.054,0.495],[-0.652,-0.644,-0.865,1.0,0.979,0.207,0.022,0.002,0.111,-0.35],[-0.621,-0.619,-0.826,0.979,1.0,0.197,0.022,0.001,0.112,-0.325],[-0.461,-0.353,-0.269,0.207,0.197,1.0,0.343,-0.023,-0.026,-0.265],[-0.29,-0.319,-0.107,0.022,0.022,0.343,1.0,0.017,-0.154,-0.119],[0.027,0.051,-0.002,0.002,0.001,-0.023,0.017,1.0,0.015,-0.018],[0.114,0.186,-0.054,0.111,0.112,-0.026,-0.154,0.015,1.0,-0.172],[0.428,0.389,0.495,-0.35,-0.325,-0.265,-0.119,-0.018,-0.172,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.26,0.74],\"tickangle\":45},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"autorange\":\"reversed\"},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,0.45],\"tickangle\":45},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.375],\"autorange\":\"reversed\"},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.55,1.0],\"tickangle\":45,\"matches\":\"x2\"},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"visible\":false,\"matches\":\"y2\",\"autorange\":\"reversed\"},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Real vs. Synthetic Similarity\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Real Data)\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Synthetic Data)\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Data Quality: Column Pair Trends (Average Score=0.93)\"},\"coloraxis\":{\"colorbar\":{\"len\":0.5,\"x\":0.8,\"y\":0.8},\"cmin\":0,\"cmax\":1,\"colorscale\":[[0.0,\"#FF0000\"],[0.5,\"#F16141\"],[1.0,\"#36B37E\"]]},\"coloraxis2\":{\"colorbar\":{\"len\":0.5,\"y\":0.2},\"cmin\":-1,\"cmax\":1,\"colorscale\":[[0.0,\"#03AFF1\"],[0.5,\"#000036\"],[1.0,\"#01E0C9\"]]},\"font\":{\"size\":18},\"height\":900,\"width\":900},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b3ea6be3-0a9b-4a04-b494-7d0c099689a3');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================ METRICS REPORT ================================\n",
            "Column Shapes Score: 0.896\n",
            "Column Trends Score: 0.925\n",
            "Overall Score: 0.911\n",
            "correlation score: 0.986\n",
            "contingency similarity score: 0.870\n",
            "log detection score: 0.732\n",
            "Alpha Precision: 0.854013, Beta Recall: 0.504189\n",
            "DCR Score = 0.507886\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Shoppers"
      ],
      "metadata": {
        "id": "Hg2OZ2Hgy2yH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/tabsyn/data/shoppers/info.json'\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "shoppers_metrics = Metrics(train_path='/content/tabsyn/data/shoppers/train.csv',\n",
        "                        test_path='/content/tabsyn/data/shoppers/test.csv',\n",
        "                        synthetic_path='/content/shoppers_codi.csv',\n",
        "                        numeric_cols=data['num_col_idx'], cat_cols=data[\"cat_col_idx\"],\n",
        "                        target_col=data['target_col_idx'][0])\n",
        "metrics = shoppers_metrics.collect_all_metrics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ujN-PbVzzJwj",
        "outputId": "e648b14f-56bf-4c45-d07c-6298786dede6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classificator results (AUC):\n",
            "Real data - : 0.927 ± 0.001\n",
            "Synthetic data - : 0.844 ± 0.013\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Column Shapes: |██████████| 18/18 [00:00<00:00, 287.12it/s]|\n",
            "Column Shapes Score: 65.52%\n",
            "\n",
            "(2/2) Evaluating Column Pair Trends: |██████████| 153/153 [00:00<00:00, 189.22it/s]|\n",
            "Column Pair Trends Score: 84.13%\n",
            "\n",
            "Overall Score (Average): 74.83%\n",
            "\n",
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Data Validity: |██████████| 18/18 [00:00<00:00, 703.16it/s]|\n",
            "Data Validity Score: 99.86%\n",
            "\n",
            "(2/2) Evaluating Data Structure: |██████████| 1/1 [00:00<00:00, 255.75it/s]|\n",
            "Data Structure Score: 100.0%\n",
            "\n",
            "Overall Score (Average): 99.93%\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"1ed7f69e-6e7f-4737-8a65-c451fb4577a9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1ed7f69e-6e7f-4737-8a65-c451fb4577a9\")) {                    Plotly.newPlot(                        \"1ed7f69e-6e7f-4737-8a65-c451fb4577a9\",                        [{\"alignmentgroup\":\"True\",\"customdata\":[[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"Administrative\",\"Administrative_Duration\",\"Informational\",\"Informational_Duration\",\"ProductRelated\",\"ProductRelated_Duration\",\"BounceRates\",\"ExitRates\",\"PageValues\",\"SpecialDay\",\"Browser\",\"TrafficType\"],\"legendgroup\":\"KSComplement\",\"marker\":{\"color\":\"#000036\",\"pattern\":{\"shape\":\"\"}},\"name\":\"KSComplement\",\"offsetgroup\":\"KSComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"Administrative\",\"Administrative_Duration\",\"Informational\",\"Informational_Duration\",\"ProductRelated\",\"ProductRelated_Duration\",\"BounceRates\",\"ExitRates\",\"PageValues\",\"SpecialDay\",\"Browser\",\"TrafficType\"],\"xaxis\":\"x\",\"y\":[0.5834910336126882,0.553032351085879,0.3119762097864287,0.2237541677930973,0.7225376227809317,0.7165900693881229,0.6016040371271515,0.9337658826709921,0.2698026493646931,0.23330629899972966,0.9294403892944039,0.7382175362710642],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"customdata\":[[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"Month\",\"OperatingSystems\",\"Region\",\"VisitorType\",\"Weekend\",\"Revenue\"],\"legendgroup\":\"TVComplement\",\"marker\":{\"color\":\"#03AFF1\",\"pattern\":{\"shape\":\"\\u002f\"}},\"name\":\"TVComplement\",\"offsetgroup\":\"TVComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"Month\",\"OperatingSystems\",\"Region\",\"VisitorType\",\"Weekend\",\"Revenue\"],\"xaxis\":\"x\",\"y\":[0.5154546273767684,0.8655492475443813,0.8762728665405064,0.9749481841939263,0.886455798864558,0.8580697485806975],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Column\"},\"categoryorder\":\"total ascending\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Score\"},\"range\":[0,1]},\"legend\":{\"title\":{\"text\":\"Metric\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Data Quality: Column Shapes (Average Score=0.66)\"},\"barmode\":\"relative\",\"margin\":{\"t\":150},\"font\":{\"size\":18},\"plot_bgcolor\":\"#F5F5F8\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1ed7f69e-6e7f-4737-8a65-c451fb4577a9');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"867123ca-b47d-4919-b8d9-098017981023\" class=\"plotly-graph-div\" style=\"height:900px; width:900px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"867123ca-b47d-4919-b8d9-098017981023\")) {                    Plotly.newPlot(                        \"867123ca-b47d-4919-b8d9-098017981023\",                        [{\"coloraxis\":\"coloraxis\",\"hovertemplate\":\"\\u003cb\\u003eColumn Pair\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSimilarity: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"Administrative\",\"Administrative_Duration\",\"Informational\",\"Informational_Duration\",\"ProductRelated\",\"ProductRelated_Duration\",\"BounceRates\",\"ExitRates\",\"PageValues\",\"SpecialDay\",\"Month\",\"OperatingSystems\",\"Browser\",\"Region\",\"TrafficType\",\"VisitorType\",\"Weekend\",\"Revenue\"],\"y\":[\"Administrative\",\"Administrative_Duration\",\"Informational\",\"Informational_Duration\",\"ProductRelated\",\"ProductRelated_Duration\",\"BounceRates\",\"ExitRates\",\"PageValues\",\"SpecialDay\",\"Month\",\"OperatingSystems\",\"Browser\",\"Region\",\"TrafficType\",\"VisitorType\",\"Weekend\",\"Revenue\"],\"z\":[[1.0,0.968,0.93,0.954,0.929,0.988,0.911,0.934,0.968,0.95,0.515,0.67,0.998,0.682,0.994,0.696,0.697,0.695],[0.968,1.0,0.863,0.85,0.874,0.828,0.96,0.997,0.996,0.971,0.515,0.827,0.996,0.843,0.994,0.865,0.802,0.783],[0.93,0.863,1.0,0.983,0.915,0.93,0.924,0.945,0.999,0.945,0.515,0.751,0.987,0.785,0.99,0.785,0.758,0.737],[0.954,0.85,0.983,1.0,0.903,0.865,0.945,0.952,0.961,0.961,0.515,0.812,0.998,0.836,0.995,0.851,0.793,0.778],[0.929,0.874,0.915,0.903,1.0,0.987,0.958,0.985,0.968,0.936,0.515,0.77,0.992,0.803,0.987,0.803,0.771,0.759],[0.988,0.828,0.93,0.865,0.987,1.0,0.993,0.976,0.951,0.969,0.515,0.843,0.991,0.862,0.984,0.923,0.833,0.816],[0.911,0.96,0.924,0.945,0.958,0.993,1.0,0.978,0.979,0.986,0.491,0.821,0.978,0.824,0.996,0.912,0.824,0.785],[0.934,0.997,0.945,0.952,0.985,0.976,0.978,1.0,0.996,0.975,0.504,0.81,0.984,0.811,0.996,0.863,0.84,0.803],[0.968,0.996,0.999,0.961,0.968,0.951,0.979,0.996,1.0,0.999,0.515,0.859,0.991,0.872,0.993,0.97,0.876,0.856],[0.95,0.971,0.945,0.961,0.936,0.969,0.986,0.975,0.999,1.0,0.481,0.806,0.98,0.829,0.984,0.877,0.794,0.751],[0.515,0.515,0.515,0.515,0.515,0.515,0.491,0.504,0.515,0.481,1.0,0.515,0.515,0.514,0.42,0.515,0.515,0.515],[0.67,0.827,0.751,0.812,0.77,0.843,0.821,0.81,0.859,0.806,0.515,1.0,0.715,0.8,0.726,0.856,0.84,0.827],[0.998,0.996,0.987,0.998,0.992,0.991,0.978,0.984,0.991,0.98,0.515,0.715,1.0,0.773,0.992,0.925,0.845,0.81],[0.682,0.843,0.785,0.836,0.803,0.862,0.824,0.811,0.872,0.829,0.514,0.8,0.773,1.0,0.703,0.873,0.866,0.852],[0.994,0.994,0.99,0.995,0.987,0.984,0.996,0.996,0.993,0.984,0.42,0.726,0.992,0.703,1.0,0.737,0.737,0.733],[0.696,0.865,0.785,0.851,0.803,0.923,0.912,0.863,0.97,0.877,0.515,0.856,0.925,0.873,0.737,1.0,0.886,0.857],[0.697,0.802,0.758,0.793,0.771,0.833,0.824,0.84,0.876,0.794,0.515,0.84,0.845,0.866,0.737,0.886,1.0,0.814],[0.695,0.783,0.737,0.778,0.759,0.816,0.785,0.803,0.856,0.751,0.515,0.827,0.81,0.852,0.733,0.857,0.814,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,0.538,0.518,0.349,0.578,0.399,-0.4,-0.447,0.032,-0.192,-0.018,-0.024],[0.538,1.0,0.588,0.548,0.55,0.712,-0.223,-0.21,0.057,-0.131,-0.006,-0.001],[0.518,0.588,1.0,0.647,0.547,0.534,-0.268,-0.273,0.046,-0.156,-0.009,-0.005],[0.349,0.548,0.647,1.0,0.476,0.627,-0.183,-0.199,-0.049,-0.107,-0.022,-0.009],[0.578,0.55,0.547,0.476,1.0,0.833,-0.286,-0.319,-0.011,-0.149,-0.029,-0.016],[0.399,0.712,0.534,0.627,0.833,1.0,-0.196,-0.201,-0.049,-0.097,-0.023,-0.005],[-0.4,-0.223,-0.268,-0.183,-0.286,-0.196,1.0,0.957,-0.159,0.103,0.021,0.067],[-0.447,-0.21,-0.273,-0.199,-0.319,-0.201,0.957,1.0,-0.165,0.155,0.021,0.068],[0.032,0.057,0.046,-0.049,-0.011,-0.049,-0.159,-0.165,1.0,-0.064,0.03,0.0],[-0.192,-0.131,-0.156,-0.107,-0.149,-0.097,0.103,0.155,-0.064,1.0,-0.037,0.016],[-0.018,-0.006,-0.009,-0.022,-0.029,-0.023,0.021,0.021,0.03,-0.037,1.0,0.09],[-0.024,-0.001,-0.005,-0.009,-0.016,-0.005,0.067,0.068,0.0,0.016,0.09,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"Administrative\",\"Administrative_Duration\",\"Informational\",\"Informational_Duration\",\"ProductRelated\",\"ProductRelated_Duration\",\"BounceRates\",\"ExitRates\",\"PageValues\",\"SpecialDay\",\"Browser\",\"TrafficType\"],\"y\":[\"Administrative\",\"Administrative_Duration\",\"Informational\",\"Informational_Duration\",\"ProductRelated\",\"ProductRelated_Duration\",\"BounceRates\",\"ExitRates\",\"PageValues\",\"SpecialDay\",\"Browser\",\"TrafficType\"],\"z\":[[1.0,0.603,0.377,0.257,0.437,0.376,-0.222,-0.315,0.096,-0.092,-0.021,-0.035],[0.603,1.0,0.313,0.249,0.299,0.369,-0.143,-0.204,0.065,-0.072,-0.013,-0.013],[0.377,0.313,1.0,0.612,0.377,0.394,-0.115,-0.163,0.048,-0.045,-0.036,-0.026],[0.257,0.249,0.612,1.0,0.282,0.356,-0.073,-0.104,0.028,-0.029,-0.018,-0.018],[0.437,0.299,0.377,0.282,1.0,0.859,-0.202,-0.289,0.054,-0.022,-0.012,-0.042],[0.376,0.369,0.394,0.356,0.859,1.0,-0.182,-0.248,0.05,-0.034,-0.006,-0.036],[-0.222,-0.143,-0.115,-0.073,-0.202,-0.182,1.0,0.912,-0.118,0.075,-0.024,0.075],[-0.315,-0.204,-0.163,-0.104,-0.289,-0.248,0.912,1.0,-0.173,0.104,-0.011,0.076],[0.096,0.065,0.048,0.028,0.054,0.05,-0.118,-0.173,1.0,-0.062,0.047,0.014],[-0.092,-0.072,-0.045,-0.029,-0.022,-0.034,0.075,0.104,-0.062,1.0,0.003,0.049],[-0.021,-0.013,-0.036,-0.018,-0.012,-0.006,-0.024,-0.011,0.047,0.003,1.0,0.106],[-0.035,-0.013,-0.026,-0.018,-0.042,-0.036,0.075,0.076,0.014,0.049,0.106,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,0.603,0.377,0.257,0.437,0.376,-0.222,-0.315,0.096,-0.092,-0.021,-0.035],[0.603,1.0,0.313,0.249,0.299,0.369,-0.143,-0.204,0.065,-0.072,-0.013,-0.013],[0.377,0.313,1.0,0.612,0.377,0.394,-0.115,-0.163,0.048,-0.045,-0.036,-0.026],[0.257,0.249,0.612,1.0,0.282,0.356,-0.073,-0.104,0.028,-0.029,-0.018,-0.018],[0.437,0.299,0.377,0.282,1.0,0.859,-0.202,-0.289,0.054,-0.022,-0.012,-0.042],[0.376,0.369,0.394,0.356,0.859,1.0,-0.182,-0.248,0.05,-0.034,-0.006,-0.036],[-0.222,-0.143,-0.115,-0.073,-0.202,-0.182,1.0,0.912,-0.118,0.075,-0.024,0.075],[-0.315,-0.204,-0.163,-0.104,-0.289,-0.248,0.912,1.0,-0.173,0.104,-0.011,0.076],[0.096,0.065,0.048,0.028,0.054,0.05,-0.118,-0.173,1.0,-0.062,0.047,0.014],[-0.092,-0.072,-0.045,-0.029,-0.022,-0.034,0.075,0.104,-0.062,1.0,0.003,0.049],[-0.021,-0.013,-0.036,-0.018,-0.012,-0.006,-0.024,-0.011,0.047,0.003,1.0,0.106],[-0.035,-0.013,-0.026,-0.018,-0.042,-0.036,0.075,0.076,0.014,0.049,0.106,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"Administrative\",\"Administrative_Duration\",\"Informational\",\"Informational_Duration\",\"ProductRelated\",\"ProductRelated_Duration\",\"BounceRates\",\"ExitRates\",\"PageValues\",\"SpecialDay\",\"Browser\",\"TrafficType\"],\"y\":[\"Administrative\",\"Administrative_Duration\",\"Informational\",\"Informational_Duration\",\"ProductRelated\",\"ProductRelated_Duration\",\"BounceRates\",\"ExitRates\",\"PageValues\",\"SpecialDay\",\"Browser\",\"TrafficType\"],\"z\":[[1.0,0.538,0.518,0.349,0.578,0.399,-0.4,-0.447,0.032,-0.192,-0.018,-0.024],[0.538,1.0,0.588,0.548,0.55,0.712,-0.223,-0.21,0.057,-0.131,-0.006,-0.001],[0.518,0.588,1.0,0.647,0.547,0.534,-0.268,-0.273,0.046,-0.156,-0.009,-0.005],[0.349,0.548,0.647,1.0,0.476,0.627,-0.183,-0.199,-0.049,-0.107,-0.022,-0.009],[0.578,0.55,0.547,0.476,1.0,0.833,-0.286,-0.319,-0.011,-0.149,-0.029,-0.016],[0.399,0.712,0.534,0.627,0.833,1.0,-0.196,-0.201,-0.049,-0.097,-0.023,-0.005],[-0.4,-0.223,-0.268,-0.183,-0.286,-0.196,1.0,0.957,-0.159,0.103,0.021,0.067],[-0.447,-0.21,-0.273,-0.199,-0.319,-0.201,0.957,1.0,-0.165,0.155,0.021,0.068],[0.032,0.057,0.046,-0.049,-0.011,-0.049,-0.159,-0.165,1.0,-0.064,0.03,0.0],[-0.192,-0.131,-0.156,-0.107,-0.149,-0.097,0.103,0.155,-0.064,1.0,-0.037,0.016],[-0.018,-0.006,-0.009,-0.022,-0.029,-0.023,0.021,0.021,0.03,-0.037,1.0,0.09],[-0.024,-0.001,-0.005,-0.009,-0.016,-0.005,0.067,0.068,0.0,0.016,0.09,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.26,0.74],\"tickangle\":45},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"autorange\":\"reversed\"},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,0.45],\"tickangle\":45},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.375],\"autorange\":\"reversed\"},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.55,1.0],\"tickangle\":45,\"matches\":\"x2\"},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"visible\":false,\"matches\":\"y2\",\"autorange\":\"reversed\"},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Real vs. Synthetic Similarity\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Real Data)\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Synthetic Data)\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Data Quality: Column Pair Trends (Average Score=0.84)\"},\"coloraxis\":{\"colorbar\":{\"len\":0.5,\"x\":0.8,\"y\":0.8},\"cmin\":0,\"cmax\":1,\"colorscale\":[[0.0,\"#FF0000\"],[0.5,\"#F16141\"],[1.0,\"#36B37E\"]]},\"coloraxis2\":{\"colorbar\":{\"len\":0.5,\"y\":0.2},\"cmin\":-1,\"cmax\":1,\"colorscale\":[[0.0,\"#03AFF1\"],[0.5,\"#000036\"],[1.0,\"#01E0C9\"]]},\"font\":{\"size\":18},\"height\":900,\"width\":900},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('867123ca-b47d-4919-b8d9-098017981023');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================ METRICS REPORT ================================\n",
            "Column Shapes Score: 0.655\n",
            "Column Trends Score: 0.841\n",
            "Overall Score: 0.748\n",
            "correlation score: 0.968\n",
            "contingency similarity score: 0.791\n",
            "log detection score: 0.205\n",
            "Alpha Precision: 0.980862, Beta Recall: 0.187444\n",
            "DCR Score = 0.481752\n"
          ]
        }
      ]
    }
  ]
}